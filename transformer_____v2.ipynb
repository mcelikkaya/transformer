{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "W5wLSGc4CxRI"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "import torchtext\n",
    "from torchtext.datasets import Multi30k\n",
    "from torchtext.data import Field, BucketIterator\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "\n",
    "import spacy\n",
    "import numpy as np\n",
    "\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StepLogger():\n",
    "    def __init__(self,capacity):\n",
    "        self.tensor_datas = {}        \n",
    "        self.capacity = capacity\n",
    "        self.added_labels = []\n",
    "        \n",
    "    \n",
    "    def add_info(self,tensor_data,tensor_label):\n",
    "        if tensor_label not in self.added_labels:\n",
    "            self.added_labels.append( tensor_label )\n",
    "        \n",
    "        if tensor_label in self.tensor_datas.keys():\n",
    "            current_arr = self.tensor_datas.get(tensor_label)\n",
    "            if len(current_arr) < self.capacity:\n",
    "                current_arr = self.tensor_datas.get(tensor_label, [])\n",
    "                current_arr.append(tensor_data)\n",
    "        else:\n",
    "            self.tensor_datas[tensor_label] = [tensor_data]\n",
    "    \n",
    "    def get_default_summary(self,show_data=False,summary_count=1):\n",
    "        self.get_summary(self.added_labels,show_data,summary_count)\n",
    "        \n",
    "    def get_summary(self,labels,show_data=False,summary_count=1):\n",
    "        print(\"summary_count\",summary_count,\"   self.capacity \",self.capacity)\n",
    "        count = 0\n",
    "        values = []\n",
    "        for i in range(summary_count):\n",
    "            print(i,\" ------------------------------------------------\")\n",
    "            for l in labels:\n",
    "                label_data = self.tensor_datas.get(l)[i]\n",
    "                values.append(label_data)\n",
    "                print(l)\n",
    "                if torch.is_tensor(label_data):\n",
    "                    print( list(label_data.size() ) )\n",
    "                if not show_data and not torch.is_tensor(label_data):\n",
    "                    print(label_data)\n",
    "                if show_data:    \n",
    "                    print(label_data)\n",
    "        return values              \n",
    "                    \n",
    "loggers = {}                    \n",
    "current_logger = StepLogger(100)   \n",
    "def add_new_logger(logger_label):\n",
    "    global current_logger\n",
    "    if logger_label in loggers.keys() :\n",
    "        print(\"using existing logger\")\n",
    "        current_logger = loggers[logger_label]\n",
    "    else:    \n",
    "        loggers[logger_label]  = StepLogger(20)\n",
    "        current_logger = loggers[logger_label]\n",
    "    \n",
    "\n",
    "def add_infos(datas,labels,labels_prefix=\"\"):\n",
    "    #print( id(current_logger))\n",
    "    for i in range(len(datas)):\n",
    "        final_label = labels_prefix+\"@\"+labels[i]\n",
    "        current_logger.add_info(datas[i],final_label.strip())\n",
    "    \n",
    "#add_info   tensor_data,tensor_label                  currentLogger.get_default_summary(show_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torchtext\n",
    "#!pip install spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "cGdVuoJiCzNA"
   },
   "outputs": [],
   "source": [
    "SEED = 1234\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "GpeZM3m3C0sm"
   },
   "outputs": [],
   "source": [
    "#spacy_en = spacy.load('en')\n",
    "spacy_en = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tok = spacy.load(\"en_core_web_sm\")\n",
    "#tokde = spacy.load(\"de_core_news_sm\")\n",
    "import de_core_news_sm\n",
    "spacy_de = de_core_news_sm.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "i mochte lesen"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy_de.tokenizer(\"i mochte lesen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "ON8_nZzQC9dh"
   },
   "outputs": [],
   "source": [
    "#!python -m spacy download de\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "EmQKpzRKC_ep"
   },
   "outputs": [],
   "source": [
    "#spacy_de = spacy.load('de')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Cy5zn968DCJ4"
   },
   "outputs": [],
   "source": [
    "def tokenize_de(text):\n",
    "    \"\"\"\n",
    "    Tokenizes German text from a string into a list of strings\n",
    "    \"\"\"\n",
    "    return [tok.text for tok in spacy_de.tokenizer(text)]\n",
    "\n",
    "def tokenize_en(text):\n",
    "    \"\"\"\n",
    "    Tokenizes English text from a string into a list of strings\n",
    "    \"\"\"\n",
    "    return [tok.text for tok in spacy_en.tokenizer(text)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "BcaY2CKCDD3R"
   },
   "outputs": [],
   "source": [
    "SRC = Field(tokenize = tokenize_de, \n",
    "            init_token = '<sos>', \n",
    "            eos_token = '<eos>', \n",
    "            lower = True, \n",
    "            batch_first = True)\n",
    "\n",
    "TRG = Field(tokenize = tokenize_en, \n",
    "            init_token = '<sos>', \n",
    "            eos_token = '<eos>', \n",
    "            lower = True, \n",
    "            batch_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tabular_set = torchtext.data.TabularDataset(\n",
    "path='D:/data8/eng_de3.csv', format='csv',\n",
    "fields=[('src', SRC),\n",
    "        ('trg', TRG)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'want', 'to', 'eat', 'bread']\n",
      "['ich', 'mochten', 'brot', 'essen']\n"
     ]
    }
   ],
   "source": [
    "#dump a sample\n",
    "print(tabular_set[0].src)\n",
    "print(tabular_set[0].trg)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO can generate different items for each\n",
    "#Real line in tutorial\n",
    "#train_data, valid_data, test_data = Multi30k.splits(exts = ('.de', '.en'), fields = (SRC, TRG))\n",
    "train_data, valid_data, test_data = tabular_set ,tabular_set, tabular_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#all of our vocublary is used at least 2 times\n",
    "SRC.build_vocab(train_data, min_freq = 2)\n",
    "TRG.build_vocab(train_data, min_freq = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S_KKeZvkDGhJ",
    "outputId": "a8cc7551-587d-4562-bc6a-c45b2ab172dd"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#our tranining size is so small so batch size will also be small\n",
    "BATCH_SIZE = 8\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tV6UWdmtDIZ4",
    "outputId": "1b2098fa-f841-4b5c-b04e-38255048fa5f"
   },
   "outputs": [],
   "source": [
    "train_iterator, valid_iterator, test_iterator = BucketIterator.splits(\n",
    "    (train_data, valid_data, test_data), \n",
    "     batch_size = BATCH_SIZE,\n",
    "     sort_key = lambda x:  len(x.src),\n",
    "     device = device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fd7vNESYDPmG"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lyv0PT9BEGfv",
    "outputId": "38a30d14-b3e0-4479-a068-d12218401677"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3ff6PRXdEL-S"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Euwh_wKfEfaA"
   },
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self, \n",
    "                 input_dim, \n",
    "                 hid_dim, \n",
    "                 n_layers, \n",
    "                 n_heads, \n",
    "                 pf_dim,\n",
    "                 dropout, \n",
    "                 device,\n",
    "                 max_length = 100):\n",
    "        super().__init__()\n",
    "\n",
    "        self.device = device\n",
    "        \n",
    "        self.tok_embedding = nn.Embedding(input_dim, hid_dim)\n",
    "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
    "        \n",
    "        self.layers = nn.ModuleList([EncoderLayer(hid_dim, \n",
    "                                                  n_heads, \n",
    "                                                  pf_dim,\n",
    "                                                  dropout, \n",
    "                                                  device) \n",
    "                                     for _ in range(n_layers)])\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
    "        \n",
    "    def forward(self, src, src_mask,is_appy_attention):\n",
    "        \n",
    "        #src = [batch size, src len]\n",
    "        #src_mask = [batch size, src len]\n",
    "        \n",
    "        batch_size = src.shape[0]\n",
    "        src_len = src.shape[1]\n",
    "        \n",
    "        pos = torch.arange(0, src_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
    "        \n",
    "        #pos = [batch size, src len]\n",
    "        add_infos([src,pos],[\"src\",\"pos\"],\"Encoder\")   \n",
    "        src = self.dropout((self.tok_embedding(src) * self.scale) + self.pos_embedding(pos))\n",
    "        \n",
    "        #src = [batch size, src len, hid dim]\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            src = layer(src, src_mask,is_appy_attention)\n",
    "            \n",
    "        add_infos([src],[\"src_final\"],\"Encoder\")    \n",
    "        #src = [batch size, src len, hid dim]\n",
    "            \n",
    "        return src"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "0pDUJqGfEqh3"
   },
   "outputs": [],
   "source": [
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, \n",
    "                 hid_dim, \n",
    "                 n_heads, \n",
    "                 pf_dim,  \n",
    "                 dropout, \n",
    "                 device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
    "        self.ff_layer_norm = nn.LayerNorm(hid_dim)\n",
    "        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device,\"encoder\")\n",
    "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim, \n",
    "                                                                     pf_dim, \n",
    "                                                                     dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, src, src_mask,is_appy_attention):\n",
    "        \n",
    "        #src = [batch size, src len, hid dim]\n",
    "        #src_mask = [batch size, src len]\n",
    "                \n",
    "        #self attention\n",
    "        _src, sattention = self.self_attention(src, src, src,is_appy_attention, src_mask) #return x, attention\n",
    "        \n",
    "        #dropout, residual connection and layer norm\n",
    "        src2 = self.self_attn_layer_norm(src + self.dropout(_src))\n",
    "        \n",
    "        #src = [batch size, src len, hid dim]\n",
    "        \n",
    "        #positionwise feedforward\n",
    "        _src2 = self.positionwise_feedforward(src2)\n",
    "        \n",
    "        #dropout, residual and layer norm\n",
    "        src3 = self.ff_layer_norm(src + self.dropout(_src2))\n",
    "        \n",
    "        add_infos([_src,src2,_src2,src3,src_mask,sattention],[\"_src\",\"src2\",\"_src2\",\"src3\",\"src_mask\",\"sattention\"],\"EncoderLayer\")\n",
    "        #src = [batch size, src len, hid dim]\n",
    "        \n",
    "        return src3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "d0kDgxYwEs6Z"
   },
   "outputs": [],
   "source": [
    "class MultiHeadAttentionLayer(nn.Module):\n",
    "    #since this layer is common while logging there must be a label to differantiate labels\n",
    "    def __init__(self, hid_dim, n_heads, dropout, device,layer_label):\n",
    "        super().__init__()\n",
    "        \n",
    "        assert hid_dim % n_heads == 0\n",
    "        \n",
    "        self.hid_dim = hid_dim\n",
    "        self.n_heads = n_heads\n",
    "        #TODO head_dim is encoding per head so ,hid_dim must divide n_heads\n",
    "        self.head_dim = hid_dim // n_heads\n",
    "        self.layer_label = layer_label\n",
    "        \n",
    "        self.fc_q = nn.Linear(hid_dim, hid_dim)\n",
    "        self.fc_k = nn.Linear(hid_dim, hid_dim)\n",
    "        self.fc_v = nn.Linear(hid_dim, hid_dim)\n",
    "        \n",
    "        add_infos([self.hid_dim,self.n_heads,self.head_dim],[\"hid_dim\",\"n_heads\",\"head_dim\"],self.layer_label)\n",
    "        \n",
    "        self.fc_o = nn.Linear(hid_dim, hid_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.scale = torch.sqrt(torch.FloatTensor([self.head_dim])).to(device)\n",
    "        \n",
    "    def forward(self, query, key, value,is_appy_attention, mask = None):\n",
    "        \n",
    "        batch_size = query.shape[0]\n",
    "        \n",
    "        #query = [batch size, query len, hid dim]\n",
    "        #key = [batch size, key len, hid dim]\n",
    "        #value = [batch size, value len, hid dim]\n",
    "                \n",
    "        Q = self.fc_q(query)\n",
    "        K = self.fc_k(key)\n",
    "        V = self.fc_v(value)\n",
    "        \n",
    "        #Q = [batch size, query len, hid dim]\n",
    "        #K = [batch size, key len, hid dim]\n",
    "        #V = [batch size, value len, hid dim]\n",
    "                \n",
    "        Q = Q.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        K = K.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        V = V.view(batch_size, -1, self.n_heads, self.head_dim).permute(0, 2, 1, 3)\n",
    "        \n",
    "        add_infos([Q,K,V],[\"Q\",\"K\",\"V\"],self.layer_label)\n",
    "        #Q = [batch size, n heads, query len, head dim]\n",
    "        #K = [batch size, n heads, key len, head dim]\n",
    "        #V = [batch size, n heads, value len, head dim]\n",
    "                \n",
    "        energy = torch.matmul(Q, K.permute(0, 1, 3, 2)) / self.scale\n",
    "        \n",
    "        #energy = [batch size, n heads, query len, key len]\n",
    "        \n",
    "        if mask is not None:\n",
    "            energy = energy.masked_fill(mask == 0, -1e10)\n",
    "        \n",
    "        attention = torch.softmax(energy, dim = -1)\n",
    "        \n",
    "        ### attention is a weight over dimensions\n",
    "        if not is_appy_attention:\n",
    "            print(\"old attention\",attention.shape)\n",
    "            print(\"old attention\",attention)\n",
    "        \n",
    "            #normally distributed literally means no attention\n",
    "            #attention = torch.tensor(np.full(attention.shape, 1/attention.shape[3]),dtype=torch.float32 )\n",
    "            #just pay attention to beginning\n",
    "            #at last dimension shape is flat 1, 2, 1, 1\n",
    "            if attention.shape[3] > 2: \n",
    "                real_shape = attention.shape\n",
    "                att1 = torch.tensor(np.full((real_shape[0], real_shape[1], real_shape[2], 3), 1/3) ,dtype=torch.float32 )\n",
    "                att2 = torch.tensor(np.full((real_shape[0], real_shape[1], real_shape[2], real_shape[3] - 3), 1/7) ,dtype=torch.float32 )\n",
    "                att3 = torch.cat( (att1,att2),3 )\n",
    "                attention = torch.softmax(att3, dim = -1)\n",
    "            \n",
    "            \n",
    "            print(\"new attention\",attention)\n",
    "                \n",
    "        #attention = [batch size, n heads, query len, key len]\n",
    "                \n",
    "        x1 = torch.matmul(self.dropout(attention), V)\n",
    "        \n",
    "        #x = [batch size, n heads, query len, head dim]\n",
    "        \n",
    "        x2 = x1.permute(0, 2, 1, 3).contiguous()\n",
    "        \n",
    "        #x = [batch size, query len, n heads, head dim]\n",
    "        \n",
    "        x3 = x2.view(batch_size, -1, self.hid_dim)\n",
    "        \n",
    "        #x = [batch size, query len, hid dim]\n",
    "        \n",
    "        x4 = self.fc_o(x3)\n",
    "        \n",
    "        #x = [batch size, query len, hid dim]\n",
    "        \n",
    "        add_infos([energy,mask,attention],[\"energy\",\"mask\",\"attention\"],self.layer_label)\n",
    "        add_infos([x1,x2,x3,x4],[\"x1\",\"x2\",\"x3\",\"x4\"],self.layer_label)\n",
    "        \n",
    "        return x4, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "AS9hQZ2aEvL7"
   },
   "outputs": [],
   "source": [
    "class PositionwiseFeedforwardLayer(nn.Module):\n",
    "    def __init__(self, hid_dim, pf_dim, dropout):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.fc_1 = nn.Linear(hid_dim, pf_dim)\n",
    "        self.fc_2 = nn.Linear(pf_dim, hid_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        \n",
    "        #x = [batch size, seq len, hid dim]\n",
    "        \n",
    "        x1 = self.dropout(torch.relu(self.fc_1(x)))\n",
    "        \n",
    "        #x = [batch size, seq len, pf dim]\n",
    "        \n",
    "        x2 = self.fc_2(x1)\n",
    "        \n",
    "        #x = [batch size, seq len, hid dim]\n",
    "        add_infos([x1,x2],[\"x1\",\"x2\"],\"PositionwiseFeedforwardLayer\")\n",
    "        \n",
    "        return x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "N7CiACvFEyQP"
   },
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self, \n",
    "                 output_dim, \n",
    "                 hid_dim, \n",
    "                 n_layers, \n",
    "                 n_heads, \n",
    "                 pf_dim, \n",
    "                 dropout, \n",
    "                 device,\n",
    "                 max_length = 100):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.device = device\n",
    "        \n",
    "        self.tok_embedding = nn.Embedding(output_dim, hid_dim)\n",
    "        self.pos_embedding = nn.Embedding(max_length, hid_dim)\n",
    "        \n",
    "        self.layers = nn.ModuleList([DecoderLayer(hid_dim, \n",
    "                                                  n_heads, \n",
    "                                                  pf_dim, \n",
    "                                                  dropout, \n",
    "                                                  device)\n",
    "                                     for _ in range(n_layers)])\n",
    "        \n",
    "        self.fc_out = nn.Linear(hid_dim, output_dim)\n",
    "        \n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "        self.scale = torch.sqrt(torch.FloatTensor([hid_dim])).to(device)\n",
    "        \n",
    "    def forward(self, trg, enc_src, trg_mask, src_mask,is_appy_attention=False):\n",
    "        \n",
    "        #trg = [batch size, trg len]\n",
    "        #enc_src = [batch size, src len, hid dim]\n",
    "        #trg_mask = [batch size, trg len]\n",
    "        #src_mask = [batch size, src len]\n",
    "                \n",
    "        batch_size = trg.shape[0]\n",
    "        trg_len = trg.shape[1]\n",
    "        \n",
    "        pos = torch.arange(0, trg_len).unsqueeze(0).repeat(batch_size, 1).to(self.device)\n",
    "                            \n",
    "        #pos = [batch size, trg len]\n",
    "            \n",
    "        trg = self.dropout((self.tok_embedding(trg) * self.scale) + self.pos_embedding(pos))\n",
    "                \n",
    "        #trg = [batch size, trg len, hid dim]\n",
    "        \n",
    "        for layer in self.layers:\n",
    "            trg, attention = layer(trg, enc_src, trg_mask, src_mask,is_appy_attention)\n",
    "        \n",
    "        #trg = [batch size, trg len, hid dim]\n",
    "        #attention = [batch size, n heads, trg len, src len]\n",
    "        \n",
    "        output = self.fc_out(trg)\n",
    "        \n",
    "        add_infos([pos,trg,output,attention],[\"pos\",\"trg\",\"output\",\"attention\"],\"Decoder\")\n",
    "        #output = [batch size, trg len, output dim]\n",
    "            \n",
    "        return output, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "_pJishp-E0as"
   },
   "outputs": [],
   "source": [
    "class DecoderLayer(nn.Module):\n",
    "    def __init__(self, \n",
    "                 hid_dim, \n",
    "                 n_heads, \n",
    "                 pf_dim, \n",
    "                 dropout, \n",
    "                 device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.self_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
    "        self.enc_attn_layer_norm = nn.LayerNorm(hid_dim)\n",
    "        self.ff_layer_norm = nn.LayerNorm(hid_dim)\n",
    "        self.self_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device,\"decoder_self\")\n",
    "        self.encoder_attention = MultiHeadAttentionLayer(hid_dim, n_heads, dropout, device,\"decoder_encoder_attention\")\n",
    "        self.positionwise_feedforward = PositionwiseFeedforwardLayer(hid_dim, \n",
    "                                                                     pf_dim, \n",
    "                                                                     dropout)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        \n",
    "    def forward(self, trg, enc_src, trg_mask, src_mask,is_appy_attention):\n",
    "        \n",
    "        #trg = [batch size, trg len, hid dim]\n",
    "        #enc_src = [batch size, src len, hid dim]\n",
    "        #trg_mask = [batch size, trg len]\n",
    "        #src_mask = [batch size, src len]\n",
    "        \n",
    "        #self attention\n",
    "        _trg1, _ = self.self_attention(trg, trg, trg,is_appy_attention, trg_mask)\n",
    "        \n",
    "        #dropout, residual connection and layer norm\n",
    "        trg2 = self.self_attn_layer_norm(trg + self.dropout(_trg1))\n",
    "            \n",
    "        #trg = [batch size, trg len, hid dim]\n",
    "            \n",
    "        #encoder attention\n",
    "        _trg2, attention = self.encoder_attention(trg2, enc_src, enc_src,is_appy_attention, src_mask)\n",
    "        \n",
    "        #dropout, residual connection and layer norm\n",
    "        trg3 = self.enc_attn_layer_norm(trg2 + self.dropout(_trg2))\n",
    "                    \n",
    "        #trg = [batch size, trg len, hid dim]\n",
    "        \n",
    "        #positionwise feedforward\n",
    "        _trg3 = self.positionwise_feedforward(trg3)\n",
    "        \n",
    "        #dropout, residual and layer norm\n",
    "        trg4 = self.ff_layer_norm(trg3 + self.dropout(_trg3))\n",
    "        \n",
    "        #trg = [batch size, trg len, hid dim]\n",
    "        #attention = [batch size, n heads, trg len, src len]\n",
    "        \n",
    "        add_infos([_trg1,trg2,_trg2,trg3,_trg3,trg4,attention],[\"_trg1\",\"trg2\",\"_trg2\",\"trg3\",\"_trg3\",\"trg4\",\"attention\"],\"DecoderLayer\")\n",
    "        \n",
    "        return trg4, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "G6KUtliuE3t_"
   },
   "outputs": [],
   "source": [
    "class Seq2Seq(nn.Module):\n",
    "    def __init__(self, \n",
    "                 encoder, \n",
    "                 decoder, \n",
    "                 src_pad_idx, \n",
    "                 trg_pad_idx, \n",
    "                 device):\n",
    "        super().__init__()\n",
    "        \n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        self.src_pad_idx = src_pad_idx\n",
    "        self.trg_pad_idx = trg_pad_idx\n",
    "        self.device = device\n",
    "        \n",
    "    def make_src_mask(self, src):\n",
    "        \n",
    "        #src = [batch size, src len]\n",
    "        \n",
    "        src_mask = (src != self.src_pad_idx).unsqueeze(1).unsqueeze(2)\n",
    "\n",
    "        #src_mask = [batch size, 1, 1, src len]\n",
    "\n",
    "        return src_mask\n",
    "    \n",
    "    def make_trg_mask(self, trg):\n",
    "        \n",
    "        #trg = [batch size, trg len]\n",
    "        \n",
    "        trg_pad_mask = (trg != self.trg_pad_idx).unsqueeze(1).unsqueeze(2)\n",
    "        \n",
    "        #trg_pad_mask = [batch size, 1, 1, trg len]\n",
    "        \n",
    "        trg_len = trg.shape[1]\n",
    "        \n",
    "        trg_sub_mask = torch.tril(torch.ones((trg_len, trg_len), device = self.device)).bool()\n",
    "        \n",
    "        #trg_sub_mask = [trg len, trg len]\n",
    "            \n",
    "        trg_mask = trg_pad_mask & trg_sub_mask\n",
    "        \n",
    "        #trg_mask = [batch size, 1, trg len, trg len]\n",
    "        \n",
    "        return trg_mask\n",
    "\n",
    "    def forward(self, src, trg,is_appy_attention):\n",
    "        \n",
    "        #src = [batch size, src len]\n",
    "        #trg = [batch size, trg len]\n",
    "                \n",
    "        src_mask = self.make_src_mask(src)\n",
    "        trg_mask = self.make_trg_mask(trg)\n",
    "        \n",
    "        #src_mask = [batch size, 1, 1, src len]\n",
    "        #trg_mask = [batch size, 1, trg len, trg len]\n",
    "        \n",
    "        enc_src = self.encoder(src, src_mask,is_appy_attention)\n",
    "        \n",
    "        #enc_src = [batch size, src len, hid dim]\n",
    "                \n",
    "        output, attention = self.decoder(trg, enc_src, trg_mask, src_mask,is_appy_attention)\n",
    "        \n",
    "        add_infos([src_mask,trg_mask,enc_src,output,attention],[\"src_mask\",\"trg_mask\",\"enc_src\",\"output\",\"attention\"],\"Seq2Seq\")\n",
    "        #output = [batch size, trg len, output dim]\n",
    "        #attention = [batch size, n heads, trg len, src len]\n",
    "        \n",
    "        return output, attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "pHzEsAinE6JP"
   },
   "outputs": [],
   "source": [
    "INPUT_DIM = len(SRC.vocab)\n",
    "OUTPUT_DIM = len(TRG.vocab)\n",
    "HID_DIM = 64\n",
    "ENC_LAYERS = 3\n",
    "DEC_LAYERS = 3\n",
    "ENC_HEADS = 2\n",
    "DEC_HEADS = 2\n",
    "ENC_PF_DIM = 128\n",
    "DEC_PF_DIM = 128\n",
    "ENC_DROPOUT = 0.1\n",
    "DEC_DROPOUT = 0.1\n",
    "\n",
    "enc = Encoder(INPUT_DIM, \n",
    "              HID_DIM, \n",
    "              ENC_LAYERS, \n",
    "              ENC_HEADS, \n",
    "              ENC_PF_DIM, \n",
    "              ENC_DROPOUT, \n",
    "              device)\n",
    "\n",
    "dec = Decoder(OUTPUT_DIM, \n",
    "              HID_DIM, \n",
    "              DEC_LAYERS, \n",
    "              DEC_HEADS, \n",
    "              DEC_PF_DIM, \n",
    "              DEC_DROPOUT, \n",
    "              device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "fAwXM4btE8q8"
   },
   "outputs": [],
   "source": [
    "SRC_PAD_IDX = SRC.vocab.stoi[SRC.pad_token]\n",
    "TRG_PAD_IDX = TRG.vocab.stoi[TRG.pad_token]\n",
    "\n",
    "model = Seq2Seq(enc, dec, SRC_PAD_IDX, TRG_PAD_IDX, device).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ujXqcVyJE_bm",
    "outputId": "d9a682ea-ac1a-4382-dccb-25ae90b52547"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRC_PAD_IDX 1\n",
      "TRG_PAD_IDX 1\n",
      "to\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "print(\"SRC_PAD_IDX\",SRC_PAD_IDX)\n",
    "print(\"TRG_PAD_IDX\",TRG_PAD_IDX)\n",
    "print(SRC.vocab.itos[10])\n",
    "print(SRC.vocab.stoi[SRC.vocab.itos[10]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-HNTNXYVFBg9",
    "outputId": "3931c50d-16b6-4ab4-bd5b-418c9b76f640"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The model has 267,281 trainable parameters\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print(f'The model has {count_parameters(model):,} trainable parameters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "l7l1Fhp7GiBL"
   },
   "outputs": [],
   "source": [
    "def initialize_weights(m):\n",
    "    if hasattr(m, 'weight') and m.weight.dim() > 1:\n",
    "        nn.init.xavier_uniform_(m.weight.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7ZnSBG0mGkkg",
    "outputId": "03f2a125-7a0e-4944-84bf-b1ac12e8b197"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Seq2Seq(\n",
       "  (encoder): Encoder(\n",
       "    (tok_embedding): Embedding(18, 64)\n",
       "    (pos_embedding): Embedding(100, 64)\n",
       "    (layers): ModuleList(\n",
       "      (0): EncoderLayer(\n",
       "        (self_attn_layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (ff_layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (self_attention): MultiHeadAttentionLayer(\n",
       "          (fc_q): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_k): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_v): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_o): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (positionwise_feedforward): PositionwiseFeedforwardLayer(\n",
       "          (fc_1): Linear(in_features=64, out_features=128, bias=True)\n",
       "          (fc_2): Linear(in_features=128, out_features=64, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): EncoderLayer(\n",
       "        (self_attn_layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (ff_layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (self_attention): MultiHeadAttentionLayer(\n",
       "          (fc_q): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_k): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_v): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_o): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (positionwise_feedforward): PositionwiseFeedforwardLayer(\n",
       "          (fc_1): Linear(in_features=64, out_features=128, bias=True)\n",
       "          (fc_2): Linear(in_features=128, out_features=64, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (2): EncoderLayer(\n",
       "        (self_attn_layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (ff_layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (self_attention): MultiHeadAttentionLayer(\n",
       "          (fc_q): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_k): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_v): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_o): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (positionwise_feedforward): PositionwiseFeedforwardLayer(\n",
       "          (fc_1): Linear(in_features=64, out_features=128, bias=True)\n",
       "          (fc_2): Linear(in_features=128, out_features=64, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (decoder): Decoder(\n",
       "    (tok_embedding): Embedding(17, 64)\n",
       "    (pos_embedding): Embedding(100, 64)\n",
       "    (layers): ModuleList(\n",
       "      (0): DecoderLayer(\n",
       "        (self_attn_layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (enc_attn_layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (ff_layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (self_attention): MultiHeadAttentionLayer(\n",
       "          (fc_q): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_k): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_v): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_o): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder_attention): MultiHeadAttentionLayer(\n",
       "          (fc_q): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_k): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_v): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_o): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (positionwise_feedforward): PositionwiseFeedforwardLayer(\n",
       "          (fc_1): Linear(in_features=64, out_features=128, bias=True)\n",
       "          (fc_2): Linear(in_features=128, out_features=64, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (1): DecoderLayer(\n",
       "        (self_attn_layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (enc_attn_layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (ff_layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (self_attention): MultiHeadAttentionLayer(\n",
       "          (fc_q): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_k): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_v): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_o): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder_attention): MultiHeadAttentionLayer(\n",
       "          (fc_q): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_k): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_v): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_o): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (positionwise_feedforward): PositionwiseFeedforwardLayer(\n",
       "          (fc_1): Linear(in_features=64, out_features=128, bias=True)\n",
       "          (fc_2): Linear(in_features=128, out_features=64, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (2): DecoderLayer(\n",
       "        (self_attn_layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (enc_attn_layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (ff_layer_norm): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "        (self_attention): MultiHeadAttentionLayer(\n",
       "          (fc_q): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_k): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_v): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_o): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (encoder_attention): MultiHeadAttentionLayer(\n",
       "          (fc_q): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_k): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_v): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (fc_o): Linear(in_features=64, out_features=64, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (positionwise_feedforward): PositionwiseFeedforwardLayer(\n",
       "          (fc_1): Linear(in_features=64, out_features=128, bias=True)\n",
       "          (fc_2): Linear(in_features=128, out_features=64, bias=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "    (fc_out): Linear(in_features=64, out_features=17, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.apply(initialize_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "siYXawnPGmjB"
   },
   "outputs": [],
   "source": [
    "LEARNING_RATE = 0.0005\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr = LEARNING_RATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "fytxABFEGpmS"
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss(ignore_index = TRG_PAD_IDX)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "UKMthDlFGq-T"
   },
   "outputs": [],
   "source": [
    "def train(model, iterator, optimizer, criterion, clip,is_appy_attention):\n",
    "    \n",
    "    model.train()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    print(\"train1\")\n",
    "    \n",
    "    for i, batch in enumerate(iterator):\n",
    "        #print(\"train2\",i,batch)\n",
    "        \n",
    "        \n",
    "        src = batch.src\n",
    "        trg = batch.trg\n",
    "        \n",
    "        \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        output, _ = model(src, trg[:,:-1],is_appy_attention)\n",
    "        \n",
    "        \n",
    "                \n",
    "        #output = [batch size, trg len - 1, output dim]\n",
    "        #trg = [batch size, trg len]\n",
    "            \n",
    "        output_dim = output.shape[-1]\n",
    "        \n",
    "        \n",
    "            \n",
    "        output = output.contiguous().view(-1, output_dim)\n",
    "        trg = trg[:,1:].contiguous().view(-1)\n",
    "                \n",
    "        #output = [batch size * trg len - 1, output dim]\n",
    "        #trg = [batch size * trg len - 1]\n",
    "            \n",
    "        loss = criterion(output, trg)\n",
    "        \n",
    "        loss.backward()\n",
    "        \n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clip)\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "v1Tiun4eGte9"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, iterator, criterion,is_appy_attention):\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    epoch_loss = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "    \n",
    "        for i, batch in enumerate(iterator):\n",
    "\n",
    "            src = batch.src\n",
    "            trg = batch.trg\n",
    "\n",
    "            output, _ = model(src, trg[:,:-1],is_appy_attention)\n",
    "            \n",
    "            #output = [batch size, trg len - 1, output dim]\n",
    "            #trg = [batch size, trg len]\n",
    "            \n",
    "            output_dim = output.shape[-1]\n",
    "            \n",
    "            output = output.contiguous().view(-1, output_dim)\n",
    "            trg = trg[:,1:].contiguous().view(-1)\n",
    "            \n",
    "            #output = [batch size * trg len - 1, output dim]\n",
    "            #trg = [batch size * trg len - 1]\n",
    "            \n",
    "            loss = criterion(output, trg)\n",
    "\n",
    "            epoch_loss += loss.item()\n",
    "        \n",
    "    return epoch_loss / len(iterator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "O59kb4yfGvjR"
   },
   "outputs": [],
   "source": [
    "def epoch_time(start_time, end_time):\n",
    "    elapsed_time = end_time - start_time\n",
    "    elapsed_mins = int(elapsed_time / 60)\n",
    "    elapsed_secs = int(elapsed_time - (elapsed_mins * 60))\n",
    "    return elapsed_mins, elapsed_secs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading model D:/data8/tut6-model_en_de.pt\n",
      "train1\n",
      "saving model D:/data8/tut6-model_en_de.pt  with loss  2.4624868392944337\n",
      "Epoch: 01 | Time: 0m 0s\n",
      "\tTrain Loss: 3.197 | Train PPL:  24.459\n",
      "\t Val. Loss: 2.462 |  Val. PPL:  11.734\n",
      "loading model D:/data8/tut6-model_en_de.pt\n",
      "train1\n",
      "saving model D:/data8/tut6-model_en_de.pt  with loss  2.182066297531128\n",
      "Epoch: 02 | Time: 0m 0s\n",
      "\tTrain Loss: 2.613 | Train PPL:  13.643\n",
      "\t Val. Loss: 2.182 |  Val. PPL:   8.865\n",
      "loading model D:/data8/tut6-model_en_de.pt\n",
      "train1\n",
      "saving model D:/data8/tut6-model_en_de.pt  with loss  1.8885936498641969\n",
      "Epoch: 03 | Time: 0m 0s\n",
      "\tTrain Loss: 2.306 | Train PPL:  10.038\n",
      "\t Val. Loss: 1.889 |  Val. PPL:   6.610\n",
      "loading model D:/data8/tut6-model_en_de.pt\n",
      "train1\n",
      "saving model D:/data8/tut6-model_en_de.pt  with loss  1.59909245967865\n",
      "Epoch: 04 | Time: 0m 0s\n",
      "\tTrain Loss: 2.153 | Train PPL:   8.610\n",
      "\t Val. Loss: 1.599 |  Val. PPL:   4.949\n",
      "loading model D:/data8/tut6-model_en_de.pt\n",
      "train1\n",
      "saving model D:/data8/tut6-model_en_de.pt  with loss  1.3336820602416992\n",
      "Epoch: 05 | Time: 0m 0s\n",
      "\tTrain Loss: 1.888 | Train PPL:   6.604\n",
      "\t Val. Loss: 1.334 |  Val. PPL:   3.795\n",
      "loading model D:/data8/tut6-model_en_de.pt\n",
      "train1\n",
      "saving model D:/data8/tut6-model_en_de.pt  with loss  1.1333380937576294\n",
      "Epoch: 06 | Time: 0m 0s\n",
      "\tTrain Loss: 1.651 | Train PPL:   5.214\n",
      "\t Val. Loss: 1.133 |  Val. PPL:   3.106\n",
      "loading model D:/data8/tut6-model_en_de.pt\n",
      "train1\n",
      "saving model D:/data8/tut6-model_en_de.pt  with loss  1.0047129154205323\n",
      "Epoch: 07 | Time: 0m 0s\n",
      "\tTrain Loss: 1.541 | Train PPL:   4.669\n",
      "\t Val. Loss: 1.005 |  Val. PPL:   2.731\n",
      "loading model D:/data8/tut6-model_en_de.pt\n",
      "train1\n",
      "saving model D:/data8/tut6-model_en_de.pt  with loss  0.879293930530548\n",
      "Epoch: 08 | Time: 0m 0s\n",
      "\tTrain Loss: 1.298 | Train PPL:   3.663\n",
      "\t Val. Loss: 0.879 |  Val. PPL:   2.409\n",
      "loading model D:/data8/tut6-model_en_de.pt\n",
      "train1\n",
      "saving model D:/data8/tut6-model_en_de.pt  with loss  0.7867147564888001\n",
      "Epoch: 09 | Time: 0m 0s\n",
      "\tTrain Loss: 1.150 | Train PPL:   3.159\n",
      "\t Val. Loss: 0.787 |  Val. PPL:   2.196\n",
      "loading model D:/data8/tut6-model_en_de.pt\n",
      "train1\n",
      "saving model D:/data8/tut6-model_en_de.pt  with loss  0.6718944311141968\n",
      "Epoch: 10 | Time: 0m 0s\n",
      "\tTrain Loss: 1.144 | Train PPL:   3.138\n",
      "\t Val. Loss: 0.672 |  Val. PPL:   1.958\n",
      "loading model D:/data8/tut6-model_en_de.pt\n",
      "train1\n",
      "saving model D:/data8/tut6-model_en_de.pt  with loss  0.5893076241016388\n",
      "Epoch: 11 | Time: 0m 0s\n",
      "\tTrain Loss: 0.985 | Train PPL:   2.678\n",
      "\t Val. Loss: 0.589 |  Val. PPL:   1.803\n",
      "loading model D:/data8/tut6-model_en_de.pt\n",
      "train1\n",
      "saving model D:/data8/tut6-model_en_de.pt  with loss  0.502508020401001\n",
      "Epoch: 12 | Time: 0m 0s\n",
      "\tTrain Loss: 1.009 | Train PPL:   2.742\n",
      "\t Val. Loss: 0.503 |  Val. PPL:   1.653\n",
      "loading model D:/data8/tut6-model_en_de.pt\n",
      "train1\n",
      "saving model D:/data8/tut6-model_en_de.pt  with loss  0.4501735806465149\n",
      "Epoch: 13 | Time: 0m 0s\n",
      "\tTrain Loss: 0.816 | Train PPL:   2.260\n",
      "\t Val. Loss: 0.450 |  Val. PPL:   1.569\n",
      "loading model D:/data8/tut6-model_en_de.pt\n",
      "train1\n",
      "saving model D:/data8/tut6-model_en_de.pt  with loss  0.3832044243812561\n",
      "Epoch: 14 | Time: 0m 0s\n",
      "\tTrain Loss: 0.715 | Train PPL:   2.044\n",
      "\t Val. Loss: 0.383 |  Val. PPL:   1.467\n",
      "loading model D:/data8/tut6-model_en_de.pt\n",
      "train1\n",
      "saving model D:/data8/tut6-model_en_de.pt  with loss  0.3428811103105545\n",
      "Epoch: 15 | Time: 0m 0s\n",
      "\tTrain Loss: 0.743 | Train PPL:   2.101\n",
      "\t Val. Loss: 0.343 |  Val. PPL:   1.409\n",
      "loading model D:/data8/tut6-model_en_de.pt\n",
      "train1\n",
      "saving model D:/data8/tut6-model_en_de.pt  with loss  0.29087174534797666\n",
      "Epoch: 16 | Time: 0m 0s\n",
      "\tTrain Loss: 0.635 | Train PPL:   1.887\n",
      "\t Val. Loss: 0.291 |  Val. PPL:   1.338\n",
      "loading model D:/data8/tut6-model_en_de.pt\n",
      "train1\n",
      "saving model D:/data8/tut6-model_en_de.pt  with loss  0.2785725176334381\n",
      "Epoch: 17 | Time: 0m 0s\n",
      "\tTrain Loss: 0.593 | Train PPL:   1.809\n",
      "\t Val. Loss: 0.279 |  Val. PPL:   1.321\n",
      "loading model D:/data8/tut6-model_en_de.pt\n",
      "train1\n",
      "saving model D:/data8/tut6-model_en_de.pt  with loss  0.2209853023290634\n",
      "Epoch: 18 | Time: 0m 0s\n",
      "\tTrain Loss: 0.524 | Train PPL:   1.689\n",
      "\t Val. Loss: 0.221 |  Val. PPL:   1.247\n",
      "loading model D:/data8/tut6-model_en_de.pt\n",
      "train1\n",
      "saving model D:/data8/tut6-model_en_de.pt  with loss  0.18054708540439607\n",
      "Epoch: 19 | Time: 0m 0s\n",
      "\tTrain Loss: 0.490 | Train PPL:   1.632\n",
      "\t Val. Loss: 0.181 |  Val. PPL:   1.198\n",
      "loading model D:/data8/tut6-model_en_de.pt\n",
      "train1\n",
      "saving model D:/data8/tut6-model_en_de.pt  with loss  0.15291300415992737\n",
      "Epoch: 20 | Time: 0m 0s\n",
      "\tTrain Loss: 0.399 | Train PPL:   1.490\n",
      "\t Val. Loss: 0.153 |  Val. PPL:   1.165\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import gc\n",
    "N_EPOCHS = 20\n",
    "CLIP = 1\n",
    "best_valid_loss = float('inf')\n",
    "\n",
    "add_new_logger(\"training\")\n",
    "\n",
    "\n",
    "model_save_path = \"D:/data8/tut6-model_en_de.pt\"\n",
    "model_to_train = model\n",
    "for epoch in range(N_EPOCHS):\n",
    "    gc.collect()\n",
    "    if os.path.isfile(model_save_path) :\n",
    "        print(\"loading model\",model_save_path)\n",
    "        #TODO\n",
    "        #model_to_train.load_state_dict(torch.load(model_save_path))\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    train_loss = train(model, train_iterator, optimizer, criterion, CLIP,is_appy_attention=True)\n",
    "    \n",
    "    valid_loss = evaluate(model, valid_iterator, criterion,is_appy_attention=True)    \n",
    "    \n",
    "    end_time = time.time()\n",
    "    \n",
    "    \n",
    "    epoch_mins, epoch_secs = epoch_time(start_time, end_time)\n",
    "    \n",
    "    \n",
    "    if valid_loss < best_valid_loss:\n",
    "        print(\"saving model\",model_save_path,\" with loss \",valid_loss)\n",
    "        best_valid_loss = valid_loss\n",
    "        torch.save(model_to_train.state_dict(), model_save_path)\n",
    "    print(f'Epoch: {epoch+1:02} | Time: {epoch_mins}m {epoch_secs}s')\n",
    "    print(f'\\tTrain Loss: {train_loss:.3f} | Train PPL: {math.exp(train_loss):7.3f}')\n",
    "    print(f'\\t Val. Loss: {valid_loss:.3f} |  Val. PPL: {math.exp(valid_loss):7.3f}')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SK3jvsb8GxZy",
    "outputId": "22b085e6-0cef-4eca-d5c2-cdf37fe7c20c"
   },
   "outputs": [],
   "source": [
    "add_new_logger(\"test_loss\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uMSAE_41GzzL",
    "outputId": "0f08f624-7891-4e72-da27-ffd1856b8cef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Test Loss: 0.153 | Test PPL:   1.165 |\n"
     ]
    }
   ],
   "source": [
    "test_loss = evaluate(model, test_iterator, criterion,is_appy_attention=True)\n",
    "\n",
    "print(f'| Test Loss: {test_loss:.3f} | Test PPL: {math.exp(test_loss):7.3f} |')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "nGSAq4qGXS-E"
   },
   "outputs": [],
   "source": [
    "def translate_sentence(sentence, src_field, trg_field, model, device,is_appy_attention, max_len = 50):\n",
    "    \n",
    "    model.eval()\n",
    "        \n",
    "    if isinstance(sentence, str):\n",
    "        nlp = spacy.load('de')\n",
    "        tokens = [token.text.lower() for token in nlp(sentence)]\n",
    "    else:\n",
    "        tokens = [token.lower() for token in sentence]\n",
    "\n",
    "    tokens = [src_field.init_token] + tokens + [src_field.eos_token]\n",
    "        \n",
    "    src_indexes = [src_field.vocab.stoi[token] for token in tokens]\n",
    "\n",
    "    src_tensor = torch.LongTensor(src_indexes).unsqueeze(0).to(device)\n",
    "    \n",
    "    src_mask = model.make_src_mask(src_tensor)\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        enc_src = model.encoder(src_tensor, src_mask,is_appy_attention)\n",
    "\n",
    "    trg_indexes = [trg_field.vocab.stoi[trg_field.init_token]]\n",
    "\n",
    "    for i in range(max_len):\n",
    "\n",
    "        trg_tensor = torch.LongTensor(trg_indexes).unsqueeze(0).to(device)\n",
    "\n",
    "        trg_mask = model.make_trg_mask(trg_tensor)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            output, attention = model.decoder(trg_tensor, enc_src, trg_mask, src_mask,is_appy_attention)\n",
    "        \n",
    "        pred_token = output.argmax(2)[:,-1].item()\n",
    "        \n",
    "        trg_indexes.append(pred_token)\n",
    "\n",
    "        if pred_token == trg_field.vocab.stoi[trg_field.eos_token]:\n",
    "            break\n",
    "    \n",
    "    trg_tokens = [trg_field.vocab.itos[i] for i in trg_indexes]\n",
    "    \n",
    "    return trg_tokens[1:], attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "oafwV72xXcuZ"
   },
   "outputs": [],
   "source": [
    "def display_attention(sentence, translation, attention, n_heads = 8, n_rows = 4, n_cols = 2):\n",
    "    \n",
    "    assert n_rows * n_cols == n_heads\n",
    "    \n",
    "    fig = plt.figure(figsize=(15,25))\n",
    "    \n",
    "    for i in range(n_heads):\n",
    "        \n",
    "        ax = fig.add_subplot(n_rows, n_cols, i+1)\n",
    "        \n",
    "        _attention = attention.squeeze(0)[i].cpu().detach().numpy()\n",
    "\n",
    "        cax = ax.matshow(_attention, cmap='bone')\n",
    "\n",
    "        ax.tick_params(labelsize=12)\n",
    "        ax.set_xticklabels(['']+['<sos>']+[t.lower() for t in sentence]+['<eos>'], \n",
    "                           rotation=45)\n",
    "        ax.set_yticklabels(['']+translation)\n",
    "\n",
    "        ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "        ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_count 1    self.capacity  20\n",
      "0  ------------------------------------------------\n",
      "Encoder@src\n",
      "[8, 5]\n",
      "Encoder@pos\n",
      "[8, 5]\n",
      "encoder@Q\n",
      "[8, 2, 5, 32]\n",
      "encoder@K\n",
      "[8, 2, 5, 32]\n",
      "encoder@V\n",
      "[8, 2, 5, 32]\n",
      "encoder@energy\n",
      "[8, 2, 5, 5]\n",
      "encoder@mask\n",
      "[8, 1, 1, 5]\n",
      "encoder@attention\n",
      "[8, 2, 5, 5]\n",
      "encoder@x1\n",
      "[8, 2, 5, 32]\n",
      "encoder@x2\n",
      "[8, 5, 2, 32]\n",
      "encoder@x3\n",
      "[8, 5, 64]\n",
      "encoder@x4\n",
      "[8, 5, 64]\n",
      "PositionwiseFeedforwardLayer@x1\n",
      "[8, 5, 128]\n",
      "PositionwiseFeedforwardLayer@x2\n",
      "[8, 5, 64]\n",
      "EncoderLayer@_src\n",
      "[8, 5, 64]\n",
      "EncoderLayer@src2\n",
      "[8, 5, 64]\n",
      "EncoderLayer@_src2\n",
      "[8, 5, 64]\n",
      "EncoderLayer@src3\n",
      "[8, 5, 64]\n",
      "EncoderLayer@src_mask\n",
      "[8, 1, 1, 5]\n",
      "EncoderLayer@sattention\n",
      "[8, 2, 5, 5]\n",
      "Encoder@src_final\n",
      "[8, 5, 64]\n",
      "decoder_self@Q\n",
      "[8, 2, 4, 32]\n",
      "decoder_self@K\n",
      "[8, 2, 4, 32]\n",
      "decoder_self@V\n",
      "[8, 2, 4, 32]\n",
      "decoder_self@energy\n",
      "[8, 2, 4, 4]\n",
      "decoder_self@mask\n",
      "[8, 1, 4, 4]\n",
      "decoder_self@attention\n",
      "[8, 2, 4, 4]\n",
      "decoder_self@x1\n",
      "[8, 2, 4, 32]\n",
      "decoder_self@x2\n",
      "[8, 4, 2, 32]\n",
      "decoder_self@x3\n",
      "[8, 4, 64]\n",
      "decoder_self@x4\n",
      "[8, 4, 64]\n",
      "decoder_encoder_attention@Q\n",
      "[8, 2, 4, 32]\n",
      "decoder_encoder_attention@K\n",
      "[8, 2, 5, 32]\n",
      "decoder_encoder_attention@V\n",
      "[8, 2, 5, 32]\n",
      "decoder_encoder_attention@energy\n",
      "[8, 2, 4, 5]\n",
      "decoder_encoder_attention@mask\n",
      "[8, 1, 1, 5]\n",
      "decoder_encoder_attention@attention\n",
      "[8, 2, 4, 5]\n",
      "decoder_encoder_attention@x1\n",
      "[8, 2, 4, 32]\n",
      "decoder_encoder_attention@x2\n",
      "[8, 4, 2, 32]\n",
      "decoder_encoder_attention@x3\n",
      "[8, 4, 64]\n",
      "decoder_encoder_attention@x4\n",
      "[8, 4, 64]\n",
      "DecoderLayer@_trg1\n",
      "[8, 4, 64]\n",
      "DecoderLayer@trg2\n",
      "[8, 4, 64]\n",
      "DecoderLayer@_trg2\n",
      "[8, 4, 64]\n",
      "DecoderLayer@trg3\n",
      "[8, 4, 64]\n",
      "DecoderLayer@_trg3\n",
      "[8, 4, 64]\n",
      "DecoderLayer@trg4\n",
      "[8, 4, 64]\n",
      "DecoderLayer@attention\n",
      "[8, 2, 4, 5]\n",
      "Decoder@pos\n",
      "[8, 4]\n",
      "Decoder@trg\n",
      "[8, 4, 64]\n",
      "Decoder@output\n",
      "[8, 4, 17]\n",
      "Decoder@attention\n",
      "[8, 2, 4, 5]\n",
      "Seq2Seq@src_mask\n",
      "[8, 1, 1, 5]\n",
      "Seq2Seq@trg_mask\n",
      "[8, 1, 4, 4]\n",
      "Seq2Seq@enc_src\n",
      "[8, 5, 64]\n",
      "Seq2Seq@output\n",
      "[8, 4, 17]\n",
      "Seq2Seq@attention\n",
      "[8, 2, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "current_logger.get_default_summary(show_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_sentence(src,is_appy_attention=True):\n",
    "    logger_name = \"\".join(src)+str( random.randint(1,180001) )\n",
    "    add_new_logger(logger_name)\n",
    "    print(f'src = {src}')\n",
    "\n",
    "    translation, attention = translate_sentence(src, SRC, TRG, model, device,is_appy_attention=is_appy_attention)\n",
    "\n",
    "    print(f'predicted trg = {translation}')\n",
    " \n",
    "    display_attention(src, translation, attention,n_heads=2,n_rows = 1, n_cols = 2)\n",
    "    return loggers[logger_name]\n",
    "\n",
    "def show_on_vis_multi(new_input_embeddings,input_sentences,valid_sentences_embeddings,valid_sentences):\n",
    "    #print(\"new_input_embedding\",new_input_embedding)\n",
    "    Xs = valid_sentences_embeddings\n",
    "    Ys = valid_sentences\n",
    "    if len(input_sentences)> 0 :\n",
    "        input_sentences = [ \"<<<\"+s+\">>>\" for s in input_sentences]\n",
    "        Xs = Xs+ [embed for embed in new_input_embeddings]\n",
    "        Ys = Ys + input_sentences \n",
    "    result = fitted.transformer_.fit_transform(np.array(Xs))\n",
    "\n",
    "    fig = matplotlib.pyplot.gcf()\n",
    "    fig.set_size_inches(18.5, 10.5)\n",
    "\n",
    "    #scatter result words\n",
    "    plt.scatter(result[:, 0], result[:, 1])\n",
    "    words = list(Ys)\n",
    "    #put an annotation on x,y cordinates for words\n",
    "    #print(\"input_sentences\",input_sentences)\n",
    "    for i, word in enumerate(words):\n",
    "        if word in input_sentences:\n",
    "            #print(\"input_sentence\",word)\n",
    "            plt.annotate(word, xy=(result[i, 0], result[i, 1]),color='#ff00ff')\n",
    "        elif \"eat\" in word:\n",
    "            plt.annotate(word, xy=(result[i, 0], result[i, 1]),color='#0000ff')\n",
    "        elif \"drink\" in word:\n",
    "            plt.annotate(word, xy=(result[i, 0], result[i, 1]),color='#00ff00')\n",
    "        elif \"read\" in word:\n",
    "            plt.annotate(word, xy=(result[i, 0], result[i, 1]),color='#ff0000')     \n",
    "        else:\n",
    "            #print(\"else\",word)\n",
    "            plt.annotate(word, xy=(result[i, 0], result[i, 1]),color='#ff00dd')\n",
    "    plt.show()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src = ['i', 'want', 'to', 'eat', 'bread']\n",
      "predicted trg = ['ich', 'mochten', 'brot', 'essen', '<eos>']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcelikkaya\\Anaconda3\\envs\\p37_tensor23\\lib\\site-packages\\ipykernel_launcher.py:17: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "C:\\Users\\mcelikkaya\\Anaconda3\\envs\\p37_tensor23\\lib\\site-packages\\ipykernel_launcher.py:18: UserWarning: FixedFormatter should only be used together with FixedLocator\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_count 1    self.capacity  20\n",
      "0  ------------------------------------------------\n",
      "DecoderLayer@trg4\n",
      "[1, 1, 64]\n",
      "tensor([[[-1.7351,  0.1618, -0.3740, -0.0206,  1.0327,  2.2861, -0.2796,\n",
      "           0.2328, -1.3153,  0.0568, -0.0163, -0.4965, -1.0999, -1.0323,\n",
      "           0.7719, -1.3633,  0.7204,  2.0212, -0.7264,  0.1892, -0.3023,\n",
      "           0.0793,  0.2864, -0.0564,  0.5614,  0.1300, -0.5955,  0.8895,\n",
      "           0.3214,  0.5536,  0.5574, -0.4192, -0.2304, -0.0123, -0.2104,\n",
      "           0.0398,  0.7016,  0.6025,  0.5994,  0.1935, -0.4751,  1.4900,\n",
      "          -0.2949, -0.8869,  0.1395,  1.5797,  2.0397, -1.4392, -0.4803,\n",
      "          -0.7776, -0.3768,  1.0322,  1.0407, -0.9410, -1.7982,  1.9598,\n",
      "          -1.0583, -1.6330,  0.3366, -0.5349, -1.3855,  0.0245, -2.3689,\n",
      "           2.1333]]])\n",
      "src = ['i', 'want', 'to', 'eat', 'apple']\n",
      "predicted trg = ['ich', 'mochten', 'apfel', 'essen', '<eos>']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_count 1    self.capacity  20\n",
      "0  ------------------------------------------------\n",
      "DecoderLayer@trg4\n",
      "[1, 1, 64]\n",
      "tensor([[[-1.8017,  0.2611, -0.2967,  0.0033,  0.9981,  2.3713, -0.3086,\n",
      "           0.1796, -1.2938,  0.0573, -0.0737, -0.5142, -1.0751, -0.9457,\n",
      "           1.0076, -1.3452,  0.7007,  2.0046, -0.7745,  0.2658, -0.4368,\n",
      "           0.1287,  0.5477,  0.0628,  0.4703,  0.2151, -0.2870,  0.8835,\n",
      "           0.2915,  0.7129,  0.5569, -0.4654, -0.2865, -0.1682, -0.4716,\n",
      "          -0.1584,  0.5534,  0.7152,  0.6311,  0.2726, -0.5361,  1.4951,\n",
      "          -0.3874, -0.9091, -0.1669,  1.5431,  2.0933, -1.4367, -0.4403,\n",
      "          -0.8956, -0.5269,  0.7874,  1.0031, -0.6711, -1.8181,  1.7943,\n",
      "          -0.9300, -1.7175,  0.4383, -0.5441, -1.2372,  0.0396, -2.3203,\n",
      "           2.1871]]])\n",
      "src = ['i', 'want', 'to', 'drink', 'water']\n",
      "predicted trg = ['ich', 'mochten', 'wasser', 'trinken', '<eos>']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_count 1    self.capacity  20\n",
      "0  ------------------------------------------------\n",
      "DecoderLayer@trg4\n",
      "[1, 1, 64]\n",
      "tensor([[[-1.2555, -0.1767, -0.3128, -0.6967,  0.7889,  2.4494, -0.5505,\n",
      "           0.2402, -1.1726,  0.5501,  0.6836, -0.2690, -0.8987, -1.7901,\n",
      "           0.6975, -0.3601,  0.6892,  1.5048, -0.4395, -0.2782,  0.2968,\n",
      "          -0.4201, -0.1267, -0.6312,  0.9145, -0.3907, -0.4252,  0.0492,\n",
      "          -0.1495,  0.4029,  0.5298, -0.2036,  0.0897, -0.1012, -0.2481,\n",
      "           0.4661,  0.8414, -0.2521,  0.7754, -0.5577, -0.2477,  1.3487,\n",
      "          -0.0739, -1.1866,  0.8717,  1.8963,  2.4227, -1.2107, -0.1035,\n",
      "          -0.6989, -0.3585,  0.6333,  1.2043, -0.7826, -1.1767,  2.0154,\n",
      "          -1.0901, -1.4531,  0.3111, -0.8848, -1.8319,  0.3316, -2.3451,\n",
      "           2.2061]]])\n",
      "src = ['i', 'want', 'to', 'drink', 'beer']\n",
      "predicted trg = ['ich', 'mochten', 'bier', 'trinken', '<eos>']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_count 1    self.capacity  20\n",
      "0  ------------------------------------------------\n",
      "DecoderLayer@trg4\n",
      "[1, 1, 64]\n",
      "tensor([[[-1.4393e+00, -7.8354e-02, -3.3327e-01, -5.3460e-01,  8.5102e-01,\n",
      "           2.2960e+00, -4.5016e-01,  4.3410e-01, -1.2985e+00,  2.0030e-01,\n",
      "           7.4137e-01, -5.8544e-01, -8.9914e-01, -1.2904e+00,  8.0904e-01,\n",
      "          -6.5790e-01,  1.0745e+00,  1.9475e+00, -4.8212e-01, -3.5777e-01,\n",
      "           7.9943e-02, -2.3565e-01, -2.0405e-01, -6.8627e-01,  9.8114e-01,\n",
      "          -1.2892e-01, -5.6943e-01,  4.8841e-01, -1.0797e-01,  3.1466e-01,\n",
      "           3.8765e-01, -2.6429e-01,  5.3330e-02, -1.8544e-03, -4.8728e-02,\n",
      "           4.7315e-01,  1.0301e+00, -8.9778e-03,  6.6789e-01, -2.7168e-01,\n",
      "          -3.9081e-01,  1.2473e+00, -1.0700e-01, -9.8187e-01,  7.0823e-01,\n",
      "           1.8982e+00,  2.1322e+00, -1.0844e+00, -4.1441e-01, -5.9106e-01,\n",
      "          -4.2744e-01,  8.6509e-01,  1.0117e+00, -1.1334e+00, -1.3198e+00,\n",
      "           1.9680e+00, -1.2130e+00, -1.4849e+00,  3.1321e-01, -7.9411e-01,\n",
      "          -1.6685e+00, -8.5119e-02, -2.5017e+00,  2.2058e+00]]])\n",
      "src = ['i', 'want', 'to', 'read', 'book']\n",
      "predicted trg = ['ich', 'mochten', 'buch', 'lesen', '<eos>']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_count 1    self.capacity  20\n",
      "0  ------------------------------------------------\n",
      "DecoderLayer@trg4\n",
      "[1, 1, 64]\n",
      "tensor([[[-1.1651,  0.0221, -0.3873, -0.1546,  0.4245,  2.2978, -0.7751,\n",
      "           0.1107, -1.0806,  0.4122,  0.1069, -0.3558, -0.8280, -1.5747,\n",
      "           0.9176, -0.9884,  1.0839,  1.6258, -0.9328, -0.2364,  0.0599,\n",
      "          -0.1125,  0.0133, -0.0950,  0.7237, -0.1864, -0.4649,  0.3563,\n",
      "           0.1715,  0.4262,  0.7281, -0.1862,  0.1080,  0.0198, -0.2683,\n",
      "           0.1423,  0.4902,  0.2354,  0.8655, -0.5280, -0.4875,  1.0731,\n",
      "          -0.0056, -1.2002,  0.9420,  1.5641,  2.1847, -1.3892, -0.2371,\n",
      "          -0.5061, -0.2089,  1.2225,  1.4283, -1.1625, -1.6043,  1.8287,\n",
      "          -0.5561, -1.8884,  0.4499, -0.8083, -1.9648,  0.2017, -2.2041,\n",
      "           2.3424]]])\n",
      "src = ['i', 'want', 'to', 'read', 'newspaper']\n",
      "predicted trg = ['ich', 'mochten', 'zeitung', 'lesen', '<eos>']\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4gAAAFVCAYAAACtj8EWAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAA4eklEQVR4nO3de4DNBd7H8ffcTe7GtaRUelZJ6aKECLkVXfZZKW2prTYWi7YlG21UEimUWyq5R0iEKCW33CK06WJtt51cIjLDXM/zhzOe2rIpM78zZ7xff5Uz5vM945zf93zO+Z0zMaFQKIQkSZIk6YQXG+kBJEmSJEmFgwVRkiRJkgRYECVJkiRJYRZESZIkSRJgQZQkSZIkhVkQJUmSJEmABVGSJEmSFGZBlCRJkiQBFkRJKtL27NkT6REkSSp03I9HZ0GUpCJq6dKlDBw40CUoSdL3uB//OwuiJBVBW7duZdy4cXTo0IFy5cqRm5sb6ZEkSYo49+PPsyBKUhESCoU4dOgQkydPZseOHfzrX/8CIDY2llAoFNnhJEmKEPfjsYsJ+RORpCIjMzOTxMRE0tPTGTp0KGlpabRt25Z69eoBhxdkTExMhKeUJClY7sdjZ0GUpCJi6dKlzJgxg1AoxPnnn0+bNm0YNWoUMTExNGvWjIYNG0Z6REmSAud+/GU8xVSSioB33nmHoUOH0rlzZ1JSUpg1axaVK1fm3nvvJSMjg4ULF7J3795IjylJUqDcj79cfKQHkCQdn6ysLNasWcPgwYPZvXs3n376KS+++CJPPfUU559/Pl26dCEtLY2yZctGelRJkgLjfvx1LIiSFOUSEhIIhUL06dOH2NhYhg8fTqVKlfjyyy+58MILqVq1aqRHlCQpcO7HX8dTTCUpSu3atYsvvvgCgDp16pCYmEibNm2oXLkyH3zwAVu3bqVMmTKRHVKSpIC5H4+PH1IjSVHojTfeYNiwYQCceeaZXH311WzatIkPPviAtLQ00tPT6d69O02bNo3wpJIkBcf9ePwsiJIUZT777DOeeeYZbrrpJs466ywGDhxIXFwcnTt3Ji4ujq+++oqyZcty+umn+7HdkqQThvsxf3iKqSRFiVAoxLZt22jdujWJiYnUqVOHkiVL0r9/fzZu3MicOXOoWLEiderU4fTTTwdw+UmSijz3Y/6yIEpSlIiJieHMM8/kpptuYt68eUc+ljs+Pp4bb7yRkiVLRnhCSZKC537MX36KqSRFgbVr17JlyxYaNGjAAw88QE5ODm3atGHgwIHEx8fz4osv8tBDD0V6TEmSAuV+zH++B1GSCrmlS5fSv39/atSowY4dO+jevTuNGjXi0UcfZcKECbRo0YK77rqLWrVq+Z4KSdIJw/1YMHwFUZIKsS1btjBixAgmTZrEvn376NKlC1OnTiUhIYE+ffpQsmRJJk2aRL9+/SI9qiRJgXE/FhzfgyhJhdihQ4e45JJLyMzMZOHChQwcOJDk5GT69u3LuHHj6Nq1K/Xq1ePmm28mMzPTZ0clSScE92PB8RVESSrEypcvzwUXXMD27dvJyMjgkksuYdeuXezbt4969eoB8NRTT7Fr1y4SExMjPO3xyc3NJTb2/5+39HQgSdLRnEj7EYLdkb6CGCG5ubkAZGdnR3gSSYXN0qVL+dvf/kafPn3YtWsXLVq04M033yQlJYUPP/yQ559/nrvuuotzzz33yDGkfPnyEZ76+MXGxnLgwAE2b94M+BHkJyr3o6SjOVH3IwS7I/2QmghJT0/n22+/5fnnn6d169ZceOGFkR5JUiGwceNG+vfvz3XXXceePXsYM2YMo0ePZt++fQwfPpxixYrRtWtXWrRoEelR89W6dev49ttveeGFF4iNjaVv376cffbZkR5LEeB+lPRTTtT9CMHvSE8xjYAZM2bw6aefkpqayqJFi0hJSXEBSmLr1q08/vjjdOvWjcaNGwNw5pln8re//Y0333yT888/n6SkJCpXrlxkTr9cu3Yt7777LsuXL6dVq1bk5ORQsWJFy+EJyv0o6aeciPsRIrcjLYgBevfdd1m6dClr1qzhL3/5Czt27KBUqVLcdtttkR5NR/Gf53tLBSk1NZVPP/2Ut99+m8aNGxMKhWjTpg2LFy/mm2++4bTTTjvytUVl+X388cfs27ePwYMHU61aNbKzszn33HMB738nEvdjdPI+qqCciPsRIrcjLYgBOvvss0lMTOTOO+8kJSWFuXPnUqpUKeLj4z3IFjJbt26lTJkyVK5cOdKj6BeI1vvRJ598QmxsLJdffjmPPfYYzz77LBMnTuT3v/89mzZt4uOPP+bQoUORHrNAdOjQ4ch/r127lgULFhx5djga/y3167gfo4s7MjpF433pRN6PELkdaUEMyPbt20lKSjpyqsz27dt59tln+etf/1okPlmpqHnvvfcYM2YM1157Leeee26RPJ+9qNmwYQMjRozg6aef5qSTTor0OMdsyZIljBo1ipSUFO677z4aNmxIbGwsAwcOZOHChZQuXZo+ffpwxhlnRHrUfDVz5kxSU1OpWbMmTZs2JS0tjVdeeYX27dtz1llnRXo8Bcj9GH3ckdEnGnfkibofIfI7MrqeRohSEydOpF+/fjz99NPs2LEDgF27dtGkSRMaNGiAnxNU+Nx8882ceuqpjBs3jtKlSwOQk5MT4an039SpU4ddu3bRq1cv0tLSIj3OMdm0aRPDhw/n+eef57777mPv3r1MmTKF2NhY+vTpw8GDBzn55JO54oorAIrMsWL8+PG88sorVKpUiVNOOYWDBw9y0kkncdlll1GxYsVIj6cAuR+jkzsy+kTbjjxR9yMUjh3pK4gFbObMmSxYsICnn36anTt38tVXX/HOO+/QtGlTDh48CBStc6Wj2X+eelG/fn1OOeUU7rvvPl544QXOOusssrOziY/3blOYhEIhcnNziYuLo3fv3nTp0oV7772XJ598kuTk5EiPd1QHDx4kJiaGqlWr8tZbb/HWW2+RkZHBrl27uPjii7n33nvJzc1lwIABVK1alY4dOxaJY0VqaipLly5l4sSJvPfee7z11lu88cYblClThnHjxhWJ66hj436MLu7I6BSNO/JE3Y9QeHakv+aigI0ZM4YqVaqQnp7O+++/z65du1i+fDn9+vXj5ptvjvR4+gmrVq0iOzubyy+/nLi4OB5++GEWLFjA66+/znfffUeVKlUiPaJ+wrhx49iwYQP16tVj4sSJVKtWjWHDhhXKU2m++uorevTowe23387KlSvZsGEDnTt3pnXr1ixdupQpU6YwYsQIcnNzWbNmDdWrV+fUU0+N9Nj54t///jfXXXcdF1xwAXv27KFx48bUqVOH6dOn07t3b6pUqVKkPoFOR+d+jE7uyOgULTvyRN6PUHh2pE/zFLCUlBSmTZtGRkYGnTt3pmnTprz88svs2bPHB0GFxPefFZ00aRIvvPACpUuX5sEHH2T27Nk88MAD5OTk0LBhQ8qWLcuMGTNISUmJ8NT6vm+++YbFixfz+OOPc9ppp3HLLbdw880306NHD5544glKlCgR6RF/oEyZMtSuXZuSJUsyYMAAQqEQ69ev54033uDpp5+mR48eR957lXf6TLT7xz/+QVJSEhUqVGDChAls2rSJevXqceqpp/LGG2/wxRdfUKxYMcBXjU4U7sfo4I6MftG0I0/E/QiFb0daEAvA7Nmz2b59Ozt37qRLly60bt2a5ORkdu/ezcyZM5k0aRJPPPGEy6+QyFt8q1evJjU1lWnTplGhQgU6depEu3btmDFjBg8++CDNmjWjWrVqLr5C4D8fPObk5LBv3z6ys7OP/Nnf//532rZtyxNPPEG/fv0Kxf3t/fffJz09nbp16/Kb3/yGZ555hgYNGvD5558zc+ZMduzYQffu3WnUqFGReoD84osvsmDBAkqXLs2///1vbr/9dtq1a8f9999PXFwc7733HsOGDaNs2bKRHlUFzP0YfdyR0Scad+SJuh+hcO5ITzHNZ+PHj2fBggV06NCBlStXsnz5coYOHcq3337LhAkTyMnJoX///tSoUSPSoyosJyeHzz77jNatW9OiRQuGDRt25LLOnTuzfv16Fi9eTKlSpSI4pfJ8fzFs2bKFSpUqUaFCBQYOHMiGDRsYPXo05cqVY+HChaxatYrbb7+d008/PaIz5z0D37ZtW7788kuaNWtGv379eOihh6hZsyZ33HEHAGlpaRQvXrxILb833niDkSNHMnHiRDIyMtiyZQsPPPAAAwcOJDY2lj179nDeeedRrVq1SI+qAuZ+jE7uyOgSbTvyRN6PUHh3pAUxH+3cuZNevXrx5JNPUqZMGQCGDx/OvHnzWLRoEWlpacTExBS6871PRD91gHnttde47777GD58OM2aNTvy5z179uTPf/7zD34JqyLj+/9uzz//PJMnT+b000/nsssuo2HDhsyYMYN58+bRvHlzVq9ezdixYyNeDgEOHDhAiRIl2LhxI5MnTyY9PZ1vvvmGU045hX379jFq1CgSEhKK3OKDw8+Mpqam0rt3b7KysoiPj+fBBx+kWrVq3HnnnZEeTwFxP0YXd2R0isYdeSLvRyi8O9JTTPNRKBRi586dbN++nTp16gBw2223sXnz5iN3AEXe9w8y06dPZ+PGjVxxxRVcffXVZGdn07VrV0aMGHFkAQ4dOjSS4+p78v7dZs2axbJly5gzZw59+vThrbfeIhQK0atXL1q0aEFOTg533313oXjj+ieffMIzzzxD8+bNadKkCaVLl+a2224jJyeHOXPm8Nprr/Hll19SvXr1Irn8SpQowe7du9m/f/+RVxgSExPJyMgAfvqBqIoe92P0cEdGr2jbkSf6foTCuyMtiPlg06ZNpKSkUL58eerXr8+aNWsoVaoUZ555JkuWLGH//v3k5uZGekyF5d3RpkyZwssvv0z9+vV5/PHH2bNnDzfffDOxsbF06dKFUaNGceWVV0Z4Wv2n7OxsVq1axS233MLu3bupWLEitWrVYv78+ezcuZM77riDk08+OdJj/kCDBg14/PHH2blzJzk5OfTt25fRo0fTr18/7rnnniL3u//mzp3LoUOHyMzM5NJLL2Xy5Mk899xz1KxZk4yMDJYvX86oUaMAP5CmqHM/Rh93ZHSLth15ou1HiI4daUE8TuPHj2fhwoWccsopPPTQQ9SrV48lS5Zw3333UatWLdauXcvw4cM9N7+QWbFiBfPnz2fSpEl89NFHrFmzhsWLFxMbG0v79u1JTk6O+vdEFZVXZv7zesTHx3PmmWdSqlQpFi1axBVXXMEVV1zBsmXLSEtLIy4uLoLT/r+VK1fy9ttvU6ZMGc4//3ymTZvGtGnTSExM5MMPP2Ty5Ml069btyPIrKv9e48ePZ9GiRXTq1Im77rqLkSNHMnDgQCZOnMjrr79OTk4Ow4cPp3r16pEeVQXM/Ri93JHRIxp35Im6HyF6dqTvQfyVcnJyWLx4MZMnT2bixIls3LiRQ4cOsWPHDhISEihbtiz79u2jVq1aVK1aNdLj6ns2btzI8uXLCYVCNGrUiDfffJMbbriB6dOnM2vWLH73u9/Ro0ePqD4Yff9geujQIRISEgrFUvilvn893n77bbKzsylTpgy1atXi0KFDdO3alYcffpht27YxevRohg8fTuXKlSM8NSxdupQhQ4bQvXt3XnjhBeLj4xk/fjxw+P0WgwcP5uqrr6Zu3bqRHTQfZWRk8NVXX/Hwww/z7LPPMmnSJN5991369evHxo0badWqFQDp6em+z6yIcz9GN3dk9IjGHXki7keIvh3pK4i/wvr16ylWrBg7duygRo0azJw5kxUrVrBr1y5yc3O56qqraN26daTHVFjeJ2TlHUg3bdrExIkTGTt2LAcPHuTAgQOcdtppVK9enYsuuohbbrmlyCy+SZMm8f777/Pvf/+ba6+9lksvvTSqPkgg73pMmDCBBQsWcPXVV9OlSxdGjhxJtWrV2L17N+PHj2f58uWMHDky4osvFAqxf/9+Zs6cyYgRI9i1axfZ2dk88cQTTJs2jbPPPpsLL7yQhx566MjXR/NtLc97771HKBSiePHilCxZkpEjR7Jp0yZGjhzJV199xfDhw2nSpAlJSUmFYvGp4Lgfo4870h0ZhBN1P0J07sjYSA8QjRYsWMDGjRs544wz+Oyzz5g9ezZt27Zl4sSJNGnShM8++4xQKIQvzhYOeb/Dac2aNQDceuuttGzZkvnz5zNr1iySkpKYP38+U6ZMoWfPnlF/vnveAXXq1KnMmTOHzp0707hxYz744ANefvllDhw4EOEJf9737zsffvghCxcuZPz48WRnZ9O4cWPOPfdcYmJiePzxx6lbty7PPvtsofho/JiYGEqXLk2tWrUYPXo0gwYNYvDgwVSqVIlZs2Yd+fTG7399UTB//ny2bt1K1apV+eabb1i4cCEjR44kISGBFStWcPLJJx+5H6pocz9GH3ekOzIIJ+p+hOjckb6C+AstXbqUVatW0alTJ1JSUrj00ktJTExkxYoVvPrqq8ybN48hQ4YUqRs2wNq1a8nKyuLyyy+P9Ci/yhdffMFtt91G48aNue6662jcuDGpqanUrFmTyZMns2XLFh555BHOOOOMSI/6q23dupUPP/yQ66+/nvT0dDZs2EDv3r2pXr06d911F4sXL2bYsGG0a9euUH9i4H9+gl56ejp16tRh6tSpLFu2jDFjxrBs2TKGDx/O7NmzOe+88yI88WHvvPMOb7zxBnFxcezevZuvv/6aPn36cOqpp/LJJ59w6NChIvmgOO+Y+Ic//IESJUpwzTXXsHr1au655x7q1KnD4sWLGTJkCAkJCZEeVQXM/Rid+xHcke7IgnWi7keI3h1pQTxGeadg7N69mzvuuIOUlBTef/991q9fT3x8POvXr+fAgQMMGjSIM888M9Lj5qtQKMSePXuoXbs2O3bsoFKlSpEe6RerUKECv/3tb/n888/5+uuvmTlzJunp6fTq1YsZM2Zw8OBBkpOTIz3mcUlKSqJ///7MmjWLs846i08//ZTU1NQjl1911VVMmzaNvXv3Rvyjrf+bvMX3yiuvMGvWLHr27Enfvn056aSTmD17NgD//Oc/OfvssyM55g9s2LCBJ554gsaNG7N3714++ugj4PB1GDduHF988QXdunUrUseG/zwmVqlShY8++ojdu3fTunVrtmzZQunSpRk6dGiRut76MfdjdO9HcEeCO7KgnIj7EaJ/R1oQj1FsbCzffvstc+fOpXz58hw8eJCJEyfyv//7v9SsWZNbb7210LyxNL/FxMTQokULvvzyS9q1a8f9998fNe8hmTdvHjk5OVx22WXcdddd3HnnnZx77rmUK1eO/v378/zzz9OgQYMi8e9WvXp17r77bp555hkaNWpEkyZNeOihhzj55JO58MILmT9/Pl9//XXE36d3LP71r3/xzDPP0LhxY+rWrUvbtm3ZvHkzgwYNolKlSrz22msMGjQo0mMC8I9//IPRo0fz8MMPc9555/HZZ59RtmxZ3nzzTf7nf/6HVq1aUbx4cWrXrl2k3lPxU8fEF198kRtuuIHy5cvTo0ePSI+ogLgfo3M/gjvSHVmwTtT9CNG/Iy2IxygUCrF582Y++ugjUlJSKFeuHEOGDPnBS/fR/uzaz6lYsSL33HMPY8aMITY2lpYtW0Z6pJ9VuXJlpk+fzuzZs+nYsSN//OMfWbFiBd27d+f000+nUqVKRWLx5WnTpg2/+c1v6Nq1K7fffvuRhd+iRQu2bNnCk08+GRXvH6lSpQodOnRg5MiRXH755XTu3Jlly5Yxe/Zs4uPjGTRoUMTfTwGHnyH86KOPWLFiBZdffjnnnXce1apV44YbbmD37t3Mnz+fyZMnH/n6orT8fuqYOHTo0EJxOpOC5X6Mzv0I7kh3ZME5kfcjRP+O9Ndc/AJZWVls2rSJCy+8sMjdkI9VZmYms2bNYtKkSXTr1o3mzZtHeqSflZ6ezpo1axg8eDBVqlRh69atTJs2rUh/vPr777/PLbfcwiOPPML+/ftp1KgRxYoVo0KFCpEe7ZhlZ2fz0ksvMWXKFHr06EGzZs2AwvfJZpmZmUyfPp2JEyfSvXv3Ix9V/cUXX5CWlsZvfvObCE9YcDwmKo+3hejcj+COdEcWnBN5P0J0Hxd9BfEXSEhI4KKLLgIO/56naPydOccrMTGRG264gdjYWAYMGEBsbOyRg1JhddJJJ9G4cWNq1qzJunXrmDx5Mrm5uZEeq0Cdf/75TJgwgZ49exITE0PTpk2javHB4V/2+7vf/Y74+Hj+/ve/A9CsWbNCd5BNTEykXbt2xMfHM2bMGLKzs2nTpk2hfg9LfvGYqDzeFqJzP4I70h1ZcE7k/QjRfVz0FUT9KpmZmcydO5e6detG3R092u6kx2PPnj0AlCtXLsKT/HrRclvLzMzkpZdeOvLLwcuXL1+oFrWkYETLMeto3JHRJRpub+7H6GNB1K9WmE5jUNEWLbe1zMxMdu/ezcknnxzpUSRFULQcs1Q0RMPtzf0YXSyIkiRJkiQAYiM9gCRJkiSpcLAgSpIkSZIAC6IkSZIkKcyCKEmSJEkCLIiSJEmSpLD4SA8QpNzcXNLS0khISCj0HwcsSTo+oVCIrKwsihcvTmysz4f+HHekJJ0Yfm4/nlAFMS0tjY8//jjSY0iSAnT22WdTsmTJSI9R6LkjJenEcrT9eEIVxISEBAD+8Ic72blzZ4HnzZ37Km3atC3wHIDt2/8ZSE6eLVu2UKtWrUCyqlc/I5AcCPbfLDGxWCA5ADNnTue3v20XWF5m5sHAsubOnUubNm0CywuK1+v4VaxYkeeee+7IsV//Xd7P6c477wpkR7766hzatr22wHMAfn9X70ByAH7Xph4z5q4KLO/lSSMCy3rppSnceOPNgWSdemrNQHIAhgzpy1/+MiCwvG3bNgaSM3v2TK6//reBZAEkJCQGljV9+lTatbspkKzLLgvmcSFAz543MXTo1ALPKVWqOHfe2fao+/GEKoh5p8zs3LmT1NTUQDKDyklKSgokJxKZQf0Mg85LSkoOJCfP119/HVhWRkZ6YFkQ/G0kKF6v/OHpksemKO/IA+mHAsmJRN7XX+8ILCvIvOTkyoHk5Nm9e29gWUHu4yCzEhKCfSwa1G3x228PBJITibyj7UfflCFJkiRJAiyIkiRJkqQwC6IkSZIkCbAgSpIkSZLCLIiSJEmSJMCCKEmSJEkKsyBKkiRJkgALoiRJkiQpzIIoSZIkSQIsiJIkSZKkMAuiJEmSJAmwIEqSJEmSwiyIkiRJkiTAgihJkiRJCrMgSpIkSZIAC6IkSZIkKcyCKEmSJEkCLIiSJEmSpDALoiRJkiQJsCBKkiRJksIsiJIkSZIkoJAXxM2bN9OtW7ejXt67d2+ee+65ACeSJCny3I+SpIJSqAvieeedx/DhwyM9hiRJhYr7UZJUUAp1QVy9ejXXXHMNaWlp3H///bRo0YLWrVszdOhQQqEQABs2bKB9+/Y0a9aMTp06kZ6eHuGpJUkqWO5HSVJBiQnlbZJCaPXq1QwYMID69euza9cuBg8eTE5ODnfccQddu3Zl9uzZbNu2jQkTJpCYmMjvfvc7br31Vq677rqf/H4ZGRls2bIl2CshSYqoWrVqkZSUFOkx8lV+70dwR0rSieZo+zE+ArP8YitXruT+++8nLi6OuLg4Jk2aBMDs2bNp1qwZycnJANSoUYM9e/b87Pdr06YtqampBTozwLp1a7n44ksKPAcgFMoNJCfP+vXrueiiiwLJiokJ7oXuIP/NkpKSA8kBWLHiHerXvyKwvIyM4F6pWLduHRdffHFgeUHxeh2/KlWqMHfu3ECyIiW/9yNA27bXBrIj165dwyWX1C3wHIDOfxkUSA7A7TdeyQsvvRVY3viRDweWtXTpmzRq1DSQrOrVzw8kB2D8+KF07NgzsLyPPlodSM6qVSuoV69+IFkACQnBPRH3zjtLuOKKJoFkNW58UyA5AP3730W/fs8WeE6ZMiXo2fPo1ysqCmJ8fDwxMTFH/j81NZVixYoduSxPTEwMhfgFUUmS8pX7UZKU3wr1exDz1KtXj9mzZ5Obm0tmZibdunVj7dq1kR5LkqSIcj9KkvJbVBTELl26kJCQwLXXXst1111Ho0aNaN68eaTHkiQpotyPkqT8VqhPMb300kuZN28eAI888siPLn/sscf+6/9LklQUuR8lSQUlKl5BlCRJkiQVPAuiJEmSJAmwIEqSJEmSwiyIkiRJkiTAgihJkiRJCrMgSpIkSZIAC6IkSZIkKcyCKEmSJEkCLIiSJEmSpDALoiRJkiQJsCBKkiRJksIsiJIkSZIkwIIoSZIkSQqzIEqSJEmSAAuiJEmSJCnMgihJkiRJAiyIkiRJkqQwC6IkSZIkCbAgSpIkSZLCLIiSJEmSJMCCKEmSJEkKi4/0AMofpUtXCDRvyZKFgWWWLVspkJyg897ZtCaQHICMHTtZ9+nWwPIuOP2MwLIA4uKCOZTl5GQHkhO8mCKaF/T1KhpCoVxCodzAsoLwzOC/BpIDcPuNawPNq1TptMCyAEqUKBtIzubNSwPJAVi/fn2geTExwR2bsrIyAsvKzc0JLAsgIyM9kJxFi14IJAegf/+7AsmrUqUyPXvedNTLfQVRkiRJkgRYECVJkiRJYRZESZIkSRJgQZQkSZIkhVkQJUmSJEmABVGSJEmSFGZBlCRJkiQBFkRJkiRJUpgFUZIkSZIEWBAlSZIkSWEWREmSJEkSYEGUJEmSJIVZECVJkiRJgAVRkiRJkhRmQZQkSZIkARZESZIkSVKYBVGSJEmSBFgQJUmSJElhFkRJkiRJEmBBlCRJkiSFWRAlSZIkSYAFUZIkSZIUZkGUJEmSJAERLIi9e/fmueee+8nLnn76ad54442AJ5IkKfLcj5KkSCqUryCuXr2a7OzsSI8hSVKh4n6UJBW0+J/7gtWrVzN06FCqVKnC9u3bSU5O5u6772bixIls376d5s2b06dPH1566SUmTpxIbGws5cuXp2/fvlSvXp20tDQefvhh3nvvPeLi4mjWrBk9evQAYMOGDbRv357du3dTo0YNnnjiCWbPns2WLVt4/PHHiYuLo1GjRgwZMoS1a9eSk5PDOeecwwMPPECJEiVo0qQJ119/PatWrSI1NZVrr72W7t27F/TPTJIk96MkqUg6plcQN2/ezN13382cOXMoUaIEY8eOZcyYMcyaNYspU6Ywd+5cxo0bx4QJE3j11Ve55ppr+NOf/kQoFGL48OFkZGQwf/58XnnlFd577z3WrFkDwI4dO3jhhRd4/fXX2bFjB4sWLaJDhw7UqlWLv/71r1x11VWMHTuWuLg4Zs2axauvvkrFihUZMmTIkdnS09OZMmUK06ZN4/nnn+eLL74omJ+UJEn/wf0oSSpqfvYVRICqVatyzjnnAFCtWjVKlixJYmIi5cqVo3jx4rz++uu0bt2acuXKAXDDDTfwyCOP8OWXX7Jy5Uruv/9+4uLiiIuLY9KkSQDMnj2bZs2akZycDECNGjXYs2fPj7LffvttvvvuO1auXAlAVlYWKSkpRy5v2rQpAJUqVSIlJYV9+/Zx6qmn/tfrM3fuq8dytfPFunVrA8sK2pIlCyM9QoFYvHheIDkZO3YGkhOJvNWr3w0sKxJ5QVm3bl2kRygQRem4WNT2I8DcuXOP4yfyy3gbjz6vvfZyIDnr168PJCcSeUHe7ovqfQyK7u5/992VkR7h2ApiYmLiD/9S/A//WkxMzI/+TigUIjs7m/j4+B9cnpqaSrFixX70fWJiYgiFQj/6Prm5ufTp04dGjRoBkJaWRkZGxpHLk5KSfvZ7/Kc2bdqSmpr6s193vNatW8vFF19S4DkApUql/PwX5aMlSxbSpEnLQLLi4o7pZpovFi+ex1VXXRNI1jub1gSSA4fLYVKlioHlXXD6GYFlrV79LpdeelkgWTk5wb33a926dVx88cUBpf34GF5QgjwuVqlSpcCfECxq+xGgTZs2Ae1Ib+P5oVKl0wLLeu21l7n66v8NJOvrr7cHkgOHy+FFF10UWN5PHRcKQrD3sWAfrwW5+2NigvvIlnffXclll11e4DlVqlRm9uxZR708X65x3bp1mT9//pFnOGfOnEmZMmU47bTTqFevHrNnzyY3N5fMzEy6devG2rX//Zm1uLi4I2/Cb9CgAZMnTyYzM5Pc3Fz69u3L0KFD82NsSZIKlPtRkhRt8qXqX3rppcTGxnLbbbeRm5tLuXLlGDNmDLGxsXTp0oVHHnmEa6+9lpycHFq3bk3z5s1ZsmTJUb9fkyZNGDp0KFlZWXTu3JlBgwZx/fXXk5OTQ82aNendu3d+jC1JUoFyP0qSok1M6FjPOSkCMjIy2LJli6eY5gNPMT1+nmKaPzzFND8UzdPv8k4xrVWr1g9Ot9RP+/8d6Smmx8NTTPOHp5geP08xzR9F+RTTo+3HQvl7ECVJkiRJwbMgSpIkSZIAC6IkSZIkKcyCKEmSJEkCLIiSJEmSpDALoiRJkiQJsCBKkiRJksIsiJIkSZIkwIIoSZIkSQqzIEqSJEmSAAuiJEmSJCnMgihJkiRJAiyIkiRJkqQwC6IkSZIkCbAgSpIkSZLCLIiSJEmSJMCCKEmSJEkKsyBKkiRJkgALoiRJkiQpzIIoSZIkSQIsiJIkSZKkMAuiJEmSJAmA+EgPEAmXXNKKvXv3B5LVsOH/BpKz9cN3A8n5vqTE5EByKlc5I5CcPFWr/k8gOZ1vvjeQHIAnn+wVaF5KyimBZQWZd+hQWiA5eUqVKh9IzqFDBwLJyZOYmBRITkJCYiA5RU1ycglOOqlUIFlFLSdP+fLBHQPT0vYFlhVkXumAjn8AS956PdC8ChWqFcmsXkOeCCwLYNDzUwPJGT3gsUBy8px++nkFnlGhQsp/vdxXECVJkiRJgAVRkiRJkhRmQZQkSZIkARZESZIkSVKYBVGSJEmSBFgQJUmSJElhFkRJkiRJEmBBlCRJkiSFWRAlSZIkSYAFUZIkSZIUZkGUJEmSJAEWREmSJElSmAVRkiRJkgRYECVJkiRJYRZESZIkSRJgQZQkSZIkhVkQJUmSJEmABVGSJEmSFGZBlCRJkiQBFkRJkiRJUpgFUZIkSZIEWBAlSZIkSWEWREmSJEkSEHBBnDp1KmPHjgVgxowZTJ48Och4SZIKJfejJKmwiA8y7Kabbjry3+vXr6dGjRpBxkuSVCi5HyVJhcVxFcTJkyczffr0I/+/bds27rzzTmrXrs2oUaPIysqiWLFi9OrVizp16jBixAj27t1LvXr1WLJkCStWrKBYsWLs2bOHvXv30q9fP4AjX9evXz9+//vfc8EFF/Dee++RmppKvXr1GDBgALGxscyaNYuxY8dSrFgxLrvsMiZMmMA//vGP4/uJSJJ0nNyPkqRodVwFsUOHDnTo0AGAKVOm8PLLL9OyZUvuu+8+JkyYQNmyZfnkk0+4/fbbWbRo0ZG/d9VVV/Hmm29So0YNOnTowIgRI/5rzueff87EiRNJT0+nVatWrFmzhvLlyzNkyBBmzZpF5cqVefrpp8nJyTmmufv16/Trr/Qv9OSTvQLLCtqChbMjPUKBeOGFJyI9QoEoyrfF+fNnRnqEArFkycJIj1AgVq5cHukRCly07keA6dOn/ror/Su8886SwLKCtHDhK5EeocC8/fbiSI9QIJa89XqkRygQCxbMivQIBabxudWDyZk2JpCcPNMCzvsp+XKK6eLFi3n++eeZOnUqixYtYufOnXTs2PHI5TExMXz++ee/+vtfeeWVxMbGUqJECU477TT27dvH1q1bqV+/PpUrVwbglltu+dlFmqd//1Hs3bv/V89zrJ58shc9egwq8ByArR++G0hOngULZ9Oq5fWBZFWuckYgOXC4HN5++72BZJUpUzGQHAj2tgjw0UdrAsuaP38mrVv/NpCsQ4fSAsmBw+WwSZOWgWQdOnQgkBw4XA4vv7xBIFmVK1dm1qyXA8k6mmjbjwDt2t3E11/v+NUzHat33lnCFVc0KfAcgJNOKhVIDhwuhy1bXhdYXpDHpbffXkzjxlcFkhUbE9zHZCx563WaXNkisLykYsUDyVmwYBatWt0QSBZAryHBPcHe+NzqvP3B9kCyRg94LJAcOFwO27f/Y4HnVKiQwogRjx718uMuiOvXr+ehhx5i/PjxVKhQgdzcXOrVq8dTTz115GtSU1OpWLEiixf/9LNOMTExhEKhI/+flZX1g8uLFSv2o6+Ni4v7wd+Ji4s73qsiSVK+cT9KkqLRcT09s23bNv785z/zxBNPcNZZZwFQr149VqxYwbZt2wBYunQpbdu25dChQz/4u3FxcWRnZwNQtmxZPvjgA0KhEAcOHOCtt9762ewGDRqwatUqduw4/CznjBkzjueqSJKUb9yPkqRodVyvID766KNkZWUxaNCgI+9vqFWrFv3796dnz56EQiHi4+MZNWoUxYv/8OX0K664gsceO/yS7c0338yyZcto3rw5lSpVom7duj949vOnVK9enfvvv58//OEPJCYmUrNmTZKTk4/n6kiSlC/cj5KkaHVcBfG555476mWtWrX60Z917dr1yH+3aNGCFi3+/3zv0aNH/+T3mThx4k/+/xdffMG//vUvXn31VWJjY1m0aBEff/zxL5pfkqSC4H6UJEWrQH8PYn6qXLkyO3fupE2bNsTFxVGyZEkeffTob7aUJOlE4H6UJB2PqC2ICQkJ9O/fP9JjSJJUqLgfJUnHI7jPEJYkSZIkFWoWREmSJEkSYEGUJEmSJIVZECVJkiRJgAVRkiRJkhRmQZQkSZIkARZESZIkSVKYBVGSJEmSBFgQJUmSJElhFkRJkiRJEmBBlCRJkiSFWRAlSZIkSYAFUZIkSZIUZkGUJEmSJAEWREmSJElSmAVRkiRJkgRYECVJkiRJYRZESZIkSRJgQZQkSZIkhcVHeoBI2LZtAzt27Awk68MPVwWSs2dPaiA53/fNnn8HknPa6bUCycmTlHRSIDm7dn0RSE4k8s4668LAsoLM2759UyA5eYoXLx1ITvnypwSSk6dq1f8JJKdChZRAcoqak0+uQWJiMD+7atXOCSTn00/fCyQnz7ffBvMYA6BkyXKBZQEkJCQFknPw4IFAcvJkZmUElnVHtwcCy+pwd4/AsqYOHxdYVuMxjwSWt2/frkBygsxL+pm7sa8gSpIkSZIAC6IkSZIkKcyCKEmSJEkCLIiSJEmSpDALoiRJkiQJsCBKkiRJksIsiJIkSZIkwIIoSZIkSQqzIEqSJEmSAAuiJEmSJCnMgihJkiRJAiyIkiRJkqQwC6IkSZIkCbAgSpIkSZLCLIiSJEmSJMCCKEmSJEkKsyBKkiRJkgALoiRJkiQpzIIoSZIkSQIsiJIkSZKkMAuiJEmSJAmwIEqSJEmSwiyIkiRJkiQgoIK4evVqrrnmmiCiJEmKKu5ISVJh4iuIkiRJkiQA4oMMy8zMZMiQIaxdu5acnBzOOeccHnjgAUqUKMGUKVOYNm0aCQkJJCUl0b9/f8466yx27NhB//79SU1NJSsri6uvvpp77rmHL7/8ko4dO9KoUSPef/999u/fz3333cdVV10V5FWSJClfuCMlSYVBTCgUChV0yOrVqxkwYAAtW7YkLS2Nv/71r8TExDB06FD2799P3759Of/881myZAkVK1bklVdeISMjgxtvvJFbb72Vjh070qRJEzIyMrjrrrto3749tWvXpmnTpowePZorr7yS119/nccee4y33nrrqHNkZGSwZcuWgr66kqRCpFatWiQlJUV6jKNyR0qSIuFo+zHQVxDffvttvvvuO1auXAlAVlYWKSkpxMXF0bJlS9q3b0/jxo1p0KABjRo1Ij09nbVr17Jv3z6GDRsGQHp6Olu3bqV27dokJCTQqFEjAM455xy+/fbbY5rjttvuZseOnQVyHb9v4cJXaNnyugLPAdizJzWQnDxr1qymbt1LA8m68MLmgeQAjB49gHvu6RtI1oEDewPJAZg06WluuaVLYHnlylUJLGv48L/RrdsjgWRt374pkByAuXNfok2bGwPJSk4uEUgOwPTpz9Gu3R8CyapQIYVnnnk8kKz8UFh2ZPfu/di9e0+BXMfvC/K49Omn7wWSA/Duuyu57LLLA8srWbJcYFmLF8/jqquCeb/swYMHAskBWL78bRo0aBxY3j33Dggk55brGzJp9rJAsgCWLVwYWNaYMY/wxz/+LZCszz//MJAcgAULZtGq1Q0FnlOxYgVefHHMUS8PtCDm5ubSp0+fIwsrLS2NjIwMAIYMGcLHH3/MypUrGTt2LHPmzOGRRx4hFAoxbdo0kpOTAdizZw9JSUns3buXhIQEYmMPv40yJiYmyKsiSVK+ckdKkgqDQD+kpkGDBkyePJnMzExyc3Pp27cvQ4cOZc+ePTRq1IgyZcrQsWNHunfvzubNmylRogQXXHABL7zwAgD79+/npptu4s033wxybEmSCpw7UpJUGAT6CmLnzp0ZNGgQ119/PTk5OdSsWZPevXtTokQJOnXqRMeOHSlWrBhxcXE8/PDDwOFnTQcMGECbNm3IzMzkmmuuoW3btnz55ZdBji5JUoFyR0qSCoNACuKll17KvHnzAHjwwQd/8mvat29P+/btf/TnVatWZcyYH58jW7VqVTZs2HDU/5ckKRq4IyVJhYm/B1GSJEmSBFgQJUmSJElhFkRJkiRJEmBBlCRJkiSFWRAlSZIkSYAFUZIkSZIUZkGUJEmSJAEWREmSJElSmAVRkiRJkgRYECVJkiRJYRZESZIkSRJgQZQkSZIkhVkQJUmSJEmABVGSJEmSFGZBlCRJkiQBFkRJkiRJUpgFUZIkSZIEWBAlSZIkSWEWREmSJEkSYEGUJEmSJIVZECVJkiRJAMRHeoBIyMrKICsrI7CsIOTm5gaSE4nMzz77IJCcoPP279sVSE6e7f98P7Cs7777JrAsgM8+2xJIzoUXXhVITtB5ycnFA8nJc+GFzQLJKV062OtVVNzc7R4ysnMCyfpjv16B5Dx1/wOB5OQ55ZQagWV9/fX2wLIA0tP3B5IT5M8Q4OSTzwwsa/LYJwPJueX6hoFlARw4sDewLIB//GNlIDm5OdmB5OQJ4vHhSclx//VyX0GUJEmSJAEWREmSJElSmAVRkiRJkgRYECVJkiRJYRZESZIkSRJgQZQkSZIkhVkQJUmSJEmABVGSJEmSFGZBlCRJkiQBFkRJkiRJUpgFUZIkSZIEWBAlSZIkSWEWREmSJEkSYEGUJEmSJIVZECVJkiRJgAVRkiRJkhRmQZQkSZIkARZESZIkSVKYBVGSJEmSBFgQJUmSJElhFkRJkiRJEmBBlCRJkiSFWRAlSZIkSYAFUZIkSZIUVuAF8cCBA0yZMoVNmzbl6/cdPHgwn332Wb5+T0mSguSOlCQVNvEF9Y3ff/99XnrpJVatWkXTpk1p1qwZS5YsYdSoUWRlZVGsWDF69epFnTp1yMrK4rHHHmPVqlXExcVRu3Zt7r//fkqUKMGUKVOYNm0aCQkJJCUl0b9/f8466yzKly/Pn/70J1JSUrjxxhtp1qwZiYmJBXV1JEnKN+5ISVJhle+vIG7evJnrrruOYcOG0aBBA15//XUeeOAB0tPTefLJJxk7diyvvPIKAwYMoGvXrqSnpzNq1Ch27tzJnDlzmDNnDrm5uTz++OPk5OTw6KOPMm7cOGbOnEm7du1Yv349ALfffjvz5s2je/fuLF++nFatWjF58uT8vjqSJOUbd6QkqbDL91cQY2NjiY2NJSYmhpiYmCN/vmLFCnbu3EnHjh2P/FlMTAyff/4577zzDj169CAhIQGA3//+9/zpT38iLi6Oli1b0r59exo3bkyDBg1o1KjRD/Li4uKOZMbGHlvfnTLlxeO/osfozTcXBJYVtHXr1kZ6hAKxYMGsSI9QIFasXBbpEQrMnDlTIz1CgXjooTsjPUKB6N37pkiPEDHRsCPrnnHy8V/RY9Tw7FODyZkZ3N4HmBlwXpBWrHgn0iMUiOnTn4v0CAWiqD6mAVi27K1Ij1AgCsPjtXwviOeeey6zZs1i06ZNTJs2jcGDB9O8eXNKlChBvXr1eOqpp458bWpqKhUrViQ3N/cHizI3N5esrCwAhgwZwscff8zKlSsZO3Ysc+bMYdiwYUyYMIGXX36ZMmXK0L59ex588MEjy/Pn3HzzbezYsTNfr/dPefPNBTRt2qrAcwD27dsdSE6edevWcvHFlwSSVaFCMA8g4PCBtFWrGwLJ2r9vVyA5cPhgU//yhoHlla9QNbCsOXOmcu21wRSOCy5oGkgOHC6HDz44LpCs5OTigeTA4XL42GPBFPrSpYvTqVPbQLKOVTTsyDX//DcZ2Tn5er1/SsOzT2XZx18UeA7AU/c/EEgOHC6Hv/3tbYHlff319sCyVqx4h/r1rwgk65RTagSSA4fLYbt2fwgs77vv9gaSE+RjGoADB4K5XnC4HDZseGUgWbk52YHkQHCP1ypXrszMWTOOenmBfUhN7dq1efTRR5kzZw5Vq1albt26rFixgm3btgGwdOlS2rZty6FDh2jYsCFTp04lKyuL3NxcJk+eTP369dmzZw+NGjWiTJkydOzYke7du7N582bg8OLMW4KtW7c+5sUnSVKkuSMlSYVVgX1ITZ6SJUtyyy23ANC/f3969uxJKBQiPj6eUaNGUbx4cTp16sSgQYO47rrryM7Opnbt2vTt25dSpUrRqVMnOnbsSLFixYiLi+Phhx8GoFevXgU9uiRJBcodKUkqbAq8IH5fq1ataNXqx6dcFitWjAcffPAn/0779u1p3759QY8mSVJEuSMlSYVBgf8eREmSJElSdLAgSpIkSZIAC6IkSZIkKcyCKEmSJEkCLIiSJEmSpDALoiRJkiQJsCBKkiRJksIsiJIkSZIkwIIoSZIkSQqzIEqSJEmSAAuiJEmSJCnMgihJkiRJAiyIkiRJkqQwC6IkSZIkCbAgSpIkSZLCLIiSJEmSJMCCKEmSJEkKsyBKkiRJkgALoiRJkiQpzIIoSZIkSQIsiJIkSZKksPhIDxCkUCgEQPny5QPLrFSpYiA5J52UEEjO91WpUiWQnHLlKgSSk6dixWDyTkqOCyQnT+XKlQPLKpcS3H0MoGLFYPLKlCkRSE7QecWKnRRITp7SpYsHklOyZDLw/8d+/Xd5P6fE+OCOTUkBZVWoEOwxKdi8gwFmBbdLKlRICSQnEnnJycE9/A7qMQ1AiRKJgWUBVK5cKZCc3JycQHLyBHEfq1Dh8O3iaPsxJnQCbc7vvvuOjz/+ONJjSJICdPbZZ1OyZMlIj1HouSMl6cRytP14QhXE3Nxc0tLSSEhIICYmJtLjSJIKUCgUIisri+LFixMb6zsqfo47UpJODD+3H0+ogihJkiRJOjqfUpUkSZIkARZESZIkSVKYBVGSJEmSBFgQJUmSJElh/wcAR19QPGiaMwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1080x1800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_count 1    self.capacity  20\n",
      "0  ------------------------------------------------\n",
      "DecoderLayer@trg4\n",
      "[1, 1, 64]\n",
      "tensor([[[-1.0915e+00,  9.6793e-02, -6.9662e-03, -9.5078e-02,  3.5858e-01,\n",
      "           2.3532e+00, -8.6234e-01,  1.6332e-01, -1.3326e+00,  2.8202e-01,\n",
      "           2.0531e-01, -4.2273e-01, -8.1339e-01, -1.4742e+00,  8.1224e-01,\n",
      "          -1.3003e+00,  1.1771e+00,  1.5905e+00, -9.2515e-01, -1.5662e-01,\n",
      "          -6.8562e-02,  2.5634e-01, -2.0009e-03, -2.0924e-02,  5.4368e-01,\n",
      "          -2.9453e-02, -4.6258e-01,  3.9134e-01,  3.3293e-01,  3.7518e-01,\n",
      "           7.8803e-01, -2.8390e-01,  1.9696e-01,  2.2666e-01, -1.9398e-01,\n",
      "           7.2410e-02,  3.9752e-01,  1.9807e-01,  4.9600e-01, -2.3617e-01,\n",
      "          -6.6564e-01,  1.1631e+00, -4.0989e-02, -1.0061e+00,  6.5785e-01,\n",
      "           1.4950e+00,  2.1544e+00, -1.3852e+00, -2.7772e-01, -5.3428e-01,\n",
      "          -1.3954e-01,  1.2118e+00,  1.5815e+00, -1.1031e+00, -1.9272e+00,\n",
      "           1.8925e+00, -6.7149e-01, -1.8552e+00,  3.7320e-01, -9.0531e-01,\n",
      "          -1.7678e+00,  1.4830e-01, -2.1957e+00,  2.2815e+00]]])\n",
      "src = ['i', 'can', 'eat', 'bread']\n",
      "predicted trg = ['ich', 'konnen', 'brot', 'essen', '<eos>']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_count 1    self.capacity  20\n",
      "0  ------------------------------------------------\n",
      "DecoderLayer@trg4\n",
      "[1, 1, 64]\n",
      "tensor([[[-2.2036,  0.3158, -1.2559, -0.4176,  1.5641,  1.6282,  0.3032,\n",
      "           0.4607, -0.5817,  0.1523, -0.7189, -0.7818, -0.8421, -1.7219,\n",
      "           0.8334, -1.3485,  0.5479,  1.8959, -0.2699,  0.6982, -0.5297,\n",
      "          -0.6569,  0.4100,  0.0972,  0.7895, -0.3111, -0.8404,  1.4349,\n",
      "           0.2640,  0.7286,  0.6928, -0.0609, -0.1210, -0.7937, -0.5933,\n",
      "          -0.2486,  0.1691,  0.4348,  0.2468,  0.2748, -0.4255,  1.7598,\n",
      "          -0.4131, -0.8081,  0.6836,  1.6644,  2.3954, -1.2789, -0.2180,\n",
      "          -0.8249, -0.3564,  1.0686,  0.2681, -0.7342, -1.5337,  1.2865,\n",
      "          -0.3170, -1.1397,  0.6116, -0.1263, -1.6215,  0.7202, -1.9995,\n",
      "           1.7733]]])\n",
      "src = ['i', 'can', 'eat', 'apple']\n",
      "predicted trg = ['ich', 'konnen', 'apfel', 'essen', '<eos>']\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4EAAAFxCAYAAADNp638AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAwMUlEQVR4nO3de3zP9f//8ft7J9McxhhLPn4ilVBJWMgxp5zWQYtEkk9EfTrTh1xKSZFSchgqZjXHjc0hyWHMaePjlOLzlYhmo4Vs7PR+//5wee+jRGLb8709b9d/au/39r4/3szr8b6/jw6Xy+USAAAAAMAKXqYHAAAAAAAUHUogAAAAAFiEEggAAAAAFqEEAgAAAIBFKIEAAAAAYBFKIAAAAABYhBIIAAAAABahBAIAAACARSiBAIBC43Q6f/e1y+UyNAkAAJ7F5I6kBBYh9190bm6u4UkAoGh4eXnpzJkz2r17tyTJ4XAYngieih0JwDYmd6RPkSVB586d08mTJ/Xpp5+qc+fOatiwoemRAKDQJCcn6+TJk/rss8/k5eWlkSNHqk6dOqbHgodiRwKwiekdSQksIvPnz9f//d//KSUlRStXrlRQUBALDijhXC6XHA5H/n9tkZSUpM2bN2vDhg3q1KmT8vLyFBwcTAHEJbEjAfuwI83uSEpgIdu8ebPWrVunrVu36qWXXlJqaqrKlSunvn37mh4NQCFxL7RTp04pMDBQWVlZ8vf3t2bR7d+/X6dOndK4ceP0j3/8Q7m5ubrtttsknX/Kn5cXr0TAeexIwD7sSM/YkZTAQlanTh35+flpwIABCgoKUlxcnMqVKycfHx9uDAElkHuJrV27VnPnzlVISIicTqeGDh2qoKAg0+MVid69e+f/f1JSkpYvX65WrVpJEsc8/A47ErALO9JzdiRH10J08OBBnTt3Tg0bNlRQUJAOHjyo6dOn65577pGfnx/LDShh3Mtt06ZN+vDDDzV8+HClp6frp59+ksPh0Llz50yPWKgWLlyoSZMm6ZtvvpEkZWRkKDY2VuHh4apdu7bh6eBp2JGAXdiRnrUjOcIWksjISL3++uuaNGmSUlNTJUnHjx9XmzZt1Lx5c94mHShBUlNTtX///vzXNiQkJOjFF1/U0aNHdeTIEb311ltaunSpli1bZnrUQvP5558rNjZWVapUUbVq1XT27Fldd911atq0qYKDg02PBw/DjgTswY70zB3J00ELwcKFC7V8+XJNmjRJaWlpOnr0qBISEtS2bVudPXtWEm+TDpQU2dnZmjt3rpKSkvTaa6/p1ltv1XXXXaeoqChlZGTo/fffV0hIiBITE9WhQwfT4xaKlJQUrVu3TpGRkdq+fbvWrFmjVatWKTAwUDNmzOB4h99hRwL2YEd67o6kBBaCEydOKDw8XCtXrtTOnTt1/PhxbdiwQTk5OerVq5fp8QAUID8/P7Vr107Z2dmaOHGihg8frsaNG2vq1Kl69913VaNGDe3fv18//vijatWqZXrcQuFyufTtt99q4MCBSk9PV6tWrfTCCy9o3rx5OnbsmEJCQqx5wT/+GjsSsAc70nN3JCWwEAQFBSk6OlpZWVkaPHiw2rZtqwULFig9PZ0bQrCCLW/o4L6edevWlb+/v6Kjo/XOO+9o9OjRGjNmjD755BMtWrRIp0+f1ksvvaQGDRqYHrlA7d27V6VKlVLlypU1e/Zs7dq1S6GhoapevbpWrVqln376Sf7+/pJ4ZAf/w46E7diR7EhP2JEOF0+8LxAxMTE6ePCg0tLSNGTIEFWsWFGlS5fWiRMnlJCQoMjISL3//vsl9l4O/N6KFSt0/Phx1a1bV/Xr15efn5/pkQrdkSNHdOjQITVr1ky5ubny8SnZ9zG5b6zu27dPGRkZql69uk6ePKklS5bov//9r0aPHi0vLy+dOnVKDodDNWvWLFE3cGfNmqXly5erfPny+vnnn/XEE0/ogQce0PDhw+Xt7a3t27dr4sSJuummm0yPCg/AjoSbjftRYkeyIz1vR1ICC8Dnn3+u5cuXq3fv3tq4caM2bNigCRMm6OTJk5o9e7by8vL05ptvcmPIElFRUfryyy8VHBwsX19f3X///erYsWOJXnS5ubmKi4vTvn37VLp0adWoUUM9evQo8fd2JiQkaMSIEapbt67279+vQYMG6YYbbtD69eu1d+9evfzyy/mf/VOSrFq1SpMnT1ZkZKSysrK0Z88ejRgxQu+88468vLyUnp6u+vXr6x//+IfpUeEB2JFws3E/SuxIdqRn7siSfTdEEUhLS9O6des0bdo0BQYGqlu3bvroo480YsQIrVy5Us2aNZPD4dB1111nelQUgV27dikpKUlLliyRl5eXJk2apHXr1snLy0vt27cvsYvOx8dHrVu31rx587Rnzx69++67ks5/3k1JumfvQt99952SkpL04YcfqmHDhoqJidHixYs1ePBg9e7dW7NmzZLT6TQ9ZqE4evSoGjdurICAAPn5+alFixZq1aqVvvvuOw0YMMD0ePAg7Ei42bofJXYkO9Izd2TJvfuhiLhcLqWlpengwYP5p/Xt21c1atTQmTNnFBAQwHKzxKFDhzRx4kQdPnxYP/zwgyRp4MCBqlmzpuLj4/M/F6YkufAAHhgYqA4dOqhjx47avn27EhISJJW814Ll5ubq9OnTeuSRR/TNN9/oxhtvlNPpVFhYmOrWrauZM2eqWrVqeu6551S/fn3T4xaKMmXK6MSJEzp9+rR8fX3lcDjk5+enrKwsSeLt/ZGPHQnJzv0osSPZkZ69IymBV2nXrl06evSoAgMD1axZM23dulUHDhyQJK1evVqnT58usfdw4GLZ2dmqUaOGnn76aVWsWFGrVq3S4cOH5efnp4EDB+rOO+9Uw4YNTY9ZoFwuV/7TWBISErRjxw516tRJb7zxhrKzs7Vy5Urt2rVL33//vU6fPm142mvnPmj7+PioXLlyioqKUmpqquLj4/P/HO6++25VqVJFkhQQEGBs1sIQFxen+fPnKyoqSrfffrt++OEHzZw5UytWrNDixYu1YcMGde7cWVLJu1GDv48dCTcb96PEjmRHev6O5DWBV+Hzzz/XihUrVK1aNb3xxhtKSkrS6tWr9e2336pevXpKSkrSRx99xOsbLDFr1ixt27ZNlSpV0vPPP689e/YoKipK9evXV/v27VWzZk3TIxaqzz77THPmzFH16tUVEhKiwYMHKyAgQB988IGOHDmiU6dOafr06QoKCjI96lVzP11ny5YtSkhIUNWqVdWyZUtlZ2erR48eevDBB9W4cWNNnz5dQ4YMUbt27UyPXKA+//xzrVy5UoMGDdJTTz2lyZMnq1q1aoqMjFRGRoby8vI0ZMgQ1alTx/So8ADsSLjZvh8ldiQ70nN3JCXwb8jLy9PXX3+tqKgoRUZGaseOHTp37pxSU1Pl6+urChUq6NSpU6pXr55uuOEG0+OiCMyZM0dxcXF69NFHNWvWLNWoUUNvvPGGvvvuO02dOlX33nuv+vTpIx8fH4+556cgxcXFKSYmRp9++qk++OADrV27VnfddZf++c9/qnz58tq9e7eqVq2q6tWrmx71mm3atEmvv/66OnfurMOHD+uXX37Rs88+q7Jly+qRRx5RjRo1NGHCBNWqVavEvNg/KytLR48e1VtvvaXp06drzpw52rx5s15//fX8e7UlKTMzk6f0gR2J37F9P0rsSHakZ+9ISuAV2rZtm/z9/ZWcnKxDhw7ptttuU2Jioo4fPy6n06n77rtP/fr1Mz0mitD+/fs1ZswYff7550pOTtacOXNUunRpZWdna8SIETp48KCuv/56Va1a1fSoBeaPL2CPiIiQr6+v7r33Xi1atEi33npr/j2a/fv3V/PmzQ1OW3AOHDigGTNm6P7771fz5s2VmpqqVatWafv27Xr//fe1c+dO9evXT88884xHvej7Wmzfvl0ul0sBAQGaMmWKateurV27dmny5Mk6evSoBg0apNjYWJUqVcr0qPAA7EhcyMb9KLEj2ZHFa0cW/xpeRJYvX64dO3boxhtv1KFDhxQTE6Nu3bopMjJSbdq00aFDh+RyuTzmxZ4oXD/++KMyMzOVk5OjvXv3av369Xr00Ud11113adOmTRo0aJBuv/32ErXgLlxu27Zt07Zt2+Tt7a0mTZpo06ZNuvHGG9WlSxfVrVtX1atXL/af9+X+t5yVlaUvvvhCe/fu1Y4dO+R0OlWlShXdcccd+vnnn3X8+HHdfvvtmjJlimbOnKlff/3V8OQFY9myZfr+++91ww036JdfftGKFSs0efJk+fr6KjExUddff32JuCcXBYMdCTcb96PEjmRHFr8dyUdEXIF169blH7iCgoLUpEkT+fn5KTExUUuWLFF8fLzGjx9fYp/O8FeSkpKUk5Oje+65x/QoRSIqKkrR0dG65ZZb1Lt3b2VmZurIkSNq0qSJfv75Z3Xv3l2PP/64vL29TY9aoNy/33PmzNHSpUvVqFEjzZgxQ7Nnz9aaNWs0YMAArVy5Uvv27dPEiRMVEhJieOKr517ma9euVXJysvLy8lSvXj3l5uZqy5YtCg0Nlb+/v5xOp/Ly8pSXl6emTZtqzZo18vf3Nz3+NXMf85588kmVKVNGXbp00ZYtW/T000/rzjvv1Ndff63x48fL19fX9KjwAOzIS2M/2rEfJXYkO7L47UhK4GW4n7N84sQJ9e/fX0FBQdq5c6e2bdsmHx8fbdu2TWfOnNG7775b7O/RuVoul0vp6elq0KCBUlNT89/1qaRatWqV5s6dq8mTJysgIEAVK1bUJ598ot9++03Tpk1TfHy83n///WJ9cL+cdevWafny5ZoxY4aioqLUokULVaxYUYcOHdLSpUu1ceNGTZs2rdi/vsHhcGjdunUaN26cunTpou+++06SdPbsWf3www/64osvlJqaqkGDBqlq1ar594h68tM+rsQfj3khISHat2+fTpw4oc6dO2vPnj0qX758/us6YDd25OWxH+3ajxI7kh1ZvHYkJfAyvLy8dPLkScXFxalSpUo6e/asIiMj9dBDD+nWW2/V448/7rEv9iwqDodDHTp00JEjR9SzZ08NHz48/y1wS6KUlBS1aNFC1atXV05OjqTzi7569erasWOH3n//fY9796eClJmZqW7duik2NlZbtmzR1KlTtWLFivwXfg8ZMqREPMXnyJEjmjlzpj777DP99ttvSk5OVvXq1fXzzz+rYsWKysnJUZcuXdS6devf/Vxxf6Tjz455s2bN0gMPPJD/7n6AGzvy8tiPdu1HiR3JjixeO5ISeBkul0u7d+/Wvn37FBQUpIoVK2r8+PG/+3DL0qVLG5zQcwQHB+vpp5/WtGnT5OXlpY4dO5oeqVCEhIRo/vz56tSpk+rVqydJ+uWXX1S3bl0NGzbM4x/6v1YVKlTQ66+/rlq1aik6OlrS+ReEt2nTpkR96Kufn5+8vb11/PhxrV69WuHh4Tp16pQ2bdqk77//Xm3btlVycrJq1Kihli1bFvvF5vZnx7wJEyaUqL9bFBx25JVhP9qxHyV2JDuyeKEEXobD4VDTpk01adIkNWzY8E9/iUvKL/a18vPz08MPPyxvb29NmjRJXl5eat++vemxClzTpk2VlJSkzz77TK1atZK3t7d27typvn37WrHgbr/9doWFhenYsWOKj49XRkaGEhIS9N5775kerUBVrFhRL730knx8fPTTTz9p6NCh2rRpk5o0aaJ+/frpxhtv1IQJE3TLLbeYHrVAXckxD3BjR14Z9qMd+1FiR7Ijixc+IuJvyMvLK5EvZi5I2dnZio2N1ccff6xRo0aVuA8ElaTjx49r+fLlWrNmjYKCgvTUU0/p5ptvNj1WkTlx4oRWrFihlStX6vrrr1f//v1L7FN84uPjNX/+fPXs2VNTpkzRiy++mP/0ltzcXPn4lOz70Tjm4e/g9+Xy2I92YEeyI4sLSiAKXHZ2tuLi4tS4ceNi/+Lny3G/5sGWezj/KDc3V5JK9EH+2LFjioiI0N69ezVw4EC1adPmos+BAoArxX60BzsSno4SiELBQQAlhdPpVGZmpsqUKcPvNYBrxnEEJQk7sviiBAIAAACARTz7o+wBAAAAAAWKEggAAAAAFqEEAgAAAIBFKIEAAAAAYBFKIAAAAABYhBIIAAAAABYpcZ9g6XQ6lZGRIV9fXz6rBABKOJfLpZycHAUEBMjLi/s1/wo7EgDs8Ff7scSVwIyMDO3fv9/0GACAIlSnTh2VLVvW9Bgejx0JAHa51H4scSXQ19dXkvTkk08qLS3NyAxxcXHq2rWrkeyDBw8ayb3Qnj17VK9ePSPZN910s5Fct5iYhQoLe9BItsvlNJLrFhsbox49wozOYJLJ65+Xl2sk183kMS84OFgzZ87MP/bj8tx/TgMGPGVsRy5ZsljdunU3kt2p8wAjuW6Dnu6qKVPjjOUvWxphLFsye6z4f/+vvpFct48/HqOhQ18zlt/xoZ7Gsu9veYeWrtthLP+HXWZvGw8dGqaPP44p8tyyZa9Tv34dLrkfS1wJdD+9JS0tTSkpKcbmMJVdqlQpI7l/ZGqOY8eOGcn1hBmczjwjuRcy+W/OE5i6/qZLoGT+756nNl4Z23fkqdMZRnI9ZQbT/05NzhAQcL2R3AsdP/6LsezMc9nGsk3nnzrlAf/uDc5wqf3ICygAAAAAwCKUQAAAAACwCCUQAAAAACxCCQQAAAAAi1ACAQAAAMAilEAAAAAAsAglEAAAAAAsQgkEAAAAAItQAgEAAADAIpRAAAAAALAIJRAAAAAALEIJBAAAAACLUAIBAAAAwCKUQAAAAACwCCUQAAAAACxCCQQAAAAAi1ACAQAAAMAilEAAAAAAsAglEAAAAAAsQgkEAAAAAItQAgEAAADAIpRAAAAAALAIJRAAAAAALEIJBAAAAACLUAIBAAAAwCLGS+Du3bv17LPPXvL8YcOGaebMmUU4EQAA5rEfAQCFxXgJrF+/vj766CPTYwAA4FHYjwCAwmK8BG7ZskVdunRRRkaGhg8frg4dOqhz586aMGGCXC6XJOk///mPwsPD1a5dOw0aNEiZmZmGpwYAoHCxHwEAhcXhcm8SQ7Zs2aLRo0erWbNmOn78uMaNG6e8vDz1799fQ4cOVUxMjA4cOKDZs2fLz89PDz/8sB5//HH16NHjTy8vKytLe/bsKdorAQAwql69eipVqpTpMQpUQe9HiR0JALa51H70MTDLn9q4caOGDx8ub29veXt7a86cOZKkmJgYtWvXTqVLl5Yk3XTTTUpPT//Ly+vatatSUlIKdeZLSU5OVqNGjYxkG+70kqRt27bprrvuMpLt5+dvJNdt06ZEhYY2M5LtdOYZyXXbsmWzmjRpanQGk0xe/7y8XCO5biaPeSEhIYqLizOSXVQKej9KUrdu3Y3tyKSkrbr77sZGsh98+AUjuW7DXgnX2PeijeUvmDfeWLZk9lhRu7aZ2yVu0dHTFB7+T2P5Dz7xpLHshzs01vyvthrL35e031i2JI0Y8ZjeemtOkeeWLx+goUPDLnm+x5RAHx8fORyO/K9TUlLk7++ff56bw+HwiKIDAEBRYD8CAAqa8dcEuoWGhiomJkZOp1PZ2dl69tlnlZSUZHosAACMYj8CAAqax5TAIUOGyNfXV927d1ePHj3UsmVLtW/f3vRYAAAYxX4EABQ0408HbdKkieLj4yVJb7/99kXnjx079rJfAwBQErEfAQCFxWMeCQQAAAAAFD5KIAAAAABYhBIIAAAAABahBAIAAACARSiBAAAAAGARSiAAAAAAWIQSCAAAAAAWoQQCAAAAgEUogQAAAABgEUogAAAAAFiEEggAAAAAFqEEAgAAAIBFKIEAAAAAYBFKIAAAAABYhBIIAAAAABahBAIAAACARSiBAAAAAGARSiAAAAAAWIQSCAAAAAAWoQQCAAAAgEUogQAAAABgEUogAAAAAFiEEggAAAAAFqEEAgAAAIBFKIEAAAAAYBEf0wMUFh8fX/n4+BnMN5Nds2YDI7kXWrDgM2Nz1K17j5FcT5jhppsaGsm9UFjYc8ayjx07ZCzbLTS0h5HcpK1LjeReqJRfaSO5fr7+RnKLO5fLKZfLaTTfhB/+b5eR3P8JNzrDddeVM5ZteobU1INGcj1lhlkfjzeW/XCHeUbzU1IOGMuWpG3btikm5oMiz83KytKePXsueT6PBAIAAACARSiBAAAAAGARSiAAAAAAWIQSCAAAAAAWoQQCAAAAgEUogQAAAABgEUogAAAAAFiEEggAAAAAFqEEAgAAAIBFKIEAAAAAYBFKIAAAAABYhBIIAAAAABahBAIAAACARSiBAAAAAGARSiAAAAAAWIQSCAAAAAAWoQQCAAAAgEUogQAAAABgEUogAAAAAFiEEggAAAAAFqEEAgAAAIBFKIEAAAAAYBFKIAAAAABYhBIIAAAAABahBAIAAACARSiBAAAAAGARSiAAAAAAWIQSCAAAAAAW+csSuGXLFnXp0qUoZgEAoNhgPwIAiiseCQQAAAAAi/j8nW9OTk7WSy+9pAkTJui///2vIiMj5eXlpUqVKmnkyJGqWbOmhg0bpjJlymjfvn06duyYbr75Zr377rsKCAhQ/fr1NXDgQCUmJiotLU0DBgxQr169JEnz58/Xl19+KafTqcDAQI0cOVK1atW67OUBAOAJ2I8AgOLkih8J3Lx5s4YPH66pU6cqKytLM2bM0OzZs7VkyRJ16dJFzzzzjFwulyRpz549mjlzppYtW6ajR49qxYoVkqTs7GxVqFBB0dHR+uijj/TOO+8oKytLW7duVWxsrKKiohQbG6sBAwZoyJAh+dmXujwAAExjPwIAipsreiTw2LFjevrpp/Xoo4/qlltu0XvvvafOnTurYsWKkqQHHnhAb7/9to4cOSJJatGihfz8/CRJderU0alTp/Ivq23btpKk2267TdnZ2crMzNTatWt16NAhhYeH53/f6dOndfLkyb+8vEuJiVl0JVet0GzevNFovmkLFnxmegRjZs4cZ3oEY4YNe9T0CEZ9+OEwQ8mmcv8nceN60yMYURz3oyTFxcVd2xW/RsnJyUbzTYqIGGN6BKMSElabHsGYNWtWmh7BmPj4ecayt23bZizbk2b4oysqgd7e3oqIiNDgwYPVsWNHOZ3Oi77H5XIpNzdXkuTv759/usPhyL8HVJJKlSqVf7r755xOp7p3766XX35ZkuR0OpWWlqby5cv/5eVdSljYA0pJOXYlV6/Abd68UU2b3mMk+4YbbjaSe6EFCz7TQw89YSS7fPlKRnLdZs4cpyeffNlI9k03NTSS6zZs2KMaO/ZLY/nHjh0yli2dL4D/+tdYI9lJW5cayXVL3Lheze5pYSS7atWqWrhovpFsqXjuR0nq2rWrUlJS/s5VLTDJyclq1KiRkeyGDdsbyXWLiBijgQNfM5b//febjWVL5wvgvfe2MZLt7f23XgFV4NasWanWrc39/gUEBBrLjo+fpy5dehrLT0k5YCxbOl8A77rrriLPzcrK0p49ey55/hU9HbRy5cpq2LChXn31Vb3yyitq1KiRli1bpvT0dEnSwoULFRgYqBo1alzVkM2bN9fSpUuVlpYmSfryyy/Vt2/fq7osAACKCvsRAFAc/a27RcLCwvTVV19p/fr16tevn/r27Sun06mKFStq2rRp8vK6ujcbbd68uZ566in1799fDodDZcqU0aRJk/LvDQUAwJOxHwEAxclflsAmTZooPj4+/+upU6fm/3/v3r0v+v6xY8de8ut9+/b97rwLv+7du/ffvjwAAExhPwIAiis+JxAAAAAALEIJBAAAAACLUAIBAAAAwCKUQAAAAACwCCUQAAAAACxCCQQAAAAAi1ACAQAAAMAilEAAAAAAsAglEAAAAAAsQgkEAAAAAItQAgEAAADAIpRAAAAAALAIJRAAAAAALEIJBAAAAACLUAIBAAAAwCKUQAAAAACwCCUQAAAAACxCCQQAAAAAi1ACAQAAAMAilEAAAAAAsAglEAAAAAAsQgkEAAAAAItQAgEAAADAIpRAAAAAALAIJRAAAAAALEIJBAAAAACL+JgeoLCUK1dJ5866jOVXCKxiJDc9PcVI7h+ZmiMrK9NI7oXS0g4byfX29jWS+z+P6ocfdhtLb9O9m7Fst6b3tTKSm5S0zEju7zgcduUWcwEBgSpbNstYftmyFY3knjqZZiTXU2Y4e/aMsWzTM3TrNsRI7oXatHnMWPb27V8by5YkX99SxrLnrN9gLFuSbr2utJEZfB0O1S7tf8nzeSQQAAAAACxCCQQAAAAAi1ACAQAAAMAilEAAAAAAsAglEAAAAAAsQgkEAAAAAItQAgEAAADAIpRAAAAAALAIJRAAAAAALEIJBAAAAACLUAIBAAAAwCKUQAAAAACwCCUQAAAAACxCCQQAAAAAi1ACAQAAAMAilEAAAAAAsAglEAAAAAAsQgkEAAAAAItQAgEAAADAIpRAAAAAALAIJRAAAAAALEIJBAAAAACLUAIBAAAAwCKUQAAAAACwCCUQAAAAACxCCQQAAAAAi1ACAQAAAMAiHlMCFy1apFatWunJJ5+87Pe1adNGu3fvLqKpAAAwi/0IAChoPqYHcIuNjdXzzz+v7t27mx4FAACPwX4EABS0QimBTqdTY8aM0c6dO5WRkSGXy6W33npL8+fPV6lSpfT999/rl19+UbNmzTRixAiNGzdOu3fv1pEjR/Trr7+qV69eGj9+vJKSkpSXl6e6detqxIgRKlOmTGGMCwBAkWA/AgA8QaE8HXTnzp1KS0vT3LlztWzZMoWFhWn69OmSpF27dunTTz/VsmXLdODAAc2dO1evvfaa6tWrp1deeUX9+vVTRESEvL29tWjRIi1ZskTBwcEaP358YYwKAECRYT8CADxBoTwSeOedd6p8+fKKjo7WTz/9pC1btiggIECBgYEKCwtTQECAJKl79+765ptv9Nhjj/3u59euXavffvtNGzdulCTl5OQoKCjob80wa1ZEwVyZq7R8RYzRfNNWr15hegRj4uLmmh7BmIiIMaZHMCr8/qaGchOM5F4oMdH8DMWBJ+xHSYqOjrz2K3MN1qxZaTTfpLnzZpgewaikpK2mRzBm5MjHDaabzJZiYswec0y79brSpke4SKGUwLVr1+rtt9/WE088obZt2+rGG2/UkiVLJEne3t753+dyueTldfGDkU6nU6+99ppatmwpScrIyFBWVtbfmqFv34FKSz1+Ddfi6i1fEaNOHcOMZGdlnzWSe6HVq1eoTZuORrIDAsobyXWLi5urrl0fMZIdElLLSK5bRMQYDRz4mrH8Nt27GcuWzhfA6KWbjWR/POYVI7luiYkJatbsXiPZVatW1cKF84xkXw1P2I+SFB7eR6mpqVd5La7NmjUr1bp1eyPZwZX/YSTXbe68GXqk5wBj+T8c3GUsWzpfAO++u7GR7G7dhhjJdRs58nGNHj3bWP727V8by46JiVRYWB9j+WOizD4wdOt1pfVdZtHfPvd1OFS7tP8lzy+Up4MmJiaqdevW6tWrl+rVq6dVq1YpLy9PkrR8+XJlZ2crKytLMTExat269UU/37x5c0VFRSk7O1tOp1MjR47UhAkTCmNUAACKDPsRAOAJCqUEhoeHa+vWreratavCwsJUvXp1HTlyRE6nU/7+/urVq5e6du2qRo0a6cEHH7zo5wcPHqxq1aopLCxMnTt3lsvl0rBhwwpjVAAAigz7EQDgCQrl6aC1atVSbGzs704bMWKEhg0bptDQ0D/9rKPIyP89V9jf31+jRo3608tevXp1gc4KAEBRYT8CADyBx3xYPAAAAACg8BXph8WPHTu2KOMAACgW2I8AgKLEI4EAAAAAYBFKIAAAAABYhBIIAAAAABahBAIAAACARSiBAAAAAGARSiAAAAAAWIQSCAAAAAAWoQQCAAAAgEUogQAAAABgEUogAAAAAFiEEggAAAAAFqEEAgAAAIBFKIEAAAAAYBFKIAAAAABYhBIIAAAAABahBAIAAACARSiBAAAAAGARSiAAAAAAWIQSCAAAAAAWoQQCAAAAgEUogQAAAABgEUogAAAAAFiEEggAAAAAFqEEAgAAAIBFKIEAAAAAYBEf0wMUluysc8rKyjSWbyq7cuXqRnL/qHKlG4zkpv96zEjuhc6dyzCSe/jwXiO5njLDN7EuY9mSFH5/U30Tu9hI9mNPDjeS6wkzlC1T2khucffUyyN0NivHWP6Lb08wkjvtndFGci+UefY3Y9n33dfPWLbpGRITFxnJ/Z/Hjc5Qu/ZdxrIlqVq1OsayX3iwt7FsSVq+fJGRGYKDK2vWrGmXPJ9HAgEAAADAIpRAAAAAALAIJRAAAAAALEIJBAAAAACLUAIBAAAAwCKUQAAAAACwCCUQAAAAACxCCQQAAAAAi1ACAQAAAMAilEAAAAAAsAglEAAAAAAsQgkEAAAAAItQAgEAAADAIpRAAAAAALAIJRAAAAAALEIJBAAAAACLUAIBAAAAwCKUQAAAAACwCCUQAAAAACxCCQQAAAAAi1ACAQAAAMAilEAAAAAAsAglEAAAAAAsQgkEAAAAAItQAgEAAADAIpRAAAAAALAIJRAAAAAALEIJBAAAAACLUAIBAAAAwCI+13oBq1ev1pQpU5STkyN/f3+9+uqrKleunP79738rOztbLpdLDz30kHr37q0DBw786emSNGXKFK1cuVJOp1PVqlXTqFGjVKVKFfXp00d33HGHtm/frpSUFIWGhmr06NHy8qK/AgA8F/sRAOCprmlT/Pjjj/rggw8UERGh2NhYjR49WkOHDtWMGTPUpk0bLVq0SBEREUpOTpbT6dTMmTP/9PTY2Fjt379f8+fP1+LFi9WyZUuNGDEiP+fw4cOKjIzUkiVLlJCQoK1bt17zFQcAoLCwHwEAnszhcrlcV/vDUVFR+uijj1S1atX809LT0zVgwAB98sknaty4sUJDQ9WxY0cFBQVpzZo1evXVVy86/bnnntPu3btVtmxZSZLT6dTZs2e1atUq9enTRw8++KB69OghSXrsscfUp08fdejQ4U9nysrK0p49e672KgEAiqF69eqpVKlSpsfI54n7UWJHAoBtLrUfr+npoE6nU6Ghofrwww/zT0tJSVFwcLC6deumjRs3atOmTfrkk0+0aNEitW7dWl999dVFpzudTg0YMEC9evWSJGVnZ+vUqVP5l+nv75///w6HQ1fSWx8Nf1ypqanXcvWu2uo1X6lN60sv4cJUuXJ1I7kXmjtvhh7pOcBIdvqvx4zkun39dbzuu6+LkWxv72t+dvc1WbEiVh079jCWX736rcayJWn69Hf01FPDjWQ3DL3XSK7boP6dNOXT5Uayy5Yprcd6tjKSfTmevB8l6Ztt+3Q2K6dgruzf1OWeeorfaKaITntntJFct7i4uera9RFj+fXrtzSWLUljxgzWa69NNpK9fftKI7lupndk7dp3GcueNGmkhgwx92/vwIH/GMuWpOXLF6lTpweKPDc4uLJmzZp2yfOv6emgoaGhSkxM1IEDByRJ69atU7du3fTcc89p2bJluv/++zVq1CiVKVNGhw8f1osvvvinpzdv3lwLFizQmTNnJEkTJ07UK6+8ci2jAQBgDPsRAODJrumhg9q1a+vNN9/UCy+8IJfLJR8fH02ZMkUVKlTQv//9b82dO1fe3t5q166d7r77bgUFBf3p6Y0aNVJqaqp69uwph8OhkJAQjR07tqCuIwAARYr9CADwZNf8/LFOnTqpU6dOF50eHR190Wm1atX609MdDoeeffZZPfvssxedFxkZedmvAQDwROxHAICn4n2kAQAAAMAilEAAAAAAsAglEAAAAAAsQgkEAAAAAItQAgEAAADAIpRAAAAAALAIJRAAAAAALEIJBAAAAACLUAIBAAAAwCKUQAAAAACwCCUQAAAAACxCCQQAAAAAi1ACAQAAAMAilEAAAAAAsAglEAAAAAAsQgkEAAAAAItQAgEAAADAIpRAAAAAALAIJRAAAAAALEIJBAAAAACLUAIBAAAAwCKUQAAAAACwCCUQAAAAACxCCQQAAAAAi1ACAQAAAMAilEAAAAAAsIiP6QEKS25etnJys43lm8o+k3HSSO4fmZojICDQSK4nzJCe/rOR3AtlZp42ln3w4C5j2aZn6P/aUCO5F7qj9e1Gckv5eBvJLe7ua9dUDm8zf3Z5J06oe7dWRrKnvTPaSK6nyMnJMj2CsRl8fPyM5HrKDN9+u95Ytun8M2dOGst2O3HiSJFn+vrmXfZ8HgkEAAAAAItQAgEAAADAIpRAAAAAALAIJRAAAAAALEIJBAAAAACLUAIBAAAAwCKUQAAAAACwCCUQAAAAACxCCQQAAAAAi1ACAQAAAMAilEAAAAAAsAglEAAAAAAsQgkEAAAAAItQAgEAAADAIpRAAAAAALAIJRAAAAAALEIJBAAAAACLUAIBAAAAwCKUQAAAAACwCCUQAAAAACxCCQQAAAAAi1ACAQAAAMAilEAAAAAAsAglEAAAAAAsQgkEAAAAAItQAgEAAADAIpRAAAAAALAIJRAAAAAALFJgJfDMmTP64osvtGvXroK6SEnSuHHjdOjQoQK9TAAAigr7EQDgaXyu9QJ27typuXPnatOmTWrbtq3atWun1atXa8qUKcrJyZG/v79effVV3XnnncrJydHYsWO1adMmeXt7q0GDBho+fLjKlCmjL774QtHR0fL19VWpUqX05ptvqnbt2qpUqZKeeeYZBQUF6ZFHHlG7du3k5+dXENcdAIBCw34EAHiqq34kcPfu3erRo4cmTpyo5s2b66uvvtKIESOUmZmpDz74QBEREYqNjdXo0aM1dOhQZWZmasqUKUpLS9PixYu1ePFiOZ1Ovffee8rLy9OYMWM0Y8YMLVy4UD179tS2bdskSU888YTi4+P1r3/9Sxs2bFCnTp0UFRVVYH8AAAAUJPYjAMDTXfUjgV5eXvLy8pLD4ZDD4cg/PTExUWlpaerXr1/+aQ6HQ4cPH1ZCQoKef/55+fr6SpL69OmjZ555Rt7e3urYsaPCw8PVqlUrNW/eXC1btvxdnre3d36ml9dfd9f586Ov9qoViPXr1xjNN23p0gWmRzAmNnaO6RGMSUhYbXoEo1atWmp6BGNCa15vegSP4en7UZKcv/567Vf0GuSdOGEkNy5urpFcT5vBpHHjnjeUbCr3f+Lj55kewZg1a1aaHsGopKStpke4yFWXwNtuu02LFi3Srl27FB0drXHjxql9+/YqU6aMQkND9eGHH+Z/b0pKioKDg+V0On+3EJ1Op3JyciRJ48eP1/79+7Vx40ZFRERo8eLFmjhxombPnq0FCxYoMDBQ4eHhGjVqVP6SvJyHHw7XsWOpV3v1rsn69WvUokVrI9nlygUZyb3Q0qULdP/9DxnJ9vX1N5LrFhs7Rz16PGYkOz39ZyO5bgkJq3XvvW2M5fv5lTaWLZ0vgO3a3W8ke/T06UZy3UJrXq9NB838/pXy8VbD6lWMZF+Kp+9HSfKqUEEOb+8Cvd5XKu/ECXlXqmQku3NoWyO5bnFxc9W16yPG8m+5pamxbOl8AXz55Q+MZH/33SYjuW7x8fPUpUtPY/kZGSeNZa9Zs1KtW7c3ln/mzElj2dL5Anj33Y2LPDckJERLliy+5PnX/MYwDRo00JgxY7R48WLdcMMNaty4sRITE3XgwAFJ0rp169StWzedO3dOLVq00JdffqmcnBw5nU5FRUWpWbNmSk9PV8uWLRUYGKh+/frpX//6l3bv3i3p/IJ0L7vOnTtf8YIDAMAk9iMAwFNd8xvDuJUtW1aPPXb+EZA333xTL7zwglwul3x8fDRlyhQFBARo0KBBevfdd9WjRw/l5uaqQYMGGjlypMqVK6dBgwapX79+8vf3l7e3t9566y1J0quvvlpQIwIAUOTYjwAAT1NgJfBCnTp1UqdOnS463d/fX6NGjfrTnwkPD1d4eHhhjAMAgEdgPwIAPAEfFg8AAAAAFqEEAgAAAIBFKIEAAAAAYBFKIAAAAABYhBIIAAAAABahBAIAAACARSiBAAAAAGARSiAAAAAAWIQSCAAAAAAWoQQCAAAAgEUogQAAAABgEUogAAAAAFiEEggAAAAAFqEEAgAAAIBFKIEAAAAAYBFKIAAAAABYhBIIAAAAABahBAIAAACARSiBAAAAAGARSiAAAAAAWIQSCAAAAAAWoQQCAAAAgEUogQAAAABgEUogAAAAAFiEEggAAAAAFqEEAgAAAIBFfEwPUNBcLpckqXLlykbnqFq1ipHcMmUqGMn9o+BgM3/+vr6ljOReKDi4kpFcP788I7kXMvV7L0m+vv7Gst2qVAk2klvKx9tIrifM4Od9/r5M97Efl+f+c3LlmT1emMo3tZs8ZYYKFcoZyzY9g+1/95mZZm8fVali7vZB2bKljWW7hYSEFHlmcPD52ySX2o8OVwnbnL/99pv2799vegwAQBGqU6eOypYta3oMj8eOBAC7XGo/lrgS6HQ6lZGRIV9fXzkcDtPjAAAKkcvlUk5OjgICAuTlxSsc/go7EgDs8Ff7scSVQAAAAADApXG3KQAAAABYhBIIAAAAABahBAIAAACARSiBAAAAAGCR/w+oktVFNGRo4QAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1080x1800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_count 1    self.capacity  20\n",
      "0  ------------------------------------------------\n",
      "DecoderLayer@trg4\n",
      "[1, 1, 64]\n",
      "tensor([[[-2.1456,  0.3651, -1.0831, -0.4128,  1.5202,  1.9401,  0.1774,\n",
      "           0.3350, -0.6851,  0.1457, -0.6312, -0.8487, -0.7933, -1.5675,\n",
      "           1.0460, -1.1919,  0.4566,  1.8388, -0.5084,  0.7221, -0.3347,\n",
      "          -0.6126,  0.7347,  0.3247,  0.6480, -0.2181, -0.7397,  1.2854,\n",
      "           0.0535,  0.7286,  0.7636, -0.1191, -0.1510, -0.8449, -0.8976,\n",
      "          -0.4689,  0.0614,  0.7150,  0.5500,  0.3988, -0.3978,  1.6192,\n",
      "          -0.4647, -0.8919,  0.2631,  1.5261,  2.4268, -1.2593, -0.2543,\n",
      "          -0.9964, -0.4749,  0.8878,  0.3588, -0.5032, -1.5154,  1.3939,\n",
      "          -0.2291, -1.4550,  0.7933, -0.0296, -1.3634,  0.5654, -2.1877,\n",
      "           1.7002]]])\n",
      "src = ['i', 'can', 'drink', 'water']\n",
      "predicted trg = ['ich', 'konnen', 'wasser', 'trinken', '<eos>']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_count 1    self.capacity  20\n",
      "0  ------------------------------------------------\n",
      "DecoderLayer@trg4\n",
      "[1, 1, 64]\n",
      "tensor([[[-1.4940e+00, -1.5930e-01, -1.0580e+00, -1.0116e+00,  9.1183e-01,\n",
      "           2.2354e+00, -1.5837e-01,  3.4703e-01, -6.4350e-01,  6.9168e-01,\n",
      "           3.9615e-01, -5.1642e-01, -6.9277e-01, -2.2253e+00,  1.0529e+00,\n",
      "          -1.7562e-01,  6.2090e-01,  1.2872e+00,  8.6541e-02, -9.4496e-02,\n",
      "           2.3152e-01, -7.8664e-01, -1.9133e-01, -4.3388e-01,  9.4037e-01,\n",
      "          -6.7833e-01, -6.3566e-01,  2.8480e-01, -5.0138e-01,  5.0984e-01,\n",
      "           4.7199e-01,  9.1885e-02,  2.4657e-01, -3.8347e-01, -5.5224e-01,\n",
      "           4.2976e-01,  5.4698e-01, -4.6524e-01,  8.0617e-01, -4.1947e-01,\n",
      "           3.2164e-02,  1.2576e+00, -8.1290e-02, -1.3973e+00,  1.0309e+00,\n",
      "           2.2332e+00,  2.6824e+00, -1.2395e+00, -4.3061e-04, -8.2146e-01,\n",
      "          -2.3078e-01,  3.4688e-01,  7.8351e-01, -6.1124e-01, -8.7725e-01,\n",
      "           1.7502e+00, -7.8963e-01, -1.2664e+00,  5.3656e-01, -7.3806e-01,\n",
      "          -1.9743e+00,  8.1836e-01, -2.0419e+00,  1.7642e+00]]])\n",
      "src = ['i', 'can', 'drink', 'beer']\n",
      "predicted trg = ['ich', 'konnen', 'bier', 'trinken', '<eos>']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_count 1    self.capacity  20\n",
      "0  ------------------------------------------------\n",
      "DecoderLayer@trg4\n",
      "[1, 1, 64]\n",
      "tensor([[[-1.8826, -0.1021, -1.3466, -0.8823,  0.8537,  1.9782, -0.1491,\n",
      "           0.5957, -0.8040,  0.5148,  0.3581, -0.8917, -0.6947, -1.9329,\n",
      "           1.1550, -0.2598,  0.7998,  1.6755,  0.1104, -0.0903,  0.1297,\n",
      "          -0.8448, -0.2988, -0.4837,  1.0550, -0.4797, -1.0824,  0.7229,\n",
      "          -0.2988,  0.3978,  0.3516,  0.2380,  0.2470, -0.4743, -0.2752,\n",
      "           0.3535,  0.7473, -0.1802,  0.8695, -0.3665, -0.1155,  1.1695,\n",
      "          -0.0365, -1.2813,  1.0191,  2.2096,  2.5821, -0.7787, -0.1849,\n",
      "          -0.7464, -0.2292,  0.4581,  0.4931, -0.9550, -0.8350,  1.5492,\n",
      "          -0.7505, -1.0200,  0.5210, -0.4772, -2.1271,  0.6722, -2.1390,\n",
      "           1.7449]]])\n",
      "src = ['i', 'can', 'read', 'book']\n",
      "predicted trg = ['ich', 'konnen', 'buch', 'lesen', '<eos>']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_count 1    self.capacity  20\n",
      "0  ------------------------------------------------\n",
      "DecoderLayer@trg4\n",
      "[1, 1, 64]\n",
      "tensor([[[-1.6181,  0.0738, -1.3756, -0.6931,  0.5647,  2.1109, -0.2417,\n",
      "           0.1541, -0.7306,  0.5670, -0.1448, -0.6642, -0.6042, -2.3205,\n",
      "           1.1240, -0.4981,  0.8233,  1.5251, -0.3632,  0.2374,  0.2460,\n",
      "          -0.8898,  0.0547,  0.3140,  0.7108, -0.4933, -1.1802,  0.5095,\n",
      "          -0.4113,  0.3731,  0.6193,  0.2694,  0.4461, -0.3963, -0.3645,\n",
      "           0.2499,  0.3351, -0.0449,  1.0867, -0.3069, -0.2174,  1.0950,\n",
      "          -0.1133, -1.3022,  1.0081,  1.9088,  2.4034, -1.1319, -0.0800,\n",
      "          -0.7118,  0.1333,  0.9760,  0.9282, -0.8480, -0.9384,  1.4168,\n",
      "          -0.2336, -1.5888,  0.7671, -0.5156, -2.2300,  0.8259, -2.1697,\n",
      "           1.6110]]])\n",
      "src = ['i', 'can', 'read', 'newspaper']\n",
      "predicted trg = ['ich', 'konnen', 'zeitung', 'lesen', '<eos>']\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4EAAAGCCAYAAABeocZLAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAA1lUlEQVR4nO3deUDU9f798TPDamCCKGK5VJZXc0srldT0prlLZhtGpZl109Sr3VsuhV2xUnP55pKiWamIS+aSWnpdwzW3TKVN85plIWC4JCjbzO8Pf3DtlmIGvAfez8dfsjiv17B8DmdmPjMOt9vtFgAAAADACk7TCwAAAAAAig8lEAAAAAAsQgkEAAAAAItQAgEAAADAIpRAAAAAALAIJRAAAAAALEIJBAAAAACLUAIBAAAAwCKUQADwEGlpaaZXAADAI5GRhYsSCAAeICEhQaNGjSLkAAD4H2Rk4aMEAoBhX3/9tWbOnKmoqCiVL19eLpfL9EoAAHgEMrJoUAIBwBC3263z588rPj5eycnJ+u677yRJTqdTbrfb7HIAABhERhYth5uvIgAYkZWVJV9fX2VkZGjChAlKT09XRESEwsPDJV0IQIfDYXhLAACKHxlZtCiBAGBAQkKCFi1aJLfbrQYNGqhLly6aNm2aHA6H2rRpoxYtWpheEQAAI8jIosfDQQGgmG3atEkTJkxQ3759FRISoiVLligsLEz/+Mc/lJmZqdWrV+vkyZOm1wQAoNiRkcXD2/QCAGCT7Oxs7dy5U2PHjtWJEyf07bffavbs2XrzzTfVoEED9evXT+np6QoODja9KgAAxYqMLD6UQAAoRj4+PnK73Ro2bJicTqcmTZqkSpUq6dixY2rUqJGqVKliekUAAIwgI4sPDwcFgGKQmpqqH374QZLUsGFD+fr6qkuXLgoLC9MXX3yhr7/+WkFBQWaXBADAADKy+PHEMABQxNatW6eJEydKkmrUqKFOnTpp//79+uKLL5Senq6MjAwNHDhQrVu3NrwpAADFi4w0gxIIAEXo6NGjeuutt9S9e3fdfPPNGjVqlLy8vNS3b195eXnpxx9/VHBwsG644Qae7hoAYBUy0hweDgoARcDtduvw4cPq2LGjfH191bBhQ5UtW1YxMTH6/PPP9eGHHyo0NFQNGzbUDTfcIEmEGwDACmSkeZRAACgCDodDNWrUUPfu3bVy5cr8p7P29vbWI488orJlyxreEAAAM8hI83h2UAAoZLt27VJiYqKaN2+ul19+Wbm5uerSpYtGjRolb29vzZ49WyNGjDC9JgAAxY6M9AycEwgAhSghIUExMTG65ZZblJycrIEDB6ply5Z6/fXXNWfOHLVr105PP/206taty/kNAACrkJGeg3sCAaCQJCYmavLkyZo7d65Onz6tfv36af78+fLx8dGwYcNUtmxZzZ07V8OHDze9KgAAxYqM9CycEwgAheT8+fO68847lZWVpdWrV2vUqFEqU6aMoqOjNXPmTPXv31/h4eF69NFHlZWVxS2cAABrkJGehXsCAaCQVKhQQbfddpuOHDmizMxM3XnnnUpNTdXp06cVHh4uSXrzzTeVmpoqX19fw9sWD5fLJafzv7c38vAeALATGflbJjOSewKLkcvlkiTl5OQY3gRAYUlISNBLL72kYcOGKTU1Ve3atdP69esVEhKir776Su+++66efvpp1alTJ/93v0KFCoa3Lj5Op1Nnz57VgQMHJPEU37g0MhIofcjIyzOZkTwxTDHKyMjQqVOn9O6776pjx45q1KiR6ZUA/Amff/65YmJi1LVrV6WlpWn69OmKjY3V6dOnNWnSJPn7+6t///5q166d6VWN2L17t06dOqX33ntPTqdT0dHRqlmzpum14KHISKB0ISMvz3RG8nDQYrJo0SJ9++23SkpK0po1axQSEkLAASXY119/rTfeeEMDBgxQq1atJEk1atTQSy+9pPXr16tBgwby8/NTWFiYdQ+B3LVrlz799FNt2bJFHTp0UG5urkJDQymAuCQyEihdyMhL85SMpAQWsU8//VQJCQnauXOn/vnPfyo5OVnXXnutevToYXo1AH9CUlKSvv32W33yySdq1aqV3G63unTporVr1+rnn39W9erV8z/XpnCTpIMHD+r06dMaO3asqlWrppycHNWpU0fSb89/gN3ISKB0IiMvzVMykhJYxGrWrClfX1/17t1bISEhWrFiha699lp5e3vzxxBKtdL6833o0CE5nU7dddddGj16tN5++23FxcXp8ccf1/79+3Xw4EGdP3/e9JpGRUVF5f97165dWrVqVf4twaXxZwJXj4yEjUrzzzYZWTBPyUhKYBE6cuSI/Pz88h/ScuTIEb399tt68cUXrXnWI9hp7969mjx5sqZMmaJrrrnG9DqFZsOGDZo2bZpCQkL0wgsvqEWLFnI6nRo1apRWr16tcuXKadiwYbrppptMr2rE4sWLlZSUpNq1a6t169ZKT0/XsmXLFBkZqZtvvtn0evAwZCRsVFrzUSIjC+JpGVk6b4bwAHFxcRo+fLimTJmi5ORkSVJqaqruueceNW/eXDwfD0qzhg0bKjU1VYMHD1Z6errpdQrF/v37NWnSJL377rt64YUXdPLkSc2bN09Op1PDhg3TuXPndN111+nuu++WJOt+x2fNmqVly5apUqVKuv7663Xu3Dldc801atq0qUJDQ02vBw9DRsJWpTEfJTKyIJ6YkdwTWAQWL16sVatWacqUKUpJSdGPP/6oTZs2qXXr1jp37pwk+x7/DDu43W65XC55eXlpyJAh6tevn/7xj3/o//7v/1SmTBnT6121c+fOyeFwqEqVKtq4caM2btyozMxMpaam6o477tA//vEPuVwujRw5UlWqVFHPnj2t+h1PSkpSQkKC4uLi9Nlnn2njxo1at26dgoKCNHPmTKu+FigYGQkbldZ8lMjIgnhqRvISEUVg+vTpqly5sjIyMrRv3z6lpqZqy5YtGj58uB599FHT6wFFbubMmdq7d6/Cw8MVFxenatWqaeLEiSXyoS8//vijBg0apCeffFLbtm3T3r171bdvX3Xs2FEJCQmaN2+eJk+eLJfLpZ07d+rGG29U1apVTa9drH766Sd17dpVt912m9LS0tSqVSs1bNhQ77//voYMGaLKlStb9+xvuDQyEjYrTfkokZFXwlMzknsCi0BISIgWLFigzMxM9e3bV61bt9YHH3ygtLQ0/hBCqffzzz9r7dq1euONN1S9enU99thjevTRRzVo0CCNHz9egYGBplf8Q4KCglS/fn2VLVtWI0eOlNvt1p49e7Ru3TpNmTJFgwYNyj9/Ke9hLrb48ssv5efnp4oVK2rOnDnav3+/wsPDVbVqVa1bt04//PCD/P39JXHPDv6LjIStSls+SmTk5Xh6RlICC8nSpUt15MgRpaSkqF+/furYsaPKlCmjEydOaPHixZo7d67Gjx9PuFli9erVSk1N1a233qp69eqV6ic5+N8/2nJzc3X69Gnl5OTkv+9f//qXIiIiNH78eA0fPrxE/B7s27dPGRkZaty4sWrVqqW33npLzZs31/fff6/FixcrOTlZAwcOVMuWLa38w3X27NlatWqVypUrp59++klPPvmkHn74YQ0dOlReXl767LPPNHHiRAUHB5teFR6AjEQe8rHk56NERhakJGQkDwctBLNmzdKqVasUFRWlbdu2acuWLZowYYJOnTqlOXPmKDc3VzExMbrllltMr4piEB8fr/nz5ys0NFQ+Pj7q1KmT2rdvXyqD7uIDe2JioipVqqSKFStq1KhR2rt3r2JjY1W+fHmtXr1a27dv15NPPqkbbrjB7NIFyHvq7oiICB07dkxt2rTR8OHDNWLECNWuXVu9evWSJKWnpysgIMDKcFu3bp2mTp2quLg4ZWZmKjExUS+//LJGjRolp9OptLQ01atXT9WqVTO9KjwAGYk85GPJzkeJjLwSJSUjuSfwT0pJSVFCQoKmT5+uoKAgRUREaNKkSXr55Ze1Zs0aNWvWTA6Ho8Q+1ht/zP79+7Vr1y4tX75cTqdTU6ZMUUJCgpxOp9q2bVuqgu7iA/u7776r+Ph43XDDDWratKnuv/9+5eTkqEOHDmrbtq127NihGTNmlIiAy8jIUGBgoGJiYhQfH6/09HT17t1b119/vbZt26bHH39cPj4++b/TtoWbdOEckMaNGysgIEC+vr5q0aKFWrVqpa+++kq9e/c2vR48CBmJPORjyc9HiYy8EiUlI3mJiD/J7XYrJSVFR44cyX9fjx49VL16dZ09e1YBAQGEmyWOHj2qiRMn6vvvv9d//vMfSdIzzzyjG2+8UStXrtT69esNb1i48g7sS5Ys0ebNm/Xhhx8qICBAGzdu1KZNmzR48GBNnjxZHTt21DvvvFMiAu7QoUN6+eWX9fHHH6tWrVoqV66c+vTpo6FDh6pcuXLasmWLjh07JsnOYMsTGBioEydO6MyZM/Lx8ZHD4ZCvr68yMzMl2ffU37g0MhIS+Vga8lEiI69USclI7gm8Svv371dISIgqVKigZs2aaefOnbr22mtVo0YNbdiwQWfOnJHL5TK9JopJVlaWqlevrmeffVbTp0/XunXr5Ovrq2rVqumZZ57Re++9l/+CyKVJTk6Otm/frscee0wnTpxQaGio6tatq48//lgpKSnq1auXrrvuOtNr/iHNmzfXG2+8oZSUFOXm5io6OlqxsbEaPny4nn32WWtf827FihU6f/68srKy1KRJE8XHx+udd95R7dq1lZmZqS1btmjatGmS7A5/XEBGIg/5WHryUSIjL6UkZiTnBF6FWbNmafXq1br++us1YsQI7dq1Sxs2bNAXX3yhunXrateuXZo0aRLnN1hi9uzZ2rNnjypUqKBBgwYpMTFR8fHxqlevntq2basbb7zR9IqF5vce2x8bG6vbb79de/fuVa1atXT33Xfr8ccfV5UqVTRw4EBVqlTJ0LZXbtu2bfrkk08UFBSkBg0aqEaNGlqwYIHOnTun2bNn65lnntGAAQPk7X3hdjPbznGYNWuW1qxZoz59+ujpp5/W1KlTdf311ysuLk7p6enKzc1Vv379VLNmTdOrwgOQkchDPpb8fJTIyIKU1IykBP4Bubm5Wrt2reLj4xUXF6fPP/9c58+fV3Jysnx8fBQcHKzTp0+rbt26qlKliul1UQzmzp2rFStWqHv37po9e7aqV6+uESNG6KuvvlJsbGz+Ad/b27vEHxAvPqh/8sknysnJUVBQkOrWravz58+rf//+evXVV3X48GHFxsZq0qRJCgsLM7x1wRISEjRu3DgNHDhQ7733nry9vTVr1ixJ0tmzZzV27Fh16tRJjRs3NruoAZmZmfrxxx/16quv6u2339bcuXP16aefavjw4fr888/VoUMHSRfOEeEhfSAjcTHyseTno0RGXk5Jz0geDnqF9uzZI39/fyUnJ+uWW27R4sWLtXXrVqWmpsrlcunee+9Vx44dTa+JYnTw4EGtW7dOCxcu1O7du1W9enWVKVNGMTExevnllzVgwABdd9118vHxMb1qocgLuDlz5mjVqlXq1KmT+vXrp6lTp6patWo6ceKEZs2apS1btmjq1KkeH3But1tnzpzR4sWLNXnyZKWmpionJ0fjx4/XggULVLNmTTVq1EgjRozI//yS/ofKH/HZZ5/J7XYrICBAZcuW1dSpU7V//35NnTpVP/74oyZNmqR77rlHfn5+HhluKF5kJC5GPpbsfJTIyIKUhozkiWGu0KpVq/T555/rpptu0tGjR7V06VJFREQoLi5O99xzj44ePSq32+0xJ3uiaH333XfKyMhQdna2vvzyS23evFndu3fX7bffru3bt6tPnz5q0KBBiTjQF+Tin+mvvvpKq1ev1qxZs5STk6NWrVqpTp06cjgceuONN9S4cWO9/fbbJeJhXg6HQ+XKlVPdunUVGxurMWPGaOzYsapUqZKWLFmioKCg33y+TT7++GN9/fXXqlKlin7++WetXr1aU6dOlY+Pj7Zu3arrrrtOTicRggvISOQhH0t+PkpkZEFKQ0ZyT+AVSEhIyD9whYSEqEmTJvL19dXWrVu1fPlyrVy5UuPGjbPuFyDPrl27lJ2drbvuusv0KsUiPj5eCxYsUK1atRQVFaWMjAwdO3ZMTZo00U8//aT77rtPTzzxhLy8vEyv+qddfMve+++/r4yMDDVs2FDz58/X5s2bNX36dG3evFmTJk3S0qVLVa9ePcMbX5lNmzZp3bp18vLy0okTJ3T8+HENGzZMVatW1aFDh3T+/Hmr/1jNO+Y99dRTCgwMVOfOnbVjxw49++yzatiwodauXatx48aVmlvx8eeQkZdGPpKPJS0fJTKyIKUlIymBl5H3gpgnTpxQr169FBISon379mnPnj3y9vbWnj17dPbsWY0ZM0Y1atQwva4RbrdbaWlpql+/vpKTk0vMSc5XK+/hLVOnTlVAQIDKly+vt956S7/88oumT5+ulStXavz48apcubLpVQtFXsAtW7ZMS5Ys0fPPP6/o6Ghdc801Wrp0qSTpP//5j8ed7Hw5e/fu1fjx49WqVSudPHlS33zzjaQL13HmzJn64YcfNGDAACt/p//3mFe5cmV98803OnHihDp27KjExESVK1dOEyZMsPLrg18jIy+PfCQfS1o+SmTk5ZS2jKQEXobT6dSpU6e0YsUKVahQQefOnVNcXJwefPBB1a5dW0888YTHnuxZXBwOh9q1a6djx47p4Ycf1tChQ0v1eR9JSUlq0aKFqlatquzsbEkXgr5q1ar6/PPPNX78+BJ3wC/Id999p7feekutWrVS48aNFRERoQMHDmjMmDGqVKmSPvroI40ZM8b0mlfkyy+/VGxsrF599VXVq1dPR48eVXBwsNavX6+//OUv6tChgwICAlS/fn3rzm+Qfv+YN3v2bHXr1i3/2f2APGTk5ZGP5GNJykeJjCxIactISuBluN1uHThwQN98841CQkJUvnx5jRs37ld36ZcpU8bghp4jNDQ0/zWAnE6n2rdvb3qlIlG5cmUtWrRIHTp0UN26dSVJP//8s2699VYNGTLE4+/6vxqVK1dWVFSUpk6dqrvuukt9+/bV5s2btXTpUnl7e2vMmDEl4hwHl8ulb775Rlu3btVdd92levXqqVq1aurWrZtOnDihjz/+WPHx8fmfb1u4Sb9/zJswYUKJehgTig8ZeWXIR/KxJCAjC1baMpKXiChAdna29u/fr0aNGln5A/9HZGVlacmSJZo7d64GDBigtm3bml6p0J09e1aTJ0/WiRMn1KpVK3l5eWnmzJmaMGGCbrjhBtPrFZmcnBwtXLhQ8+bN06BBg9SmTRtJJe/ZwLKysvT+++8rLi5OAwcOzH/65h9++EHp6emqVauW4Q3N45iHP4KflytDPt5ger0iU1ryUSIjr0RpOuZxT2ABfHx8dPvtt0u68BpIpeFk5qLi6+urbt26yel0auTIkXI6nfkHw9IiMDBQvXv31qpVq7RkyRKFhIRo1KhRpTrgJMnb21sPPfSQvL299a9//UuS1KZNmxJ3APT19dXDDz8sb29vTZ8+XTk5OerSpYuqVq1qejWPwTEPfwQ/L1eGfCy9Sks+SmTklShNxzzuCUShy8rK0ooVK9S4ceNSfeDIO+ehND7E5VJKy/c2KytLCxcuzH9R6woVKpTIwAZQspSWY2hByMeS/b0lI+1ACUSRKIkPg8CVKS3f26ysLJ04cULXXXed6VUAWKS0HEPxW6Xpe0tGln6UQAAAAACwiGe/lD0AAAAAoFBRAgEAAADAIpRAAAAAALAIJRAAAAAALEIJBAAAAACLlLoXi3e5XEpPT5ePj0+peZpeAMDvc7vdys7OVkBAgJxObtcsCBkJAHYoKB9LXQlMT0/XwYMHTa8BAChGNWvWVNmyZU2v4fHISACwy6XysdSVQB8fH0nSU089pZSUFCM7rFixQl26dDEy+8iRI0bmXiwxMVF169Y1Mvumm2oYmZtn+fIPFRFxn5HZbrfLyNw8Jn/uPYHN19/kdQ8NDdU777yTf+zH5eV9nf72tz5KTU01ssOSJR+oW7cHjcwe+fY7RubmqRNSTl/8fNrY/Ff+9jdjsyXpgw8W6MEHI43M9vHxMzI3z/z5s9W9ew9j8wMCrjU2e+bMyerdu7+x+S9OHGNstiTVDLhGB9Mzin2ut8Ohm64pc8l8LHUlMO/hLSkpKUpKSjK2h6nZfn5mD3J5TO1h8ntuegfTJVDyjK+/STZff9PXnYc2Xpm8r1NqaqqOHz9ubA9Ts7Nc5o+TJncw+T03vYOvr7+RuRdLTk42NjswMNPYbElKSTFzo5MkZbvdxmZ7wg6XykdOoAAAAAAAi1ACAQAAAMAilEAAAAAAsAglEAAAAAAsQgkEAAAAAItQAgEAAADAIpRAAAAAALAIJRAAAAAALEIJBAAAAACLUAIBAAAAwCKUQAAAAACwCCUQAAAAACxCCQQAAAAAi1ACAQAAAMAilEAAAAAAsAglEAAAAAAsQgkEAAAAAItQAgEAAADAIpRAAAAAALAIJRAAAAAALEIJBAAAAACLUAIBAAAAwCKUQAAAAACwCCUQAAAAACxCCQQAAAAAixgvgQcOHNCAAQMu+fEhQ4bonXfeKcaNAAAwj3wEABQV4yWwXr16mjRpkuk1AADwKOQjAKCoGC+BO3bsUOfOnZWenq6hQ4eqXbt26tixoyZMmCC32y1J2rt3ryIjI9WmTRv16dNHGRkZhrcGAKBokY8AgKLicOcliSE7duzQyJEj1axZM6Wmpmrs2LHKzc1Vr1691L9/fy1dulSHDx/WnDlz5Ovrq4ceekhPPPGEunbt+ruXl5mZqcTExOK9EgAAo+rWrSs/Pz/TaxSqws5HiYwEANtcKh+9Dezyu7Zt26ahQ4fKy8tLXl5emjt3riRp6dKlatOmjcqUKSNJuuWWW5SWllbg5XXp0kVJSUlFuvOl7N69W3fccYeR2YY7vSRpz549uv32243Mdjq9jMzNs2vXTt15Z2Mjs91ul5G5eUz+3HsCm6+/yeteuXJlrVixwsjs4lLY+ShJ3bo9qOPHjxfZzpezbdsW3XVXcyOz3/rQ7M9Kw4rB2pt60tj8/vffb2y2JG3Z8omaN29lZLavr7+RuXk2bFite+5pb2x+YGCQsdnLly9QRESksfmj5pk9d7pOYIC+OJte7HN9HA7VDLjmkh/3mBLo7e0th8OR/3ZSUpL8/f3zP5bH4XB4RNEBAKA4kI8AgMJm/JzAPOHh4Vq6dKlcLpeysrI0YMAA7dq1y/RaAAAYRT4CAAqbx5TAfv36ycfHR/fdd5+6du2qli1bqm3btqbXAgDAKPIRAFDYjD8ctEmTJlq5cqUk6bXXXvvNx0ePHn3ZtwEAKI3IRwBAUfGYewIBAAAAAEWPEggAAAAAFqEEAgAAAIBFKIEAAAAAYBFKIAAAAABYhBIIAAAAABahBAIAAACARSiBAAAAAGARSiAAAAAAWIQSCAAAAAAWoQQCAAAAgEUogQAAAABgEUogAAAAAFiEEggAAAAAFqEEAgAAAIBFKIEAAAAAYBFKIAAAAABYhBIIAAAAABahBAIAAACARSiBAAAAAGARSiAAAAAAWIQSCAAAAAAWoQQCAAAAgEUogQAAAABgEUogAAAAAFjE2/QCRcXb21c+Pn7G5pua3a3b80bmXuyll6KM7XFbg3uMzPWEHc6dP2tk7sVq1WpqbPapUynGZucJC7vJ9ArGmLruFStWNDK3pMvOzlRW1nlj803Njn7yb0bm5lm58n2jO5QpE2hstukdMjLOGJl7sczMDGOzH4waYGy2JLW/7wljs59oebex2ZK0Z88eIztkZmYqMTHxkh/nnkAAAAAAsAglEAAAAAAsQgkEAAAAAItQAgEAAADAIpRAAAAAALAIJRAAAAAALEIJBAAAAACLUAIBAAAAwCKUQAAAAACwCCUQAAAAACxCCQQAAAAAi1ACAQAAAMAilEAAAAAAsAglEAAAAAAsQgkEAAAAAItQAgEAAADAIpRAAAAAALAIJRAAAAAALEIJBAAAAACLUAIBAAAAwCKUQAAAAACwCCUQAAAAACxCCQQAAAAAi1ACAQAAAMAilEAAAAAAsAglEAAAAAAsQgkEAAAAAItQAgEAAADAIpRAAAAAALBIgSVwx44d6ty5c3HsAgBAiUE+AgBKKu4JBAAAAACLeP+RT969e7f++c9/asKECTp06JDi4uLkdDpVoUIFRUdH68Ybb9SQIUMUGBiob775RsePH9df/vIXjRkzRgEBAapXr56eeeYZbd26VSkpKerdu7ceffRRSdKiRYs0f/58uVwuBQUFKTo6WjVq1Ljs5QEA4AnIRwBASXLFJfDTTz9VdHS0YmNjdfLkSc2cOVMLFy5U+fLltWTJEj333HP66KOPJEmJiYmaM2eOHA6HHn74Ya1evVoPPPCAsrKyFBwcrAULFigxMVHdu3fXAw88oH379mnZsmWKj49XmTJltGXLFvXr10+rVq267OVdztKli//El+XP2759q9H5pr30UpTpFYx5e+Zo0ysYM3fuFNMrGLVy5fumVzDG5ute0vJRklasWFGkX5OC7N692+h8k2z+XZGktWtXml7BmK1bN5lewZi+T3U0NnvPnj3GZnvSDv/rikrg8ePH9eyzz6p79+6qVauW3njjDXXs2FHly5eXJHXr1k2vvfaajh07Jklq0aKFfH19JUk1a9bU6dOn8y+rdevWkqQ6deooKytLGRkZ+uSTT3T06FFFRkbmf96ZM2d06tSpAi/vUu6//wEdP378Sq5eodu+favCw5sZmd25c18jcy/20ktReu21eCOzvztywMjcPG/PHK2new8xMvvc+bNG5uaZO3eKHnusn7H5p06lGJstXfjDrnPnh43uYIrJ6x4aWlHvvvuWkdlSycxHSerSpYuSkpL+3JW/Srt379Ydd9xhZHZY2E1G5uYxfZzIzMwwNlu6UADvvdfMebQZGWeMzM2zdesmNWt2t7H5Ub3M/G0iXSiAU9/52Nj8d6ZGG5stXSiAt99+e7HPzczMVGJi4iU/fkUl0MvLSzNmzFDfvn3Vvn17uVyu33yO2+1WTk6OJMnf3z///Q6HQ263O/9tPz+//Pfn/T+Xy6X77rtPL7zwgiTJ5XIpJSVF5cqVK/DyAAAwhXwEAJREV/TEMBUrVlSjRo00ePBgvfjii7rjjjv08ccfKy0tTZK0ePFiBQUFqXr16le1RPPmzfXRRx8pJeXCLfnz589Xjx49ruqyAAAoLuQjAKAk+kNPDHP//ffr3//+tzZv3qyePXuqR48ecrlcKl++vKZPny6n8+qebLR58+Z6+umn1atXLzkcDgUGBmrKlCn5t4YCAODJyEcAQElSYAls0qSJVq7870m8sbGx+f+Oivrtk3+MHj36km9/8803v/rYxW9HRUX94csDAMAU8hEAUFLxOoEAAAAAYBFKIAAAAABYhBIIAAAAABahBAIAAACARSiBAAAAAGARSiAAAAAAWIQSCAAAAAAWoQQCAAAAgEUogQAAAABgEUogAAAAAFiEEggAAAAAFqEEAgAAAIBFKIEAAAAAYBFKIAAAAABYhBIIAAAAABahBAIAAACARSiBAAAAAGARSiAAAAAAWIQSCAAAAAAWoQQCAAAAgEUogQAAAABgEUogAAAAAFiEEggAAAAAFqEEAgAAAIBFKIEAAAAAYBFv0wsUlaZNI3Tq1C/G5rdq1d3I3M2bFxmZ+2tRxvZo1KitkbkXqxhazcjcL7/cZmTuxc6ePWVsttvtMjbb9A5nz540Mvdiv/zys5G5AQGlNsaKlL9/gMqUKWtsvqnZTqf5275N7pCbm2NstukdqlW71chcT9mhzz+jjM3WyZNG5z/x1HBjsyXp733vM7JD2bJl1OvxS/9dbP5oCAAAAAAoNpRAAAAAALAIJRAAAAAALEIJBAAAAACLUAIBAAAAwCKUQAAAAACwCCUQAAAAACxCCQQAAAAAi1ACAQAAAMAilEAAAAAAsAglEAAAAAAsQgkEAAAAAItQAgEAAADAIpRAAAAAALAIJRAAAAAALEIJBAAAAACLUAIBAAAAwCKUQAAAAACwCCUQAAAAACxCCQQAAAAAi1ACAQAAAMAilEAAAAAAsAglEAAAAAAsQgkEAAAAAItQAgEAAADAIpRAAAAAALAIJRAAAAAALEIJBAAAAACLFHoJnD9/vmbMmCFJWrRokeLj4wt7BAAAJQ75CADwFN6FfYHdu3fP//eePXt0yy23FPYIAABKHPIRAOApCiyB8fHxev/99/PfPnz4sHr37q369etr2rRpys7Olr+/vwYPHqyGDRtq8uTJOnnypMLDw7VhwwZt3bpV/v7+SktL08mTJzV8+HBJyv+84cOH6/HHH9dtt92mzz77TElJSQoPD9fIkSPldDq1ZMkSzZgxQ/7+/mratKnmzJmjL7/8sui+IgAAXAHyEQBQUhVYAqOiohQVFSVJmjdvnj744AO1b99eL7zwgubMmaPg4GAdOnRITz75pNasWZP//+69916tX79et9xyi6KiojR58uTLzvn+++8VFxenjIwMdejQQTt37lSFChU0btw4LVmyRGFhYZoyZYpyc3Ov6IoNHtzjij6vqIwa1c/QZFNzf2316mWmVzDm9df7Gppsau5/LVs21/QKRn300QemVzAmIWG96RWKXUnNR0latGjB1V3pQrJ580aj801avtzs1960DRtWm17BmPnzY80NP3nS3GxJDoPz/973PmOzPWmH/3XFDwddu3at3n33Xc2fP19r1qxRSkqKevbsmf9xh8Oh77///qoX+etf/yqn06nAwEBVr15dp0+f1tdff61mzZopLCxMkvTYY48VGJZ5xoyZrVOnfrnqff6MUaP6aejQKUZm7927zsjci61evUzt23c1MrtRo7ZG5uZ5/fW+GjZsqpHZX365zcjcPMuWzVXXro8Zm5+dfd7YbOlCAezU6UEjs8+eNRvuCQnr1bJlayOzw8IqaeHCeUZm5ylp+ShJDz0UqePHk696pz9j8+aNatHir0ZmBwdXMjI3z/LlCxQREWls/tmzp4zNli4UwHvuaW9kdqVKNxiZm2f+/Fh17/6ssfnzVi80Nttx8qTcwcHG5k96bZax2dKFAjhx6ofFPrds2TLq9fil/y6+ohK4Z88ejRgxQrNmzVLFihXlcrkUHh6uN998M/9zkpKSFBoaqrVr1/7uZTgcDrnd7vy3s7Ozf/Vxf3//33yul5fXr/6Pl5fXlawLAECxIB8BACVRgc8OevjwYf3973/X+PHjdfPNN0uSwsPDtXXrVh0+fFiSlJCQoIiICJ0//+tb4r28vJSTkyNJCg4O1hdffCG3262zZ89q48aCHwrSvHlzbd++XcnJF26tXLRo0R+7dgAAFBHyEQBQUhV4T+Drr7+u7OxsjRkzJv98g7p16yomJkbPP/+83G63vL29NW3aNAUEBPzq/959990aPXq0JOnRRx/V5s2b1bZtW1WqVEmNGzf+1a2Yv+fGG2/U0KFD9dRTT8nX11e1a9dWmTJlrva6AgBQaMhHAEBJVWAJfOeddy75sQ4dOvzmff3798//d7t27dSuXbv8t2Njf/+E2Li4uN99+4cfftB3332n5cuXy+l0as2aNTp48GBBKwMAUOTIRwBASVXorxNYmMLCwpSSkqIuXbrIy8tLZcuW1euvv256LQAAjCIfAQB/hkeXQB8fH8XExJheAwAAj0I+AgD+jAKfGAYAAAAAUHpQAgEAAADAIpRAAAAAALAIJRAAAAAALEIJBAAAAACLUAIBAAAAwCKUQAAAAACwCCUQAAAAACxCCQQAAAAAi1ACAQAAAMAilEAAAAAAsAglEAAAAAAsQgkEAAAAAItQAgEAAADAIpRAAAAAALAIJRAAAAAALEIJBAAAAACLUAIBAAAAwCKUQAAAAACwCCUQAAAAACxCCQQAAAAAi1ACAQAAAMAilEAAAAAAsAglEAAAAAAs4m16gaKyb98GJSenGJreTzt3fmRkckbGGSNz/9fp06lG5iYmbjIy97/6Gtvhjjs6GJl7sUaN7jU2e9++DcZm5/H3DzAyt06d5kbmXqxJky5G5gYHX2tkLkqmEyeOmV7B6A7Nmj1gbHae229vZ2Ru4zbNjMy9WLeevYzNXvz+WmOzH7z3DqPzv9y309jsC+4zskNISJCktpf8OPcEAgAAAIBFKIEAAAAAYBFKIAAAAABYhBIIAAAAABahBAIAAACARSiBAAAAAGARSiAAAAAAWIQSCAAAAAAWoQQCAAAAgEUogQAAAABgEUogAAAAAFiEEggAAAAAFqEEAgAAAIBFKIEAAAAAYBFKIAAAAABYhBIIAAAAABahBAIAAACARSiBAAAAAGARSiAAAAAAWIQSCAAAAAAWoQQCAAAAgEUogQAAAABgEUogAAAAAFiEEggAAAAAFqEEAgAAAIBFKIEAAAAAYBFKIAAAAABYhBIIAAAAABYptBK4Y8cOde7cubAuDgCAUoOMBAB4Eu4JBAAAAACLeBf2BWZlZWncuHHatWuXcnNzdeutt+rll19WYGCg5s2bpwULFsjHx0d+fn6KiYnRzTffrOTkZMXExCgpKUnZ2dnq1KmTnn32WR07dkw9e/ZUy5YttW/fPp05c0YvvPCC7r333sJeGwCAIkdGAgA8gcPtdrsL44J27NihkSNHqn379kpPT9eLL74oh8OhCRMm6MyZM4qOjlaDBg20YcMGhYaGatmyZcrMzNQjjzyiJ554Qj179tQ999yjzMxMPf3004qMjFT9+vXVunVrxcbG6q9//av+/e9/a/To0dq4ceMl98jMzFRiYmJhXCUAQAlRt25d+fn5mV7jkshIAIAJl8rHQr8n8JNPPtEvv/yibdu2SZKys7MVEhIiLy8vtW/fXpGRkWrVqpWaN2+uli1bKiMjQ7t27dLp06c1ceJESVJGRoa+/vpr1a9fXz4+PmrZsqUk6dZbb9WpU6euaI9HH+2h5OSUwr56V2T9+lVq3bqDkdkZGWeMzL3Y9u1bFR7ezMjsihWrGpmbZ/nyBYqIiDQy+447zPzM5Rk+vIdiYmYbm79v3wZjsyVp8eLZeuCBHkZm16jR0MjcPG+8MVAvvvimkdnBwddq6NBeRmZfDU/JyIceitTx48lFch0LsnnzRrVo8Vcjs3Nzs43MzbNt2xbddVdzY/ObNXvA2GxJGjt2kF544f+MzG7cxszfJXkeatdYi/6909h8h9PcGWAP3nuHPli729j8tR8sNTZbkqZPf01/+9tLxT43JCRIr7/+wiU/Xugl0OVyadiwYfmhlJ6erszMTEnSuHHjdPDgQW3btk0zZszQhx9+qNdee01ut1sLFixQmTJlJElpaWny8/PTyZMn5ePjI+f//8F1OByFvS4AAMWGjAQAeIJCv1mgefPmio+PV1ZWllwul6KjozVhwgSlpaWpZcuWCgoKUs+ePTVw4EAdOHBAgYGBuu222/Tee+9Jks6cOaPu3btr/fr1hb0aAABGkZEAAE9Q6PcE9u3bV2PGjNH999+v3Nxc1a5dW0OGDFFgYKD69Omjnj17yt/fX15eXnr11VclXbj1c+TIkerSpYuysrLUuXNnRURE6NixY4W9HgAAxpCRAABPUGglsEmTJlq5cqUk6ZVXXvndz4mMjFRk5G/Pl6pSpYqmT5/+u+/fu3fvJd8GAKAkICMBAJ6E1wkEAAAAAItQAgEAAADAIpRAAAAAALAIJRAAAAAALEIJBAAAAACLUAIBAAAAwCKUQAAAAACwCCUQAAAAACxCCQQAAAAAi1ACAQAAAMAilEAAAAAAsAglEAAAAAAsQgkEAAAAAItQAgEAAADAIpRAAAAAALAIJRAAAAAALEIJBAAAAACLUAIBAAAAwCKUQAAAAACwCCUQAAAAACxCCQQAAAAAi1ACAQAAAMAilEAAAAAAsAglEAAAAAAsQgkEAAAAAIt4m16gqOTkZCk7O9PYfFOzc3Kyjcz9X6b2yMo6b2SuJ+yQkLDAyNz/6mF0h4oVqxmbncfHx9/I3I497jMy1xN28PcptTFWpJo2jdCpU2eNzW/VqruRuf7+AUbmXqxTpz7GZjft0tTY7DztH48wMnfO+MlG5uZ5qF1jrZw3z9j8X35JMzb7wXvnaN60ScbmHz/+H2Oz8xw4kFDsM8PCwi77ce4JBAAAAACLUAIBAAAAwCKUQAAAAACwCCUQAAAAACxCCQQAAAAAi1ACAQAAAMAilEAAAAAAsAglEAAAAAAsQgkEAAAAAItQAgEAAADAIpRAAAAAALAIJRAAAAAALEIJBAAAAACLUAIBAAAAwCKUQAAAAACwCCUQAAAAACxCCQQAAAAAi1ACAQAAAMAilEAAAAAAsAglEAAAAAAsQgkEAAAAAItQAgEAAADAIpRAAAAAALAIJRAAAAAALEIJBAAAAACLUAIBAAAAwCKUQAAAAACwCCUQAAAAACxCCQQAAAAAixRaCTx79qzmzZun/fv3F9ZFSpLGjh2ro0ePFuplAgBQXMhHAICn8f6zF7Bv3z4tXLhQ27dvV+vWrdWmTRtt2LBB06ZNU3Z2tvz9/TV48GA1bNhQ2dnZGj16tLZv3y4vLy/Vr19fQ4cOVWBgoObNm6cFCxbIx8dHfn5+iomJ0c0336wKFSroueeeU0hIiB555BG1adNGvr6+hXHdAQAoMuQjAMBTOdxut/tq/uOBAwcUHR2t8uXL68EHH8wPn++++079+/fXnDlzFBwcrEOHDunJJ5/UmjVrNHPmTB06dEgTJkyQl5eXXnrpJfn4+OiVV15RgwYNtGHDBoWGhmrZsmXKzMzUI488kj9v7969WrRokXbs2KFevXopKirqd/fKzMxUYmLi1X01AAAlUt26deXn52d6DUmem48SGQkAtrlUPl71PYFOp1NOp1MOh0MOhyP//Vu3blVKSop69uyZ/z6Hw6Hvv/9emzZt0qBBg+Tj4yNJevzxx/Xcc8/Jy8tL7du3V2RkpFq1aqXmzZurZcuWv5rn5eWVP9PpLPhRrA8/3F3Hjydf7dX7UzZt2qC7777HyOxz584amXuxXbt26s47GxuZHRJynZG5eVavXqb27bsamZ2dnWlkbp7161epdesOxuZXrFjN2GxJWrBguiIj/2Zk9rPRQ4zMzdOqzo365IsjRmb7+3irac2qRmZfiqfnoySNHz9Pp06ZyYuRI59RdPQMI7P9/QOMzM3z0ktReu21eGPzm3Zpamy2JLWuX0Pr9x82MnvO+MlG5uaZPftN9egx0Nj8X35JMzZ7yZI56tbtCWPzjx//j7HZkrRt2xbddVfzYp8bFhamJUs+uOTHr7oE1qlTR0uWLNH+/fu1YMECjR07Vm3btlVgYKDCw8P15ptv5n9uUlKSQkND5XK5fhWILpdL2dnZkqRx48bp4MGD2rZtm2bMmKEPP/xQEydO1Jw5c/TBBx8oKChIkZGReuWVV/JDEgAAT0M+AgA83Z9+Ypj69evr9ddf14cffqgqVaqocePG2rp1qw4fvnBLT0JCgiIiInT+/Hm1aNFC8+fPV3Z2tlwul+Lj49WsWTOlpaWpZcuWCgoKUs+ePTVw4EAdOHBA0oWAzAu7jh07EnAAgBKBfAQAeKo//cQwecqWLavHHntMkhQTE6Pnn39ebrdb3t7emjZtmgICAtSnTx+NGTNGXbt2VU5OjurXr6/o6Ghde+216tOnj3r27Cl/f395eXnp1VdflSQNHjy4sFYEAKDYkY8AAE9TaCXwYh06dFCHDr89N8jf31+vvPLK7/6fyMhIRUZGFsU6AAB4BPIRAOAJeLF4AAAAALAIJRAAAAAALEIJBAAAAACLUAIBAAAAwCKUQAAAAACwCCUQAAAAACxCCQQAAAAAi1ACAQAAAMAilEAAAAAAsAglEAAAAAAsQgkEAAAAAItQAgEAAADAIpRAAAAAALAIJRAAAAAALEIJBAAAAACLUAIBAAAAwCKUQAAAAACwCCUQAAAAACxCCQQAAAAAi1ACAQAAAMAilEAAAAAAsAglEAAAAAAsQgkEAAAAAItQAgEAAADAIpRAAAAAALCIt+kFCpvb7ZYkVaxYwegeYWGVjMw9f76skbn/q3LlykbmBgeHGpl7sUqVzOyQnZ1pZO7FTF13SQoJCTE2O0/FimZ28Pcxfyg3tYOft5ek/x77cXl5X6drrw0wukdQUKCRuX5+1xiZe7Fy5cx97W0+VlSoUN7IXE/Zwd/f7P0+Zv8uzzA4+4KwsLBin1mxYkVJl85Hh7uUJecvv/yigwcPml4DAFCMatasqbJlPeNGME9GRgKAXS6Vj6WuBLpcLqWnp8vHx0cOh8P0OgCAIuR2u5Wdna2AgAA5nZzhUBAyEgDsUFA+lroSCAAAAAC4NG42BQAAAACLUAIBAAAAwCKUQAAAAACwCCUQAAAAACzy/wCPwYVSri47gQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1080x1800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_count 1    self.capacity  20\n",
      "0  ------------------------------------------------\n",
      "DecoderLayer@trg4\n",
      "[1, 1, 64]\n",
      "tensor([[[-1.5493,  0.1125, -1.0487, -0.7417,  0.6217,  2.0610, -0.1950,\n",
      "           0.3665, -0.9629,  0.3925, -0.1169, -0.7896, -0.6054, -2.3183,\n",
      "           1.0516, -0.8280,  0.9416,  1.6249, -0.3791,  0.3730,  0.1544,\n",
      "          -0.7484,  0.0766,  0.4210,  0.6122, -0.2611, -1.2581,  0.5797,\n",
      "          -0.2293,  0.4127,  0.5584,  0.3321,  0.5770, -0.4395, -0.2765,\n",
      "           0.1189,  0.1427, -0.1042,  0.7509,  0.0205, -0.2799,  1.2296,\n",
      "          -0.2310, -1.2462,  0.8703,  1.7787,  2.5345, -1.0739, -0.2313,\n",
      "          -0.7073,  0.1258,  1.1364,  1.0461, -0.8271, -1.2829,  1.3563,\n",
      "          -0.1591, -1.6436,  0.7129, -0.4675, -2.1107,  0.6023, -2.2233,\n",
      "           1.6800]]])\n",
      "src = ['we', 'want', 'to', 'eat', 'bread']\n",
      "predicted trg = ['wir', 'mochten', 'brot', 'essen', '<eos>']\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4gAAAFDCAYAAAB4ACCQAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAyu0lEQVR4nO3dd3SUdfr+8WsyaUCooQUEpCqK7ldglxakg0FpFsyCNBdxQVBgd2UREEVUOguCKEVKCIYaEKWDgIQakBIVWBEBlyQYEyCF1JnfH0zyQwEFzXxmJnm/ztlz1knIdT+Qee65Zp5JLHa73S4AAAAAQKHn5eoBAAAAAADugYIIAAAAAJBEQQQAAAAAOFAQAQAAAACSKIgAAAAAAAcKIgAAAABAEgURAAAAAOBAQQQAAAAASKIgAoBHstvtrh4h39lstp/9d0E8RgCA8xXE/WFyR1IQXST3Hzk7O9vFkwDwFMePH1d4eLgkyWKxFLgF6OXlpZSUFJ04cULS9WNE4cN+BPB7sCPzj7fTvjJ+VXp6ui5fvqyPPvpIHTt2VP369V09EgA3lpmZqW+//VZr1qyRj4+PunfvnrcAC0KRio6O1uXLl7Vw4UJ5eXlpzJgxqlOnjqvHgguwHwHcLXZk/qIgusDKlSv17bffKjY2Vlu2bFFgYCALEMBt2Ww2+fr66sknn1RCQoIiIiLk6+urrl27evwCPHTokPbv3689e/YoJCREOTk5Kl++POWwkGI/Arhb7Mj8R0E0aP/+/dq1a5cOHjyof/7zn4qPj1eJEiXUp08fV4+G27DZbPLy4kpsuFbu9+DSpUt15MgR+fn5aenSpUpNTVXPnj09egGePn1aV65c0eTJk1W1alVlZ2frwQcflMT9rzBhP3om7qNwB+zI/EdBNKhOnTry9fVV//79FRgYqPXr16tEiRLy9vbmJOtmTp48qVKlSqlixYquHgWQdP0BdEREhNasWaOkpCTFxMRo8eLFKlq0qLp16+aRi0+Sevbsmff/Dx06pI0bN6ply5aSxDmxEGE/ehZ2JNwNOzJ/ccY15OzZs0pPT1f9+vUVGBios2fPat68eWratKl8fX1Zfm7myJEjevbZZzVt2jRt3rzZ1eOgEPrlm+uTk5NVpkwZ+fr6qkKFCvrzn/+satWqaebMmVq7dq1rhvwDVq9erVmzZmn79u2SpNTUVK1du1ahoaGqVauWi6eDSexHz8OOhKuxI52Ls64BYWFhev311zVr1izFx8dLkn788Ue1bt1awcHBBe6nLBUEPXr0UJUqVTR//nyVLFlSkpSTk+PiqVBY3HgpzOXLlyVJ9913n/z8/LRp0ybl5OSoRIkSqlKlitq0aaOGDRu6cNq7t2jRIq1du1YVKlRQ5cqVde3aNRUtWlSNGzdW+fLlXT0eDGI/eiZ2JFyJHel8XGLqZKtXr9bGjRs1a9YsXbp0Sf/73/+0e/dutWnTRteuXZPEj3J3F7+8jKlZs2aqXLmy/vWvf2nhwoWqVauWsrOz5e3N3QbOc+PiW7hwoaKiolSyZEm9/vrreuCBB7Rt2zbt2LFDDzzwgCIjIzV37lzdc889Lp76zsXGxmrXrl0KCwvTkSNH9Pnnn2vbtm0qVaqU5s+fz/mwEGE/ehZ2JNwBO9LMOZF7sZMlJCQoNDRUW7Zs0bFjx/Tjjz9qz549ysrKUo8ePVw9Hm6Qu/j27dun7OxsDRgwQFarVePHj1efPn20efNmJScnKygoyMWToiDLPfmHh4dry5YteuONN/TMM8/Iz89PQ4cO1cmTJ7V//37Fx8dr5syZqlKliosnvjt2u11fffWVBgwYoMTERLVs2VLDhw/XihUrFBcXp6CgII/9YQK4O+xHz8KOhDtgR5rZkRREJwsMDFRERIQyMjI0aNAgtWnTRqtWrVJiYiIPgtzEjc+KLl26VAsXLlTJkiU1duxYRUZGavTo0crJyVHz5s1VunRprVy5UoGBgS6eGr9UkH6QxcWLF7V9+3bNnj1bP/zwg7p166bo6Gi9+eabGjlypB599FGPO398/fXX8vPzU7ly5bRkyRIdP35cTZo0UZUqVbRt2zZduHBB/v7+knjVqLBgP3oGdmTBwI50b+62IymIThAZGamzZ8/q0qVLGjx4sDp27KgiRYooISFBq1ev1tKlSzV16lSP+sYtyHJPmAcOHFBsbKwiIiJUrlw5DRw4UN27d9fKlSs1duxYtW3bVlWrVmXxuZEffvhB586dU7NmzTx6+f1ykWVlZSkzM1MJCQnasmWLevTooWeeeUbPPvusSpUqpTFjxuQtCk+wePFibdy4USVLltTFixfVr18/de/eXSNHjpTVatWRI0c0Y8YMlS5d2tWjwsnYj56HHem52JGewR13pMXOO8Dz1aJFi7Rx40b17NlTe/fu1Z49ezRt2jRdvnxZS5YsUU5OjsaNG6fatWu7etQ/zNOenbmdnJwcnTt3Th07dlSHDh00Y8aMvI8NGjRIhw8f1tatW1WiRAkXTolfys7O1vr163Xq1CkVKVJE1apVU9euXT1uCd54Pzpz5oxKly6tkiVLKjk5WefPn9eqVas0btw4RUZGav/+/Ro8eLBHXTKzbds2vf/++woLC1NGRoZiYmI0evRovfvuu/Ly8lJiYqIeeughVa1a1dWjwskK036U2JFwLXakZ3DbHWlHvomPj7f37dvXnpSUlHfbjBkz7O3atbPb7XZ7SkqKPTU11UXT4UY2m+2m2z799FN73bp17Vu3bv3Z7cOGDbN///33pkbDXUhKSrKHhoba69WrZ//ss8/ybr/Vv6+7W7x4sb1fv372UaNG2f/617/aL126ZA8LC7M3atTIHhERYW/VqpX9zJkzrh7zri1atMj+7rvv2u12uz0zM9Nus9nsY8aMsc+bN8/Fk8Ek9qNnYUcWDOxI9+euO5JLTPOR3W7XpUuXdPbsWT3yyCOSpD59+ujEiRNKSUlRQECAiyfMH5GRkfruu+/k5eWlxo0bq0mTJq4e6a7Yb3g2asWKFTp69KgeffRRPf7448rOztaQIUP03nvvqW3btpKkadOmuXJc/MKNz36WKlVKHTp00D333KMjR44oICBAjz76qMc9a79u3Tpt3bpVCxYs0MiRI1WhQgX5+vqqZcuWSk5O1qFDh/TBBx+oRo0arh71rgUEBCghIUFXr17Ne4XB19dXGRkZkgrOqyz4dYVlP0rsSLgWO9KzuOuOpCDmg+PHjyswMFBly5ZVs2bNdPDgQZUoUUI1a9bUjh07dPXqVdlsNlePmS8WL16srVu3qn///powYYKuXr2qBg0ayNfX19Wj3bHcO9qyZcu0atUqNWvWTJMmTVJiYqJ69OghLy8vDR48WHPmzFGrVq1cPC1uZLfb8xbf7t27VaJECYWEhKh79+6aMGGCtmzZolKlSsnX11eVKlVy20uefnnCj4uLU//+/bV69WolJSVp9uzZmjt3rkqWLKmBAwcqMzPTo+5j69evV3p6ujIzM9WoUSOFh4drwYIFqlu3rjIyMrRnzx7NmTNHEj+QpqArTPtRYkfCtdiRnsETdiQF8Q9atGiRNm3apMqVK+vNN99UkyZNtGPHDv3rX/9SvXr1dOjQIc2cOdNt74R346uvvtKxY8e0ePFiLV++XDVr1tTw4cO1cOFCPf7446pcubLHPNiLiorShg0btHTpUp06dUoHDx7U1q1b5eXlpdDQUBUpUsTj3xNVEF+ZufF3Hy1dulRVqlRRUFCQBg0apKFDh2r69OmaPn26rly5onnz5rl42lu78d/lk08+UdmyZeXj46Pp06erYsWKWrBggSwWi06fPq0WLVpIknx8fFw58l1ZtGiRtmzZooEDB+qFF17Q+++/r3fffVdhYWHavHmzcnJyNHPmTFWvXt3Vo8LJCtN+lNiRnoYdyY50BU/ZkRTE3yknJ0dbt27V9u3bFRERoaNHjyomJkZXr15VkyZN1LFjR125ckUDBgzwqF/QeTvR0dE6evSo7rnnHg0bNkwpKSmaN2+eYmNjtX37dvXu3dtjTrRHjx7Vl19+qUaNGunbb7/Vzp07NWnSJK1YsUIzZszQxYsXNWzYMI85nlu58QSbnp4uHx8fWa1WF0+VP9avX68vvvhC27dv1/Tp07Vz504tXLhQL774okaNGqUTJ06oYsWKbvuT9HL/XbZu3arFixdrxYoV8vPz0/Lly9W8eXN99913On36tM6dO6fGjRv/7M+4s4yMjLxfdB4WFqalS5eqVatWqlu3ro4eParx48dLktLS0lS0aFEXTwtnKmz7UWJHehp2JDvSNE/bkRTE3+Hw4cPy9/dXfHy8ateurdWrVysqKko//vijbDab2rVrp44dO7p6zHyRexL96quvFBERoT/96U9KTEzUxIkTZbVadfz4cXl7eyszM1NFihRx9bi3lHs9fu6xHD9+XGFhYZo7d66uXbumlJQUVatWTdWrV1eDBg303HPPecTJ5nZuXHxLly7VsWPHdPHiRXXp0kWNGjVStWrVXDzh3fnls7yxsbFq3ry5zpw5o+zsbL3wwguaN2+eRo4cqeeff17BwcEunPb2bnxfyJEjR7RkyRLVqVNHVqtVDRo00ODBg7Vx40Zt3bpVVqtVU6dO9Zhn6I8cOSK73a5ixYqpePHiev/993X8+HG9//77+t///qeZM2eqdevW8vPzc4vFB+cpTPtRYkd6InYkO9I0T9yRFMTfYePGjapevbpq1Kih3bt36/Tp0+rfv79atmypBQsW6Ny5c7I7fnuIJ59EJengwYNq1KiR+vTpo7i4OB09elQZGRmaOHGiJOns2bOaMmWKSpYs6eJJby/3hJN7LL1799aZM2e0YcMGXb58WYGBgdqwYYOWLVumKVOmqHz58i6e+I/J/Z77+OOPtW7dOk2aNEnbtm3TV199pQsXLujFF1/0mB8IcePiO3z4sCTJarWqUaNG2rdvn2rUqKEnnnhCUVFR8vX1Vc2aNV057q/K/T48c+aM7Ha7KleurMzMTH322Wd6/PHH1alTJzVr1kz+/v7Kzs72qMvuNmzYoOrVq6tLly766aef9O2332rt2rXy8fFRVFSUKlWq5FE/Vh2/X2HajxI70hOxI90TO9K9diS/B/Eu7dq1S5MmTdKSJUsUGBiY98bYqKgo/fTTT1q4cKGmTJni1nfCO3XhwgW1a9dOLVu2VJcuXeTr66ukpCRVrVpVycnJSk5OVsOGDT3iEqEbj6Vr167y8/NTbGysihYtqvDwcBUpUkQjR45U3bp1XT3q73by5El988036tatm9LS0vTGG2/o2WefVYMGDSRdv1xjxowZmjNnjkf9jiDp+rO8n332mRo2bKj58+dryZIl+uCDD9S/f38lJyfrgw8+0IwZM9zyuA4fPqxLly4pJCRE4eHhCg8P10MPPaRNmzbp4Ycfzvtfhw4dXD3q75J7Tpw/f76CgoIUERGhAwcO6OrVq3rkkUe0detWTZkypcD8bjvcXmHajxI70tOwI9mRruCpO5JXEO9Q7kvfCQkJev755xUYGKhjx47p8OHD8vb21uHDh5WSkqKJEycWmOVXrlw5PfXUUzp//rzi4+O1atUqpaen68UXX9Qzzzzj6vHuyo3HEhcXp9WrVystLU0jRozQypUrde3aNbe9/OdO+fn5ady4cVqzZo1q1aqlb7/9VrGxsXkfb9eunSIiIpSUlOSWS+J2du3apY0bN2r+/PkKDw9X8+bNVaZMGZ07d06fffaZ9u7dqw8//NAtj8lut+vUqVOaN2+eTp48qfPnz2vevHmqWLGi7r//fk2cOFGBgYFKSEiQv79/3hvuPcEvz4lBQUE6deqUEhIS1LFjR8XExKhkyZKaNm1agTkn4tYK436U2JGehh3pfsfEjnTfHUlBvENeXl66fPmy1q9fr7Jly+ratWsKCwvT008/rbp166p3795u88bSP+rTTz9VTk6OGjdurBdeeEH9+/fXgw8+qDJlyuitt97SmjVrFBISomLFirn9JUK/dizjxo3TRx99pODg4ALx71a9enUNGDBAs2fPVosWLdS6dWu9+eabqlSpkurXr68NGzYoLi5OFStWdPWodyUtLU2dO3fW2rVrdeDAAX3wwQfatGmTihcvrmeffVaDBw9222OyWCx6+umn5evrqzlz5qhBgwaqXLmysrOz1a9fP509e1ZlypSR3W7X/fff7+px78qtzomLFy/Wk08+qbJly2rYsGGuHhGGFKb9KLEjPRU70v2wI90XBfEO2e12nThxQqdOnVJgYKDKlCmjKVOm6KGHHsr7HE9/di1XxYoVtWLFCkVGRqpv37568cUXFRUVpaFDh+ree+9VxYoVPeb6/N86lgoVKhSIxZerU6dOuv/++zVkyBD169cvb+F36NBBMTExmj59use9f6R06dJ6/fXXVbNmTUVEREi6/h6F1q1b/+z+5658fX3VuXNnpaen64MPPtCuXbvyngW1WCyqUaOGOnfu7OIp796tzonTpk3ziH8T5K/CtB8ldqQnY0e6H3ake+I9iHchKytLx48fV/369d3+WcE/Ki0tTQcPHtTkyZMVFBSkkydPKiIiwiPeS/FLBelY7tSxY8f03HPP6e2339bVq1fVokUL+fv7q1y5cq4e7a5du3ZN06dPV1xcnNq3b6/U1FQtX75ckyZNUq1atVw93h3LyspSZGSkli9frk6dOqly5cqaM2eOpkyZoho1arh6vN+lMJ0T8esK2/dCQdorBelY7hQ70v2wI90LBfF3ysnJKTC/M+fXxMfHKzo6WuHh4ZowYYLH/EjhWylIx3InvvzySw0fPlwWi0Xh4eEKCgpy9Ui/W0JCgjZt2qQtW7aoUqVKev7551WnTh1Xj3XXMjMztXLlSo0fP17BwcEaPXq0x/1I9dspLOdE/LbC9L1QkPZKQTqWO8GOdD/sSPdBQcQd8bRv7F9TkI7ltyQmJkqSypQp4+JJ8kd2drYkydvbc6+Oz8zM1JYtW/TII4+ocuXKrh4HQD4oSHulIB3Lb2FHuh92pHugIAKAYb/8xcYAAOA6dqTrURABAAAAAJIkL1cPAAAAAABwDxREAAAAAIAkCiIAAAAAwIGCCAAAAACQREEEAAAAADh47i9K+R1sNptSU1Pl4+PDj88FgALObrcrKytLxYoVk5cXz4f+FnYkABQOv7UfC1VBTE1N1enTp109BgDAoDp16qh48eKuHsPtsSMBoHC53X4sVAXRx8dHkvSPf4xUQsJPTs9bvHiu+vQZ4PQcSapUqZaRnFzvvvuqRo6cZCTrypUfjeRI0vvvT9agQf8yklWlSl0jOZI0cuTzevfdj4zlff11lLGssLAF6tXrb0ayMjLSjORI0ooVH6t7978ayapbt6mRHEl6880hGjv2PSNZpUoV17BhffPO/fh1uX9Pw4ePMLIjlyyZr969+zs9R5JSU64YyZGk1WtW6qknnzGW52W1GstauTJCzzwTaiTLajV3v42ICFNoaC9jefXqNTeSM3r0AI0fP9dIliTFxn5rLGv27El66aVXjWQ9+GAzIzmSNGhQF73//jqn5xQvXkS9erW/7X4sVAUx95KZhISfFB9/yUimqRw/v7JGcm7000+XjeQkJTn/gcqNfvzRTF5AwFUjObmSkszlmfq+N52Xnp5qJCdXXFy8kZwKFcw9eJakxESzeVwueWcK8o5MSU4ykpMrLi7OWJaX1exDOVPnJW9vs0/sxMebOS5JqlzZ3D42uftNPX4ynXflitndbzLvdvuRN2UAAAAAACRREAEAAAAADhREAAAAAIAkCiIAAAAAwIGCCAAAAACQREEEAAAAADhQEAEAAAAAkiiIAAAAAAAHCiIAAAAAQBIFEQAAAADgQEEEAAAAAEiiIAIAAAAAHCiIAAAAAABJFEQAAAAAgAMFEQAAAAAgiYIIAAAAAHCgIAIAAAAAJFEQAQAAAAAOFEQAAAAAgCQKIgAAAADAgYIIAAAAAJDkwQVxxowZWrt2ravHAADA7bAjAQC/l7erB/i9XnnlFVePAACAW2JHAgB+L7d9BbFLly7at2+fJOnTTz/VQw89pPT0dEnSqFGj1LRpUy1YsECSVK9ePb3yyivq0KGDTpw44bKZAQAwgR0JAHAWi91ut7t6iFuZNWuWUlNTNWLECI0YMUJRUVGaMGGCmjVrpubNm+u+++5T06ZN9be//U333XefJk6cqK5du/7q18zIyFBMTIyZAwAAuIV69erJz8/P1WPkK3YkAOCPut1+dNtLTNu1a6fhw4fr1VdfVXR0tPr27auoqCgVK1ZMVatWVbly5X72+Q0bNrzjr92nzwDFx1/K75FvsmnTWj32WFen50hS1aoPGMnJNXfuOxow4DUjWUlJcUZyJGnlyo/0zDPPG8mqXv1hIzmSNGnSUL366n+M5R09ut1Y1pYt69W+fScjWenpqUZyJGn37h169NHWRrL+9CczOZL03nujNWTIeCNZZcqU1JtvDjGSZZozd2Tv3v2N7MjNmz9Rhw6dnZ4jSSnJSUZyJClq7xdq1rS5sTwvq7mHcl988bmaN29lJMvb28dIjiR9/vkWtWrV3lhe/fpmsqZO/af+8Y8pRrIk6cKFb4xlrVixQN27/81I1iOPtDGSI0kjR/bQu+8uc3pOyZLFNGhQl9t+3G0vMb3vvvuUlZWl7du3695771WrVq0UFRWlHTt2qEOHDjd9ftGiRV0wJQAA5rEjAQDO4rYFUZLatm2rqVOnqlmzZqpZs6ZSUlK0fv16tW9v7lkeAADcETsSAOAMbl0Q27Vrp++++05NmzaVJDVt2lTlypVTUFCQiycDAMC12JEAAGdw2/cgStIjjzyiU6dO5f33+PH//30rEyZMyPv/N34OAACFATsSAOAMbv0KIgAAAADAHAoiAAAAAEASBREAAAAA4EBBBAAAAABIoiACAAAAABwoiAAAAAAASRREAAAAAIADBREAAAAAIImCCAAAAABwoCACAAAAACRREAEAAAAADhREAAAAAIAkCiIAAAAAwIGCCAAAAACQREEEAAAAADhQEAEAAAAAkiiIAAAAAAAHCiIAAAAAQBIFEQAAAADgQEEEAAAAAEiiIAIAAAAAHLxdPYArJCbGKiEh1khWQsIPRnKys7OM5Nzou++OGcmx221GcnIlJpr53jj61X4jOZL036+/VuSnc43llQ4obixLki5fvmQkx9e3iJGcXDabme/9ffvWGsm5brSxvKCgIElDjGQVJElJ8frpJzPnwZ9+umgkx7SMzGvGsvxMn5dyso3kXE27aiRHkg4fPqyrV38ylmexWAwl/VO7dkUYyjLP1OPQ7747biRHkkaO7KHVq6c7PScoKEiDBnW57cd5BREAAAAAIImCCAAAAABwoCACAAAAACRREAEAAAAADhREAAAAAIAkCiIAAAAAwIGCCAAAAACQREEEAAAAADhQEAEAAAAAkiiIAAAAAAAHCiIAAAAAQBIFEQAAAADgQEEEAAAAAEiiIAIAAAAAHCiIAAAAAABJFEQAAAAAgAMFEQAAAAAgiYIIAAAAAHCgIAIAAAAAJFEQAQAAAAAOFEQAAAAAgCQKIgAAAADAgYIIAAAAAJDkwoL473//WwsWLLjlx2bNmqVt27YZnggAANdjPwIAXMktX0E8cOCAsrOzXT0GAABuhf0IAHA279/6hAMHDmjatGkKCgrS2bNnVaRIEQ0YMEBhYWE6e/as2rdvr9dee03Lly9XWFiYvLy8VLZsWY0ZM0bVq1dXamqqxo8fryNHjshqtapt27YaNmyYJOnLL79UaGioEhISVLt2bU2dOlWRkZGKiYnRpEmTZLVa1aJFC02ZMkWHDh1STk6OHnjgAY0ePVoBAQFq3bq1unXrpn379ik2NlZdunTR0KFDnf13BgAA+xEAUCDd0SuIJ06c0IABA7Ru3ToFBARo7ty5+vDDD7VmzRotW7ZM69ev1/z587VkyRJ98skneuKJJ/TSSy/Jbrdr5syZysjI0IYNG7R27VodOXJEBw8elCTFx8dr4cKF2rx5s+Lj47Vlyxb17NlT9erV06uvvqp27dpp7ty5slqtWrNmjT755BOVL19eU6ZMyZstLS1Ny5YtU0REhD766CNduHDBOX9TAAD8AvsRAFDQ/OYriJJ0zz336IEHHpAkVa1aVcWLF5evr6/KlCmjYsWKafPmzerYsaPKlCkjSXryySf19ttv64cfftDevXs1cuRIWa1WWa1WLV26VJIUGRmptm3bqkiRIpKk2rVrKzEx8absnTt3Kjk5WXv37pUkZWVlKTAwMO/jbdq0kSRVqFBBgYGBunLliqpUqfKrx7N+/fo7Oex8ER0dbSzLtG3bPnP1CE6xfftGIzn//fprIzmuyDt48ICxLFfkmbJnz05Xj+AUBem8WND2o8SOzA8F9bgkKWrvF0ZyDh8+bCTHFXkmvz8K8vdiQT226OhDrh7hzgqir6/vz/+Q98//mMViuenP2O12ZWdny9vb+2cfj42Nlb+//01fx2KxyG633/R1bDabXnvtNbVo0UKSlJqaqoyMjLyP+/n5/ebX+KVOnTopNjb2Nz/vj4qOjlbDhg2dniNJpUpVMJKTa9u2z9S27eNGsux2m5Ec6Xo5bNMmxEjW+dhzRnKk6+WwtuNBrAmlA4obyzp48ID+8pdGRrJ8fYsYyZGul8Pg4JZGstLTU4zkSGbPi0FBQU4vOwVtP0oFc0eaZPq4/Ayel6L2fqFmTZsbyUrPSDOSI10vhw0aNDCWd6vzgjMU1PuYZPrYzPx7SdfLYcOGf3Z6zvX9+MltP54vP6TmL3/5izZs2JD3DOfq1atVqlQpVatWTU2aNFFkZKRsNpsyMzP18ssv69ChX2/GVqs17034wcHBCg8PV2Zmpmw2m8aMGaNp06blx9gAADgV+xEA4Gnu6BXE39KoUSN5eXmpT58+stlsKlOmjD788EN5eXlp8ODBevvtt9WlSxfl5OSoY8eOat++vXbs2HHbr9e6dWtNmzZNWVlZGjRokCZOnKhu3bopJydHdevW1b///e/8GBsAAKdiPwIAPI3FfqfXnBQAGRkZiomJKZCXz3CJaf7gEtP8wSWmfxyXmP5xuZeY1qtX72eXW+LWCvKONIlLTPMHl5j+cQX1PiZxiekflXuJ6e32o1v+HkQAAAAAgHkURAAAAACAJAoiAAAAAMCBgggAAAAAkERBBAAAAAA4UBABAAAAAJIoiAAAAAAABwoiAAAAAEASBREAAAAA4EBBBAAAAABIoiACAAAAABwoiAAAAAAASRREAAAAAIADBREAAAAAIImCCAAAAABwoCACAAAAACRREAEAAAAADhREAAAAAIAkCiIAAAAAwIGCCAAAAACQREEEAAAAADhQEAEAAAAAkiRvVw/gCsHBT+vy5WQjWe3a9TWSEx29yUjOjSwWi5EcH58iRnJy+fqayXug9p+M5EjSunUfG8179NFnjWWZzLtw/msjObkqV6plJOdqcqKRnFzlylU1klOmTDkjOQWNv38xFSlS3EiWqRzTTB7XtWtmHs/kysi8ZiTH1GMMSYqOjjaa5+8fUCCzjn532lhWysWLOnnxopGselXvNZKTy9vbx0DGr1dAXkEEAAAAAEiiIAIAAAAAHCiIAAAAAABJFEQAAAAAgAMFEQAAAAAgiYIIAAAAAHCgIAIAAAAAJFEQAQAAAAAOFEQAAAAAgCQKIgAAAADAgYIIAAAAAJBEQQQAAAAAOFAQAQAAAACSKIgAAAAAAAcKIgAAAABAEgURAAAAAOBAQQQAAAAASKIgAgAAAAAcKIgAAAAAAEkURAAAAACAAwURAAAAACCJgggAAAAAcKAgAgAAAAAkuUlBPHDggJ544ok/9DVmzZqlbdu25dNEAAC4B3YkAMAktyiI+eHAgQPKzs529RgAALgddiQA4E55u3qAXGlpaXr55Zd17tw5lShRQuPGjdOHH36oy5cv68KFC2rZsqX+/ve/680339TJkydlsVjUvHlzDR8+XMuXL1dMTIwmTZokq9Wqdu3aufpwAADIN+xIAIApFrvdbnf1EAcOHFDfvn0VHh6u+vXra/ny5Vq1apVq1qypuLg4LVq0SJI0YsQIFS9eXKNGjVJWVpYGDhyoRo0aacCAAerVq5d69uypxx577LY5GRkZiomJMXRUAAB3UK9ePfn5+bl6jN+NHQkAcIbb7Ue3eQXxvvvuU/369SVJ3bp10xtvvKHy5curQYMGeZ+ze/duffzxx7JYLPL19VVoaKgWL16sAQMG3FXWxImLdflycr7OfyvvvjtYI0fOcnqOJEVHbzKSk2vr1k/Vrt0fe0/MnfL29jWSI0kbN65RSMiTRrJ8fc09YF237mN16fJXY3m1a//ZWNaUKcP1z39OM5J14fzXRnIkafmK+Xq2e38jWVeTE43kSGbvY+XLl9PixR8ayXI2kzvymWdCFRcXn6/z38oXX3yu5s1bOT3HNNPHde2a8x/P5IqOjlbDhg2N5Zli+rj8/QOM5OzZs1PBwS2NZEnS0e9OG8tKuXhRAZUqGcmqV/VeIzmStH//XjVu3NTpOUFBFRUZuea2H3eb9yB6ef18FIvFIm9vbxUtWjTvNpvNJovF8rP/5j0VAICCjh0JADDFbQriqVOn9M0330iSli9frgYNGqhIkSI/+5zg4GAtXbpUdrtdmZmZWrFihZo2vd6yrVYrixAAUCCxIwEAprhNQaxRo4ZmzZqlzp07a8eOHZowYcJNnzN69GglJiaqU6dO6tSpk6pXr66///3vkqTWrVtr2rRpioyMND06AABOxY4EAJjiFu9BbNSokdavX3/T7b9cgKVLl9bUqVNv+TV69+6t3r17O2U+AABchR0JADDJbV5BBAAAAAC4FgURAAAAACCJgggAAAAAcKAgAgAAAAAkURABAAAAAA4URAAAAACAJAoiAAAAAMCBgggAAAAAkERBBAAAAAA4UBABAAAAAJIoiAAAAAAABwoiAAAAAEASBREAAAAA4EBBBAAAAABIoiACAAAAABwoiAAAAAAASRREAAAAAIADBREAAAAAIImCCAAAAABwoCACAAAAACRREAEAAAAADt6uHsAV9u//RHFxcQaSBmvnzo8N5EhZWRlGcm6UlGTi71Dy8ytqJCfX1asJRnLKl69mJCeXl5e5u/tXX+0xliUNN5xnztXkRCM5H25YbSTHdJ7VSErB07LlX3XlSqqRrJCQF4zkfPPNPiM5ue69t56xrKSkeGNZklSxYg0jOSkpSUZycgUElDaW5e9fzFhWQEApY1kNatc1lrVr13ZjedWrP2wkx2Re2bKBv/pxXkEEAAAAAEiiIAIAAAAAHCiIAAAAAABJFEQAAAAAgAMFEQAAAAAgiYIIAAAAAHCgIAIAAAAAJFEQAQAAAAAOFEQAAAAAgCQKIgAAAADAgYIIAAAAAJBEQQQAAAAAOFAQAQAAAACSKIgAAAAAAAcKIgAAAABAEgURAAAAAOBAQQQAAAAASKIgAgAAAAAcKIgAAAAAAEkURAAAAACAAwURAAAAACCJgggAAAAAcKAgAgAAAAAkURABAAAAAA4URAAAAACAJMnbmV98x44dmjNnjrKysuTv768RI0aoRIkSGjVqlDIzM2W32/X000+rZ8+eOnPmzC1vl6Q5c+Zoy5Ytstlsqly5ssaOHasKFSqoV69e+r//+z8dOXJEsbGxatKkid566y15edF7AQDui/0IAHBXFrvdbnfGF/7+++81ZMgQLVmyRKVLl9Z///tf9evXT82bN1f16tU1YMAA/fjjj3rnnXc0depUjR49Wvfee+9Nt3/yySfatWuXJk+eLG9vby1fvlzbtm3TvHnz1KtXL5UpU0bTp09XWlqaQkJCNHnyZDVu3PiWM2VkZCgmJsYZhwsAcFP16tWTn5+fq8fI4477UWJHAkBhc7v96LRXEKOionTp0iX17ds37zaLxaL7779fs2fP1vHjx9WkSRONHj1aXl5eateunUaMGHHT7Z9//rlOnDihp556SpJks9l07dq1vK/ZqlUreXl5KSAgQNWqVdOVK1d+c7Zu3Z5SXFxcvh/zL+3bF6UmTZo5PUeSsrIyjOTkio6OVsOGDY1k+fkVNZIjSVFRu9Ws2aNGssqXr2YkR5IiI8PUrVsvY3np6anGsjZuXKOQkCeN5Zli8rg+3LDaSI4kVbVYdN45z0vexCqpssViJOtuuPN+lKTZs9fpyhXn34dfe62H3nlnmdNzJOmbb/YZyZGksLD31KvXEGN5SUnxxrI+/XSFnniiu5GslJQkIzmStHPnVrVs2c5Ynr9/MSM5mzat1WOPdTWSJUnXriUby9q1a7tatGhjJKtSpdpGciTp448/0F//+nen55QtG6j33nv7th93WkG02Wxq0qSJ/vOf/+TdFhsbq/Lly6tz587au3ev9u3bp9mzZ2vNmjVq1aqVNm/efNPtNptN/fv3V48ePSRJmZmZP1ty/v7+ef/fYrHISS+IAgCQL9iPAAB35rQ3IzRp0kRRUVE6c+aMJGnXrl3q3LmzXnnlFW3YsEGPP/64xo4dq4CAAJ0/f17/+Mc/bnl7cHCwVq1apZSUFEnSjBkz9OqrrzprbAAAnIr9CABwZ057BbFWrVoaN26chg8fLrvdLm9vb82ZM0elS5fWqFGjtHz5clmtVrVt21Z//vOfFRgYeMvbGzZsqPj4eHXv3l0Wi0VBQUGaMGGCs8YGAMCp2I8AAHfm1J9iGhISopCQkJtuj4iIuOm2mjVr3vJ2i8Wil19+WS+//PJNHwsLC/vV/wYAwB2xHwEA7oqfdw0AAAAAkERBBAAAAAA4UBABAAAAAJIoiAAAAAAABwoiAAAAAEASBREAAAAA4EBBBAAAAABIoiACAAAAABwoiAAAAAAASRREAAAAAIADBREAAAAAIImCCAAAAABwoCACAAAAACRREAEAAAAADhREAAAAAIAkCiIAAAAAwIGCCAAAAACQREEEAAAAADhQEAEAAAAAkiiIAAAAAAAHCiIAAAAAQJLk7eoBXMFut8lmyzGSZSqnQLPbC2Tejz9eMJLjirzs7ExjWZKUlBRnJMfHx89ITq6UlCQjOd0aNjSSI0mHDx82lpeRkaGYmBgjWQVJpxcfV7ahrNBXuxvJGf70BiM5uZKTzdx3JSkx8aKxLJN5OTmmvguvu3Yt2WieKenpqcayMjPTjWWZzPv++xNGckzmpadX/NWP8woiAAAAAEASBREAAAAA4EBBBAAAAABIoiACAAAAABwoiAAAAAAASRREAAAAAIADBREAAAAAIImCCAAAAABwoCACAAAAACRREAEAAAAADhREAAAAAIAkCiIAAAAAwIGCCAAAAACQREEEAAAAADhQEAEAAAAAkiiIAAAAAAAHCiIAAAAAQBIFEQAAAADgQEEEAAAAAEiiIAIAAAAAHCiIAAAAAABJFEQAAAAAgAMFEQAAAAAgiYIIAAAAAHBwekFMSUnRsmXLdPz48Xz9upMnT9a5c+fy9WsCAGASOxIA4G68nfWFjx07puXLl2vfvn1q06aN2rZtqx07dmjOnDnKysqSv7+/RowYoUceeURZWVmaMGGC9u3bJ6vVqocfflgjR45UQECAli1bpoiICPn4+MjPz0/jxo1TrVq1VLZsWb300ksKDAzUs88+q7Zt28rX19dZhwMAQL5hRwIA3FW+v4J44sQJde3aVTNmzFBwcLA2b96s0aNHKy0tTdOnT9fcuXO1du1avfXWWxoyZIjS0tI0Z84cXbp0SevWrdO6detks9k0adIk5eTk6J133tH8+fO1evVqde/eXYcPH5Yk9evXT59++qmGDh2qPXv2KCQkROHh4fl9OAAA5Bt2JADA3eX7K4heXl7y8vKSxWKRxWLJuz0qKkqXLl1S3759826zWCw6f/68du/erWHDhsnHx0eS1KtXL7300kuyWq167LHHFBoaqpYtWyo4OFgtWrT4WZ7Vas3L9PK6s767dm3kHz/QO3TgwH5jWaZFR0e7egSniNr7hatHcIo9e3a6egSn2b9/r6tHcIovvvjcSE5uqTDFdJ478YQdWdXbaRcX3aSGoay1a5cayXFVnkl79+5x9QhOUVAfr+3cudXVIzjNvn1Rrh7BKdzhuPL9zPzggw9qzZo1On78uCIiIjR58mS1b99eAQEBatKkif7zn//kfW5sbKzKly8vm832s0Vps9mUlZUlSZoyZYpOnz6tvXv3au7cuVq3bp1mzJihJUuWaNWqVSpVqpRCQ0M1duzYvOX5W7p27abY2Nh8Pe5bOXBgvxo1auz0HEnKyck2kpMrOjpaDRs2NJLl51vESI50vRw2a9rcSJbFy2okR7peDoODWxrLy87ONJa1f/9eNW7c1EiWj4+fkRzpejls3ryVkay0tKtGcqTr5bBBgwZGsjIyMhQTE2Mk6055wo48n50tExulhre3vss2s7uGP93XSI50vRx27fqcsbxLl743lrV37x41bRpsJMvk4xqTj9ckqUiR4kZydu7cqpYt2xnJkqSMjDRjWfv2RalJk2bG8kwxdVwVK1ZUZOTq237caT+k5uGHH9Y777yjdevW6Z577tFf/vIXRUVF6cyZM5KkXbt2qXPnzkpPT1fz5s318ccfKysrSzabTeHh4WrWrJkSExPVokULlSpVSn379tXQoUN14sQJSdcXZ+4S7Nix4x0vPgAAXI0dCQBwV06/tqN48eJ67rnrz6SNGzdOw4cPl91ul7e3t+bMmaNixYpp4MCBmjhxorp27ars7Gw9/PDDGjNmjEqUKKGBAweqb9++8vf3l9Vq1fjx4yVJI0aMcPboAAA4FTsSAOBuzL3RQFJISIhCQkJuut3f319jx4695Z8JDQ1VaGios0cDAMCl2JEAAHfg9N+DCAAAAADwDBREAAAAAIAkCiIAAAAAwIGCCAAAAACQREEEAAAAADhQEAEAAAAAkiiIAAAAAAAHCiIAAAAAQBIFEQAAAADgQEEEAAAAAEiiIAIAAAAAHCiIAAAAAABJFEQAAAAAgAMFEQAAAAAgiYIIAAAAAHCgIAIAAAAAJFEQAQAAAAAOFEQAAAAAgCQKIgAAAADAgYIIAAAAAJBEQQQAAAAAOHi7egCT7Ha7JKl8+XLGMoOCgozk5ORkG8m5kalj8/XxN5KTq2LFikZyLF5WIzm5TB2XJOXkZBrLkqSgIDPH5u3tayQnV8WKFYzkZGRkGMkxnZeZef37MPfcj1+X+/dk8sxk6kFI+fJlDSWZz/PySjeWJZnbJTZbjpGcXKYe00iSv38xY1mm9ogkZWRcM5YlmX1cY5KJ4ypX7noXut1+tNgL0eZMTk7W6dOnXT0GAMCgOnXqqHjx4q4ew+2xIwGgcLndfixUBdFmsyk1NVU+Pj6yWCyuHgcA4ER2u11ZWVkqVqyYvLx4R8VvYUcCQOHwW/uxUBVEAAAAAMDt8ZQqAAAAAEASBREAAAAA4EBBBAAAAABIoiACAAAAABz+H8qbo/5kh6tvAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x1800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_count 1    self.capacity  20\n",
      "0  ------------------------------------------------\n",
      "DecoderLayer@trg4\n",
      "[1, 1, 64]\n",
      "tensor([[[-1.2708,  0.3755, -0.1442, -0.7491,  0.9974,  2.1600, -0.3645,\n",
      "           0.3054, -1.6588, -0.5482,  0.2102, -0.2257, -1.0522, -1.2532,\n",
      "           0.5423, -1.7919,  1.0234,  1.6629, -1.3029,  0.2927, -0.2699,\n",
      "           0.0435,  0.1871,  0.7128,  0.3651,  0.1868, -0.6788,  0.8081,\n",
      "          -0.1153,  0.5708,  0.2078, -0.1559, -0.0295, -0.2620, -0.2809,\n",
      "           0.1026,  0.4893,  0.1280,  0.6138,  0.5686, -0.6734,  1.5511,\n",
      "          -0.3869, -1.0898,  0.0463,  1.4609,  2.0184, -1.0990, -0.3993,\n",
      "          -0.7370, -0.1108,  0.7482,  1.4289, -0.8267, -1.5997,  2.1433,\n",
      "          -0.9065, -1.4872,  0.9177, -0.6118, -0.7378,  0.0241, -2.3250,\n",
      "           2.2794]]])\n",
      "src = ['we', 'want', 'to', 'eat', 'apple']\n",
      "predicted trg = ['wir', 'mochten', 'apfel', 'essen', '<eos>']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_count 1    self.capacity  20\n",
      "0  ------------------------------------------------\n",
      "DecoderLayer@trg4\n",
      "[1, 1, 64]\n",
      "tensor([[[-1.3944,  0.4491, -0.1688, -0.7077,  0.9164,  2.2670, -0.3990,\n",
      "           0.2358, -1.6414, -0.4647,  0.0174, -0.2985, -1.0076, -1.2270,\n",
      "           0.6598, -1.8078,  0.9226,  1.6960, -1.2539,  0.3553, -0.2720,\n",
      "           0.1042,  0.3693,  0.7590,  0.2756,  0.2755, -0.6512,  0.8062,\n",
      "          -0.0179,  0.7085,  0.3513, -0.0920, -0.0133, -0.3461, -0.4422,\n",
      "           0.0365,  0.3461,  0.2974,  0.6386,  0.6463, -0.6972,  1.5139,\n",
      "          -0.4439, -1.1511, -0.1109,  1.4601,  2.0449, -1.0995, -0.4087,\n",
      "          -0.8374, -0.1957,  0.6296,  1.3503, -0.7719, -1.6132,  1.9952,\n",
      "          -0.7777, -1.5385,  0.9730, -0.5427, -0.8233,  0.1499, -2.2540,\n",
      "           2.2483]]])\n",
      "src = ['we', 'want', 'to', 'drink', 'water']\n",
      "predicted trg = ['wir', 'mochten', 'wasser', 'trinken', '<eos>']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_count 1    self.capacity  20\n",
      "0  ------------------------------------------------\n",
      "DecoderLayer@trg4\n",
      "[1, 1, 64]\n",
      "tensor([[[-0.9610,  0.1613, -0.1625, -1.2414,  0.8785,  2.1478, -0.4000,\n",
      "           0.6600, -1.6157, -0.4534,  0.8738, -0.1425, -0.9410, -1.6259,\n",
      "           0.4628, -0.9592,  1.3966,  1.3379, -1.2698,  0.0527, -0.1222,\n",
      "          -0.1366, -0.1617,  0.4260,  0.5701, -0.2196, -0.6542,  0.4483,\n",
      "          -0.4127,  0.5988,  0.0174, -0.0704,  0.0567, -0.4782, -0.2161,\n",
      "           0.2479,  0.5710, -0.5350,  0.7363,  0.0474, -0.6493,  1.4432,\n",
      "          -0.3819, -1.4143,  0.4048,  1.5405,  2.3143, -0.8388, -0.2017,\n",
      "          -0.4720, -0.1404,  0.3412,  1.5493, -0.7255, -1.2086,  2.1571,\n",
      "          -0.8610, -1.1417,  0.7525, -0.8706, -0.8254,  0.0094, -2.3268,\n",
      "           2.7001]]])\n",
      "src = ['we', 'want', 'to', 'drink', 'beer']\n",
      "predicted trg = ['wir', 'mochten', 'bier', 'trinken', '<eos>']\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4gAAAFDCAYAAAB4ACCQAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAzUElEQVR4nO3deUCU5f7+8YsdRdxwAVGL3LKsc1xOlsvRXNNK0yytLLXUciv1V7kcTTN3zdRj4r4higsKaZp7mmSKmmumR8MsZRHJEJB9fn808LVyy+CeGXi//oIZmOt+YOb5cM3zzOBksVgsAgAAAAAUes62XgAAAAAAwD5QEAEAAAAAkiiIAAAAAAArCiIAAAAAQBIFEQAAAABgRUEEAAAAAEiiIAIAAAAArCiIAAAAAABJFEQAgJ3Izs7+3ecWi8VGKwEAwL6YnJEURBvJ+SVnZmbaeCUAYB+cnZ2VlJSk48ePS5KcnJxsvCLYAvMRAP7M5Ix0zbdbxm2lpqbq6tWrWrRokdq2bas6derYekkAYDMHDx7U1atXtXjxYjk7O2vkyJGqXr26rZcFG2A+AsDvmZ6RFEQbWLNmjc6ePavo6Ght3bpVPj4+DEAAhVJkZKS++eYb7d27V23atFFWVpbKlStHOSykmI8A8H9sNSMpiAZ988032r17tw4cOKB3331XsbGxKl68uLp162brpeEWsrOz5ezMmdhAfjlz5ox+/fVXTZkyRZUrV1ZmZqYefvhhSTz+ChPmo2PiMQrkL1vNSAqiQdWrV5e7u7t69uwpHx8fbdiwQcWLF5erqys7WTvz/fffq2TJkvL19bX1UnAXcl6onXM+fmZmplxdC87uzWKxFNjX473yyiu5H0dGRmrz5s1q2rSpJLFPLESYj46FGelYmJGOy1Yzkj2uIVFRUUpNTVWdOnXk4+OjqKgozZ8/Xw0aNJC7uzvDz84cPnxYnTt31rRp07RlyxZbLwd3kJKSkjscgoODNWfOnALzDpg3Dr7Y2FgbrybvhIaGatasWdqxY4ckKTk5WWFhYerSpYuqVq1q49XBJOaj42FGOhZmpOOx9Yxkr2tAUFCQPvjgA82aNSv3znv58mU1a9ZMjRo1KjAP0oLk5ZdfVqVKlbRgwQKVKFFCkpSVlWXjVeFmoqKiNHjw4Nx39YqPj1dAQICcnJxyf2d/fGtoR5Iz+EJCQvTuu+8qPT3dxiv6+5YsWaKwsDCVL19e/v7+un79uooWLarHH39c5cqVs/XyYBDz0TExIx0HM9Lx2MOMLDjHl+1UaGioNm/erFmzZikuLk4XL17Unj171Lx5c12/fl0Sb+VuL/54GlPDhg3l7++v9957T4sXL1bVqlUL3GkZBUF6eroqVqyoOXPmaNCgQfL09FRUVJRSUlJUtGhRSY5/qmJ4eLhWrVqlKVOmyN3d3aFPp4mOjtbu3bsVFBSkw4cPa9euXdq+fbtKliypBQsWOOx24a9jPjoWZqRjYkY6FnuZkTyK81l8fLy6dOmirVu36ujRo7p8+bL27t2rjIwMvfzyy7ZeHm6Qs4Pct2+fMjMz1bt3b7m4uGjs2LHq1q2btmzZomvXrsnPz8/GK4X0f6eV1KhRQy+99JLWrFmj6dOn69y5c/Lx8VFoaKjq1KkjLy8v/fvf/1aLFi1sveS79sfhlp6erlOnTunkyZOqWrWqQw8/i8WikydPqnfv3kpISFDTpk01ePBgrV69WjExMfLz83Po7cPdYz46FmakY2FGOuYMsZcZSUHMZz4+PgoJCVFaWpr69u2r5s2ba+3atUpISHDoO3BBcuOzosuXL9fixYtVokQJjRo1SuvXr9eIESOUlZWlxo0bq1SpUlqzZo18fHxsvOrC7cbHTmJiogICAvT6669r6dKlioyM1JtvvqmAgABFRUXpyy+/VI0aNWy84rt347ZdvHhR3t7eat++vVxcXDRy5EiVLFlSTZo0cbg37vjuu+/k4eGhsmXLatmyZTp27JieeOIJVapUSdu3b9dPP/0kT09PSRw1KiyYj46BGel4mJHMyL/LycIJ/nlu/fr1ioqKUlxcnPr376/SpUurSJEiio+P1549exQUFKSPP/5YVapUsfVScYP9+/drz5496t69u8qWLas+ffrohx9+0Jo1a1S8eHFFRESocuXKqlSpkq2XWqjdOBwWLVqkXbt2KTExUTNmzFCRIkX06aef6tKlS3rvvfccauj90eLFi7V//35JUrly5dSvXz9t375dM2fO1Lhx4xzq2d6lS5dq8+bNKlGihC5duqQePXqoY8eOGjZsmFxcXHT48GHNmDFD1apVs/VSkc+Yj46LGekYmJHMyLzgONXaQSxZskQhISG57zDUpUsXnThxQtu2bdOgQYO0du1aTZkypUAMv4Ly3EJWVpZ++OEHdevWTT///LPKli0rSQoMDFSVKlXUsmVLJSYmqmHDhgw+O5Az+A4dOqSdO3dq2LBh+sc//qHOnTsrKSlJ/fr1U4UKFTR37lylpqY65Ivv16xZo927d2vOnDnKyspSVlaWvLy89MILL6hv374aO3asUlJSHOIxuH37doWHh2vhwoWaMGGC3nvvPU2fPl0RERFq166dnnjiCc2ZM4dyWAgUpvkoMSNhG8xIZmSesCDPxMbGWrp372755Zdfci+bMWOGpWXLlhaLxWJJSkqyJCcn22h1uFF2dvafLtu4caOlZs2alm3btv3u8kGDBlnOnz9vamm4hXPnzlmioqIsFovFsnr1astLL71k+frrr3OvHz9+vKVBgwaW06dPW2JiYiyXL1+20Ur/vunTp1tOnTplWbx4saV79+6WpKQky3/+8x/L559/brFYLL/bx9i7JUuWWCZMmGCxWCyW9PR0S3Z2tmXkyJGW+fPn23hlMIn56FiYkY6HGcmMzEscQcxDFotFcXFxioqKyr2sW7duuu+++5SUlCQvL6/cd4xyZOvXr9fHH3+sTz75RPv27bP1cv4yyw2nX6xevVrDhw/XF198oaeffloTJkzQgAEDtH379tyvnzZtmu677z5bLReSrl69qrCwMJUsWVKZmZl65JFHdOTIEW3evDn3a4YNG6ZmzZqpT58+KlWqlMqUKWPDFd89yx+e4bRYLIqJidF7772nU6dOae7cufLy8lJ8fHzu1+S8rbwjKFasmOLj45WYmCg3Nzc5OTnJ3d1daWlpkgrOURbcXmGZjxIzEuYxI5mReY03qckDx44dk4+Pj8qUKaOGDRvqwIEDKl68uKpUqaKdO3cqMTHRIQ/h38zSpUu1bds29ezZUxMnTlRiYqLq1q0rd3d3Wy/truUMvhUrVmjt2rVq2LChJk+erISEBL388stydnZW//79FRgYqCeffNLGq4XFYlHJkiU1ePBgfffddwoNDVX//v21bt06derUSRUrVlTv3r0lSR999JHi4+Md5v544x9iBw8elJeXl4oUKaK+ffvq6aef1gsvvCCLxaKwsDBFRUXp0UcflWT/b+KyYcMGpaamKj09XfXr11dwcLAWLlyomjVrKi0tTXv37lVgYKAk+98W/D2FaT5KzEiYx4xkRuYH3qTmb1qyZIm++OIL+fv768MPP1RkZKR27typkydPqlatWoqMjNTMmTMLxOtrTp48qYULF2rKlClatWqVIiIiNHHiRK1YsUJPP/20/P397f5BmSMiIkKBgYGaN2+eTp8+rYkTJ6po0aJq3bq1unTpou3btysgIMChXwtjKSDvApiVlSUXFxdt2bJFR44c0cWLF1WxYkW99dZb+umnn9S1a1f16NFDb7/9tiTH3O4lS5Zox44deuihh/TFF19o7ty5unz5skaNGqWqVasqOTlZo0ePdoj9yJIlS7R161b16dNHvXr10uzZs+Xv76+goCAlJycrKytL/fv3V/Xq1W29VOSzwjQfJWako3HEWXEzzEhmZH6gIN6jrKwsbdu2TcHBwQoKCtKRI0eUmpqq2NhYubm5qVSpUvr1119Vq1YtVaxY0dbL/dsOHjyoI0eOKDExUefPn1dSUpLmz5+v6OhoDR48WEuXLlWRIkVsvcy7cuTIEe3du1cWi0VNmjTRjh071LFjR61evVrr1q3TCy+8oEGDBjncDvRGNw6A1NRUubm5ycXFxcar+mtOnTql8uXLq3Tp0tq0aZMWLlyo0NBQHTlyRMuWLct917KoqCi99dZb+vzzz1WqVClbL/sv2759u4KCgrR06VKNGzdOV65c0fDhw5WZmanixYsrMzNT2dnZKlmypK2XeltpaWm6ePGixo4dq/nz52v58uX65ptv9MEHH+jIkSNq06aNJP3unzOjYCps81FiRjoaZqTjYEbaBqeY3oNDhw7J09NTsbGxqlatmkJDQxUREaHLly8rOztbLVu2VNu2bW29zDyRsxM9efKkQkJC9I9//EMJCQmaNGmSXFxcdOzYMbm6uio9Pd1uh1/O/8LJ2ZZjx44pKChI8+bN0/Xr15WUlKT77rtPAQEBqlu3rrp27VpgBt/y5ct19OhRXbp0Se3bt1f9+vUd4rUi165d07Jly3TlyhW9+OKL2rBhQ+4zg//85z+VlpamNWvWaMqUKXr//ff15ZdfOswpM3/830xpaWlq3ry5Fi5cqLNnzyowMFArV67UhQsXNGrUKBuu9O4dPnxYFotFXl5e8vb21uzZs3Xs2DHNnj1bFy9e1MyZM9WsWTN5eHjYxeBD/ilM81FiRjoiZqR9Y0bax4ykIN6DzZs3KyAgQA888ID27NmjM2fOqGfPnmratKkWLlyoH3/8MfdFpY68E5WkAwcOqH79+urWrZtiYmJ05MgRpaWladKkSZKkqKgoTZ061a5fEJyzo8nZltdee03nzp3Tpk2bdPXqVfn4+GjTpk1asWKFpk6dqnLlytl4xX9Pzn1u5cqVCg8P1+TJk7V9+3adPHlSP/30k958800VK1bMxqu8PW9vb/Xs2VMLFixQUFCQfH19lZaWps8//1xPP/206tevr4yMDG3evFlpaWl2vz03yrk/njp1SkWLFlVCQoJ27NghNzc3zZs3T25ubrp48WLuP8R1BJs2bVJAQIDat2+vK1eu6OzZswoLC5Obm5siIiJUoUIFh/qHxbh3hWk+SsxIR8SMtG/MSPvAKaZ/0e7duzV58mQtW7ZMPj4+Sk9Pl7u7uyIiInTlyhUtXrxYU6dOdejz8nP89NNPatmypZo2bar27dvL3d1dv/zyiypXrqxr167p2rVrqlevnkOcInTjtjz33HPy8PBQdHS0ihYtquDgYBUpUkTDhg1TzZo1bb3Ue/b999/r1KlT6tChg1JSUjR69Gh17txZdevWlSRt27ZNM2bMUGBgoEP8r6qc/3P0888/q2TJkvLx8VG5cuVUu3ZttWrVSpJ0/fp1u31W/o8OHTqkuLg4tWnTRsHBwQoJCVH16tW1bds2lSpVSi+88IIqVqyo1NRULV26VJ9++qkeeOABWy/7jnL2iQsWLJCfn59CQkK0f/9+JSYmqnbt2tq2bZumTp3qEK8Nwd9TmOajxIx0NMxI+8aMtK8ZyRHEu5RzyDs+Pl6vv/66fHx8dPToUR06dEiurq46dOiQkpKSNGnSpAIz/MqWLavnn39eFy5cUGxsrNauXavU1FS9+eabeuGFF2y9vL/kxm2JiYlRaGioUlJSNGTIEK1Zs8ahdqK34uHhoTFjxmjdunWqWrWqzp49q+jo6NzrW7ZsqZCQEP3yyy92P/zCw8O1bNky/fe//9XJkyd17tw5ffPNN3Jzc9PevXvl4uKi5s2bO8wziBaLRadPn9b8+fP1/fff68KFC5ozZ458fX21fPlyTZgwQadOnVJcXJySk5M1c+ZMux98f9wn+vn56fTp04qPj1fbtm114sQJlShRQtOmTSsw+0TcXGGcjxIz0tEwI+0XM9L+9osUxLvk7Oysq1evasOGDSpTpoyuX7+uoKAgderUSTVr1tRrr71mNy8s/bs2btyorKwsPf744+rVq5d69uyphx9+WKVLl9ZHH32kdevWqU2bNvLy8rL7U4Ruty1jxozRokWL1KhRowLxewsICFDv3r316aefqkmTJmrWrJk+/PBDVahQQXXq1NGmTZsUExMjX19fWy/1js6cOaN27drp/vvvl7+/v86dO6cTJ07o7Nmzqlmzpv75z39KcpxT1JycnNSpUye5u7srMDBQdevWlb+/vzIzM9WtWzedO3dOAQEB6tGjh1JTUx1iqN9sn7h06VJ17NhRZcqU0aBBg2y9RBhSmOajxIx0VMxI+8WMtD8UxLtksVh0/PhxnT59Wj4+PipdurSmTp2qRx55JPdrHP3ZtRy+vr5avXq11q9fr+7du+vNN99URESEBg4cqPvvv1++vr4Ocz77nbalfPnyBWLw5Xj22Wf14IMPasCAAerRo0fuwG/durVOnDihTz75xCFeP1K5cmXt2rVLLVq0UEBAgB588EGVKFFC5cqV01tvvSUfHx9bL/Evc3d3V7t27ZSamqo5c+Zo9+7datKkiSTJxcUl9w0EPDw8bLnMu3azfeK0adN+t09E4VCY5qPEjHRkzEj7xYy0L7wG8S/IyMjQsWPHVKdOHYd5VuZepaSk6MCBA5oyZYr8/Pz0/fffKyQkxCFeS/FHBWlb7tbRo0fVtWtXjRs3TomJiWrSpIk8PT1VtmxZWy/trsTGxmry5Mny9fXV448/rpSUFC1dulSffPKJypcvb+vl/S0ZGRlav369Vq1apWeffVb+/v4KDAzUxx9/rICAAFsv7y8pTPtE3F5huy8UpLlSkLblbjEj7Rcz0j5QEO9Rzj8mLehiY2N18OBBBQcHa+LEiapcubKtl3TPCtK23I1vv/1WgwcPlpOTk4KDg+Xn52frJf0l58+f15o1a3T06FF5eHjovffe04MPPmjrZeWJ9PR0rVmzRmPHjlWjRo00YsQIh3hr9dspLPtE3Flhui8UpLlSkLblbjAj7Rcz0vYoiLgrjnbHvp2CtC13kpCQIEkqXbq0jVdybywWi1JTU2WxWArUaU7SbwNw69atql27tvz9/W29HAB/Q0GaKwVpW+6EGWm/mJG2RUEEABu58R82AwCA/8OMtB0KIgAAAABAkuRs6wUAAAAAAOwDBREAAAAAIImCCAAAAACwoiACAAAAACRREAEAAAAAVq62XoBJ2dnZSk5OlpubG2+bCwAFnMViUUZGhry8vOTszPOhd8KMBIDC4U7zsVAVxOTkZJ05c8bWywAAGFS9enV5e3vbehl2jxkJAIXLreZjoSqIbm5ukqShQ0fpypWEfM+bP/+/6tVrQL7nSFKzNi8aycnxUsfGWrnuKyNZp48dNZIjSaNH99fo0bOMZPlWuN9IjiS91fsZzZm30VhexFfrjWUFBS3Uq6++YSQrMyPDSI4krQxZppe6vGYkq+ZDTxjJkaQPPuijMWMCjWSVKOGtd97pmrvvx+3l/JzGjJmmhISr+Z43ffoYDRz4Qb7nSFJCwiUjOZK0bNkCvfZaT2N56empxrJCQparS5euhtLMHcUOCQlSly6vGsvLzDQzS9auDVGnTl2MZElS6dK+xrLmzZuu3r0HGsnq2M3c4/mphrX0RcSJfM8p4uGmJvVq3HI+FqqCmHPKzJUrCYqLizeSaSonKdncgDCdmZDwq5Ec03lFi6UYycmRmGguLzY2zliWybzMjHQjOTliY2ON5Pj6JRrJyfHLL2bzOF3y7uT8nBISrio+Pv+fRJVkLOfy5YK5T5KktLTrxrIkKSbGzH7J9OPW1P5WkjIMzpKYmBhjWZmZZmuFqb+xU1LNzn6Tebd6nPGiDAAAAACAJAoiAAAAAMCKgggAAAAAkERBBAAAAABYURABAAAAAJIoiAAAAAAAKwoiAAAAAEASBREAAAAAYEVBBAAAAABIoiACAAAAAKwoiAAAAAAASRREAAAAAIAVBREAAAAAIImCCAAAAACwoiACAAAAACRREAEAAAAAVhREAAAAAIAkCiIAAAAAwIqCCAAAAACQREEEAAAAAFhREAEAAAAAkhy4IM6YMUNhYWG2XgYAAHaHGQkAuFeutl7AvXrnnXdsvQQAAOwSMxIAcK/s9ghi+/bttW/fPknSxo0b9cgjjyg1NVWS9J///EcNGjTQwoULJUm1atXSO++8o9atW+v48eM2WzMAACYwIwEA+cXJYrFYbL2Im5k1a5aSk5M1ZMgQDRkyRBEREZo4caIaNmyoxo0bq0aNGmrQoIHeeOMN1ahRQ5MmTdJzzz1329tMS0vTiRMnzGwAAMAu1KpVSx4eHrZeRp5iRgIA/q5bzUe7PcW0ZcuWGjx4sN5//30dPHhQ3bt3V0REhLy8vFS5cmWVLVv2d19fr169u77tXr0GKC4uPq+X/Cfh4SvVvv1L+Z4jSc90et1ITo5er7bU/KBtRrKORx4wkiNJM2f+R2+/Pc5IVsXK1YzkSNL7776oyVNXG8vbvjXIWNbWrRvUqtWzRrIyM9KN5EjSzl1b1OzJ1kay/vHPZkZyJOmTT4Zo0KBJRrJKlSquDz7oYyTLtPyckQMHfqD4+IS8XvKfLF8+S1279s/3HEm6fPmCkRxJ2rLlM7Vu3c5YXlradWNZX365TU2btjSS5eTkZCRHknbt2qonn2xlLC/D0CzZu/dLNWrU1EiWJJUpU9FYVljYcj33XFcjWa8NGGwkR5I6Nq+jdTsO53tOUU93PdWw1i2vt9tTTGvUqKGMjAzt2LFD999/v5588klFRERo586dat36z380FS1a1AarBADAPGYkACC/2G1BlKQWLVro448/VsOGDVWlShUlJSVpw4YNatXK3LM8AADYI2YkACA/2HVBbNmypX744Qc1aNBAktSgQQOVLVtWfn5+Nl4ZAAC2xYwEAOQHu30NoiTVrl1bp0+fzv187NixuR9PnDgx9+MbvwYAgMKAGQkAyA92fQQRAAAAAGAOBREAAAAAIImCCAAAAACwoiACAAAAACRREAEAAAAAVhREAAAAAIAkCiIAAAAAwIqCCAAAAACQREEEAAAAAFhREAEAAAAAkiiIAAAAAAArCiIAAAAAQBIFEQAAAABgRUEEAAAAAEiiIAIAAAAArCiIAAAAAABJFEQAAAAAgBUFEQAAAAAgiYIIAAAAALCiIAIAAAAAJFEQAQAAAABWrrZegC3ExJxXdHS0kayLF/9nJGfj2kVGcnL0erWlsUw3N08jOTkuXTprJCciYp2RHEk6dOiQVq2cZCyvVas4Y1mSVLduayM5kZGbjeTkcHYxs4v+6qu1RnJ+M8RYnp+fn6Q+RrIKknPnvjU2I7///hsjOaZduXLJWFbZspWNZUlSkSLeRnLi4n40kiP9NiMTE68Yy3NycjKWlZqaZCzr559PG8symTd+SG8jOZLU8eBBI3l+fn56asOGW17PEUQAAAAAgCQKIgAAAADAioIIAAAAAJBEQQQAAAAAWFEQAQAAAACSKIgAAAAAACsKIgAAAABAEgURAAAAAGBFQQQAAAAASKIgAgAAAACsKIgAAAAAAEkURAAAAACAFQURAAAAACCJgggAAAAAsKIgAgAAAAAkURABAAAAAFYURAAAAACAJAoiAAAAAMCKgggAAAAAkERBBAAAAABYURABAAAAAJIoiAAAAAAAKwoiAAAAAECSDQvi0KFDtXDhwpteN2vWLG3fvt3wigAAsD3mIwDAluzyCOL+/fuVmZlp62UAAGBXmI8AgPzmeqcv2L9/v6ZNmyY/Pz9FRUWpSJEi6t27t4KCghQVFaVWrVpp+PDhWrVqlYKCguTs7KwyZcpo5MiRCggIUHJyssaOHavDhw/LxcVFLVq00KBBgyRJ3377rbp06aL4+HhVq1ZNH3/8sdavX68TJ05o8uTJcnFxUZMmTTR16lRFRkYqKytLDz30kEaMGKFixYqpWbNm6tChg/bt26fo6Gi1b99eAwcOzO+fGQAAzEcAQIF0V0cQjx8/rt69eys8PFzFihXTvHnzNHfuXK1bt04rVqzQhg0btGDBAi1btkyfffaZnnnmGfXr108Wi0UzZ85UWlqaNm3apLCwMB0+fFgHDhyQJMXGxmrx4sXasmWLYmNjtXXrVr3yyiuqVauW3n//fbVs2VLz5s2Ti4uL1q1bp88++0zlypXT1KlTc9eWkpKiFStWKCQkRIsWLdJPP/2UPz8pAAD+gPkIACho7ngEUZIqVqyohx56SJJUuXJleXt7y93dXaVLl5aXl5e2bNmitm3bqnTp0pKkjh07aty4cfr555/19ddfa9iwYXJxcZGLi4uWL18uSVq/fr1atGihIkWKSJKqVaumhISEP2V/+eWXunbtmr7++mtJUkZGhnx8fHKvb968uSSpfPny8vHx0a+//qpKlSrddns2bNhwN5udJw4ePGgsy7Tw8JW2XkK+WLt2sZGcQ4cOGcmxRd6ECf2NZZnNM7td27d/bjTPlIMHI229hDxT0OajxIzMCwV1uyRp8+Z1RnIK8ow0ef8oyPfFgjRLbmQPv7O7Koju7u6//ybX33+bk5PTn77HYrEoMzNTrq6uv7s+Ojpanp6ef7odJycnWSyWP91Odna2hg8friZNmkiSkpOTlZaWlnu9h4fHHW/jj5599llFR0ff8ev+roMHD6pevXr5niNJ/v7VjOTkCA9fqfbtXzKS5ebmaSRH+q0cdurUw0hWVNQxIznSb4Ovbt26xvJatTLzM5R+K4fDhs0ykhUZudlIjvRbOWzR4mkjWVevxhnJkX4b6PXq/ctIlp+fnzZs+CxfMwrafJQK5ow0yfR2lS1b2VjW5s3r1KZNRyNZcXE/GsmRzM/Im+0X8oP5x5iZ7ZLMzhLp7vadecHU7+y3+XjrJwPz5E1qHnvsMW3atCn3Gc7Q0FCVLFlS9913n5544gmtX79e2dnZSk9P19tvv63IyNs3fhcXl9wX4Tdq1EjBwcFKT09Xdna2Ro4cqWnTpuXFsgEAyFfMRwCAo7mrI4h3Ur9+fTk7O6tbt27Kzs5W6dKlNXfuXDk7O6t///4aN26c2rdvr6ysLLVt21atWrXSzp07b3l7zZo107Rp05SRkaG+fftq0qRJ6tChg7KyslSzZk0NHTo0L5YNAEC+Yj4CABzNHQti/fr1tXHjxtzPP/jgg99dv3//fklS9erV9corr/zp+4sWLapx48b96fKJEyfe8vPXXntNr732Wu7no0aNuuna/jhEbzdUAQDIS8xHAEBBZJf/BxEAAAAAYB4FEQAAAAAgiYIIAAAAALCiIAIAAAAAJFEQAQAAAABWFEQAAAAAgCQKIgAAAADAioIIAAAAAJBEQQQAAAAAWFEQAQAAAACSKIgAAAAAACsKIgAAAABAEgURAAAAAGBFQQQAAAAASKIgAgAAAACsKIgAAAAAAEkURAAAAACAFQURAAAAACCJgggAAAAAsKIgAgAAAAAkURABAAAAAFYURAAAAACAJMnV1guwha69hiopOdVIVp//N8lIzrrlgUZybpSZmWEk51pigpGcHAlXLhnJKVPG30iOJG3Z8pnRvAoVqhnLkqSYmCgjOZODlxnJMZ03oGMHIzk5PDyKGMlxd/c0klPQPPxwI/n6XjWSVbt2SzM5jzc2kpPj9T5jjGUtnWcuS5ISEszMSGdnFyM5khQZecBo3qOPNi2QWb/+etlYliTdd99DRnJ+SYgxkpOjuLdPvmcU8yp12+s5gggAAAAAkERBBAAAAABYURABAAAAAJIoiAAAAAAAKwoiAAAAAEASBREAAAAAYEVBBAAAAABIoiACAAAAAKwoiAAAAAAASRREAAAAAIAVBREAAAAAIImCCAAAAACwoiACAAAAACRREAEAAAAAVhREAAAAAIAkCiIAAAAAwIqCCAAAAACQREEEAAAAAFhREAEAAAAAkiiIAAAAAAArCiIAAAAAQBIFEQAAAABgRUEEAAAAAEiyo4K4f/9+PfPMM3+6fMaMGQoLCzO/IAAA7ADzEQBgkqutF3An77zzjq2XAACA3WE+AgDyg10VxJSUFL399tv68ccfVbx4cY0ZM0Zz585VtWrV9MYbb+jcuXMaN26crl69qqysLL366qvq1KmT9u/fr3Hjxqlo0aJKTk5WaGio3N3dbb05AADkCeYjAMAUJ4vFYrH1IqTfTqHp3r27goODVadOHa1atUpr165VlSpVVK1aNXXr1k3t27fX5MmT9fDDD+vatWvq3Lmzxo8fr7S0NHXv3l3bt2+Xv7//LTPS0tJ04sQJg1sFALC1WrVqycPDw9bLuGcm5qPEjASAwuZW89GujiDWqFFDderUkSR16NBBo0ePVrly5SRJ58+f14ULFzR8+PDcr09NTdV3332nKlWqyM/P747DL8eqzyKUlJya9xvwB2+81FwLV+7I9xxJWrc80EhOjs8/X6unn+5kJOt6yjUjOZK0c9cWNXuytZEsN3dzf7Bu2fKZWrduZyyvQoVqxrIWL/5YPXr8PyNZAyYOv/MX5ZE65X10OPaKkawBHTsYyZGkiIg9atjw30ayfH19FRq62khWfjM1HyVp6NBJunLlap6u/2bmz5+gXr2G5XuOJNV+vLGRHEnq+0ZbzV64yVje0nljjGXt3/+N6td/3EhWdna2kRxJiow8oH/96zFjeY88YmYfuGjRVL3++rtGsiTp118vG8sKDV2q55/vZiTrl4QYIzmSub9Dy5cvr5Uhy255vV0VRGfn379njpOTk1xdf1tiVlaWvL29FR4ennt9fHy8vL29deTIERUtWtToWgEAMIX5CAAwxW7exVSSTp8+rVOnTkmSVq1apbp166pIkSKSpICAAHl6euYOwOjoaD3zzDOcDgMAKPCYjwAAU+yqID7wwAOaNWuW2rVrp507d2rixIm517m7u2v27Nlau3atnn32Wb3++ut65513VLduXRuuGACA/Md8BACYYjenmNavX18bNmz40+U3DsEHH3xQQUFBN/3ejRs35uv6AACwBeYjAMAkuzqCCAAAAACwHQoiAAAAAEASBREAAAAAYEVBBAAAAABIoiACAAAAAKwoiAAAAAAASRREAAAAAIAVBREAAAAAIImCCAAAAACwoiACAAAAACRREAEAAAAAVhREAAAAAIAkCiIAAAAAwIqCCAAAAACQREEEAAAAAFhREAEAAAAAkiiIAAAAAAArCiIAAAAAQBIFEQAAAABgRUEEAAAAAEiiIAIAAAAArFxtvQBbWL1kumJiYvI9542XmmvRf0fne44kpWekGcm5UVzcBSM5/v7VjeTkKF6irJGcevWeMpKTo3HjF41lbd4011iWJJ05fcBIzvR3PzSSI0nLgmYay/vfRTOPZUmKO3/eWF5WRoauXLxoJKsgyc7OUnZ2pqEsMzm7t6wzkiNJfd9oazSvVq3GxrJM5p07d8RITg4vrxLGslJTkwtkVvny9xvLMpkXH/+zkZwcWQb2i9mW22dwBBEAAAAAIImCCAAAAACwoiACAAAAACRREAEAAAAAVhREAAAAAIAkCiIAAAAAwIqCCAAAAACQREEEAAAAAFhREAEAAAAAkiiIAAAAAAArCiIAAAAAQBIFEQAAAABgRUEEAAAAAEiiIAIAAAAArCiIAAAAAABJFEQAAAAAgBUFEQAAAAAgiYIIAAAAALCiIAIAAAAAJFEQAQAAAABWFEQAAAAAgCQKIgAAAADAioIIAAAAAJCUhwXx9ddfV0JCwp8u79Wrl86ePXvb7x06dKgWLlyYV0sBAMCuMCMBAI7CNa9uKCIi4qaXz58/P68iAABwSMxIAICjyJOCOGzYMElSt27ddPbsWbVu3VqnT5/W4MGDNWHCBM2YMUMpKSn65JNPVKlSJf3vf/9TZmamPvzwQ9WtW/d3tzV+/HidPn1as2fPlpubm6ZOnarIyEhlZWXpoYce0ogRI1SsWDE1a9ZMHTp00L59+xQdHa327dtr4MCBebE5AADkGWYkAMCROFksFkte3FCNGjW0b98+derUSc8//7z69esnSWrWrFnu8OvRo4dCQ0NVs2ZNLVq0SDt37tTy5cs1dOhQVa1aVZcuXVJcXJymTZsmd3d3zZo1S8nJyXr//ffl5OSkadOmKTExUaNHj1azZs3UunVrDRkyRLGxsWrZsqU+//xzVapU6ZZrTEtL04kTJ/JicwEADqJWrVry8PCw6RqYkQAAe3Or+Zhnp5jeqF69eje9vEKFCqpZs6Yk6aGHHtL69etzr1uyZImuXLmisLAwubu7S5K+/PJLXbt2TV9//bUkKSMjQz4+Prnf07x5c0lS+fLl5ePjo19//fW2wy/H8x1fUExMzL1t3F8Q8fVXatigcb7nSFJ6RpqRnByRkQf0r389ZiTL37+6kRxJCgtbruee62okq169p4zkSNKIEV01duxyY3mbN801lmXycValSm0jOZK0LGimXnv1bSNZX3z1mZEcSYo7f17l7r/fSFZWRoauXLxoJOuvsPcZ+f7743Xlyi/3tnF/wcKFU/TGG+/le44kJV3L/+3JsWr1AnV+saexvGLepYxlmfydnTt3xEiOJH355TY1bdrSWF6FClWN5KxYEaiXX+5jJEuSSpYsZyxr9uwP1bfvKCNZJ0/uNZIjSbt371CTJs3zPcfXt7xWrVpxy+vzpSAWLVr0ppd7enrmfuzk5KQbD17+61//Up06dTRs2DCtWrVKbm5uys7O1vDhw9WkSRNJUnJystLS/q8I3dh4/3h7AADYI2YkAMCe5dm7mLq4uCgzM/Oev79WrVrq2rWrvL29NWvWLElSo0aNFBwcrPT0dGVnZ2vkyJGaNm1aXi0ZAAAjmJEAAEeRZwXxqaee0quvvqrk5OR7vg0nJyeNHz9eK1as0OHDh9W3b1/5+/urQ4cOatu2rSwWi4YOHZpXSwYAwAhmJADAUeTZKaa3etZy586duR9v3Lgx9+P69evnfj5x4sTcy/39/RUZGZn7+ahRNz+/+MbbvdnnAADYC2YkAMBR5NkRRAAAAACAY6MgAgAAAAAkURABAAAAAFYURAAAAACAJAoiAAAAAMCKgggAAAAAkERBBAAAAABYURABAAAAAJIoiAAAAAAAKwoiAAAAAEASBREAAAAAYEVBBAAAAABIoiACAAAAAKwoiAAAAAAASRREAAAAAIAVBREAAAAAIImCCAAAAACwoiACAAAAACRREAEAAAAAVhREAAAAAIAkCiIAAAAAwMrV1guwhRe7D1RScqqRrNcHjDaSs2DmB0ZybuTq6mYk58qVi0ZyTOeFhU03kiNJI0Z0NZrn5uZhLEuSsi3ZRnLS0lKM5JjO83Qz81g2nZdpJKXg8fHxl4tLcSNZ5crdZySn9+h3jeTkGPzxOGNZA55vZyxLko4f32MkJzs7y0hOjqSkX4xlxUT/UCCzfvzxpLEs6UMdPbrLSFJGRpqRnBzXryfle0Zqqvdtr+cIIgAAAABAEgURAAAAAGBFQQQAAAAASKIgAgAAAACsKIgAAAAAAEkURAAAAACAFQURAAAAACCJgggAAAAAsKIgAgAAAAAkURABAAAAAFYURAAAAACAJAoiAAAAAMCKgggAAAAAkERBBAAAAABYURABAAAAAJIoiAAAAAAAKwoiAAAAAEASBREAAAAAYEVBBAAAAABIoiACAAAAAKwoiAAAAAAASRREAAAAAIAVBREAAAAAIImCCAAAAACwyveCmJSUpBUrVujYsWN5ertTpkzRjz/+mKe3CQCAScxIAIC9cc2vGz569KhWrVqlffv2qXnz5mrRooV27typwMBAZWRkyNPTU0OGDFHt2rWVkZGhiRMnat++fXJxcdGjjz6qYcOGqVixYlqxYoVCQkLk5uYmDw8PjRkzRlWrVlWZMmXUr18/+fj4qHPnzmrRooXc3d3za3MAAMgzzEgAgL3K8yOIx48f13PPPacZM2aoUaNG2rJli0aMGKGUlBR98sknmjdvnsLCwvTRRx9pwIABSklJUWBgoOLi4hQeHq7w8HBlZ2dr8uTJysrK0vjx47VgwQKFhobqxRdf1KFDhyRJPXr00MaNGzVw4EDt3btXbdq0UXBwcF5vDgAAeYYZCQCwd3l+BNHZ2VnOzs5ycnKSk5NT7uURERGKi4tT9+7dcy9zcnLShQsXtGfPHg0aNEhubm6SpFdffVX9+vWTi4uLnnrqKXXp0kVNmzZVo0aN1KRJk9/lubi45GY6O99d3+3cruHf39C79MZLzQtUzo327YswnmnCV1/tsvUS8sXBgwdtvYR8U1Dvi6tWLzCSc+F//zOSY6s8e+IIM3LIkG5/f0Pv0oQJ/Y1lmVS/UnljWQcO7DeWZYs8UwrqjNy5a4utl5BvIiL22HoJ+cIeHmN5XhAffvhhrVu3TseOHVNISIimTJmiVq1aqVixYnriiSc0ffr03K+Njo5WuXLllJ2d/btBmZ2drYyMDEnS1KlTdebMGX399deaN2+ewsPDNWPGDC1btkxr165VyZIl1aVLF40aNSp3eN7Jqs8ilJScmqfbfTNvvNRcC1fuyPccSVow8wMjOTn27YvQE0+YKdquruZOi/rqq11q3PhJI1nXr18zkiP9Nvjq1atnLM/NzcNYlsn7YuVKNY3kSL+Vw84v9jSSte/b3UZypN/KYeVq1YxkZWZk6NL580ay7pYjzMhJk5bq6tX83z9NmNBfw4bNyvccSXqu7wtGcqTfyuH+n2KN5Q14vp2xrAMH9uuxx+obycrOzjKSI5mfkcW9fYzk7Ny1Rc2ebG0kS5LS0q8by4qI2KOGDf9tJCsjI81IjmTuMebn56fw8LBbXp9vb1Lz6KOPavz48QoPD1fFihX12GOPKSIiQufOnZMk7d69W+3atVNqaqoaN26slStXKiMjQ9nZ2QoODlbDhg2VkJCgJk2aqGTJkurevbsGDhyo48ePS/ptcOYMwbZt29714AMAwNaYkQAAe5Vvb1KTw9vbW127dpUkjRkzRoMHD5bFYpGrq6sCAwPl5eWlPn36aNKkSXruueeUmZmpRx99VCNHjlTx4sXVp08fde/eXZ6ennJxcdHYsWMlSUOGDMnvpQMAkK+YkQAAe5PvBfFGbdq0UZs2bf50uaenp0aNGnXT7+nSpYu6dOmS30sDAMCmmJEAAHuQ7/8HEQAAAADgGCiIAAAAAABJFEQAAAAAgBUFEQAAAAAgiYIIAAAAALCiIAIAAAAAJFEQAQAAAABWFEQAAAAAgCQKIgAAAADAioIIAAAAAJBEQQQAAAAAWFEQAQAAAACSKIgAAAAAACsKIgAAAABAEgURAAAAAGBFQQQAAAAASKIgAgAAAACsKIgAAAAAAEkURAAAAACAFQURAAAAACCJgggAAAAAsHK19QJMslgskqSiRTyMZRbz8jSS4+vrayTHFpmurm5GcnL4+pY3kpOaWsxITg4/Pz9jWa6u7sayJHP3xbJlfYzkmM7LzMgwkmM6LycnZ9+P28v5ORUv7mUss2RJbyM57i5mnw83mWdy324yLzs7y0hODpM/x2JepYxllS9v5m8aSUrPSDWWJZmb/ZmZ6UZycpi4L5YrV07Sreejk6UQTc5r167pzJkztl4GAMCg6tWry9vbTBFxZMxIAChcbjUfC1VBzM7OVnJystzc3OTk5GTr5QAA8pHFYlFGRoa8vLzk7MwrKu6EGQkAhcOd5mOhKogAAAAAgFvjKVUAAAAAgCQKIgAAAADAioIIAAAAAJBEQQQAAAAAWP1/01K7qxAF1dIAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1080x1800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_count 1    self.capacity  20\n",
      "0  ------------------------------------------------\n",
      "DecoderLayer@trg4\n",
      "[1, 1, 64]\n",
      "tensor([[[-1.0165,  0.4878, -0.0045, -1.2868,  0.8624,  1.8859, -0.4240,\n",
      "           0.7703, -1.7317, -0.7830,  0.9475, -0.1908, -0.8685, -1.3315,\n",
      "           0.4200, -1.2805,  1.7512,  1.4842, -1.5434,  0.0443, -0.3493,\n",
      "           0.0647, -0.2037,  0.5402,  0.5951, -0.1063, -0.6514,  0.6778,\n",
      "          -0.4544,  0.4750, -0.1743, -0.0636, -0.0215, -0.4578, -0.1425,\n",
      "           0.3961,  0.6538, -0.6783,  0.5324,  0.3768, -0.8311,  1.3493,\n",
      "          -0.3442, -1.2811,  0.2099,  1.5124,  2.0844, -0.7114, -0.4239,\n",
      "          -0.2671, -0.0674,  0.4429,  1.4889, -0.7970, -1.2941,  1.9478,\n",
      "          -0.8199, -0.9858,  0.8221, -0.7046, -0.4676, -0.4599, -2.2920,\n",
      "           2.7452]]])\n",
      "src = ['we', 'want', 'to', 'read', 'book']\n",
      "predicted trg = ['wir', 'mochten', 'buch', 'lesen', '<eos>']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_count 1    self.capacity  20\n",
      "0  ------------------------------------------------\n",
      "DecoderLayer@trg4\n",
      "[1, 1, 64]\n",
      "tensor([[[-0.7249,  0.3082, -0.0573, -0.6692,  0.2951,  2.3105, -0.8651,\n",
      "           0.3326, -1.5486, -0.3742,  0.3705, -0.1829, -0.8131, -1.5901,\n",
      "           0.5296, -1.6991,  1.5513,  1.0963, -1.7132,  0.0432, -0.1899,\n",
      "           0.1140, -0.0751,  0.9754,  0.2776, -0.1516, -0.3815,  0.4109,\n",
      "          -0.3690,  0.5323,  0.1943,  0.0576,  0.0442, -0.2151, -0.3141,\n",
      "           0.2344,  0.2238, -0.2032,  0.7055,  0.1905, -0.6736,  1.0941,\n",
      "          -0.0373, -1.3098,  0.5140,  1.5054,  2.0098, -1.0837, -0.1387,\n",
      "          -0.4588,  0.0722,  0.7910,  1.9307, -1.0721, -1.6694,  1.9519,\n",
      "          -0.4048, -1.5296,  1.1264, -0.7539, -0.8961,  0.0604, -2.1251,\n",
      "           2.4543]]])\n",
      "src = ['we', 'want', 'to', 'read', 'newspaper']\n",
      "predicted trg = ['wir', 'mochten', 'zeitung', 'lesen', '<eos>']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_count 1    self.capacity  20\n",
      "0  ------------------------------------------------\n",
      "DecoderLayer@trg4\n",
      "[1, 1, 64]\n",
      "tensor([[[-0.5766,  0.3795,  0.1720, -0.8571,  0.5580,  2.2756, -0.7535,\n",
      "           0.2298, -1.5177, -0.4276,  0.2811, -0.0829, -0.9159, -1.5136,\n",
      "           0.3753, -2.0917,  1.3577,  1.2351, -1.3485,  0.0803, -0.0445,\n",
      "           0.2827, -0.0826,  0.9267,  0.2730, -0.1790, -0.7913,  0.3920,\n",
      "          -0.0993,  0.4354,  0.5099,  0.0807,  0.2815, -0.0762, -0.3767,\n",
      "           0.1477,  0.1519, -0.1456,  0.5127,  0.2530, -0.9299,  1.2626,\n",
      "          -0.1637, -1.1200,  0.3439,  1.4537,  2.0428, -1.3149, -0.1762,\n",
      "          -0.5142,  0.1406,  0.7603,  1.8441, -0.9614, -1.7431,  2.0750,\n",
      "          -0.5470, -1.4342,  0.9135, -0.9014, -1.0513,  0.2710, -1.9231,\n",
      "           2.3935]]])\n",
      "src = ['we', 'can', 'eat', 'bread']\n",
      "predicted trg = ['wir', 'konnen', 'brot', 'essen', '<eos>']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_count 1    self.capacity  20\n",
      "0  ------------------------------------------------\n",
      "DecoderLayer@trg4\n",
      "[1, 1, 64]\n",
      "tensor([[[-1.6484,  0.5072, -0.6435, -1.0962,  1.2411,  1.8856,  0.0793,\n",
      "           0.5953, -1.3378, -0.6374, -0.2024, -0.4824, -0.7758, -1.6804,\n",
      "           0.4490, -1.7475,  1.2681,  1.3394, -1.2408,  0.6897, -0.6924,\n",
      "          -0.4954,  0.3157,  1.0996,  0.4629, -0.1533, -0.4415,  1.2670,\n",
      "          -0.4326,  0.8451,  0.0580,  0.0717, -0.1735, -0.9212, -0.5106,\n",
      "          -0.2048,  0.1019,  0.0731,  0.2143,  0.7606, -0.4169,  1.5833,\n",
      "          -0.4659, -1.0326,  0.3068,  1.6569,  2.2715, -0.8995, -0.0858,\n",
      "          -0.7367, -0.0341,  0.6717,  1.0036, -0.6012, -1.4487,  1.7396,\n",
      "          -0.3828, -1.1396,  1.0524, -0.4437, -0.4334,  0.3226, -2.3293,\n",
      "           2.0920]]])\n",
      "src = ['we', 'can', 'eat', 'apple']\n",
      "predicted trg = ['wir', 'konnen', 'apfel', 'essen', '<eos>']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_count 1    self.capacity  20\n",
      "0  ------------------------------------------------\n",
      "DecoderLayer@trg4\n",
      "[1, 1, 64]\n",
      "tensor([[[-1.7435,  0.5399, -0.6595, -1.0296,  1.1856,  1.9937,  0.0362,\n",
      "           0.4209, -1.3025, -0.5065, -0.3449, -0.5767, -0.6637, -1.5576,\n",
      "           0.6236, -1.6362,  0.9974,  1.5047, -1.1987,  0.6918, -0.4806,\n",
      "          -0.4350,  0.5933,  1.1462,  0.4330, -0.0581, -0.4820,  1.2135,\n",
      "          -0.3943,  0.8967,  0.2011,  0.0700, -0.1244, -0.9491, -0.8039,\n",
      "          -0.3274, -0.0536,  0.4120,  0.4393,  0.7666, -0.4437,  1.5945,\n",
      "          -0.4501, -1.1783,  0.0635,  1.4635,  2.3417, -0.8051, -0.1464,\n",
      "          -0.9390, -0.1924,  0.5689,  0.9372, -0.5562, -1.4558,  1.6227,\n",
      "          -0.2867, -1.2797,  1.1824, -0.2530, -0.5458,  0.3853, -2.3855,\n",
      "           1.9748]]])\n",
      "src = ['we', 'can', 'drink', 'water']\n",
      "predicted trg = ['wir', 'konnen', 'wasser', 'trinken', '<eos>']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_count 1    self.capacity  20\n",
      "0  ------------------------------------------------\n",
      "DecoderLayer@trg4\n",
      "[1, 1, 64]\n",
      "tensor([[[-1.1002,  0.3218, -0.4536, -1.5529,  1.0014,  2.1873, -0.1004,\n",
      "           0.8891, -1.3094, -0.6954,  0.7325, -0.3544, -0.7756, -1.6526,\n",
      "           0.4221, -1.0481,  1.7669,  0.9923, -1.2194,  0.2911, -0.4355,\n",
      "          -0.3907, -0.1138,  0.8638,  0.5354, -0.5038, -0.3943,  0.7360,\n",
      "          -0.8274,  0.8032, -0.1287,  0.1296,  0.0148, -0.8383, -0.3975,\n",
      "           0.0312,  0.2220, -0.5102,  0.3925,  0.4154, -0.3846,  1.2284,\n",
      "          -0.4595, -1.4691,  0.5016,  1.7123,  2.4673, -0.9991, -0.0860,\n",
      "          -0.3959, -0.0374,  0.2112,  1.4287, -0.5522, -1.1159,  1.8253,\n",
      "          -0.4952, -0.8446,  0.8155, -0.8622, -0.5698,  0.0876, -2.3488,\n",
      "           2.4766]]])\n",
      "src = ['we', 'can', 'drink', 'beer']\n",
      "predicted trg = ['wir', 'konnen', 'bier', 'trinken', '<eos>']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_count 1    self.capacity  20\n",
      "0  ------------------------------------------------\n",
      "DecoderLayer@trg4\n",
      "[1, 1, 64]\n",
      "tensor([[[-1.3322,  0.4572, -0.5091, -1.6939,  0.8735,  2.0133, -0.0721,\n",
      "           1.0604, -1.4741, -0.9523,  0.6993, -0.4989, -0.6484, -1.5290,\n",
      "           0.3213, -1.1618,  1.9606,  1.2580, -1.3868,  0.2680, -0.5583,\n",
      "          -0.3446, -0.2377,  0.9299,  0.4810, -0.2945, -0.5510,  0.9624,\n",
      "          -0.7460,  0.7004, -0.2942,  0.1815,  0.0070, -0.9803, -0.1832,\n",
      "           0.1625,  0.3286, -0.5173,  0.3089,  0.6235, -0.5432,  1.2287,\n",
      "          -0.3511, -1.2993,  0.4531,  1.6830,  2.3046, -0.5703, -0.2370,\n",
      "          -0.2041,  0.0248,  0.3378,  1.1824, -0.6654, -1.1695,  1.6806,\n",
      "          -0.5240, -0.5751,  0.8313, -0.6827, -0.3498, -0.1027, -2.4157,\n",
      "           2.4123]]])\n",
      "src = ['we', 'can', 'read', 'book']\n",
      "predicted trg = ['wir', 'konnen', 'buch', 'lesen', '<eos>']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_count 1    self.capacity  20\n",
      "0  ------------------------------------------------\n",
      "DecoderLayer@trg4\n",
      "[1, 1, 64]\n",
      "tensor([[[-1.0062,  0.1636, -0.6088, -1.3062,  0.3905,  2.4705, -0.4130,\n",
      "           0.6426, -1.4660, -0.5408,  0.4808, -0.3553, -0.5929, -1.8173,\n",
      "           0.4921, -1.2016,  1.6834,  0.9664, -1.3872,  0.4165, -0.3748,\n",
      "          -0.5140,  0.0855,  1.2546,  0.3511, -0.2743, -0.4754,  0.6086,\n",
      "          -0.9920,  0.6019,  0.0426,  0.3427,  0.1916, -0.5302, -0.3533,\n",
      "           0.0190,  0.0902, -0.2978,  0.6079,  0.2890, -0.3558,  1.0029,\n",
      "          -0.2068, -1.2997,  0.5645,  1.8170,  2.2589, -0.9298,  0.1011,\n",
      "          -0.5338,  0.2828,  0.6982,  1.5459, -0.7788, -1.3660,  1.6634,\n",
      "          -0.2101, -1.3468,  1.1590, -0.7825, -0.7155,  0.2586, -2.4768,\n",
      "           2.0051]]])\n",
      "src = ['we', 'can', 'read', 'newspaper']\n",
      "predicted trg = ['wir', 'konnen', 'zeitung', 'lesen', '<eos>']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_count 1    self.capacity  20\n",
      "0  ------------------------------------------------\n",
      "DecoderLayer@trg4\n",
      "[1, 1, 64]\n",
      "tensor([[[-0.9262,  0.3960, -0.4180, -1.4009,  0.6062,  2.1746, -0.2034,\n",
      "           0.5143, -1.3925, -0.5048,  0.0505, -0.5035, -0.6675, -2.2045,\n",
      "           0.3964, -1.6614,  1.6777,  0.9584, -1.1487,  0.5610, -0.2519,\n",
      "          -0.4941, -0.0229,  1.5541,  0.0615, -0.2713, -0.7612,  0.5570,\n",
      "          -0.7750,  0.7411,  0.2845,  0.3917,  0.4841, -0.6692, -0.4239,\n",
      "           0.0290, -0.1522, -0.3629,  0.5450,  0.5990, -0.4404,  1.2021,\n",
      "          -0.4981, -1.2009,  0.6146,  1.5968,  2.3028, -1.0099,  0.1150,\n",
      "          -0.4379,  0.3966,  0.7724,  1.5670, -0.8126, -1.4610,  1.4854,\n",
      "           0.0231, -1.2555,  1.0710, -0.6924, -0.9734,  0.4182, -2.0424,\n",
      "           1.9311]]])\n",
      "src = ['i', 'eat', 'bread']\n",
      "predicted trg = ['ich', 'essen', 'apfel', '<eos>']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_count 1    self.capacity  20\n",
      "0  ------------------------------------------------\n",
      "DecoderLayer@trg4\n",
      "[1, 1, 64]\n",
      "tensor([[[-2.2283,  0.6052, -1.0877, -0.0069,  1.5969,  1.2031,  0.2160,\n",
      "           0.2202, -0.5560,  0.4877, -1.0837, -0.9387, -0.7872, -1.8994,\n",
      "           1.0272, -1.5494,  0.4993,  1.7648, -0.4433,  0.5920, -0.5268,\n",
      "          -0.5957,  0.2870,  0.3271,  0.8080, -0.0508, -0.2542,  1.3729,\n",
      "           0.3637,  0.9436,  0.5639, -0.3572, -0.3437, -0.7933, -0.6274,\n",
      "           0.0224,  0.3759,  0.2494,  0.1818,  0.3562, -0.2316,  1.9853,\n",
      "          -0.6547, -0.9718,  0.5564,  1.3363,  2.3483, -1.3930, -0.2283,\n",
      "          -0.6492, -0.5194,  1.0797,  0.3888, -0.4978, -1.6146,  1.1814,\n",
      "          -0.5036, -1.2848,  0.6935, -0.1493, -1.5331,  0.5756, -1.7552,\n",
      "           1.9742]]])\n",
      "src = ['i', 'eat', 'apple']\n",
      "predicted trg = ['ich', 'essen', 'apfel', '<eos>']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_count 1    self.capacity  20\n",
      "0  ------------------------------------------------\n",
      "DecoderLayer@trg4\n",
      "[1, 1, 64]\n",
      "tensor([[[-2.2193,  0.6343, -0.9034, -0.1362,  1.5597,  1.5312,  0.1514,\n",
      "           0.2429, -0.7609,  0.3059, -0.8034, -1.0096, -0.6419, -1.6337,\n",
      "           1.2061, -1.3076,  0.4923,  1.9334, -0.6246,  0.6098, -0.3806,\n",
      "          -0.5633,  0.6074,  0.3910,  0.7875,  0.0837, -0.2755,  1.2112,\n",
      "           0.1189,  0.9575,  0.6368, -0.3732, -0.2761, -0.8307, -0.8485,\n",
      "          -0.3226,  0.3107,  0.4985,  0.3914,  0.4187, -0.3282,  1.8337,\n",
      "          -0.6637, -1.0370,  0.1395,  1.3128,  2.3255, -1.2866, -0.2587,\n",
      "          -0.8117, -0.6347,  0.8762,  0.4190, -0.3075, -1.5525,  1.2058,\n",
      "          -0.3542, -1.5685,  0.8087, -0.0591, -1.3973,  0.3560, -2.0791,\n",
      "           1.9555]]])\n",
      "src = ['i', 'drink', 'water']\n",
      "predicted trg = ['ich', 'trinken', 'bier', '<eos>']\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA34AAAFkCAYAAAB/++nAAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAApuElEQVR4nO3df2DN9eLH8dd+j/kxpo38KImI3Fq3VHQJFb6l6ZZ8KympuCL5VqxvNzfCwpc7P2t+hOFLmnEnSiIxYYhRN+IutzTzK7GN/TzfP7r2tXs2trXt/TnvPR9/2c6289oxn5fXOZ9z5uVyuVwCAAAAAFjL23QAAAAAAEDFYvgBAAAAgOUYfgAAAABgOYYfAAAAAFiO4QcAAAAAlmP4AQAAAIDlGH4AAAAAYDmGHwAAAABYjuEHACiT/Pz8Qm+7XC5DSQAAcA6n9iPDz5CLPxC5ubmGkwBA2Xh7eys9PV379u2TJHl5eRlOBFvQkQA8mVP7keFnyIULF/TTTz8pKipKu3fvNh0HqJIuvQcuIyPDYBLPs3PnTq1fv14vvPCCJkyYoIMHD5qOBIvQkYB5dGTZOLkffU0HqIqWL1+uQ4cOKTU1VevWrVNISIjCw8NNxwKqFJfLVXAP3OLFiyVJvXv3lp+fn8lYjpeUlKRt27Zpy5Yt6t69u/Ly8hQaGqoWLVqYjgZL0JGAeXRk6XlCPzL8KtG2bdu0adMm7dixQ6+88orS0tJUq1Yt9evXz3Q0oMq5WGjr16/Xxo0bNXbsWAqtBA4ePKhffvlFEydOVJMmTZSbm6vWrVtL+vX0PG9vTiRB2dCRgHPQkaXnCf3I8KtELVq0kL+/vwYMGKCQkBAlJCSoVq1a8vX1dcwPBDzTxdMxLh6oc3Nz5evLP+/LycvL088//6w333xT1157rby8vPh3WAJPPPFEwZ+TkpK0du1aderUSZK47fCb0JGoCPRj2dCRpecJ/eiMFFVASkqKLly4oPDwcIWEhCglJUWzZ8/WXXfdJX9/f8f8QMAzZWZmFjol491333XMK0g5yaW3iZeXl+rVq6fY2FidOXNGS5cuVXZ2tsF0zhYXF6fp06frs88+k/Tr8z1WrlypPn366PrrrzecDp6OjkRFoR9Ljo4sG0/qR46klSA2NlZvvvmmpk+frrS0NEnSiRMn1LlzZ3Xo0IEDEH6TlJQUDR8+vOCVo06ePKmmTZvKy8tLeXl5ktxfVrgquvT5CsuXL9eYMWP09ttv6+TJk4qOjlZCQoLef/99nT9/3nBS55k/f75WrlypsLAwNWzYUOfPn1f16tV1xx13KDQ01HQ8eDg6EhWFfiw5OrJsPK0feay7gsXFxWnt2rWaPn26jh8/rqNHj+qLL75Qly5dCv7xOOUlXuGZsrOz1ahRI7377rt6+eWXFRgYqJSUFGVmZqp69eqSnHOKgUkX/50tWrRIn3zyiYYOHaoxY8YoPT1dUVFRmjFjhvr27St/f389++yzhtM6R2pqqjZt2qTY2Fjt3r1bGzdu1Pr16xUcHKw5c+Zw/MJvQkeiItGPJUdHlp4n9qOXi7vSKtR7772nBg0aKDMzU3v37tWJEye0ZcsWvfnmm3r88cdNx4MHu/TeuUOHDmn58uU6evSoDh8+rJCQEB09elTh4eEKCgrSH/7wB3Xt2tVwYjPOnz+vatWqSZLS0tL09ttvKyoqSqtXr9bnn3+uCRMmaN68eXrmmWf0/fffq3bt2rrmmmsMp3aOn376SREREbr55pt1+vRpderUSbfccos++OADjRw5Ug0aNCj0swiUBh2JikA/lhwdWXae2I884lfBQkJCtHTpUmVlZelPf/qTunTpog8//FCnT5923A8DPMelPztnz55V06ZN1b9/fy1YsEBJSUl64YUX1LRpU6WkpOjzzz/XDTfcYDixGUePHlViYqK6deum7Oxs1axZU2FhYRoxYoTOnz+v2bNnKyMjQ1988YX+8z//U23btjUd2TG++eYbBQQE6KqrrtLChQuVnJysO++8U40bN9b69ev1ww8/KDAwUBKPyKDs6EiUN/qx5OjIsvHkfmT4VYD4+HilpKTo+PHjevHFF9WjRw9Vq1ZNJ0+eVFxcnBYtWqT/+Z//cdwPAzzDpaU2b948bdy4UWfPnlV0dLT69eun9PR0rV69Wq+++qoiIiIUERFhNrBB58+f14YNG7Ru3TpdffXV+q//+i9lZmYqJSVFM2bMkLe3t7788kv5+vryKm+XWLBggdauXavatWvrp59+0jPPPKPevXsrMjJSPj4+2r17t6Kjo1WnTh3TUeGB6EhUFPqxdOjI0vP0fuRUz3I2f/58rV27Vk888YS2bt2qLVu2aPLkyTpz5owWLlyovLw8jR49Ws2bNzcdFR5u165dmjJlil5//XUtXbpUn3zyiZYsWaIaNWpoxowZSk9P17hx46rkK+JdWv4xMTGaNWtWwYE5LS1Nr7zyigICAuTl5aXjx4/rnXfeUcuWLQ2ndob169dr5syZio2NVVZWlvbv36833nhD48ePl7e3t06fPq2bbrpJTZo0MR0VHoiORGWgHy+PjiwbG/qR4VeOjh8/rhEjRmjKlCkKDg6WJE2dOlWrV6/WunXrlJGRIS8vr4InFAOl8Y9//EPe3t669tprtXz5csXHx2vIkCG68847JUnjx4/X6tWr9f7776t27dry8fFRvXr1DKeufP9+etiBAwd09OhRLVy4UOHh4Ro4cKBcLpd2796tvLw8XXfddbr66qsNJnaWBQsWKDU1VSNHjlROTo58fX01atQoNWnSRAMGDDAdDx6MjkRFoR9Ljo4sOxv6serdzVGBXC6Xjh8/rpSUlIL39evXT9dcc43S09MVFBREoaFMzpw5o5UrVyo4OFi5ubm66aabtGfPHq1du7bgYyIjI9W5c2cNGjRIderUqZKldmmhLVu2TKNGjdL333+vzp07a/Dgwdq+fbsWL16sNWvWyMfHRx06dKDQ/k2NGjV08uRJnT17Vn5+fvLy8pK/v7+ysrIkiZfWR5nRkagI9GPJ0ZG/jQ39yAm75SA5OVkhISGqV6+e2rdvrx07dqhWrVpq1qyZNmzYoLNnz/J7YlBmLpdLwcHBGj58uL755hvFxcXpxRdf1IoVK/TII4+oUaNGev755yVJY8aM0cmTJ+Xv7284tRkXC23JkiX68MMPddddd+mdd97RqVOn9Pjjj2vo0KGKjY3Vjz/+qOjoaMNpnSMhIUEXLlxQdna22rVrp8WLF2vu3Llq1aqVsrKytGXLFs2aNUuS856oDuejI1FR6MfSoSNLz7Z+5FTP32j+/Pn6+OOP1bBhQ7311ltKSkrShg0b9PXXX6tNmzZKSkrS1KlTeb4CyiwvL08+Pj765JNPtGfPHh09elSNGjXSwIED9cMPP+jJJ5/UM888o6FDh0pyP42jqklMTNSsWbMUExOjAwcOKCoqStWrV9f999+vnj17ysfHR1lZWapVq5bpqI4wf/58rVu3ToMGDdJzzz2nmTNnqmHDhoqNjVVGRoby8vL04osvqkWLFqajwgPRkahI9GPp0ZElZ2M/MvzKKC8vT59++qkWL16s2NhY7dmzRxcuXFBaWpr8/PxUp04d/fLLL2rTpo0aNWpkOi480N///neFhYWpbt26WrNmjebOnau4uDjt2bNHCxcuVGhoqAYPHqyUlBQNHDhQH330kWNfRaqy7NmzR1u2bJHL5VLHjh312Wef6eGHH9YHH3yg+Ph4Pfrooxo8eHCVvsf3oqysLB09elRvv/22Zs+erUWLFmnbtm168803tWfPHnXv3l2SCv2iY6Ck6EhUJPqxbOjIkrG5HznVswx27dqlwMBApaWlqXnz5oqLi1NiYqJOnDih/Px83XvvverRo4fpmPBg586d08KFC3Xq1Cn17t1bCQkJBfeI33zzzcrKytLy5cs1ceJEvfbaa/r888+r5IE6Pz9f3t7eBffiJicnKzY2VjExMTp//rzS09N1zTXXqGnTpgoPD9cTTzxRJW+nf7d79265XC4FBQWpZs2amjlzppKTkzVz5kwdPXpUU6dOVefOnRUQEOBxpQbz6EhUJPqx5OjI0rO9H3lxlzJYu3at9uzZo+uuu05HjhxRfHy8evbsqdjYWHXu3FlHjhyRy+XyiCd5wplq1qypAQMGKCQkRLGxsapVq5aysrL00UcfSZLatWuniIgI5eXlKSsrq8oeqC++DPeOHTskSU899ZS6deumNWvWaMWKFQoICNCaNWu0ZMkSDR8+XKGhoSbjOsaaNWv07bffqlGjRjp16pQ+/vhjzZw5U35+fkpMTNTVV19dJV/iHOWDjkRFoh9Ljo4sPdv7kVM9S2nTpk2aMGGCFi5cqJCQEGVnZ8vf31+JiYk6deqU3n//fU2aNEnNmjUzHdUjJCUlKScnR3fddZfpKI6zfPlybdq0ST/++KOCg4MVEhKi0NBQ3XLLLbrvvvsk/frLV6tVq2Y4qVk//PCD7r33XnXq1EkREREKCAhQamqqqlevrsWLF6tatWqKjIxUq1atTEd1hIvHsDlz5qhBgwZaunSptm/frrNnz+qWW27Rp59+qkmTJvGcK5QJHVm+6Mii0Y8lR0eWXFXoR071LKGLD5efPHlS/fv3V0hIiPbu3atdu3bJ19dXu3btUnp6ut555x0KrYRcLpdOnz6ttm3bKi0tTWFhYaYjOcaqVau0cOFCTZs2TV9//bUOHz6sbdu2yc/PT1u2bJGPj4+6dOmiwMBA01GNu+qqq/THP/5R//znP3Xs2DHFxcUpMzNTI0aM0PLlyyn/f/n3Y1iDBg104MABnTx5Uj169ND+/ftVu3ZtTZ48mWMYSo2OLH90ZNHox9KhI6+sKvUjw6+EvL29debMGSUkJKhevXo6f/68YmNj9cgjj6hVq1Z66qmnPPJJniZ5eXnp/vvv148//qjevXsrMjKS5338y8GDB9WzZ09de+21atiwoQ4fPqz9+/fr0KFDatWqlW6++WZJnvHSwRVl9erVysvL0x133KHnnntOAwYMUOvWrVW3bl2NHj1a8+bNU4cOHfg3+S9FHcMWLFighx9+WPXq1dPLL79sOiI8GB1Z/ujIotGPJUNHllxV6keGXwm5XC7t27dPBw4cUEhIiOrWratJkybppptuKviYqn6PSVmFhoZq4MCBeu+99+Tt7a1u3bqZjmRckyZNtHHjRnXt2lVNmzZVy5YtVbt27YLbKiQkxHRE4+rXr1/wSmRPP/20XnjhBSUmJmrYsGG69tprFRYWRqFdoqhj2OTJkwsdw4CyoiMrDh1ZGP1YMnRkyVWlfuQ5fqWQk5Oj5ORkhYeHV/l7kspbdna2VqxYoUWLFmno0KEF5+hXVWlpaZowYYLq16+vO+64Q5mZmVqwYIGmTJnC6T6XyMzM1I4dOzRx4kQ1aNBA3377rZYuXcrLwxeDYxgqEj9fFYeO/H/0Y8nRkSVXVY5fDL8yuvhLQ1F+srOztXLlSk2bNk2jRo1S165dTUcy6vvvv9fy5cu1d+9eBQQE6NVXX1XLli1Nx3KktLQ07dy5U4sXL1ZUVJSaNGliOpLjcQxDReLnq/zRkf+PfiwdOrJ0bD5+MfzgKNnZ2UpISNDtt9+uxo0bm45jnMvl0oULF+RyuTglowRsPlgDAB35/+jH0qMjwfCD41z8RaMAAKAwOhJAWTH8AAAAAMBynvur5wEAAAAAJcLwAwAAAADLMfwAAAAAwHIMPwAAAACwHMMPAAAAACznazpAecjPz1dGRob8/Px4iWMAsJzL5VJOTo6CgoLk7c39l1dCRwJA1XClfrRi+GVkZOjgwYOmYwAAKlGLFi1Us2ZN0zEcj44EgKqluH60Yvj5+flJkp599lkdP37ccJrCEhIS9OCDD5qO4SYlJcV0hCLt379fbdq0MR3DTevWbU1HKNKyZUv02GOPm47hJjc313SEYsXFfaA//rG36RhusrPPm45QJCcew0JDQzV37tyCYz8u7+Lt9PzzL+jEiROG0xQWH79CvXo9bDqGm+++c+ZQdmpHNm3a1HSEIjnx+CVJ1as78w4rp/6fQpJ69RlkOoKbPr3u1tL4zaZjFBJUPUAP3n97sf1oxfC7eOrK8ePHlZqaajiNOydmCggIMB2hWE7MduxYmukIxXJittzcHNMRLuvYsWOmI7jJyso0HaFYTjyGSeK0xRK6eDudOHFCqanO+9l3YiYn9tBFTszm1GOE5MxsQUHOPd478f8UkpSeccF0hCI5NVdx/ciTIwAAAADAcgw/AAAAALAcww8AAAAALMfwAwAAAADLMfwAAAAAwHIMPwAAAACwHMMPAAAAACzH8AMAAAAAyzH8AAAAAMByDD8AAAAAsBzDDwAAAAAsx/ADAAAAAMsx/AAAAADAcgw/AAAAALAcww8AAAAALMfwAwAAAADLMfwAAAAAwHIMPwAAAACwHMMPAAAAACzH8AMAAAAAyzH8AAAAAMByDD8AAAAAsBzDDwAAAAAsx/ADAAAAAMsx/AAAAADAcgw/AAAAALAcww8AAAAALMfwAwAAAADLMfwAAAAAwHIMPwAAAACwHMMPAAAAACzH8AMAAAAAyxkZfvv27dPQoUOLvXzkyJGaO3duJSYCAMA8+hEAUFGMDL+bbrpJU6dONXHVAAA4Fv0IAKgoRobf9u3b9cADDygjI0ORkZG6//771aNHD02ePFkul0uS9NVXX6lPnz7q2rWrBg0apMzMTBNRAQCoNPQjAKCieLkuNkkl2r59u8aMGaP27dvrxIkTmjhxovLy8tS/f38NGTJE8fHxOnz4sBYuXCh/f389+uijeuqppxQREVHk18vKytL+/fsr95sAABjVpk0bBQQEmI5Rrsq7HyU6EgCqmuL60ddAlgJbt25VZGSkfHx85OPjo0WLFkmS4uPj1bVrV1WrVk2S1Lx5c50+ffqKX+/BBx9UampqhWYurZ07d+r3v/+96RhuDOz9Etm1a5duvfVW0zHc1KgRbDpCkTZt+kwdO3YxHcNNbm6O6QjFSkz8Qu3b/8F0DDdZWc581MaJx7AGDRooISHBdIwKVd79KEm9ej2s1NRjFZa5LLZt26o77rjLdAw3OTlZpiMUyakd6eXlZTpCkZx4/JKkoKDapiMUyan/p5Ckvs+NNB3BzYAn79WcRZ+ajlFIjaBA9el1d7GXGx1+vr6+hQ4WqampCgwMLLjsIi8vL8cOFQAAyhv9CAAob0Z/ncOdd96p+Ph45efnKzs7W0OHDlVSUpLJSAAAGEc/AgDKm9Hh9+KLL8rPz08PPfSQIiIi1LFjR913330mIwEAYBz9CAAob0ZO9WzXrp1Wr14tSRo7dqzb5VFRUZd9GwAAG9GPAICKYvQRPwAAAABAxWP4AQAAAIDlGH4AAAAAYDmGHwAAAABYjuEHAAAAAJZj+AEAAACA5Rh+AAAAAGA5hh8AAAAAWI7hBwAAAACWY/gBAAAAgOUYfgAAAABgOYYfAAAAAFiO4QcAAAAAlmP4AQAAAIDlGH4AAAAAYDmGHwAAAABYjuEHAAAAAJZj+AEAAACA5Rh+AAAAAGA5hh8AAAAAWI7hBwAAAACWY/gBAAAAgOUYfgAAAABgOYYfAAAAAFiO4QcAAAAAlmP4AQAAAIDlGH4AAAAAYDmGHwAAAABYjuEHAAAAAJZj+AEAAACA5Rh+AAAAAGA5hh8AAAAAWM7XdIDy5O8XqAD/aqZjuHFipurVa5mOUKTNmzc6MttfZswxHaFYb06LMR3BzZLod01HuKyWLduZjuAmO/uC6QjFatXqTtMRCqlXr67pCB4pNzdHubnZpmO4cWKmJk1uNB2hSPHxsY7MFh5+n+kIxXJitti/zTMdoUjnjx3TjgNfm45RpCFPjTQdoQj36mCys26vOnVqSbq72Mt5xA8AAAAALMfwAwAAAADLMfwAAAAAwHIMPwAAAACwHMMPAAAAACzH8AMAAAAAyzH8AAAAAMByDD8AAAAAsBzDDwAAAAAsx/ADAAAAAMsx/AAAAADAcgw/AAAAALAcww8AAAAALMfwAwAAAADLMfwAAAAAwHIMPwAAAACwHMMPAAAAACzH8AMAAAAAyzH8AAAAAMByDD8AAAAAsBzDDwAAAAAsx/ADAAAAAMsx/AAAAADAcgw/AAAAALAcww8AAAAALMfwAwAAAADLMfwAAAAAwHIMPwAAAACwHMMPAAAAACzH8AMAAAAAyzH8AAAAAMByDD8AAAAAsBzDDwAAAAAsx/ADAAAAAMtdcfj1799fp0+fdnv/c889p0OHDl32c0eOHKm5c+eWPR0AAA5GRwIAPIXvlT4gMTGxyPfPnj273MMAAOBJ6EgAgKe47PCLjIyUJPXr10+HDh3S/fffrwMHDmj48OEaP368oqOjlZmZqSlTpqhx48b67rvvlJubq7feeku33nproa81btw4HThwQDNnzpSfn58mTZqkpKQk5eXl6cYbb9Qbb7yhGjVqqHPnzurVq5e+/PJLpaam6qGHHtKwYcMq7AYAAKAs6EgAgCe57Kme48ePlyQtWLBADRo0UPPmzbV27Vrde++9hT4uOTlZ/fv318qVK/Xwww9rypQpBZe5XC6NHj1aP/30k2bPnq2goCDFxMTIx8dHK1as0N/+9jeFhoZq0qRJBZ+TmZmpJUuWaOnSpZo3b55++OGH8vyeAQD4zehIAIAnueKpnpf6/e9/X+T7r776arVq1UqSdOONNyo+Pr7gsvnz5+vUqVNauXKl/P39JUmff/65zp07p61bt0qScnJyFBISUvA5Xbp0kSSFhYUpJCREv/zyixo3bnzFfHErlpfm26k0iVs3m47gUTZv3mg6gkfp0raZ6QhuusydaDrCZc11eD6niY2dZjqCR3B6RyYkJJTtG6tgO3fuNB3Bo8THx5qO4FFiYsaZjuDm/LFjpiMUy6nZJkwYZjpCkZyaqzilGn7Vq1cv8v2BgYEFf/by8pLL5Sp4+7bbblN4eLgiIyO1bNky+fn5KT8/X6+//ro6duwoScrIyFBWVlbB5wQEBBT79S7njw8/qmMO+4FN3LpZ7e+623QMN94+pfqrrzSbN2/U3XffYzqGm7/MmGM6QpG6tG2mz5IPm47hZkn0u6YjFGvu3Il69tlXTcdwk519wXSEIsXGTlPfvkNMxyikXr26mjLlLdMx3Di9Ix988EGlpqaW6nuqaDt37ix2MJvUuHEr0xGKFB8fq169+pqO4eaqq658x4MJMTHj9Pzzr5uO4Sb2b/NMRyjS+WPHVK1+fdMxijTkqZGmI7iZMGGYXnvtr6ZjFFKnTi1FRvYv9vIrvqqnj4+PcnNzyxygTZs2evLJJ1WzZk1Nnz5dktShQwctXrxY2dnZys/P15///GdNnjy5zNcBAIAJdCQAwFNccfh169ZNffv2VUZGRpmvxMvLS+PGjdOSJUu0e/du/elPf1LDhg3Vq1cv9ejRQy6XSyNHOm/JAwBwOXQkAMBTXPF8v+LuZdywYUPBn1evXl3w53bt2hW8HRUVVfD+hg0bKikpqeDtUaNGXfHrFvU2AABOQUcCADzFFR/xAwAAAAB4NoYfAAAAAFiO4QcAAAAAlmP4AQAAAIDlGH4AAAAAYDmGHwAAAABYjuEHAAAAAJZj+AEAAACA5Rh+AAAAAGA5hh8AAAAAWI7hBwAAAACWY/gBAAAAgOUYfgAAAABgOYYfAAAAAFiO4QcAAAAAlmP4AQAAAIDlGH4AAAAAYDmGHwAAAABYjuEHAAAAAJZj+AEAAACA5Rh+AAAAAGA5hh8AAAAAWI7hBwAAAACWY/gBAAAAgOUYfgAAAABgOYYfAAAAAFiO4QcAAAAAlmP4AQAAAIDlGH4AAAAAYDmGHwAAAABYjuEHAAAAAJZj+AEAAACA5XxNByhPTw58TRmZWaZjuBn02njTEdzMjR5tOkKxfH39TEdwE/O28/4OJanLB3McmS2sflPTES4rKCjYdAQ3x459ZTpCsU6fTjUdoRBf31zTETzSHXc8pJ9/Pms6hptOnR43HcHNU/89wHSEYr01b4bpCG6iXxljOkKx8vJyTEdw077NraYjFGn9+o8cm+2GG24zHaFIGRlnTEcoJCDg8pfziB8AAAAAWI7hBwAAAACWY/gBAAAAgOUYfgAAAABgOYYfAAAAAFiO4QcAAAAAlmP4AQAAAIDlGH4AAAAAYDmGHwAAAABYjuEHAAAAAJZj+AEAAACA5Rh+AAAAAGA5hh8AAAAAWI7hBwAAAACWY/gBAAAAgOUYfgAAAABgOYYfAAAAAFiO4QcAAAAAlmP4AQAAAIDlGH4AAAAAYDmGHwAAAABYjuEHAAAAAJZj+AEAAACA5Rh+AAAAAGA5hh8AAAAAWI7hBwAAAACWY/gBAAAAgOUYfgAAAABgOYYfAAAAAFiO4QcAAAAAlmP4AQAAAIDlGH4AAAAAYDmGHwAAAABYjuEHAAAAAJar8OG3fft2PfDAA27vj46O1sqVKyv66gEAcCT6EQBQmXxNXfFLL71k6qoBAHAs+hEAUBEqZfhlZmZq6NChOnLkiGrVqqXRo0frvffeU/PmzfXss8/q8OHDGjt2rM6cOaO8vDz17dtXjzzyiLZv366xY8eqevXqysjIUFxcnPz9/SsjMgAAFY5+BABUlkoZfqmpqZo0aZLCw8O1bNkyvfbaa2rWrJkkKTc3V0OHDtWECRPUunVrnTt3To899piuv/56SdJ3332n9evXq2HDhpURFQCASkM/AgAqi5fL5XJV5BVs375d48ePL3i+QnZ2tn73u9+pc+fOCg8PV8eOHdWrVy9dd911BZ9z7tw5DRgwQM2aNVNkZKQ2bNhw2evIysrS/v37K/LbAAA4TJs2bRQQEGA6RplVRj9KdCQAVDXF9WOlPOLn7V34NWS8vLzk6/vrVefl5almzZpatWpVweUnT55UzZo1tWfPHlWvXr3E1xO/LkkZmVnlE7qcPBnRQYtWbjEdw83c6NGmIxRp48Z1uuee+0zHcBN6VRPTEYq07IM5eqz3ANMx3ITVb2o6QrGmTv1vDR061nQMN4cPf2U6QpE++uhD/cd/PGI6RiGhoVfp/fdnmY5RLiqrHyVp7Ng5+vnns789dDmaNGm4XnllsukYbp76b+cdVyWpbZ1aSnbY36EkRb8yxnSEIs2dO1HPPvuq6Rhujhz5xnSEIq1f/5G6dv0P0zGKdMMNt5mO4GbGjL9o8OC/mI5RSN26wRozZlixl1fKr3M4cOCA/v73v0uSli1bpltvvVXVqlWTJDVt2lSBgYEFxZaamqoHHniAeycBANajHwEAlaVSht91112n6dOnq2fPntqwYYOioqIKLvP399fMmTP14Ycf6sEHH1T//v310ksv6dZbb62MaAAAGEM/AgAqS4Wf6tmuXTslJCS4vf/ScmvZsqViY2OL/NzVq1dXaD4AAEygHwEAlalSHvEDAAAAAJjD8AMAAAAAyzH8AAAAAMByDD8AAAAAsBzDDwAAAAAsx/ADAAAAAMsx/AAAAADAcgw/AAAAALAcww8AAAAALMfwAwAAAADLMfwAAAAAwHIMPwAAAACwHMMPAAAAACzH8AMAAAAAyzH8AAAAAMByDD8AAAAAsBzDDwAAAAAsx/ADAAAAAMsx/AAAAADAcgw/AAAAALAcww8AAAAALMfwAwAAAADLMfwAAAAAwHIMPwAAAACwHMMPAAAAACzH8AMAAAAAyzH8AAAAAMByDD8AAAAAsBzDDwAAAAAsx/ADAAAAAMsx/AAAAADAcgw/AAAAALAcww8AAAAALOdrOkB52rFxo06dOmM6RiFPRnTQF2vWmI7hJj39jOkIxXJituys86YjFOvHHw+YjuAmqEaw6QiXlZ7+s+kIbl4eF2U6QrGcli3Qz6rqqjQLYifJ39/fdIxC9icn6+N1803HcHNPx96mIxRp2rQ3NPvNqaZjuMnNzTEdoVhOzJaVlWk6QrGcmu2bb7aajlAkp+UKCwu77OU84gcAAAAAlmP4AQAAAIDlGH4AAAAAYDmGHwAAAABYjuEHAAAAAJZj+AEAAACA5Rh+AAAAAGA5hh8AAAAAWI7hBwAAAACWY/gBAAAAgOUYfgAAAABgOYYfAAAAAFiO4QcAAAAAlmP4AQAAAIDlGH4AAAAAYDmGHwAAAABYjuEHAAAAAJZj+AEAAACA5Rh+AAAAAGA5hh8AAAAAWI7hBwAAAACWY/gBAAAAgOUYfgAAAABgOYYfAAAAAFiO4QcAAAAAlmP4AQAAAIDlGH4AAAAAYDmGHwAAAABYjuEHAAAAAJZj+AEAAACA5Rh+AAAAAGA5hh8AAAAAWI7hBwAAAACWY/gBAAAAgOXKPPzS09O1ZMkSJScnl2ceTZw4UUeOHCnXrwkAQGWiIwEATuNb2k/Yu3evli1bpi+//FJdunRR165dtWHDBs2aNUs5OTkKDAzUiBEjdMsttygnJ0dRUVH68ssv5ePjo7Zt2yoyMlI1atTQkiVLtHTpUvn5+SkgIECjR4/W9ddfr3r16mnw4MEKCQnRY489pq5du8rf378ivncAAMoVHQkAcKoSP+K3b98+RUREKDo6Wh06dNAnn3yiN954Q5mZmZoyZYpiYmK0cuVKjRkzRkOGDFFmZqZmzZql48ePa9WqVVq1apXy8/M1YcIE5eXlady4cZozZ47i4uLUu3dv7dq1S5L0zDPPaPXq1Ro2bJi2bNmi7t27a/HixRV2AwAA8FvRkQAApyvxI37e3t7y9vaWl5eXvLy8Ct6fmJio48eP6+mnny54n5eXl/75z3/qiy++0Msvvyw/Pz9JUt++fTV48GD5+PioW7du6tOnjzp16qQOHTqoY8eOha7Px8en4Dq9vUu2T8ePf62k306liokZZzpCEZyY6VdJSTtMR/AoiVs3m47gcebNm2Q6gkfp+rvrTUdwPE/oyIPffvvbv9EKsL+cT4ctD9OmvWE6QrGcnM2JFiz4q+kIHmXz5o2mI3iUjRvXmY5QKiUefq1bt9aKFSuUnJyspUuXauLEibrvvvtUo0YN3XnnnfrrX/9a8LGpqakKDQ1Vfn5+oQLMz89XTk6OJGnSpEk6ePCgtm7dqpiYGK1atUrR0dFauHChPvzwQwUHB6tPnz4aNWpUQSleSWTkBJ06daak31KliIkZp+eff910DDdffbXedIQiJSXt0G233W46hht/vwDTEYqUuHWz2t91t+kYbm5o2c50hGLNmzdJ/fu/YjqGm8dfGmg6QpG6/u56rd97yHSMQgL9fNXhxmtNxyjEEzqyRcuWjjstdH9ystq0bWs6hpt7OvY2HaFI06a9oSFD3jYdw83ZsydNRyjSggV/Vb9+w0zHcPOPf+w1HaFImzdv1N1332M6RpF8fUt2nKtMGzeu0z333Gc6RiFhYWFaujS22MtL/eIubdu21bhx47Rq1So1atRIt99+uxITE3X48GFJ0qZNm9SzZ09duHBBd999t/73f/9XOTk5ys/P1+LFi9W+fXudPn1aHTt2VHBwsJ5++mkNGzZM+/btk/RrIV4stx49epS40AAAMI2OBAA4Valf3OWimjVr6sknn5QkjR49WsOHD5fL5ZKvr69mzZqloKAgDRo0SO+8844iIiKUm5urtm3b6s9//rNq1aqlQYMG6emnn1ZgYKB8fHz09tu/3oM1YsSI8vnOAAAwhI4EADhNmYffpbp3767u3bu7vT8wMFCjRo0q8nP69OmjPn36lMfVAwDgWHQkAMAJ+AXuAAAAAGA5hh8AAAAAWI7hBwAAAACWY/gBAAAAgOUYfgAAAABgOYYfAAAAAFiO4QcAAAAAlmP4AQAAAIDlGH4AAAAAYDmGHwAAAABYjuEHAAAAAJZj+AEAAACA5Rh+AAAAAGA5hh8AAAAAWI7hBwAAAACWY/gBAAAAgOUYfgAAAABgOYYfAAAAAFiO4QcAAAAAlmP4AQAAAIDlGH4AAAAAYDmGHwAAAABYjuEHAAAAAJZj+AEAAACA5Rh+AAAAAGA5hh8AAAAAWI7hBwAAAACWY/gBAAAAgOUYfgAAAABgOYYfAAAAAFiO4QcAAAAAlmP4AQAAAIDlfE0HKA8ul0uSFBxcy3CSooWEBJuO4KZBgwamIxTLidn8fP1NRyhW/fr1TUdwExJSx3SEy3JivkA/5x6OnZYt4F95Lh77cXkXb6ec7GzDSYqW7cBcdevWNh2hWE7M5u+fbzpCserVq2s6gpvMzDDTEYpVv74zs/n4+JmOUKSwMGfdXlddVU9S8f3o5bKgOc+dO6eDBw+ajgEAqEQtWrRQzZo1TcdwPDoSAKqW4vrRiuGXn5+vjIwM+fn5ycvLy3QcAEAFcrlcysnJUVBQkLy9ecbCldCRAFA1XKkfrRh+AAAAAIDicVcpAAAAAFiO4QcAAAAAlmP4AQAAAIDlGH4AAAAAYLn/A7zTKLXM/KgrAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x1800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_count 1    self.capacity  20\n",
      "0  ------------------------------------------------\n",
      "DecoderLayer@trg4\n",
      "[1, 1, 64]\n",
      "tensor([[[-1.3563,  0.0422, -0.8679, -0.8678,  1.1392,  1.8855, -0.1270,\n",
      "           0.2566, -0.4521,  0.8330,  0.3570, -0.4964, -0.6675, -2.3615,\n",
      "           1.1495, -0.2879,  0.6563,  1.0907,  0.0223, -0.2717,  0.2654,\n",
      "          -0.6657, -0.3894, -0.3598,  0.9974, -0.7496, -0.0276,  0.0962,\n",
      "          -0.6706,  0.6491,  0.3554, -0.1952,  0.0642, -0.3700, -0.6933,\n",
      "           0.7649,  0.6557, -0.8054,  0.8702, -0.3361,  0.1373,  1.4080,\n",
      "          -0.2944, -1.5716,  1.0804,  1.9512,  2.6475, -1.5069, -0.0048,\n",
      "          -0.7286, -0.3543,  0.2191,  1.0297, -0.3619, -0.8129,  1.7381,\n",
      "          -0.9766, -1.4542,  0.6312, -0.7693, -1.8725,  0.6020, -1.7865,\n",
      "           1.9981]]])\n",
      "src = ['i', 'drink', 'beer']\n",
      "predicted trg = ['ich', 'trinken', 'bier', '<eos>']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_count 1    self.capacity  20\n",
      "0  ------------------------------------------------\n",
      "DecoderLayer@trg4\n",
      "[1, 1, 64]\n",
      "tensor([[[-1.6892,  0.3214, -1.1203, -0.6529,  1.1742,  1.5235, -0.0738,\n",
      "           0.3997, -0.6484,  0.7315,  0.1935, -0.9347, -0.6558, -2.1463,\n",
      "           1.4502, -0.6200,  0.9328,  1.5716, -0.1017, -0.2593,  0.0439,\n",
      "          -0.6129, -0.4715, -0.3893,  1.1698, -0.3070, -0.3466,  0.5589,\n",
      "          -0.4356,  0.5708,  0.1810, -0.0949,  0.0413, -0.5568, -0.4589,\n",
      "           0.8131,  0.9525, -0.5911,  0.8359, -0.0866, -0.1003,  1.4078,\n",
      "          -0.3017, -1.5215,  0.9194,  1.8329,  2.5878, -1.1135, -0.3713,\n",
      "          -0.4938, -0.3565,  0.3364,  0.8204, -0.7030, -0.8413,  1.4620,\n",
      "          -0.9536, -1.3398,  0.6948, -0.6043, -2.0001,  0.2305, -1.8845,\n",
      "           2.1564]]])\n",
      "src = ['i', 'read', 'book']\n",
      "predicted trg = ['ich', 'lesen', '<eos>']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_count 1    self.capacity  20\n",
      "0  ------------------------------------------------\n",
      "DecoderLayer@trg4\n",
      "[1, 1, 64]\n",
      "tensor([[[-1.3883,  0.2873, -0.9255, -0.0515,  0.4380,  1.7947, -0.6253,\n",
      "          -0.1469, -0.4674,  0.7399, -0.4869, -0.6750, -0.4386, -2.6014,\n",
      "           1.3044, -0.8187,  1.3671,  1.1180, -0.7115,  0.1020,  0.2449,\n",
      "          -0.4632, -0.1407,  0.6695,  0.3931, -0.4153, -0.4319,  0.2412,\n",
      "          -0.3167,  0.6467,  0.6167, -0.0223,  0.3938, -0.3077, -0.4427,\n",
      "           0.4011,  0.1334, -0.2060,  0.9641, -0.2467, -0.0654,  1.1551,\n",
      "          -0.3544, -1.4183,  1.0784,  1.3896,  2.2502, -1.5674, -0.1008,\n",
      "          -0.2899,  0.0140,  1.2035,  1.5147, -0.8611, -1.2879,  1.2170,\n",
      "          -0.1171, -1.9604,  1.0001, -0.7481, -2.3328,  0.4986, -1.7120,\n",
      "           1.9908]]])\n",
      "src = ['i', 'read', 'newspaper']\n",
      "predicted trg = ['ich', 'lesen', 'zeitung', '<eos>']\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4EAAAF2CAYAAADQop1EAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAu9UlEQVR4nO3deVzUdeLH8TfDIQZ4BOKR2eGx+UstKi2K0jXzKsj67brmsWnXI11ztXI9StvUvLXEAzU1E1EzxTN1vVrKo1S8K7PMPIofoHgkKOf8/nClWMA8Bj4zfF7Pv4KB6c04zJv3zHdmvJxOp1MAAAAAACs4TAcAAAAAAJQeRiAAAAAAWIQRCAAAAAAWYQQCAAAAgEUYgQAAAABgEUYgAAAAAFiEEQgAAAAAFmEEAgAAAIBFGIEAcB3S0tJMRwAAwO3Qj+6NEQgA1yghIUEjRoyg6AAA+A360f0xAgHgGhw4cEAzZsxQp06ddOONNyovL890JAAAjKMfPQMjEACugtPp1IULFxQXF6fk5GT9+OOPkiSHwyGn02k2HAAAhtCPnsXLyb8KAFyxrKws+fn5KSMjQ+PHj1d6erqioqIUHh4u6WIJenl5GU4JAEDpoh89CyMQAK5QQkKCPv74YzmdTt11112KjIxUTEyMvLy81KJFCz388MOmIwIAUOroR8/D4aAAcAU+++wzjR8/Xj169FBwcLDi4+NVrVo1vfbaa8rMzNSaNWt06tQp0zEBAChV9KNn8jEdAADcXXZ2trZt26YxY8boxIkT+v777/Xhhx/qvffe01133aWePXsqPT1dlStXNh0VAIBSQz96LkYgAPwOX19fOZ1ODRw4UA6HQ9HR0apataqOHz+ue+65RzVr1jQdEQCAUkc/ei4OBwWAYqSmpurYsWOSpLCwMPn5+SkyMlLVqlXTV199pQMHDqhSpUpmQwIAUMroR8/HC8MAQBHWr1+vCRMmSJJq166txx9/XHv37tVXX32l9PR0ZWRkqHfv3nr00UcNJwUAoPTQj2UDIxAA/suRI0c0efJkPfPMM6pTp45GjBghb29v9ejRQ97e3vrpp59UuXJl3XrrrbzkNQDAGvRj2cHhoADwH06nU4cOHVLbtm3l5+ensLAwBQUFaciQIdq9e7eWLVum0NBQhYWF6dZbb5UkCg4AUObRj2UPIxAA/sPLy0u1a9fWM888o5UrV+a/pLWPj4/+8pe/KCgoyHBCAABKH/1Y9vDqoAAgafv27dq/f78iIiL05ptvKjc3V5GRkRoxYoR8fHz04Ycf6u233zYdEwCAUkU/lk08JxCA9RISEjRkyBDVrVtXycnJ6t27t5o2barhw4drzpw5atWqlV588UU1aNCA5zgAAKxBP5ZdPBIIwGr79+/XxIkTNXfuXJ05c0Y9e/bU/Pnz5evrq4EDByooKEhz587V4MGDTUcFAKDU0I9lG88JBGC1CxcuqHHjxsrKytKaNWs0YsQIlS9fXoMGDdKMGTP0yiuvKDw8XB07dlRWVhb3cgIArEA/lm08EgjAaiEhIbr77rt1+PBhZWZmqnHjxkpNTdWZM2cUHh4uSXrvvfeUmpoqPz8/w2ndU15enhyOX+9T5JAgAPB89KNruGtH8kigG8jLy5Mk5eTkGE4C2CEhIUFvvPGGBg4cqNTUVLVq1UobNmxQcHCwvvnmG82aNUsvvvii7rzzzvzfy5CQEMOp3ZfD4dC5c+e0b98+SbwsOFyLjgRKD/3oeu7akbwwjBvIyMjQ6dOnNWvWLLVt21b33HOP6UhAmbV7924NGTJE7dq1U1pamqZNm6apU6fqzJkzio6Olr+/v1555RW1atXKdFSPsGPHDp0+fVoffPCBHA6HBg0apHr16pmOhTKEjgRKB/3oeu7ckRwOatjHH3+s77//XklJSVq7dq2Cg4MpOKCEHDhwQKNHj1avXr3UrFkzSVLt2rX1xhtvaMOGDbrrrrtUrlw5VatWzW0O13BX27dv1xdffKFNmzapTZs2ys3NVWhoqNuUG8oGOhIoHfSja3lCRzICDfniiy+UkJCgbdu26fXXX1dycrIqVKigZ5991nQ0oMxKSkrS999/r3//+99q1qyZnE6nIiMjtW7dOp08eVK33HJL/tdScJd38OBBnTlzRmPGjFGtWrWUk5OjO++8U1Lh5z8AV4uOBEoX/ehantCRjEBD6tWrJz8/P73wwgsKDg7WihUrVKFCBfn4+LjNlQOejevRr7777js5HA49+OCDGjlypN5//33FxsaqS5cu2rt3rw4ePKgLFy6YjulROnXqlP/f27dv1+rVq/PvPeZ6h+tFR6IkcR36Ff1YMjyhIxmBBhw+fFjlypXLP6Tl8OHDev/99/WPf/yDV1eCS+zatUsTJ07UpEmTdMMNN5iOY9TGjRsVExOj4OBg9e3bVw8//LAcDodGjBihNWvWqGLFiho4cKBuv/1201E9wuLFi5WUlKT69evr0UcfVXp6upYuXaoOHTqoTp06puOhDKAjUZLox1/Rj67nSR3pHlPUIrGxsRo8eLAmTZqk5ORkSVJqaqqaN2+uiIgI8To9cIWwsDClpqaqX79+Sk9PNx3HmL179yo6OlqzZs1S3759derUKc2bN08Oh0MDBw7U+fPnVaNGDT3yyCOSxO/f75g9e7aWLl2qqlWr6qabbtL58+d1ww036IEHHlBoaKjpeCgD6EiUNPrxIvrR9TytI3kksBQtXrxYq1ev1qRJk5SSkqKffvpJn332mR599FGdP39eEsdZ4/o4nU7l5eXJ29tb/fv3V8+ePfXaa6/p3XffVfny5U3HK1Xnz5+Xl5eXatasqU8//VSffvqpMjMzlZqaqvvuu0+vvfaa8vLyNHToUNWsWVNdu3bl9+8ykpKSlJCQoNjYWO3cuVOffvqp1q9fr0qVKmnGjBlcdrhudCRKEv34K/rR9TyxI3mLiFI0bdo0Va9eXRkZGdqzZ49SU1O1adMmDR48WB07djQdD2XIjBkztGvXLoWHhys2Nla1atXShAkTrDn05aefflKfPn3UrVs3bdmyRbt27VKPHj3Utm1bJSQkaN68eZo4caLy8vK0bds23Xbbbbr55ptNx3ZrP//8s9q1a6e7775baWlpatasmcLCwrRw4UL1799f1atX5xXjcF3oSJQG+pF+LAme2JE8EliKgoODtWDBAmVmZqpHjx569NFHtWjRIqWlpbndFQOe6+TJk1q3bp1Gjx6tW265RZ07d1bHjh3Vp08fjRs3ToGBgaYjlrhKlSqpUaNGCgoK0tChQ+V0OpWYmKj169dr0qRJ6tOnT/5ziy4d6oKiff311ypXrpyqVKmiOXPmaO/evQoPD9fNN9+s9evX69ixY/L395fEozS4PnQkShr9SD+6mid3JCOwhC1ZskSHDx9WSkqKevbsqbZt26p8+fI6ceKEFi9erLlz52rcuHFud8WA5/jvP45yc3N15swZ5eTk5H/un//8p6KiojRu3DgNHjy4zF7f9uzZo4yMDDVp0kR33HGHJk+erIiICB09elSLFy9WcnKyevfuraZNm/JH5RX48MMPtXr1alWsWFE///yzunXrpvbt22vAgAHy9vbWzp07NWHCBFWuXNl0VHgoOhIliX78Ff3oep7ekRwOWoJmz56t1atXq1OnTtqyZYs2bdqk8ePH6/Tp05ozZ45yc3M1ZMgQ1a1b13RUeKjf3lDv379fVatWVZUqVTRixAjt2rVLU6dO1Y033qg1a9Zo69at6tatm2699VazoUvApZf7joqK0vHjx9WiRQsNHjxYb7/9turXr6/nnntOkpSenq6AgAAK7gqsX79eU6ZMUWxsrDIzM7V//369+eabGjFihBwOh9LS0tSwYUPVqlXLdFR4KDoSJYl+vIh+LBlloSMZgSUkJSVF/fr107vvvqtKlSpJkqKjo7Vy5UqtXbtW6enp8vLysuYYdLjeb2+oZ82apbi4ON1666164IEH9PDDD+vjjz/WypUr1bJlS3355ZeaPn16mSw4STp37pwCAwO1e/duxcXFKSMjQydPntRNN92kM2fOKCYmRr6+vpTbVfjwww+VlJSk/v37Kzs7Wz4+PnrrrbdUq1YtvfDCC6bjwcPRkShJ9OOv6MeSURY6ksNBS4jT6VRKSooOHz6ssLAwSdKzzz6rffv25f9CAtfj0o11fHy8Pv/8cy1btkwDBw7Up59+KqfTqX79+qlVq1bKzc3VSy+9VGaf2P3dd99p8uTJatmypZo3b66KFSvq2WefVW5urpYtW6ZPPvlEx48f12233UbBXYXAwECdOHFCZ8+eVYUKFSRJfn5+yszMlFT4MCvgatCRKEn040X0Y8kpCx3JCHSxvXv3Kjg4WCEhIXrooYe0bds2VahQQbVr19bGjRt19uxZ5eXlmY6JMiInJ0dbt25V586ddeLECYWGhqpBgwZatWqVUlJS9Nxzz6lGjRqmY5a4iIgIjR49WikpKcrNzdWgQYM0depUDR48WC+//LJbvj+PO1qxYoUuXLigrKws3X///YqLi9PMmTNVv359ZWZmatOmTYqJiZHkfk9wh2egI1Fa6MeL6EfXKWsdyZvFu9Ds2bM1fPhwjR8/XtnZ2QoPD9fx48fVt29fDR48WNOnT9ewYcPy7zEArtZ/H73t4+Oj2rVrq0KFClq7dq0eeeQRvfTSSwoKClJ6erq8vb0NJS15W7Zs0fDhw7Vu3TpVr15dCxYs0OnTp+Xn56dvvvlGcXFxysnJyS84jny/vNmzZ2v+/PmqVq2ahg4dqqNHj2rEiBE6efKk/vWvf2nDhg2Kjo7WbbfdZjoqPBQdiZJEP/6KfnS9stiRPBLoArm5uVq3bp02bNigBQsWaPfu3dq/f7/Onj2r8PBwtW3bVmfOnNFLL72kmjVrmo4LD/XbQwv+/e9/KycnR5UqVVLXrl114cIFRUdHq1WrVtq4caMyMzP197//XVWrVjWcumQkJCRo7Nix6t27tz744ANt27ZNs2fPVu/evXXu3DlduHBBERER8vH59SbOE+6VMyEzMzP/TbljY2M1d+5c/fGPf1T9+vW1e/duDRs2TJKUkZHB87NwTehIlDT68Vf0o2uV5Y5kBF6nxMRE+fv7Kzk5WXXr1tXixYu1efNmpaamKi8vT4899pjatm1rOibKgEs30nPmzNHq1av1+OOPq2fPnpoyZYpq1aqlEydOaPbs2dq0aZOmTJmiatWqGU7sek6nU2fPntXixYs1ceJEpaamKicnR+PGjdOCBQtUr1493XPPPXr77bfzv55yK97OnTvldDoVEBCgoKAgTZkyRXv37tWUKVP0008/KTo6Ws2bN1e5cuU8rtzgHuhIlAb6kX4sCWW9Izkc9DqtXr1au3fv1u23364jR45oyZIlioqKUmxsrJo3b64jR47I6XTyUDuu2W+vO998843WrFmj2bNnKycnR82aNdOdd94pLy8vjR49Wk2aNNH7779fZl9S3cvLSxUrVlSDBg00depUjRo1SmPGjFHVqlUVHx+f/yqDv/16FG/VqlU6cOCAatasqZMnT2rNmjWaMmWKfH19tXnzZtWoUUMOBzWBa0dHoiTRj7+iH12vrHckjwReh4SEBG3dulXdu3dXcHCw7r//fvn5+Wnz5s1avny5Vq5cqbFjx/KLdoW2b9+u7OxsPfjgg6ajuI3f3lO3cOFCZWRkKCwsTPPnz9fnn3+uadOm6fPPP1d0dLSWLFmihg0bGk5ccj777DOtX79e3t7eOnHihP7v//5PAwcO1M0336zvvvtOFy5c4A/Jq3Dp9uv5559XYGCgnnjiCX355Zd6+eWXFRYWpnXr1mns2LHy9fU1HRUeio50LTqyIPrxV/Sj69nQkYzAa3DpjTdPnDih5557TsHBwdqzZ48SExPl4+OjxMREnTt3TqNGjVLt2rVNx/UITqdTaWlpatSokZKTk8vssfpX61LBLV26VPHx8Xr11Vc1aNAg3XDDDVqyZIkk6YcfflC9evVMxixxu3bt0rhx49SsWTOdOnVK3377raSLl8uMGTN07Ngx9erVi9+3K/Dft1/Vq1fXt99+qxMnTqht27bav3+/KlasqPHjx3N54prQka5HRxZGP15EP7qWTR3JCLwGDodDp0+f1ooVKxQSEqLz588rNjZWf/rTn1S/fn399a9/9cgniJrk5eWlVq1a6fjx42rfvr0GDBjA80T+48cff9TkyZPVrFkzNWnSRFFRUdq3b59GjRqlqlWr6pNPPtGoUaNMxywxX3/9taZOnaphw4apYcOGOnLkiCpXrqwNGzboD3/4g9q0aaOAgAA1atSI5zhcgaJuvz788EM9/fTTCgkJUZ8+fUxHhIejI12Pjiwa/Ug/uppNHckIvAZOp1P79u3Tt99+q+DgYN14440aO3ZsgUMNypcvbzCh5woNDdXLL7+sadOmyeFwqHXr1qYjGVe9enV16tRJU6ZM0YMPPqgePXro888/15IlS+Tj46NRo0aV2ec45OXl6dtvv9XmzZv14IMPqmHDhqpVq5aefvppnThxQqtWrVJcXFz+11Nwv6+o26/x48eX6UOlULroyJJDRxZEP9KPrmZTR3o5OUj4mmRnZ2vv3r265557+MVysaysLMXHx2vu3Lnq1auXWrZsaTqScTk5Ofroo480b9489enTRy1atJBkx6t7ZWVlaeHChYqNjVXv3r3Vpk0bSdKxY8eUnp6uO+64w3BCz8PtF0oa17GSQ0cWRD/Sj65my+0XjwReI19fX917772SLr4HUll+09HS5ufnp6effloOh0NDhw6Vw+HIv1G3lY+Pj/785z/Lx8dH//znPyVJLVq0KNM3Tpf4+fmpffv28vHx0bRp05STk6PIyEjdfPPNpqN5LG6/UNK4jpUcOrIg+pF+dDVbbr8YgS5QVq8cJvn5+aldu3by9vbWH/7wB9Nx3IKfn5+eeuop+fj4WHeZXPqjJzs7W5MnT9YDDzygkJAQK0q+pHH7hZLGdcz16MiC6Ef6saSU5dsvDgeFW7PhcI6rZfNlkpWVpRMnTqhGjRqmowCAcTb3QVFsvjzoR1wtRiAAAAAAWMRz3+YeAAAAAHDVGIEAAAAAYBFGIAAAAABYhBEIAAAAABZhBAIAAACARcrc+wTm5eUpPT1dvr6+1r5MMADYwOl0Kjs7WwEBAXI4uE/z99CPAGCP3+vIMjcC09PTdfDgQdMxAAClpF69egoKCjIdw+3RjwBgn+I6ssyNQF9fX0nS88+/oJSUFMNpClqxYrkiI6NMxyjk8OEfTEco0v79+9WgQQPTMQq57bbbTEco0ooVKxQZGWk6hsfg8ro67nh5hYaGaubMmfm3+7i8S5fTCy+86Hb9KEnLly9TVNSTpmMUsGrzJtMRipVz8qR8goNNxyigQxv3+vf7rblzZ6lz5+dMxyjAnR+Rj42dqS5dnjcdo5A3Jk8wHaFId1QI1IGz50zHKMDXy0u1gwKK7cgyNwIv/UKlpKQoKSnJcJrC3DFTuXLlTEcoljtmc8d/w0vcOZs74vK6Ou56ebnzH1LuxN37UXK/65iXt7fpCJflbvmSk93vzoXfcrd87n7b5W6XlyRl5zlNRyiW22X7zxGgxV3PeBIFAAAAAFiEEQgAAAAAFmEEAgAAAIBFGIEAAAAAYBFGIAAAAABYhBEIAAAAABZhBAIAAACARRiBAAAAAGARRiAAAAAAWIQRCAAAAAAWYQQCAAAAgEUYgQAAAABgEUYgAAAAAFiEEQgAAAAAFmEEAgAAAIBFGIEAAAAAYBFGIAAAAABYhBEIAAAAABZhBAIAAACARRiBAAAAAGARRiAAAAAAWIQRCAAAAAAWYQQCAAAAgEUYgQAAAABgEUYgAAAAAFiEEQgAAAAAFmEEAgAAAIBFGIEAAAAAYBFGIAAAAABYhBEIAAAAABZhBAIAAACARRiBAAAAAGARoyNw37596tWrV7Gn9+/fXzNnzizFRAAAuAc6EgBQUoyOwIYNGyo6OtpkBAAA3BIdCQAoKUZH4JdffqknnnhC6enpGjBggFq1aqW2bdtq/PjxcjqdkqRdu3apQ4cOatGihbp3766MjAyTkQEAKBV0JACgpPiYDiBJ0dHRyszM1KpVq5Sbm6vnnntO27ZtkyQlJydrzpw58vPz05///GetXbtW7dq1+93zXLFieQmnvjY7dmw3HaGQxMRE0xGK5Y7ZduzYYTpCsdw5mzvi8ro6XF5muLojly9fVgqpr8327dtMRyggOyXFdITLcrd869atNB3hstw9n7tZu3aF6QgepWGlINMRropbjMAtW7ZowIAB8vb2lre3t+bOnStJWrJkiVq0aKHy5ctLkurWrau0tLQrOs/IyCglJSWVWOZrsWPHdt13X2PTMQpxOvNMRyhSYmKi7r33XtMxCvHy8jIdoUg7duzQfffdZzqGx+DyujrueHlVr15dK1aU/T9SXN2RUVFPul0/ShcHYOPGTUzHKGD3kR9NRyhWdkqKfENDTccooNld7vXv91vr1q3UY489YTpGAe7694R0cQC2bBlpOkYh4xbOMx2hSA0rBWnf6V9MxyjA1+GlOyoEFnu6W4xAHx+fAr8ISUlJ8vf3zz/tEi8vr/xDYAAAsAEdCQBwNbd4i4jw8HAtWbJEeXl5ysrKUq9evbR9u/sdNgkAQGmjIwEAruYWI7Bnz57y9fXVk08+qXbt2qlp06Zq2bKl6VgAABhHRwIAXM3o4aD333+/Vq68+CTdd955p9DpI0eOvOzHAACUVXQkAKCkuMUjgQAAAACA0sEIBAAAAACLMAIBAAAAwCKMQAAAAACwCCMQAAAAACzCCAQAAAAAizACAQAAAMAijEAAAAAAsAgjEAAAAAAswggEAAAAAIswAgEAAADAIoxAAAAAALAIIxAAAAAALMIIBAAAAACLMAIBAAAAwCKMQAAAAACwCCMQAAAAACzCCAQAAAAAizACAQAAAMAijEAAAAAAsAgjEAAAAAAswggEAAAAAIswAgEAAADAIoxAAAAAALAIIxAAAAAALMIIBAAAAACLMAIBAAAAwCKMQAAAAACwCCMQAAAAACzCCAQAAAAAizACAQAAAMAijEAAAAAAsIiP6QAlpVq1W+RwBJiOUchNN9UxHaGQu+9ubjpCkWbOHOOW2Zo372w6QrHcMdsvv6SZjlCsxo3bmo5QpKSfvzcdoUg1b6pnOkIBoaEhpiN4JKczT05nnukYRXK3XA83uMd0hGJt3LjG7fLVrh1mOsJl3XprQ9MRCti5c63pCMVKTEzUyZM/m45RyMu9R5qOUKSGXR7TFyu+MB2jgMAAf93x9MPFns4jgQAAAABgEUYgAAAAAFiEEQgAAAAAFmEEAgAAAIBFGIEAAAAAYBFGIAAAAABYhBEIAAAAABZhBAIAAACARRiBAAAAAGARRiAAAAAAWIQRCAAAAAAWYQQCAAAAgEUYgQAAAABgEUYgAAAAAFiEEQgAAAAAFmEEAgAAAIBFGIEAAAAAYBFGIAAAAABYhBEIAAAAABZhBAIAAACARRiBAAAAAGARRiAAAAAAWIQRCAAAAAAWYQQCAAAAgEUYgQAAAABgEUYgAAAAAFiEEQgAAAAAFmEEAgAAAIBFGIEAAAAAYBFGIAAAAABYhBEIAAAAABZhBAIAAACARRiBAAAAAGARRiAAAAAAWMRlI/DLL7/UE0884aqzAwCgTKAfAQDuhkcCAQAAAMAiPq4+w6ysLI0dO1bbt29Xbm6u/ud//kdvvvmmAgMDNW/ePC1YsEC+vr4qV66chgwZojp16ig5OVlDhgxRUlKSsrOz9fjjj+vll1/W8ePH1bVrVzVt2lR79uzR2bNn1bdvXz322GOujg0AQImiHwEA7sLljwROnz5d3t7eio+P1/LlyxUaGqqxY8cqNzdXw4cP14wZM7R48WK1b99eiYmJkqS+ffvqf//3fxUfH69FixZpy5YtWrVqlSTp2LFjioiI0KJFi/Taa69p+PDhro4MAECJox8BAO7Cy+l0Ol1xRl9++aWGDh0qf39//fLLL/L395ckZWdnKzg4WLGxsXr99de1c+dONWvWTBEREWratKkyMzN17733ql69evnnlZGRoTZt2qh9+/Zq3bq19u7dK4fDoWPHjikqKkq7du0qNkdmZqb279/vih8JAOABGjRooHLlypmOUSz6EQBgSnEd6fLDQfPy8jRw4EA1bdpUkpSenq7MzExJ0tixY3Xw4EFt2bJF06dP17Jly/TOO+/I6XRqwYIFKl++vCQpLS1N5cqV06lTp+Tr6yuH4+IDll5eXlec48UXX1FKygkX/3TXZ9my+XryyWdMxygkJKSm6QhFmjlzjJ5/vq/pGIUEB99kOkKRRo/urX/84z3TMQr55Zc00xGKFBMzRN27DzYdo0hJP39vOkIhS5fNU7snO5qOUUBoaIimvx9tOsYVc5d+jIyMVFJSkot/uuu3Y8cO3XfffaZjFFChQojpCMXauHGNmjdvbTpGAbVrh5mOUKz33x+hF18cYDpGATt3rjUdoViJiYm69957Tcco5OXeI01HKNKLXR7T+7HrTMcoIDDAX888/XCxp7v8cNCIiAjFxcUpKytLeXl5GjRokMaPH6+0tDQ1bdpUlSpVUteuXdW7d2/t27dPgYGBuvvuu/XBBx9Iks6ePatnnnlGGzZscHU0AACMoR8BAO7C5Y8E9ujRQ6NGjdJTTz2l3Nxc1a9fX/3791dgYKC6d++url27yt/fX97e3ho2bJiki/eADh06VJGRkcrKytITTzyhqKgoHT9+3NXxAAAwgn4EALgLl43A+++/XytXrpQkvfXWW0V+TYcOHdShQ4dCn69Zs6amTZtW5Od/+/yG//4YAAB3Rz8CANwN7xMIAAAAABZhBAIAAACARRiBAAAAAGARRiAAAAAAWIQRCAAAAAAWYQQCAAAAgEUYgQAAAABgEUYgAAAAAFiEEQgAAAAAFmEEAgAAAIBFGIEAAAAAYBFGIAAAAABYhBEIAAAAABZhBAIAAACARRiBAAAAAGARRiAAAAAAWIQRCAAAAAAWYQQCAAAAgEUYgQAAAABgEUYgAAAAAFiEEQgAAAAAFmEEAgAAAIBFGIEAAAAAYBFGIAAAAABYhBEIAAAAABZhBAIAAACARRiBAAAAAGARRiAAAAAAWIQRCAAAAAAWYQQCAAAAgEUYgQAAAABgEUYgAAAAAFjEx3SAkuLjU06+vv6mYxTijpm++mqz6QjFcsdst99+l+kIxTp+/FvTEQqpVau+6QjFqlgxxHSEItWoUcd0hCLde19r0xEKqFgxwHQEj/T6sHd1PivbdIwiDYuJNR2hgOAa7nkbccmoWPe6vEa88prpCJd18uRPpiMUcO+9rUxHKNb06cPdMl9S0iHTEYr0YpfHtHzhDNMxCggNraJnnn642NN5JBAAAAAALMIIBAAAAACLMAIBAAAAwCKMQAAAAACwCCMQAAAAACzCCAQAAAAAizACAQAAAMAijEAAAAAAsAgjEAAAAAAswggEAAAAAIswAgEAAADAIoxAAAAAALAIIxAAAAAALMIIBAAAAACLMAIBAAAAwCKMQAAAAACwCCMQAAAAACzCCAQAAAAAizACAQAAAMAijEAAAAAAsAgjEAAAAAAswggEAAAAAIswAgEAAADAIoxAAAAAALAIIxAAAAAALMIIBAAAAACLMAIBAAAAwCKMQAAAAACwCCMQAAAAACzCCAQAAAAAizACAQAAAMAijEAAAAAAsAgjEAAAAAAswggEAAAAAIu4dATOnz9f06dPlyR9/PHHiouLc+XZAwDgsehIAIC78HHlmT3zzDP5/52YmKi6deu68uwBAPBYdCQAwF1cdgTGxcVp4cKF+R8fOnRIL7zwgho1aqSYmBhlZ2fL399f/fr1U1hYmCZOnKhTp04pPDxcGzdu1ObNm+Xv76+0tDSdOnVKgwcPlqT8rxs8eLC6dOmiu+++Wzt37lRSUpLCw8M1dOhQORwOxcfHa/r06fL399cDDzygOXPm6Ouvvy7ZSwQAgCtARwIAPNVlR2CnTp3UqVMnSdK8efO0aNEitW7dWn379tWcOXNUuXJlfffdd+rWrZvWrl2b/32PPfaYNmzYoLp166pTp06aOHHiZUMcPXpUsbGxysjIUJs2bbRt2zaFhIRo7Nixio+PV7Vq1TRp0iTl5ua64EcGAOD60ZEAAE91RYeDrlu3TrNmzdL8+fO1du1apaSkqGvXrvmne3l56ejRo9cc4o9//KMcDocCAwN1yy236MyZMzpw4IAeeughVatWTZLUuXPn3y3K34qJGXvNeUrSokUfmI7gUb74YovpCB5l3rwY0xE8ysiRvUxH8CiDBv3VdAS35Gkd2fSuOtecpaS1blzfdASP0vimKqYjFBAfP8d0hMty93zuZvr04aYjeJQVKz4yHeGq/O4ITExM1Ntvv63Zs2erSpUqysvLU3h4uN577738r0lKSlJoaKjWrVtX5Hl4eXnJ6XTmf5ydnV3gdH9//0Jf6+3tXeB7vL29r/iHkqTu3V9XaurJq/qekrZo0Qf605+6mY5RyPHj35qOUKQvvtiiBx540HSMQm6//S7TEYo0b16MOnbsbjpGIbVquecfdSNH9lL//tGmYxQpIKCS6QiFDBr0Vw0d6l5/QFWsGKBevf7XaAZP7MiEPd/rfFb2739hKWvduL7WbP/GdIwCgmuEmI5QrMY3VdH2n1JNxyhgxCuvmY5QrPj4OXr6afe6IyskpKbpCMWaPn24XnppoOkYhSQlHTIdoUgrVnykyMi/mI5RQGhoFc2cOanY0y/76qCHDh3S3//+d40bN0516ly85zA8PFybN2/WoUMX/xESEhIUFRWlCxcuFPheb29v5eTkSJIqV66sr776Sk6nU+fOndOnn376u8EjIiK0detWJScnS7r4SmoAALgLOhIA4Kku+0jg8OHDlZ2drVGjRuU/16BBgwYaMmSIXn31VTmdTvn4+CgmJkYBAQEFvveRRx7RyJEjJUkdO3bU559/rpYtW6pq1apq0qRJgXswi3LbbbdpwIABev755+Xn56f69eurfPny1/OzAgDgMnQkAMBTXXYEzpw5s9jT2rRpU+hzr7zySv5/t2rVSq1atcr/eOrUqUWeT2xsbJEfHzt2TD/++KOWL18uh8OhtWvX6uDBg5eLCwBAqaEjAQCeyqXvE+hK1apVU0pKiiIjI+Xt7a2goCANH84TVAEAoCMBANfDbUegr6+vhgwZYjoGAABuh44EAFyPy74wDAAAAACgbGEEAgAAAIBFGIEAAAAAYBFGIAAAAABYhBEIAAAAABZhBAIAAACARRiBAAAAAGARRiAAAAAAWIQRCAAAAAAWYQQCAAAAgEUYgQAAAABgEUYgAAAAAFiEEQgAAAAAFmEEAgAAAIBFGIEAAAAAYBFGIAAAAABYhBEIAAAAABZhBAIAAACARRiBAAAAAGARRiAAAAAAWIQRCAAAAAAWYQQCAAAAgEUYgQAAAABgEUYgAAAAAFiEEQgAAAAAFmEEAgAAAIBFGIEAAAAAYBFGIAAAAABYhBEIAAAAABZhBAIAAACARRiBAAAAAGARH9MBSoq3w1veDm/TMQpxx0y5uTmmIxTLHbP5+weYjlAsd8x27twZ0xGK5a7ZKlYMMR2hSD4+7lUZ7pbHU3R+qqV8/fxMxyjkhwMH1KPLU6ZjFPB8l0GmIxSr8RudtHb2WtMxCqhQwT1vuy5xt3wpKUdNR7gsd8yXl5drOkKx3C3b7+XhkUAAAAAAsAgjEAAAAAAswggEAAAAAIswAgEAAADAIoxAAAAAALAIIxAAAAAALMIIBAAAAACLMAIBAAAAwCKMQAAAAACwCCMQAAAAACzCCAQAAAAAizACAQAAAMAijEAAAAAAsAgjEAAAAAAswggEAAAAAIswAgEAAADAIoxAAAAAALAIIxAAAAAALMIIBAAAAACLMAIBAAAAwCKMQAAAAACwCCMQAAAAACzCCAQAAAAAizACAQAAAMAijEAAAAAAsAgjEAAAAAAswggEAAAAAIswAgEAAADAIoxAAAAAALAIIxAAAAAALMIIBAAAAACLMAIBAAAAwCKMQAAAAACwCCMQAAAAACzikhF47tw5zZs3T3v37nXF2eUbM2aMjhw54tLzBACgNNGRAAB343M937xnzx599NFH2rp1qx599FG1aNFCGzduVExMjLKzs+Xv769+/fopLCxM2dnZGjlypLZu3Spvb281atRIAwYMUGBgoObNm6cFCxbI19dX5cqV05AhQ1SnTh2FhITob3/7m4KDg/WXv/xFLVq0kJ+fn6t+dgAASgwdCQBwV9f0SOC+ffvUrl07TZgwQREREfrXv/6lN998UxkZGXr33Xc1ffp0LV26VEOHDtUrr7yijIwMxcTEKCUlRcuWLdOyZcuUl5en0aNHKzc3V8OHD9eMGTO0ePFitW/fXomJiZKkbt26aeXKlerdu7c2bdqkNm3aKC4uzqUXAAAArkRHAgDc3TU9EuhwOORwOOTl5SUvL6/8z2/evFkpKSnq2rVr/ue8vLx09OhRffbZZ+rTp498fX0lSV26dNHf/vY3eXt7q3Xr1urQoYOaNWumiIgINW3atMD/z9vbO///6XBc2W6dNHnUtfxoJe6jhTNMR/Ao27dvMx3Bo8yaNdZ0BI8yadIg0xE8yoABHU1H8Aju3pHHfvjBNT9oCfjhwAHTEQp4441OpiNclvvlc7c8Bc2ePd50BI+ydOlc0xE8yiefLDId4apc0wi88847FR8fr71792rBggUaM2aMWrZsqcDAQIWHh+u9997L/9qkpCSFhoYqLy+vQBnm5eUpOztbkjR27FgdPHhQW7Zs0fTp07Vs2TJNmDBBc+bM0aJFi1SpUiV16NBBb731Vn5B/p6ef+un1NST1/LjlZiPFs7QX9q/YDpGIT8cdu3zVFxl+/Ztaty4iekYhTRs+IjpCEWaNWusnnvuddMxCrnhhoqmIxRp0qRB6tlzqOkYRbrpptqmIxQyYEBHjRgxz3SMAipWDFCPHk+ajlGIu3fkzbffLl83PGz0hwMHdPsdd5iOUcDzXdz3jqI33uikd95xr0d+v/su0XSEYs2ePV5du75qOkYBp0+nmI5QrKVL56pdu86mYxSSnX3BdIQiffLJIj3++J9MxyggNLSKPvggptjTr+uFYRo1aqThw4dr2bJlqlmzppo0aaLNmzfr0KFDkqSEhARFRUXpwoULevjhhzV//nxlZ2crLy9PcXFxeuihh5SWlqamTZuqUqVK6tq1q3r37q19+/ZJuliOl4qubdu2VzwAAQAwjY4EALir63phmEuCgoLUufPFewuGDBmiV199VU6nUz4+PoqJiVFAQIC6d++uUaNGqV27dsrJyVGjRo00aNAgVahQQd27d1fXrl3l7+8vb29vDRs2TJLUr18/V8QDAMAYOhIA4G5cMgJ/q02bNmrTpk2hz/v7++utt94q8ns6dOigDh06uDoKAABuhY4EALgD3iweAAAAACzCCAQAAAAAizACAQAAAMAijEAAAAAAsAgjEAAAAAAswggEAAAAAIswAgEAAADAIoxAAAAAALAIIxAAAAAALMIIBAAAAACLMAIBAAAAwCKMQAAAAACwCCMQAAAAACzCCAQAAAAAizACAQAAAMAijEAAAAAAsAgjEAAAAAAswggEAAAAAIswAgEAAADAIoxAAAAAALAIIxAAAAAALMIIBAAAAACLMAIBAAAAwCKMQAAAAACwCCMQAAAAACzCCAQAAAAAizACAQAAAMAijEAAAAAAsAgjEAAAAAAswggEAAAAAIswAgEAAADAIoxAAAAAALCIj+kAruZ0OiVJN95Y2XCSolWpEmw6QiHnL1Q3HaFY1au7X7bgYPe8bknuma18+SDTEYp1440VTUcoUsWKAaYjFMndcgUFlZf06+0+Lu/S5ZSTnW04SfGys7JMRyjA3a7z/83d8oWEuF8H/Za75fPzyzMd4bJCQ0NMRygkOzvTdIRihYZWMR2hgODgGyUV35FezjLWnr/88osOHjxoOgYAoJTUq1dPQUHue2eDu6AfAcA+xXVkmRuBeXl5Sk9Pl6+vr7y8vEzHAQCUEKfTqezsbAUEBMjh4NkNv4d+BAB7/F5HlrkRCAAAAAAoHnedAgAAAIBFGIEAAAAAYBFGIAAAAABYhBEIAAAAABb5fy6ne/BvRKpIAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x1800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_count 1    self.capacity  20\n",
      "0  ------------------------------------------------\n",
      "DecoderLayer@trg4\n",
      "[1, 1, 64]\n",
      "tensor([[[-1.3310,  0.3143, -0.5670, -0.0079,  0.4881,  1.6575, -0.5386,\n",
      "           0.0704, -0.8225,  0.4714, -0.4300, -0.8002, -0.5819, -2.5604,\n",
      "           1.2567, -1.3654,  1.3762,  1.1168, -0.8291,  0.2423, -0.0643,\n",
      "          -0.1705, -0.0619,  0.7693,  0.1967, -0.1704, -0.4825,  0.3635,\n",
      "           0.1540,  0.6834,  0.6824, -0.0164,  0.4630, -0.1279, -0.4207,\n",
      "           0.2560, -0.0357, -0.1932,  0.6555, -0.0621, -0.2576,  1.3966,\n",
      "          -0.4933, -1.2610,  0.8514,  1.2433,  2.4091, -1.4521, -0.1000,\n",
      "          -0.1553,  0.0834,  1.1929,  1.6449, -0.8260, -1.7430,  1.2176,\n",
      "          -0.1580, -1.8651,  0.7478, -0.6603, -2.2274,  0.3502, -1.6665,\n",
      "           2.1667]]])\n",
      "src = ['we', 'eat', 'bread']\n",
      "predicted trg = ['wir', 'essen', 'apfel', '<eos>']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_count 1    self.capacity  20\n",
      "0  ------------------------------------------------\n",
      "DecoderLayer@trg4\n",
      "[1, 1, 64]\n",
      "tensor([[[-1.7160,  0.6839, -0.5133, -0.6894,  1.2650,  1.6201, -0.0398,\n",
      "           0.3235, -1.2411, -0.4238, -0.5122, -0.6255, -0.6987, -1.8270,\n",
      "           0.6128, -1.9661,  1.0564,  1.2961, -1.3181,  0.6329, -0.6641,\n",
      "          -0.4068,  0.3026,  1.3534,  0.3841,  0.0839, -0.0686,  1.1745,\n",
      "          -0.3384,  1.0658,  0.0299, -0.1080, -0.2551, -0.8864, -0.5767,\n",
      "           0.0166,  0.2741,  0.0467,  0.2193,  0.8524, -0.3110,  1.7588,\n",
      "          -0.6589, -1.0755,  0.1084,  1.4065,  2.2417, -1.1178, -0.2899,\n",
      "          -0.6597, -0.1087,  0.7052,  1.1540, -0.3673, -1.5123,  1.6168,\n",
      "          -0.5218, -1.3229,  1.2042, -0.3313, -0.5636,  0.2443, -2.0936,\n",
      "           2.1168]]])\n",
      "src = ['we', 'eat', 'apple']\n",
      "predicted trg = ['wir', 'essen', 'apfel', '<eos>']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_count 1    self.capacity  20\n",
      "0  ------------------------------------------------\n",
      "DecoderLayer@trg4\n",
      "[1, 1, 64]\n",
      "tensor([[[-1.9206,  0.7174, -0.6296, -0.6984,  1.2312,  1.7303, -0.0038,\n",
      "           0.2943, -1.2200, -0.3046, -0.6290, -0.7564, -0.5861, -1.6422,\n",
      "           0.7732, -1.7469,  0.9116,  1.5835, -1.1929,  0.6606, -0.5230,\n",
      "          -0.3832,  0.4536,  1.2303,  0.4502,  0.2378, -0.2841,  1.1667,\n",
      "          -0.2385,  1.0763,  0.2590, -0.0058, -0.1274, -0.8938, -0.7595,\n",
      "          -0.1759,  0.1422,  0.3338,  0.3352,  0.8168, -0.4025,  1.7949,\n",
      "          -0.6869, -1.2357, -0.0265,  1.3360,  2.2348, -1.0170, -0.2630,\n",
      "          -0.8035, -0.2490,  0.6393,  0.9399, -0.4114, -1.4819,  1.4186,\n",
      "          -0.3720, -1.3911,  1.2213, -0.1470, -0.8142,  0.3291, -2.2291,\n",
      "           1.9818]]])\n",
      "src = ['we', 'drink', 'water']\n",
      "predicted trg = ['wir', 'trinken', 'bier', '<eos>']\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA34AAAFkCAYAAAB/++nAAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAq40lEQVR4nO3df3zO9eL/8ee1X+bHUGOjlVCJE5Wpk3AO+ZHolzolnX6QdEOdVD6d0OlwO4hhh5QoIrMwrTFZfiXiGLHNV+icw6HV6czajBbbmP24vn/0sQ/nusY2217vvfa4/6X9fG69937ueV3v65rL7Xa7BQAAAACwlo/pAAAAAACAqsXwAwAAAADLMfwAAAAAwHIMPwAAAACwHMMPAAAAACzH8AMAAAAAyzH8AAAAAMByDD8AAAAAsBzDDwBQIcXFxRf8t9vtNpQEAADncGo/MvwMOXdAFBYWGk4CABXj4+OjnJwc7d+/X5LkcrkMJ4It6EgANZlT+5HhZ8iZM2d09OhRRUREaM+ePabjALXS+bfA5ebmGkxS8yQnJ2vTpk0aPny4pk+frkOHDpmOBIvQkYB5dGTFOLkf/UwHqI1iY2N1+PBhpaena+PGjQoODlZ4eLjpWECt4na7S26BW7p0qSRp4MCB8vf3NxnL8ZKSkvTVV19p+/bt6tevn4qKihQSEqI2bdqYjgZL0JGAeXRk+dWEfmT4VaOvvvpKW7du1e7du/Xqq68qIyNDDRs21ODBg01HA2qdc4W2adMmbdmyRW+++SaFVgaHDh3Szz//rBkzZqhFixYqLCzUTTfdJOmXy/N8fLiQBBVDRwLOQUeWX03oR4ZfNWrTpo0CAgI0bNgwBQcHa82aNWrYsKH8/Pwcc0CgZjp3Oca5E3VhYaH8/PjxvpiioiL99NNPGj9+vFq2bCmXy8XPYRk88cQTJf9OSkrSunXr1KNHD0nie4fLQkeiKtCPFUNHll9N6EdnpKgFUlNTdebMGYWHhys4OFipqalasGCBunTpooCAAMccEKiZ8vLyLrgk47333nPMM0g5yfnfE5fLpSZNmig6OlrZ2dmKiYnR2bNnDaZztri4OM2ZM0dffPGFpF8e7xEfH69Bgwbp+uuvN5wONR0diapCP5YdHVkxNakfOZNWg+joaI0fP15z5sxRRkaGJOnYsWPq2bOnunXrxgkIlyU1NVWjR48ueeaorKwstWrVSi6XS0VFRZI8n1a4Njr/8QqxsbGaNGmSJk+erKysLM2ePVtr1qzRhx9+qNOnTxtO6jyLFy9WfHy8QkNDFRYWptOnT6tevXrq3LmzQkJCTMdDDUdHoqrQj2VHR1ZMTetH7uuuYnFxcVq3bp3mzJmjzMxMpaWladu2berVq1fJD49TnuIVNdPZs2d19dVX67333tMrr7yiwMBApaamKi8vT/Xq1ZPknEsMTDr3c/bRRx9pw4YNGjVqlCZNmqScnBxFRETo3Xff1VNPPaWAgAA9++yzhtM6R3p6urZu3aro6Gjt2bNHW7Zs0aZNm9S4cWN98MEHnL9wWehIVCX6sezoyPKrif3ocnNTWpV6//331bx5c+Xl5enrr7/WsWPHtH37do0fP16///3vTcdDDXb+rXOHDx9WbGys0tLSdOTIEQUHBystLU3h4eGqX7++fvvb36p3796GE5tx+vRp1a1bV5KUkZGhyZMnKyIiQgkJCfryyy81ffp0LVq0SM8884y+++47NWrUSNdee63h1M5x9OhRDRgwQLfeeqtOnDihHj16qGPHjvr44481duxYNW/e/IJjESgPOhJVgX4sOzqy4mpiP3KPXxULDg5WTEyM8vPz9fzzz6tXr1765JNPdOLECccdDKg5zj92Tp48qVatWmno0KGKiopSUlKShg8frlatWik1NVVffvmlbrzxRsOJzUhLS1NiYqLuuecenT17VkFBQQoNDdWYMWN0+vRpLViwQLm5udq2bZsef/xx3XzzzaYjO8bf//531alTR02bNtWSJUu0b98+3Xnnnbrmmmu0adMm/fDDDwoMDJTEPTKoODoSlY1+LDs6smJqcj8y/KrAqlWrlJqaqszMTP3hD39Q//79VbduXWVlZSkuLk4fffSR/vrXvzruYEDNcH6pLVq0SFu2bNHJkyc1e/ZsDR48WDk5OUpISNAf//hHDRgwQAMGDDAb2KDTp09r8+bN2rhxo6666ir9z//8j/Ly8pSamqp3331XPj4+2rlzp/z8/HiWt/NERUVp3bp1atSokY4ePapnnnlGAwcO1Lhx4+Tr66s9e/Zo9uzZuuKKK0xHRQ1ER6Kq0I/lQ0eWX03vRy71rGSLFy/WunXr9MQTT2jHjh3avn27Zs6cqezsbC1ZskRFRUWaOHGibrjhBtNRHY1bei8tJSVFs2bN0uuvv66YmBht2LBBy5YtU4MGDfTuu+8qJydHU6ZMqZXPiHf+8TN//nzNmzev5MSckZGhV199VXXq1JHL5VJmZqamTZumtm3bGk7tDJs2bdLcuXMVHR2t/Px8HThwQG+88YamTp0qHx8fnThxQh06dFCLFi1MR0UNREdWDjry4ujHi6MjK8aGfmT4VaLMzEyNGTNGs2bNUuPGjSVJb7/9thISErRx40bl5ubK5XKVPKAYKI9vv/1WPj4+atmypWJjY7Vq1Sq9+OKLuvPOOyVJU6dOVUJCgj788EM1atRIvr6+atKkieHU1e+/fyE6ePCg0tLStGTJEoWHh2vEiBFyu93as2ePioqK1Lp1a1111VUGEztLVFSU0tPTNXbsWBUUFMjPz08TJkxQixYtNGzYMNPxUIPRkagq9GPZ0ZEVZ0M/cr9tJXK73crMzFRqaqo6duwoSRo8eLD279+vnJwcNWjQwHBC51u1alXJCbxz584lJ+3aLjs7W/Hx8Ro6dKgKCwvVoUMHTZgwQevWrSv5Ho0bN055eXkaOXKk1q1bp4CAAMOpq9/5hbZixQr9/e9/V5cuXdS3b18FBQXprbfeUlBQkBo3bqywsDCOLy8aNGigrKwsnTx5Ug0bNpQkBQQEKD8/XxL3NKDi6MjLR0d6oh/Ljo68PDb0Y+27f7sK7Nu3T2lpaWrcuLG6du2q3bt368iRI5KkzZs36+TJk/ydmDKIiopSXFycOnXqpA0bNmjjxo38sVD9ciJp3LixRo8eraNHj2rq1KkKDQ3VypUrtXLlSs2fP7/kbSdNmqQVK1bU2lI7d8JdtmyZVqxYoaCgIE2bNk3Lli3T7bffrlGjRiklJUVRUVEKDQ01nNY51qxZo9jYWC1dulS33HKLvv32Wy1cuFDr16/X6tWrtX37dvXv31+S8x6oDuejIysHHemJfiwfOrL8bOtHLvW8TIsXL9b69esVFhamv/zlL0pKStLmzZv1zTffqH379kpKStLbb7/N4xUu4ZtvvtHChQs1Y8YMrVixQomJiYqIiNCyZct07733KiwsrEb8QFWFoqIi+fr6asOGDdq7d6/S0tJ09dVXa8SIEfrhhx/05JNP6plnntGoUaMk1YxbnKpSYmKi5s2bp/nz5+vgwYOKiIhQvXr11LdvXz3wwAPy9fVVfn5+ya11td3ixYu1ceNGjRw5Us8995zmzp2rsLAwRUdHKzc3V0VFRfrDH/6gNm3amI6KGoiOrBx0pHf0Y/nRkWVnYz8y/CqoqKhIn3/+uZYuXaro6Gjt3btXZ86cUUZGhvz9/XXFFVfo559/Vvv27XX11VebjutoycnJ2rt3r06ePKnvvvtOOTk5WrBggdLT0zV69GhFRUWV/I2Z2uQf//iHQkNDdeWVV2rt2rVauHCh4uLitHfvXi1ZskQhISF64YUXlJqaqhEjRuizzz5z7LNIVZe9e/dq+/btcrvd6t69u7744gs9/PDD+vjjj7Vq1So9+uijeuGFF2r1Lb7n5OfnKy0tTZMnT9aCBQv00Ucf6auvvtL48eO1d+9e9evXT5Iu+EPHQFnRkZWHjvREP1YMHVk2Nvcjj/GrgJSUFAUGBiojI0M33HCD4uLilJiYqGPHjqm4uFh9+vQpudsXpTt3y9s333yjmJgY3XLLLTpx4oSmTZsmX19f7du3T35+fjp79mytK7VTp05pyZIlOn78uAYOHKg1a9aU3CJ+6623Kj8/X7GxsZoxY4Zee+01ffnll7XyRF1cXCwfH5+SY2nfvn2Kjo7W/Pnzdfr0aeXk5Ojaa69Vq1atFB4erieeeKJWfp/+2549e+R2u1W/fn0FBQVp7ty52rdvn+bOnau0tDS9/fbb6tmzp+rUqVPjSg3m0ZGVg470jn4sOzqy/GzvR4ZfBaxbt06tWrVS69attW3bNh06dEjDhg1Tjx49tHDhQn3//fc6d0dqbb+k4GJ2796tO+64Q4MHD9aPP/6ovXv3Kj8/X9OmTZMkpaamKjIyUo0aNTKctPoFBQVp2LBh+uCDDxQdHa1mzZopPz9fn332me69917dcccdKigo0Lp165Sfn19rnxTh3NNwnzuWnn76aR05ckRr165Vdna2goODtXbtWi1btkyRkZEKCQkxnNgZ1q5dq1atWunBBx/U8ePHdfjwYcXHx8vf31+JiYm66qqrauVTnKNy0JGVg470jn4sOzqy/GzvRy71LKetW7dq+vTpWrJkiYKDg3X27FkFBAQoMTFRx48f14cffqjIyEhdd911pqM62g8//KA+ffqoR48eevDBBxUQEKCffvpJLVq00KlTp3Tq1CnddttttfoSoNjYWG3dulX/+c9/1LhxYwUHByskJEQdO3bU3XffLemXP75am27p9eb8Y2nAgAGqU6eO0tPTVa9ePS1dulR169bVuHHj1K5dO9NRHeHcOeyDDz5Q8+bNFRMTo127dunkyZPq2LGjPv/8c0VGRvKYK1QIHVk56MiLox/Ljo4su9rQj9zjV0bn7i7PysrS0KFDFRwcrK+//lopKSny8/NTSkqKcnJyNG3aNAqtDJo2barf/e53+ve//62MjAx98sknOnPmjIYPH65HH33UdDzjVq9erSVLluidd97RN998oyNHjuirr76Sv7+/tm/fLl9fX/Xq1UuBgYGmoxp3/rH0448/Ki4uTnl5eRozZoxiY2Mp///13+ew5s2b6+DBg8rKylL//v114MABNWrUSDNnzuQchnKjIysXHVk6+rF86MhLq039yPArIx8fH2VnZ2vNmjVq0qSJTp8+rejoaD3yyCNq166dnn766Rr5IM/qlpCQoKKiInXu3FnPPfechg0bpptuuklXXnmlJk2apJUrV6pfv36qX79+rb4E6NChQ3rggQfUsmVLhYWF6ciRIzpw4IAOHz6sdu3a6dZbb5VUuy+TutixNHHiRC1atEjdunXjZ/J/eTuHRUVF6eGHH1aTJk30yiuvmI6IGoyOrBx05KXRj2VDR5ZdbepHhl8Zud1u7d+/XwcPHlRwcLCuvPJKRUZGqkOHDiVvU9tvMSmLZs2alTx71JAhQzR8+HAlJibq5ZdfVsuWLdWsWbNafT3+OS1atNCWLVvUu3dvtWrVSm3btlWjRo0UEhKiESNGKDg42HRE4y51LIWGhlJo5/F2Dps5c+YF5zCgoujIykFHXhr9WDZ0ZNnVpn7kMX7lUFBQoH379ik8PLzW35J0OfLy8rR7927NmDFDzZs31z//+U/FxMTU2scqeJORkaHp06erWbNm6ty5s/Ly8hQVFaVZs2bxR1XPw7FUPpzDUJU4vioH57WLox/LjmOp7GrL+YvhV0Hn/mgoKi4jI0PJyclaunSpIiIi1KJFC9ORHOW7775TbGysvv76a9WpU0d//OMf1bZtW9OxHIljqfw4h6EqcXxdPs5rpaMfy4djqXxsPn8x/GCczT9gl8vtduvMmTNyu91cklEGHEsAbMN5zTv6sfw4lsDwAwAAAADL1dy/QAgAAAAAKBOGHwAAAABYjuEHAAAAAJZj+AEAAACA5Rh+AAAAAGA5hh8AAAAAWM7PdIDKUFxcrNzcXPn7+8vlcpmOAwCoQm63WwUFBapfv758fLj98lLoSACoHS7Vj1YMv9zcXB06dMh0DABANWrTpo2CgoJMx3A8OhIAapfS+tGK4efv7y9JGjt2go4fP2E4zYUWLHhHzz33oukYHq655lemI3g1fvxITZw4z3QMD4cOJZmO4NVHHy3Sk08ONR3Dw7XXtjcdoVRvvjlaf/rTTNMxPPR8+F7TEbzq1elGfZFy0HSMCwQG+Klrh+tKzv24uHPfp/nz43XyZK7hNBd69dUnFBm51HQMDwcO/M10BK8WL35PQ4aMMB3Dw+nTJ01H8GrFimV67LHfm47hweVy5pUKMTEfadCgJ03H8GpO7HLTETw0KSpSlq+v6RgX8HG7dWVxcan9aMXwO3fpyvHjJ5SZmWU4jScnZqpf/2fTEUp14oTzsmVkZJqOUConZgsKyjYd4aJOnMg2HcHD6fwC0xFK5dRsXLZYNue+TydP5io7O8dwGk9OzJSZecx0hFI5MVtubrbpCKX68ccM0xE8OHX4Sc78fklSsUPP907NVVo/OvfIAwAAAABUCoYfAAAAAFiO4QcAAAAAlmP4AQAAAIDlGH4AAAAAYDmGHwAAAABYjuEHAAAAAJZj+AEAAACA5Rh+AAAAAGA5hh8AAAAAWI7hBwAAAACWY/gBAAAAgOUYfgAAAABgOYYfAAAAAFiO4QcAAAAAlmP4AQAAAIDlGH4AAAAAYDmGHwAAAABYjuEHAAAAAJZj+AEAAACA5Rh+AAAAAGA5hh8AAAAAWI7hBwAAAACWY/gBAAAAgOUYfgAAAABgOYYfAAAAAFiO4QcAAAAAlmP4AQAAAIDlGH4AAAAAYDmGHwAAAABYjuEHAAAAAJZj+AEAAACA5Rw3/GbPnq34+HjTMQAAcBw6EgBQUX6mA/y3l156yXQEAAAciY4EAFRUtd/j9+CDD2rnzp2SpISEBHXo0EFnzpyRJP3pT39Sly5dtHDhQklS+/bt9dJLL6lv377av39/dUcFAKBa0ZEAgKpS7ff49enTR9u2bdOdd96pv/3tb2rUqJGSk5PVtWtXbd26Ve3atSt524KCAt11112aPXt2mT72ggXvVFXsy7J69XLTEWqUt94aazpCjfL55wmmI9Q48+ZNNB2hRrmvS3vTEWqNquzIV199oqpiX5bJk4ebjuCFEzP9Yu3aONMRapStW78wHaFG+fLLz01H8K6w0HQCr0Icmqs0Robf6NGj9dprryk5OVlDhgxRYmKi6tevrxYtWqhp06YXvP1tt91W5o/93HMvKjMzq7IjX5bVq5frwQcfNx3DQ6tWt5iO4NVbb43Vyy9HmI7h4ZtvtpuO4NXnnyeoT5/7TMfwcP314aYjlGrevIkaOXK86Rge7n1qoOkIXt3Xpb0SdhwwHeMCdev4q1enG03HqBJV2ZGRkUuVnZ1T2ZEvy+TJw/XGG++bjuFhz56NpiN4tXZtnPr3/53pGB5yc7NNR/Bq69Yv1L17L9MxPLhcjnuKDUm/jL4ePfqYjuHVx9u3mI7gIaSwUJl+znrUnI/brSZFRaW/vhqzSJJuvPFGFRQU6IsvvlDLli111113KTExUZs3b1bfvn093r5evXrVHREAACPoSABAVTFyk0Pv3r3117/+VV27dtV1112nnJwcrVmzRnfffbeJOAAAOAYdCQCoCkaGX58+ffTtt9+qS5cukqQuXbqoadOmat68uYk4AAA4Bh0JAKgKRi5M7dixow4ePFjy35MnTy75d0TE/z2+6/y3AQCgNqAjAQBVwZmPLgUAAAAAVBqGHwAAAABYjuEHAAAAAJZj+AEAAACA5Rh+AAAAAGA5hh8AAAAAWI7hBwAAAACWY/gBAAAAgOUYfgAAAABgOYYfAAAAAFiO4QcAAAAAlmP4AQAAAIDlGH4AAAAAYDmGHwAAAABYjuEHAAAAAJZj+AEAAACA5Rh+AAAAAGA5hh8AAAAAWI7hBwAAAACWY/gBAAAAgOUYfgAAAABgOYYfAAAAAFiO4QcAAAAAlmP4AQAAAIDlGH4AAAAAYDmGHwAAAABYjuEHAAAAAJZj+AEAAACA5Rh+AAAAAGA5hh8AAAAAWI7hBwAAAACWY/gBAAAAgOX8TAeoTMePp+vYsR9Nx/Bw7NgPpiN4CAioazpCqdLSDpmO4GHxps9MR/DO7XZktlcHDTcd4aKyszNNR/Dw0dvvmI7g1X1d3ndctqZNg9Wr0xTTMWqcrVtjlJ6ebjrGBSZPHq716xeYjuHB5XLu7eJO/J0iPLyP6Qilatu2s+kIHpKT15uO4FVKSopOnTphOoZXTZteYzqCh/Xr4/V07/tMx7hAaGiIoqLml/p6557ZAAAAAACVguEHAAAAAJZj+AEAAACA5Rh+AAAAAGA5hh8AAAAAWI7hBwAAAACWY/gBAAAAgOUYfgAAAABgOYYfAAAAAFiO4QcAAAAAlmP4AQAAAIDlGH4AAAAAYDmGHwAAAABYjuEHAAAAAJZj+AEAAACA5Rh+AAAAAGA5hh8AAAAAWI7hBwAAAACWY/gBAAAAgOUYfgAAAABgOYYfAAAAAFiO4QcAAAAAlmP4AQAAAIDlGH4AAAAAYDmGHwAAAABYjuEHAAAAAJZj+AEAAACA5Rh+AAAAAGA5hh8AAAAAWI7hBwAAAACWY/gBAAAAgOUYfgAAAABgOYYfAAAAAFiO4QcAAAAAlrvk8Bs6dKhOnDjh8fLnnntOhw8fvuj7jh07VgsXLqx4OgAAHIyOBADUFH6XeoPExESvL1+wYEGlhwEAoCahIwEANcVFh9+4ceMkSYMHD9bhw4fVt29fHTx4UKNHj9bUqVM1e/Zs5eXladasWbrmmmv0r3/9S4WFhfrLX/6iTp06XfCxpkyZooMHD2ru3Lny9/dXZGSkkpKSVFRUpF/96ld644031KBBA/Xs2VMPPfSQdu7cqfT0dD344IN6+eWXq+wbAABARdCRAICa5KKXek6dOlWSFBUVpebNm+uGG27QunXr1KdPnwvebt++fRo6dKji4+P18MMPa9asWSWvc7vdmjhxoo4ePaoFCxaofv36mj9/vnx9fbVy5Up9+umnCgkJUWRkZMn75OXladmyZYqJidGiRYv0ww8/VObXDADAZaMjAQA1ySUv9Tzfbbfd5vXlV111ldq1aydJ+tWvfqVVq1aVvG7x4sU6fvy44uPjFRAQIEn68ssvderUKe3YsUOSVFBQoODg4JL36dWrlyQpNDRUwcHB+vnnn3XNNddcMt/KlZ+U58upNjt2bDcdoUaJjV1kOoInt9t0glKFOTDb8uXvmY5wUU7P5zQxMe+bjlAjOL0j16xZU7EvrIolJyebjlCjJCXtNh2hRnn//TdNR/CQkpJiOkKpnJpt/fp40xG8cmqu0pRr+NWrV8/rywMDA0v+7XK55D7vF9Hbb79d4eHhGjdunFasWCF/f38VFxfr9ddfV/fu3SVJubm5ys/PL3mfOnXqlPrxLubhhx/Rjz/+WJ4vqcrt2LFdXbp0Mx3DQ1hYG9MRvIqNXaRHHx1qOoaHtz750HQEr8LcbqW5XKZjeHh10HDTEUq1fPl7evzxEaZjeCjrea66xcS8r0EO+//ZtGmw3nlniukYHpzekffff7/S09PL9TVVteTk5FIHs0kulzOf9Dwpabduv/3XpmN4CA/vc+k3MuD999/U8OF/Mh3DQ3LyetMRvEpJSfG4DN0pmja99I1b1W39+njdc88A0zEuEBoaoqio+aW+/pJnNl9fXxUWFlY4QPv27fXkk08qKChIc+bMkSR169ZNS5cu1dmzZ1VcXKw///nPmjlzZoU/BwAAJtCRAICa4pLD75577tFTTz2l3NzcCn8Sl8ulKVOmaNmyZdqzZ4+ef/55hYWF6aGHHlL//v3ldrs1duzYCn98AABMoCMBADXFJS/1LO1Wxs2bN5f8OyEhoeTfd9xxR8l/R0RElLw8LCxMSUlJJf89YcKES35cb/8NAIBT0JEAgJrCmRexAwAAAAAqDcMPAAAAACzH8AMAAAAAyzH8AAAAAMByDD8AAAAAsBzDDwAAAAAsx/ADAAAAAMsx/AAAAADAcgw/AAAAALAcww8AAAAALMfwAwAAAADLMfwAAAAAwHIMPwAAAACwHMMPAAAAACzH8AMAAAAAyzH8AAAAAMByDD8AAAAAsBzDDwAAAAAsx/ADAAAAAMsx/AAAAADAcgw/AAAAALAcww8AAAAALMfwAwAAAADLMfwAAAAAwHIMPwAAAACwHMMPAAAAACzH8AMAAAAAyzH8AAAAAMByDD8AAAAAsBzDDwAAAAAsx/ADAAAAAMsx/AAAAADAcn6mA1Sm+atXqdjlMh3jQoWFit/9lekUHh7t2t10hFJlZn5vOoKHx39zl+kIXm3bttmR2dq3/43pCBd1xRWhpiN4yMr6j+kIpSouLjQd4QJOy1NT3HXX75WdnWM6hof+/YebjuBhyrzXTUfwqvDYMf2/71JNx/DQs2Nn0xFKlZq6z3QED76+zvz1e/fuXY7N5u9fx3QEr06dOmE6wgXq1w+46Ou5xw8AAAAALMfwAwAAAADLMfwAAAAAwHIMPwAAAACwHMMPAAAAACzH8AMAAAAAyzH8AAAAAMByDD8AAAAAsBzDDwAAAAAsx/ADAAAAAMsx/AAAAADAcgw/AAAAALAcww8AAAAALMfwAwAAAADLMfwAAAAAwHIMPwAAAACwHMMPAAAAACzH8AMAAAAAyzH8AAAAAMByDD8AAAAAsBzDDwAAAAAsx/ADAAAAAMsx/AAAAADAcgw/AAAAALAcww8AAAAALMfwAwAAAADLMfwAAAAAwHIMPwAAAACwHMMPAAAAACzH8AMAAAAAyzH8AAAAAMByDD8AAAAAsBzDDwAAAAAsx/ADAAAAAMtV+fDbtWuX7rvvPo+Xz549W/Hx8VX96QEAcCT6EQBQnfxMfeKXXnrJ1KcGAMCx6EcAQFWoluGXl5enUaNG6fvvv1fDhg01ceJEvf/++7rhhhv07LPP6siRI3rzzTeVnZ2toqIiPfXUU3rkkUe0a9cuvfnmm6pXr55yc3MVFxengICA6ogMAECVox8BANWlWoZfenq6IiMjFR4erhUrVui1117TddddJ0kqLCzUqFGjNH36dN100006deqUHnvsMV1//fWSpH/961/atGmTwsLCqiMqAADVhn4EAFQXl9vtdlflJ9i1a5emTp1a8niFs2fP6pZbblHPnj0VHh6u7t2766GHHlLr1q1L3ufUqVMaNmyYrrvuOo0bN06bN2++6OfIz8/XgQMHqvLLAAA4TPv27VWnTh3TMSqsOvpRoiMBoLYprR+r5R4/H58Ln0PG5XLJz++XT11UVKSgoCCtXr265PVZWVkKCgrS3r17Va9evTJ/nixfXxW7XJUTupKEFBYq08/YQylL9WjX7qYjeLV16xfq3r2X6Rgeqvj2kQrbtm2zfvvbnqZjeGjf/jemI5Rq7ty/6PnnJ5iO4SEr6z+mI3j18ccLNXDgs6ZjXKBp02C9++500zEqRXX1oyTNnLlc2dk5lx+6Ek2c+JzGj19gOoaHKfNeNx3Bq8Jjx+TXtKnpGB56duxsOoJXGzeu0d133286hofs7EzTEbzavXuXfv3rO0zH8Mrf33k38iUmblPXrr81HeMCzZo1U1zcx6W+vlr+nMPBgwf1j3/8Q5K0YsUKderUSXXr1pUktWrVSoGBgSXFlp6ervvuu49bJwEA1qMfAQDVpVqGX+vWrTVnzhw98MAD2rx5syIiIkpeFxAQoLlz5+qTTz7R/fffr6FDh+qll15Sp06dqiMaAADG0I8AgOpS5dcg3nHHHVqzZo3Hy88vt7Zt2yo6Otrr+yYkJFRpPgAATKAfAQDVqVru8QMAAAAAmMPwAwAAAADLMfwAAAAAwHIMPwAAAACwHMMPAAAAACzH8AMAAAAAyzH8AAAAAMByDD8AAAAAsBzDDwAAAAAsx/ADAAAAAMsx/AAAAADAcgw/AAAAALAcww8AAAAALMfwAwAAAADLMfwAAAAAwHIMPwAAAACwHMMPAAAAACzH8AMAAAAAyzH8AAAAAMByDD8AAAAAsBzDDwAAAAAsx/ADAAAAAMsx/AAAAADAcgw/AAAAALAcww8AAAAALMfwAwAAAADLMfwAAAAAwHIMPwAAAACwHMMPAAAAACzH8AMAAAAAyzH8AAAAAMByDD8AAAAAsBzDDwAAAAAs52c6QGUa+8zzysw8ZjrGBT79NEbD+j9iOoaH3NyfTUcolROzuVzOvY3k9Okc0xE8/PRThukIF+XEfEeO7DUdwauUlBTHZcvPz9eBAwdMx6hxbv5tR53OLzAdw8PtfTubjuBh2669piN41aV1mCOzFRacNR2hVE7M5ufnbzpCqZya7ezZM6YjeOW0XAUF+Rd9vXN/mwUAAAAAVAqGHwAAAABYjuEHAAAAAJZj+AEAAACA5Rh+AAAAAGA5hh8AAAAAWI7hBwAAAACWY/gBAAAAgOUYfgAAAABgOYYfAAAAAFiO4QcAAAAAlmP4AQAAAIDlGH4AAAAAYDmGHwAAAABYjuEHAAAAAJZj+AEAAACA5Rh+AAAAAGA5hh8AAAAAWI7hBwAAAACWY/gBAAAAgOUYfgAAAABgOYYfAAAAAFiO4QcAAAAAlmP4AQAAAIDlGH4AAAAAYDmGHwAAAABYjuEHAAAAAJZj+AEAAACA5Rh+AAAAAGA5hh8AAAAAWI7hBwAAAACWY/gBAAAAgOUYfgAAAABgOYYfAAAAAFiuwsMvJydHy5Yt0759+yozj2bMmKHvv/++Uj8mAADViY4EADiNX3nf4euvv9aKFSu0c+dO9erVS71799bmzZs1b948FRQUKDAwUGPGjFHHjh1VUFCgiIgI7dy5U76+vrr55ps1btw4NWjQQMuWLVNMTIz8/f1Vp04dTZw4Uddff72aNGmiF154QcHBwXrsscfUu3dvBQQEVMXXDgBApaIjAQBOVeZ7/Pbv368BAwZo9uzZ6tatmzZs2KA33nhDeXl5mjVrlubPn6/4+HhNmjRJL774ovLy8jRv3jxlZmZq9erVWr16tYqLizV9+nQVFRVpypQp+uCDDxQXF6eBAwcqJSVFkvTMM88oISFBL7/8srZv365+/fpp6dKlVfYNAADgctGRAACnK/M9fj4+PvLx8ZHL5ZLL5Sp5eWJiojIzMzVkyJCSl7lcLv373//Wtm3b9Morr8jf31+S9NRTT+mFF16Qr6+v7rnnHg0aNEg9evRQt27d1L179ws+n6+vb8nn9PEp2z794IN3yvrlVKtPP40xHaFGSU5ONh2hRklK2m06Qo2zfPl7piN4OPeLvRM5OZtT1ISO7H1b28v/QqvA/V07mI5Qo3RpHWY6gofNWzaYjlAqJ2dzoh07tpuOUKPUtN/Byjz8brrpJq1cuVL79u1TTEyMZsyYobvvvlsNGjTQnXfeqbfeeqvkbdPT0xUSEqLi4uILCrC4uFgFBQWSpMjISB06dEg7duzQ/PnztXr1as2ePVtLlizRJ598osaNG2vQoEGaMGFCSSleyrBhLyoz81hZv6Rq8emnMXrggUGmY3g4evSw6QheJScn67bbbjMdw4PL5cznQUpK2q3bb/+16Rgerr8+3HSEUi1f/p4ef3yE6RgeDh1KMh3Bq5SUFHXq1Ml0jAvk5+frwIEDpmNcoCZ05Kbkf+p0fkGlft2X6/6uHbQmcb/pGB6Cm19pOoJXXVqHace3aaZjeHjj2aGmI3i1ecsG9byrr+kYHs7k55qO4NWOHdvVpUs30zG8Kig4azqCByf+Dta8eXN9+unqUl9f7t9mb775Zk2ZMkWrV6/W1VdfrV//+tdKTEzUkSNHJElbt27VAw88oDNnzug3v/mNli9froKCAhUXF2vp0qXq2rWrTpw4oe7du6tx48YaMmSIXn75Ze3f/8uJPz09vaTc+vfvX+ZCAwDANDoSAOBU5X5yl3OCgoL05JNPSpImTpyo0aNHy+12y8/PT/PmzVP9+vU1cuRITZs2TQMGDFBhYaFuvvlm/fnPf1bDhg01cuRIDRkyRIGBgfL19dXkyZMlSWPGjKmcrwwAAEPoSACA01R4+J2vX79+6tevn8fLAwMDNWHCBK/vM2jQIA0a5LxLIAEAqEx0JADACZz5wCUAAAAAQKVh+AEAAACA5Rh+AAAAAGA5hh8AAAAAWI7hBwAAAACWY/gBAAAAgOUYfgAAAABgOYYfAAAAAFiO4QcAAAAAlmP4AQAAAIDlGH4AAAAAYDmGHwAAAABYjuEHAAAAAJZj+AEAAACA5Rh+AAAAAGA5hh8AAAAAWI7hBwAAAACWY/gBAAAAgOUYfgAAAABgOYYfAAAAAFiO4QcAAAAAlmP4AQAAAIDlGH4AAAAAYDmGHwAAAABYjuEHAAAAAJZj+AEAAACA5Rh+AAAAAGA5hh8AAAAAWI7hBwAAAACWY/gBAAAAgOUYfgAAAABgOYYfAAAAAFjOz3SAyuB2uyVJwcFXGk7iXUhIU9MRPLjduaYjlKp58+amI3hwuZx7G4kTv19NmgSbjnBRTsyXn59vOkKpnJbt7Nmzkv7v3I+LO/d9CgzwN5zEu7p1nJerjp+v6QilcmK20NBQ0xFK5cRs+WfzTEcoVbNmzUxH8KqwsMB0BK+c9jtYSEiIpNL70eW2oDlPnTqlQ4cOmY4BAKhGbdq0UVBQkOkYjkdHAkDtUlo/WjH8iouLlZubK39/f7lcLtNxAABVyO12q6CgQPXr15ePj3PvjXcKOhIAaodL9aMVww8AAAAAUDpuKgUAAAAAyzH8AAAAAMByDD8AAAAAsBzDDwAAAAAs9/8BAXg9F9+My0AAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 1080x1800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_count 1    self.capacity  20\n",
      "0  ------------------------------------------------\n",
      "DecoderLayer@trg4\n",
      "[1, 1, 64]\n",
      "tensor([[[-1.1483,  0.4610, -0.3890, -1.3613,  1.2036,  1.9240, -0.1139,\n",
      "           0.7863, -1.2242, -0.5376,  0.6498, -0.3335, -0.7967, -1.8895,\n",
      "           0.4162, -1.1006,  1.7219,  0.9264, -1.1573,  0.2508, -0.4497,\n",
      "          -0.3315, -0.1035,  0.9860,  0.6157, -0.5163, -0.1599,  0.7111,\n",
      "          -0.7995,  0.9364, -0.2729,  0.0451, -0.0962, -0.8918, -0.3937,\n",
      "           0.2016,  0.3648, -0.7840,  0.3961,  0.4489, -0.3592,  1.4004,\n",
      "          -0.7241, -1.4660,  0.3985,  1.5299,  2.4945, -1.0878, -0.1903,\n",
      "          -0.3420, -0.0834,  0.1393,  1.5064, -0.4712, -1.0557,  1.7288,\n",
      "          -0.6087, -0.8858,  0.8159, -0.7843, -0.6225, -0.0191, -2.1256,\n",
      "           2.6937]]])\n",
      "src = ['we', 'drink', 'beer']\n",
      "predicted trg = ['wir', 'trinken', 'bier', '<eos>']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_count 1    self.capacity  20\n",
      "0  ------------------------------------------------\n",
      "DecoderLayer@trg4\n",
      "[1, 1, 64]\n",
      "tensor([[[-1.2769,  0.7480, -0.3103, -1.4688,  1.0633,  1.6964, -0.1605,\n",
      "           0.9613, -1.4167, -0.8423,  0.6252, -0.4441, -0.7190, -1.6858,\n",
      "           0.3078, -1.2791,  2.0213,  1.0885, -1.4904,  0.2453, -0.5958,\n",
      "          -0.2212, -0.1915,  1.0538,  0.6322, -0.3166, -0.2517,  0.8536,\n",
      "          -0.7106,  0.8569, -0.4732,  0.0294, -0.1991, -0.9615, -0.2492,\n",
      "           0.3201,  0.5459, -0.8575,  0.2683,  0.5622, -0.5772,  1.2815,\n",
      "          -0.5898, -1.3703,  0.2546,  1.4677,  2.3523, -0.6810, -0.4000,\n",
      "          -0.0392,  0.0545,  0.2721,  1.3948, -0.4873, -1.0658,  1.5451,\n",
      "          -0.5738, -0.5928,  0.8362, -0.6337, -0.3343, -0.4298, -2.0989,\n",
      "           2.7362]]])\n",
      "src = ['we', 'read', 'book']\n",
      "predicted trg = ['wir', 'lesen', '<eos>']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_count 1    self.capacity  20\n",
      "0  ------------------------------------------------\n",
      "DecoderLayer@trg4\n",
      "[1, 1, 64]\n",
      "tensor([[[-0.9017,  0.6584, -0.2569, -0.7741,  0.2071,  2.1448, -0.8264,\n",
      "           0.3286, -1.2872, -0.4518,  0.2317, -0.3442, -0.4990, -2.0219,\n",
      "           0.5940, -1.7045,  1.9103,  0.7549, -1.7414,  0.2858, -0.3417,\n",
      "          -0.0154,  0.0442,  1.5871,  0.1050, -0.2556, -0.0886,  0.4069,\n",
      "          -0.8530,  0.7170, -0.0843,  0.2014,  0.0759, -0.5231, -0.4612,\n",
      "           0.2757,  0.1336, -0.4262,  0.5979,  0.3459, -0.4750,  0.9421,\n",
      "          -0.1868, -1.3326,  0.3760,  1.4812,  2.1005, -1.2022,  0.0316,\n",
      "          -0.2792,  0.2641,  0.6366,  1.9226, -0.7236, -1.5101,  1.4193,\n",
      "          -0.0342, -1.4224,  1.3398, -0.6782, -0.7180, -0.0882, -2.0199,\n",
      "           2.4215]]])\n",
      "src = ['we', 'read', 'newspaper']\n",
      "predicted trg = ['wir', 'lesen', 'zeitung', '<eos>']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_count 1    self.capacity  20\n",
      "0  ------------------------------------------------\n",
      "DecoderLayer@trg4\n",
      "[1, 1, 64]\n",
      "tensor([[[-0.7197,  0.6837, -0.0770, -0.8533,  0.6764,  1.7710, -0.4415,\n",
      "           0.2117, -1.1695, -0.6475, -0.2107, -0.4392, -0.6839, -2.2435,\n",
      "           0.5878, -2.2792,  1.7688,  0.6510, -1.4407,  0.5571, -0.2183,\n",
      "          -0.1168,  0.0730,  1.7598, -0.0762, -0.3282, -0.4204,  0.4027,\n",
      "          -0.5432,  0.9893,  0.1987,  0.2086,  0.2875, -0.5541, -0.5658,\n",
      "           0.2300, -0.1645, -0.5223,  0.4959,  0.6773, -0.5599,  1.2942,\n",
      "          -0.6240, -1.1351,  0.2341,  1.2642,  2.1393, -1.2572,  0.0121,\n",
      "          -0.1869,  0.3817,  0.5870,  1.9588, -0.6295, -1.6273,  1.4121,\n",
      "          -0.0137, -1.3795,  1.1973, -0.6467, -0.8701,  0.1833, -1.5484,\n",
      "           2.3187]]])\n"
     ]
    }
   ],
   "source": [
    "valid_sentences_embeddings = []\n",
    "for i in range(len(tabular_set)):\n",
    "    test_logger = test_sentence(tabular_set[i].src)\n",
    "    #train_data.examples[example_idx].src\n",
    "    #test_logger.get_default_summary()\n",
    "    trg4 = test_logger.get_summary(labels=[\"DecoderLayer@trg4\"],show_data=True)\n",
    "    valid_sentences_embeddings.append(trg4[0].numpy().flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src = ['i', 'want', 'to', 'eat', 'bread']\n",
      "old attention torch.Size([1, 2, 7, 7])\n",
      "old attention tensor([[[[0.0415, 0.3681, 0.0384, 0.1063, 0.2461, 0.1053, 0.0942],\n",
      "          [0.3521, 0.1698, 0.2067, 0.0140, 0.0268, 0.2263, 0.0043],\n",
      "          [0.0244, 0.5596, 0.0133, 0.1487, 0.1773, 0.0077, 0.0691],\n",
      "          [0.0380, 0.0859, 0.0229, 0.1295, 0.1001, 0.0349, 0.5887],\n",
      "          [0.2128, 0.0780, 0.0073, 0.0144, 0.0418, 0.0997, 0.5460],\n",
      "          [0.1206, 0.2104, 0.4938, 0.0090, 0.1079, 0.0524, 0.0060],\n",
      "          [0.0326, 0.1687, 0.0541, 0.0843, 0.1424, 0.4997, 0.0182]],\n",
      "\n",
      "         [[0.0120, 0.0078, 0.9186, 0.0076, 0.0032, 0.0384, 0.0124],\n",
      "          [0.0413, 0.1678, 0.1164, 0.0069, 0.0563, 0.5186, 0.0927],\n",
      "          [0.1431, 0.0130, 0.0358, 0.3068, 0.3401, 0.0465, 0.1147],\n",
      "          [0.5635, 0.0241, 0.0728, 0.0364, 0.2163, 0.0020, 0.0849],\n",
      "          [0.0316, 0.0374, 0.0316, 0.0148, 0.0373, 0.0238, 0.8235],\n",
      "          [0.0326, 0.0089, 0.0062, 0.0017, 0.8961, 0.0451, 0.0093],\n",
      "          [0.0250, 0.0111, 0.2165, 0.5416, 0.0264, 0.0368, 0.1426]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 7, 7])\n",
      "old attention tensor([[[[0.1312, 0.0742, 0.1786, 0.2706, 0.1212, 0.1347, 0.0896],\n",
      "          [0.0657, 0.1301, 0.1237, 0.3458, 0.1422, 0.0738, 0.1187],\n",
      "          [0.1769, 0.0371, 0.0356, 0.0131, 0.3751, 0.2310, 0.1312],\n",
      "          [0.5057, 0.0317, 0.0405, 0.0188, 0.2673, 0.1093, 0.0267],\n",
      "          [0.0275, 0.1231, 0.0176, 0.0896, 0.5685, 0.0815, 0.0923],\n",
      "          [0.1310, 0.2806, 0.1194, 0.1762, 0.0912, 0.0581, 0.1436],\n",
      "          [0.1040, 0.0854, 0.5227, 0.0597, 0.1207, 0.0477, 0.0597]],\n",
      "\n",
      "         [[0.2528, 0.2248, 0.1109, 0.1487, 0.1100, 0.0335, 0.1194],\n",
      "          [0.0141, 0.0441, 0.1215, 0.0740, 0.4022, 0.2652, 0.0789],\n",
      "          [0.0450, 0.0966, 0.5442, 0.0524, 0.1257, 0.1290, 0.0071],\n",
      "          [0.0584, 0.0782, 0.0558, 0.0775, 0.2400, 0.2418, 0.2483],\n",
      "          [0.1357, 0.1781, 0.0619, 0.0787, 0.1448, 0.1467, 0.2542],\n",
      "          [0.0439, 0.1712, 0.1364, 0.0775, 0.0434, 0.4208, 0.1070],\n",
      "          [0.0165, 0.0227, 0.5865, 0.0844, 0.1551, 0.0411, 0.0936]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 7, 7])\n",
      "old attention tensor([[[[0.1307, 0.1880, 0.1024, 0.0983, 0.2446, 0.1666, 0.0693],\n",
      "          [0.1583, 0.0976, 0.0522, 0.0871, 0.4594, 0.0389, 0.1064],\n",
      "          [0.0352, 0.0717, 0.1727, 0.1668, 0.3091, 0.1204, 0.1240],\n",
      "          [0.0396, 0.0308, 0.1812, 0.1201, 0.1672, 0.0759, 0.3852],\n",
      "          [0.1155, 0.1068, 0.0307, 0.0511, 0.5886, 0.0524, 0.0548],\n",
      "          [0.3361, 0.0135, 0.1951, 0.0156, 0.4209, 0.0113, 0.0075],\n",
      "          [0.1307, 0.0287, 0.3464, 0.0776, 0.3645, 0.0131, 0.0389]],\n",
      "\n",
      "         [[0.0957, 0.1381, 0.2660, 0.2720, 0.1647, 0.0554, 0.0081],\n",
      "          [0.0183, 0.0570, 0.0985, 0.2857, 0.1366, 0.1824, 0.2216],\n",
      "          [0.0665, 0.1149, 0.0340, 0.1048, 0.0594, 0.1399, 0.4804],\n",
      "          [0.0754, 0.1200, 0.1356, 0.0978, 0.0925, 0.2151, 0.2636],\n",
      "          [0.0191, 0.0197, 0.5240, 0.2524, 0.0668, 0.0824, 0.0357],\n",
      "          [0.0818, 0.2234, 0.0930, 0.1195, 0.3175, 0.1421, 0.0227],\n",
      "          [0.1132, 0.1581, 0.1502, 0.2559, 0.0572, 0.1516, 0.1137]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 7])\n",
      "old attention tensor([[[[0.2615, 0.1843, 0.0066, 0.0183, 0.2645, 0.2025, 0.0623]],\n",
      "\n",
      "         [[0.0755, 0.1006, 0.6626, 0.0085, 0.0934, 0.0332, 0.0263]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 7])\n",
      "old attention tensor([[[[0.6835, 0.0680, 0.0834, 0.0058, 0.0631, 0.0837, 0.0125]],\n",
      "\n",
      "         [[0.2414, 0.1933, 0.0228, 0.0788, 0.1372, 0.1324, 0.1941]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 7])\n",
      "old attention tensor([[[[0.0102, 0.9383, 0.0072, 0.0102, 0.0146, 0.0138, 0.0058]],\n",
      "\n",
      "         [[0.0125, 0.4200, 0.0623, 0.1296, 0.0414, 0.0610, 0.2732]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.5428, 0.4572]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0282, 0.9718]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.5428, 0.4572]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0282, 0.9718]]]])\n",
      "old attention torch.Size([1, 2, 2, 7])\n",
      "old attention tensor([[[[0.2615, 0.1843, 0.0066, 0.0183, 0.2645, 0.2025, 0.0623],\n",
      "          [0.0032, 0.0056, 0.9033, 0.0565, 0.0070, 0.0026, 0.0218]],\n",
      "\n",
      "         [[0.0755, 0.1006, 0.6626, 0.0085, 0.0934, 0.0332, 0.0263],\n",
      "          [0.4830, 0.0188, 0.1519, 0.0462, 0.2120, 0.0637, 0.0243]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0088, 0.9912]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.2083, 0.7917]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0088, 0.9912]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.2083, 0.7917]]]])\n",
      "old attention torch.Size([1, 2, 2, 7])\n",
      "old attention tensor([[[[0.6835, 0.0680, 0.0834, 0.0058, 0.0631, 0.0837, 0.0125],\n",
      "          [0.0620, 0.1182, 0.0856, 0.1922, 0.4591, 0.0367, 0.0461]],\n",
      "\n",
      "         [[0.2414, 0.1933, 0.0228, 0.0788, 0.1372, 0.1324, 0.1941],\n",
      "          [0.1631, 0.1348, 0.0195, 0.2628, 0.0260, 0.3159, 0.0780]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.2982, 0.7018]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.2710, 0.7290]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.2982, 0.7018]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.2710, 0.7290]]]])\n",
      "old attention torch.Size([1, 2, 2, 7])\n",
      "old attention tensor([[[[0.0102, 0.9383, 0.0072, 0.0102, 0.0146, 0.0138, 0.0058],\n",
      "          [0.0100, 0.0268, 0.1181, 0.6987, 0.0728, 0.0499, 0.0236]],\n",
      "\n",
      "         [[0.0125, 0.4200, 0.0623, 0.1296, 0.0414, 0.0610, 0.2732],\n",
      "          [0.0014, 0.0115, 0.1338, 0.7481, 0.0248, 0.0423, 0.0381]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.5428, 0.4572, 0.0000],\n",
      "          [0.0250, 0.0402, 0.9348]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.0282, 0.9718, 0.0000],\n",
      "          [0.0938, 0.0120, 0.8942]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 7])\n",
      "old attention tensor([[[[0.2349, 0.1093, 0.0010, 0.0082, 0.3005, 0.3250, 0.0210],\n",
      "          [0.0091, 0.0100, 0.8145, 0.0961, 0.0158, 0.0112, 0.0433],\n",
      "          [0.1022, 0.5244, 0.0171, 0.0700, 0.1659, 0.0549, 0.0655]],\n",
      "\n",
      "         [[0.0143, 0.0432, 0.7883, 0.0327, 0.0641, 0.0178, 0.0396],\n",
      "          [0.5694, 0.0162, 0.1519, 0.0183, 0.1754, 0.0570, 0.0117],\n",
      "          [0.0275, 0.0183, 0.2375, 0.2009, 0.0955, 0.3717, 0.0485]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.0214, 0.9786, 0.0000],\n",
      "          [0.1174, 0.0635, 0.8191]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.1152, 0.8848, 0.0000],\n",
      "          [0.0188, 0.1281, 0.8531]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 7])\n",
      "old attention tensor([[[[0.5038, 0.0427, 0.1656, 0.0124, 0.0537, 0.1858, 0.0360],\n",
      "          [0.1112, 0.1560, 0.1486, 0.1033, 0.2965, 0.1265, 0.0579],\n",
      "          [0.1276, 0.1647, 0.1289, 0.1913, 0.0672, 0.1448, 0.1754]],\n",
      "\n",
      "         [[0.1085, 0.2871, 0.0132, 0.1135, 0.0504, 0.2653, 0.1620],\n",
      "          [0.0809, 0.3378, 0.0021, 0.0833, 0.0133, 0.3392, 0.1434],\n",
      "          [0.0566, 0.2148, 0.0241, 0.2001, 0.0198, 0.3343, 0.1504]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.5188, 0.4812, 0.0000],\n",
      "          [0.2748, 0.5564, 0.1688]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.1627, 0.8373, 0.0000],\n",
      "          [0.1054, 0.7441, 0.1505]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 7])\n",
      "old attention tensor([[[[0.0523, 0.6509, 0.0378, 0.0176, 0.0891, 0.0606, 0.0917],\n",
      "          [0.0183, 0.2714, 0.0669, 0.3772, 0.1085, 0.0639, 0.0938],\n",
      "          [0.2059, 0.2910, 0.0392, 0.0487, 0.1975, 0.1545, 0.0633]],\n",
      "\n",
      "         [[0.0734, 0.1813, 0.0241, 0.0088, 0.0959, 0.3729, 0.2436],\n",
      "          [0.0302, 0.0746, 0.0699, 0.0415, 0.0718, 0.3960, 0.3159],\n",
      "          [0.0233, 0.0175, 0.0033, 0.0022, 0.0406, 0.8878, 0.0253]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5428, 0.4572, 0.0000, 0.0000],\n",
      "          [0.0250, 0.0402, 0.9347, 0.0000],\n",
      "          [0.0966, 0.8249, 0.0517, 0.0267]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0282, 0.9718, 0.0000, 0.0000],\n",
      "          [0.0938, 0.0120, 0.8942, 0.0000],\n",
      "          [0.0014, 0.0028, 0.0023, 0.9935]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 7])\n",
      "old attention tensor([[[[2.9420e-01, 1.1060e-01, 7.6121e-04, 7.8047e-03, 2.3704e-01,\n",
      "           3.3228e-01, 1.7310e-02],\n",
      "          [8.7492e-03, 8.1367e-03, 8.3358e-01, 9.6762e-02, 9.8053e-03,\n",
      "           8.7710e-03, 3.4196e-02],\n",
      "          [1.2470e-01, 5.4941e-01, 1.6054e-02, 7.6731e-02, 1.2289e-01,\n",
      "           5.2274e-02, 5.7932e-02],\n",
      "          [1.6606e-01, 1.3018e-02, 4.7770e-01, 9.1811e-02, 1.5646e-01,\n",
      "           3.7201e-02, 5.7748e-02]],\n",
      "\n",
      "         [[6.2481e-03, 4.0011e-02, 7.9956e-01, 3.3803e-02, 6.6677e-02,\n",
      "           1.4996e-02, 3.8700e-02],\n",
      "          [4.1952e-01, 1.9030e-02, 1.9264e-01, 2.4329e-02, 2.6137e-01,\n",
      "           6.8832e-02, 1.4287e-02],\n",
      "          [1.2725e-02, 1.7599e-02, 2.2509e-01, 2.3072e-01, 1.0474e-01,\n",
      "           3.5835e-01, 5.0772e-02],\n",
      "          [1.4222e-02, 1.7983e-01, 6.1019e-01, 2.5005e-02, 8.0334e-02,\n",
      "           3.0923e-02, 5.9493e-02]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0238, 0.9762, 0.0000, 0.0000],\n",
      "          [0.1735, 0.0454, 0.7811, 0.0000],\n",
      "          [0.0539, 0.2938, 0.2532, 0.3991]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0545, 0.9455, 0.0000, 0.0000],\n",
      "          [0.0094, 0.1432, 0.8474, 0.0000],\n",
      "          [0.0131, 0.7509, 0.1981, 0.0379]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 7])\n",
      "old attention tensor([[[[0.6278, 0.0156, 0.1238, 0.0094, 0.0426, 0.1572, 0.0237],\n",
      "          [0.0996, 0.0866, 0.1457, 0.1440, 0.3634, 0.1129, 0.0477],\n",
      "          [0.1111, 0.0971, 0.1154, 0.3126, 0.0687, 0.1214, 0.1737],\n",
      "          [0.3772, 0.1204, 0.1512, 0.0517, 0.1101, 0.1204, 0.0689]],\n",
      "\n",
      "         [[0.2224, 0.1545, 0.0387, 0.1372, 0.1102, 0.2542, 0.0828],\n",
      "          [0.1640, 0.2229, 0.0032, 0.0837, 0.0217, 0.4364, 0.0682],\n",
      "          [0.0895, 0.1375, 0.0561, 0.2475, 0.0323, 0.3420, 0.0952],\n",
      "          [0.0289, 0.1859, 0.0382, 0.3143, 0.0202, 0.1750, 0.2376]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5261, 0.4739, 0.0000, 0.0000],\n",
      "          [0.1948, 0.6532, 0.1520, 0.0000],\n",
      "          [0.0285, 0.1088, 0.8281, 0.0346]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.2415, 0.7585, 0.0000, 0.0000],\n",
      "          [0.1259, 0.5679, 0.3062, 0.0000],\n",
      "          [0.1775, 0.1028, 0.3952, 0.3245]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 7])\n",
      "old attention tensor([[[[0.1339, 0.2887, 0.0794, 0.0117, 0.1866, 0.1110, 0.1886],\n",
      "          [0.0221, 0.0734, 0.1190, 0.4368, 0.1632, 0.0798, 0.1058],\n",
      "          [0.3808, 0.0674, 0.0458, 0.0237, 0.2324, 0.1802, 0.0698],\n",
      "          [0.0802, 0.1188, 0.1099, 0.0276, 0.1070, 0.1232, 0.4333]],\n",
      "\n",
      "         [[0.1981, 0.2482, 0.0181, 0.0063, 0.1305, 0.2382, 0.1605],\n",
      "          [0.0859, 0.0923, 0.0888, 0.0516, 0.1234, 0.2558, 0.3021],\n",
      "          [0.0900, 0.0239, 0.0025, 0.0022, 0.0762, 0.7888, 0.0165],\n",
      "          [0.1710, 0.0902, 0.0123, 0.0149, 0.0971, 0.5230, 0.0916]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "predicted trg = ['ich', 'mochten', 'essen', '<eos>']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcelikkaya\\Anaconda3\\envs\\p37_tensor23\\lib\\site-packages\\ipykernel_launcher.py:17: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "C:\\Users\\mcelikkaya\\Anaconda3\\envs\\p37_tensor23\\lib\\site-packages\\ipykernel_launcher.py:18: UserWarning: FixedFormatter should only be used together with FixedLocator\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_count 1    self.capacity  20\n",
      "0  ------------------------------------------------\n",
      "DecoderLayer@trg4\n",
      "[1, 1, 64]\n",
      "src = ['i', 'want', 'to', 'eat', 'apple']\n",
      "old attention torch.Size([1, 2, 7, 7])\n",
      "old attention tensor([[[[4.1988e-02, 3.7201e-01, 3.8808e-02, 1.0744e-01, 2.4874e-01,\n",
      "           9.5845e-02, 9.5168e-02],\n",
      "          [4.4784e-01, 2.1599e-01, 2.6298e-01, 1.7861e-02, 3.4141e-02,\n",
      "           1.5733e-02, 5.4593e-03],\n",
      "          [2.4344e-02, 5.5801e-01, 1.3295e-02, 1.4825e-01, 1.7676e-01,\n",
      "           1.0424e-02, 6.8916e-02],\n",
      "          [3.4790e-02, 7.8705e-02, 2.0942e-02, 1.1865e-01, 9.1674e-02,\n",
      "           1.1595e-01, 5.3930e-01],\n",
      "          [2.1809e-01, 7.9920e-02, 7.4703e-03, 1.4751e-02, 4.2848e-02,\n",
      "           7.7389e-02, 5.5953e-01],\n",
      "          [3.9561e-02, 3.1939e-01, 2.3901e-01, 5.0944e-02, 6.3972e-02,\n",
      "           6.5649e-02, 2.2147e-01],\n",
      "          [5.2775e-02, 2.7346e-01, 8.7654e-02, 1.3663e-01, 2.3085e-01,\n",
      "           1.8913e-01, 2.9505e-02]],\n",
      "\n",
      "         [[1.2396e-02, 8.0565e-03, 9.4878e-01, 7.8338e-03, 3.3117e-03,\n",
      "           6.7688e-03, 1.2853e-02],\n",
      "          [7.2553e-02, 2.9507e-01, 2.0457e-01, 1.2208e-02, 9.8984e-02,\n",
      "           1.5366e-01, 1.6295e-01],\n",
      "          [1.4136e-01, 1.2822e-02, 3.5399e-02, 3.0307e-01, 3.3592e-01,\n",
      "           5.8121e-02, 1.1331e-01],\n",
      "          [5.5753e-01, 2.3829e-02, 7.1982e-02, 3.6020e-02, 2.1403e-01,\n",
      "           1.2637e-02, 8.3971e-02],\n",
      "          [3.2314e-02, 3.8197e-02, 3.2297e-02, 1.5129e-02, 3.8102e-02,\n",
      "           2.5187e-03, 8.4144e-01],\n",
      "          [8.3992e-04, 1.2834e-01, 9.2329e-03, 3.7718e-01, 2.4753e-02,\n",
      "           1.3491e-02, 4.4616e-01],\n",
      "          [2.3793e-02, 1.0560e-02, 2.0608e-01, 5.1569e-01, 2.5127e-02,\n",
      "           8.2996e-02, 1.3576e-01]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 7, 7])\n",
      "old attention tensor([[[[0.1273, 0.0691, 0.1631, 0.2773, 0.1229, 0.1548, 0.0854],\n",
      "          [0.0602, 0.1319, 0.1195, 0.3465, 0.1358, 0.0764, 0.1297],\n",
      "          [0.2137, 0.0433, 0.0388, 0.0155, 0.4395, 0.0964, 0.1527],\n",
      "          [0.5526, 0.0347, 0.0451, 0.0229, 0.2902, 0.0202, 0.0344],\n",
      "          [0.0301, 0.1130, 0.0162, 0.1045, 0.5657, 0.0687, 0.1017],\n",
      "          [0.1400, 0.2369, 0.0232, 0.0383, 0.2665, 0.0305, 0.2646],\n",
      "          [0.0862, 0.0745, 0.4669, 0.0586, 0.1020, 0.1535, 0.0582]],\n",
      "\n",
      "         [[0.2492, 0.1983, 0.1012, 0.1442, 0.1070, 0.0985, 0.1016],\n",
      "          [0.0182, 0.0468, 0.1503, 0.0950, 0.5426, 0.0539, 0.0932],\n",
      "          [0.0321, 0.0713, 0.3989, 0.0445, 0.0955, 0.3523, 0.0054],\n",
      "          [0.0647, 0.0820, 0.0580, 0.0903, 0.2428, 0.1751, 0.2871],\n",
      "          [0.1166, 0.1385, 0.0544, 0.0768, 0.1312, 0.2562, 0.2263],\n",
      "          [0.0761, 0.0531, 0.2193, 0.0865, 0.0061, 0.5053, 0.0535],\n",
      "          [0.0184, 0.0215, 0.5384, 0.0821, 0.1573, 0.0837, 0.0986]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 7, 7])\n",
      "old attention tensor([[[[0.1295, 0.2033, 0.0867, 0.0882, 0.2001, 0.2379, 0.0543],\n",
      "          [0.1356, 0.0884, 0.0476, 0.0580, 0.3299, 0.2794, 0.0610],\n",
      "          [0.0348, 0.0762, 0.2042, 0.1965, 0.2991, 0.0519, 0.1373],\n",
      "          [0.0429, 0.0331, 0.1986, 0.0989, 0.1911, 0.0951, 0.3402],\n",
      "          [0.0752, 0.0794, 0.0254, 0.0344, 0.5978, 0.1581, 0.0298],\n",
      "          [0.0636, 0.0287, 0.0393, 0.0264, 0.5090, 0.3182, 0.0148],\n",
      "          [0.1172, 0.0243, 0.2738, 0.0454, 0.2865, 0.2352, 0.0176]],\n",
      "\n",
      "         [[0.0586, 0.0847, 0.2555, 0.2226, 0.1135, 0.2597, 0.0053],\n",
      "          [0.0172, 0.0619, 0.1102, 0.2943, 0.1823, 0.0850, 0.2491],\n",
      "          [0.0493, 0.1100, 0.0296, 0.1171, 0.0573, 0.0538, 0.5828],\n",
      "          [0.0659, 0.1144, 0.1167, 0.0940, 0.0926, 0.2758, 0.2405],\n",
      "          [0.0148, 0.0177, 0.4710, 0.2483, 0.0651, 0.1559, 0.0273],\n",
      "          [0.0247, 0.0196, 0.2914, 0.3035, 0.0494, 0.2621, 0.0493],\n",
      "          [0.0948, 0.1669, 0.1676, 0.3100, 0.0717, 0.0839, 0.1051]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 7])\n",
      "old attention tensor([[[[0.2839, 0.2418, 0.0068, 0.0249, 0.2792, 0.0786, 0.0848]],\n",
      "\n",
      "         [[0.0606, 0.0740, 0.5611, 0.0068, 0.0749, 0.2002, 0.0225]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 7])\n",
      "old attention tensor([[[[0.6812, 0.0666, 0.0835, 0.0054, 0.0668, 0.0870, 0.0094]],\n",
      "\n",
      "         [[0.2501, 0.2460, 0.0188, 0.0804, 0.1275, 0.1000, 0.1771]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 7])\n",
      "old attention tensor([[[[0.0096, 0.9450, 0.0078, 0.0124, 0.0137, 0.0069, 0.0046]],\n",
      "\n",
      "         [[0.0088, 0.3509, 0.0468, 0.1493, 0.0388, 0.1857, 0.2198]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.5428, 0.4572]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0282, 0.9718]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.5428, 0.4572]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0282, 0.9718]]]])\n",
      "old attention torch.Size([1, 2, 2, 7])\n",
      "old attention tensor([[[[0.2839, 0.2418, 0.0068, 0.0249, 0.2792, 0.0786, 0.0848],\n",
      "          [0.0037, 0.0054, 0.8546, 0.0506, 0.0073, 0.0573, 0.0211]],\n",
      "\n",
      "         [[0.0606, 0.0740, 0.5611, 0.0068, 0.0749, 0.2002, 0.0225],\n",
      "          [0.4258, 0.0175, 0.1515, 0.0405, 0.1984, 0.1380, 0.0283]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0072, 0.9928]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.2379, 0.7621]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0072, 0.9928]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.2379, 0.7621]]]])\n",
      "old attention torch.Size([1, 2, 2, 7])\n",
      "old attention tensor([[[[0.6812, 0.0666, 0.0835, 0.0054, 0.0668, 0.0870, 0.0094],\n",
      "          [0.0660, 0.0937, 0.0639, 0.1422, 0.4557, 0.1411, 0.0374]],\n",
      "\n",
      "         [[0.2501, 0.2460, 0.0188, 0.0804, 0.1275, 0.1000, 0.1771],\n",
      "          [0.2411, 0.2154, 0.0232, 0.3094, 0.0367, 0.0678, 0.1065]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.3062, 0.6938]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.3811, 0.6189]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.3062, 0.6938]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.3811, 0.6189]]]])\n",
      "old attention torch.Size([1, 2, 2, 7])\n",
      "old attention tensor([[[[0.0096, 0.9450, 0.0078, 0.0124, 0.0137, 0.0069, 0.0046],\n",
      "          [0.0086, 0.0540, 0.1062, 0.7027, 0.0541, 0.0582, 0.0163]],\n",
      "\n",
      "         [[0.0088, 0.3509, 0.0468, 0.1493, 0.0388, 0.1857, 0.2198],\n",
      "          [0.0010, 0.0134, 0.1062, 0.8199, 0.0149, 0.0120, 0.0328]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.5428, 0.4572, 0.0000],\n",
      "          [0.0250, 0.0402, 0.9348]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.0282, 0.9718, 0.0000],\n",
      "          [0.0938, 0.0120, 0.8942]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 7])\n",
      "old attention tensor([[[[0.3269, 0.1881, 0.0013, 0.0143, 0.4047, 0.0278, 0.0368],\n",
      "          [0.0097, 0.0100, 0.7358, 0.0859, 0.0162, 0.1015, 0.0410],\n",
      "          [0.1020, 0.5242, 0.0149, 0.0850, 0.1478, 0.0616, 0.0644]],\n",
      "\n",
      "         [[0.0124, 0.0362, 0.6994, 0.0264, 0.0547, 0.1351, 0.0357],\n",
      "          [0.4851, 0.0147, 0.1605, 0.0166, 0.1680, 0.1415, 0.0136],\n",
      "          [0.0317, 0.0222, 0.3148, 0.2423, 0.1404, 0.1822, 0.0663]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.0171, 0.9829, 0.0000],\n",
      "          [0.1070, 0.0745, 0.8186]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.1368, 0.8632, 0.0000],\n",
      "          [0.0195, 0.1155, 0.8650]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 7])\n",
      "old attention tensor([[[[0.6031, 0.0445, 0.1482, 0.0106, 0.0759, 0.0905, 0.0272],\n",
      "          [0.1123, 0.1186, 0.1095, 0.0728, 0.3794, 0.1659, 0.0415],\n",
      "          [0.1651, 0.1727, 0.1043, 0.1678, 0.1015, 0.1462, 0.1423]],\n",
      "\n",
      "         [[0.1164, 0.4016, 0.0107, 0.1294, 0.0539, 0.1110, 0.1769],\n",
      "          [0.1132, 0.5438, 0.0023, 0.1065, 0.0175, 0.0344, 0.1824],\n",
      "          [0.0820, 0.3368, 0.0243, 0.2694, 0.0259, 0.0314, 0.2301]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.5784, 0.4216, 0.0000],\n",
      "          [0.2955, 0.4525, 0.2520]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.2781, 0.7219, 0.0000],\n",
      "          [0.1721, 0.6543, 0.1736]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 7])\n",
      "old attention tensor([[[[0.0321, 0.6318, 0.0403, 0.0238, 0.0713, 0.1338, 0.0669],\n",
      "          [0.0119, 0.2494, 0.0630, 0.4477, 0.0732, 0.0992, 0.0557],\n",
      "          [0.1284, 0.2585, 0.0365, 0.0631, 0.1622, 0.3098, 0.0415]],\n",
      "\n",
      "         [[0.0611, 0.2533, 0.0356, 0.0260, 0.1187, 0.1822, 0.3231],\n",
      "          [0.0285, 0.1195, 0.1153, 0.1268, 0.0887, 0.1194, 0.4019],\n",
      "          [0.1388, 0.1487, 0.0329, 0.0361, 0.2919, 0.1303, 0.2214]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5428, 0.4572, 0.0000, 0.0000],\n",
      "          [0.0250, 0.0402, 0.9347, 0.0000],\n",
      "          [0.0966, 0.8249, 0.0517, 0.0267]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0282, 0.9718, 0.0000, 0.0000],\n",
      "          [0.0938, 0.0120, 0.8942, 0.0000],\n",
      "          [0.0014, 0.0028, 0.0023, 0.9935]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 7])\n",
      "old attention tensor([[[[0.4163, 0.1922, 0.0010, 0.0136, 0.3280, 0.0196, 0.0294],\n",
      "          [0.0097, 0.0082, 0.7801, 0.0860, 0.0106, 0.0738, 0.0315],\n",
      "          [0.1274, 0.5515, 0.0144, 0.0922, 0.1134, 0.0464, 0.0547],\n",
      "          [0.1516, 0.0108, 0.4850, 0.0716, 0.1422, 0.0865, 0.0523]],\n",
      "\n",
      "         [[0.0058, 0.0340, 0.7014, 0.0293, 0.0589, 0.1338, 0.0368],\n",
      "          [0.3455, 0.0161, 0.1863, 0.0219, 0.2388, 0.1751, 0.0162],\n",
      "          [0.0148, 0.0206, 0.2810, 0.2874, 0.1527, 0.1735, 0.0699],\n",
      "          [0.0141, 0.1601, 0.4704, 0.0246, 0.0676, 0.2051, 0.0581]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0176, 0.9824, 0.0000, 0.0000],\n",
      "          [0.1544, 0.0555, 0.7900, 0.0000],\n",
      "          [0.0435, 0.3964, 0.2041, 0.3560]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0669, 0.9331, 0.0000, 0.0000],\n",
      "          [0.0095, 0.1315, 0.8590, 0.0000],\n",
      "          [0.0144, 0.7288, 0.2214, 0.0353]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 7])\n",
      "old attention tensor([[[[0.7299, 0.0168, 0.1082, 0.0089, 0.0581, 0.0602, 0.0180],\n",
      "          [0.1007, 0.0647, 0.0930, 0.0965, 0.4586, 0.1540, 0.0325],\n",
      "          [0.1531, 0.1071, 0.0868, 0.2793, 0.1100, 0.1232, 0.1405],\n",
      "          [0.4538, 0.1185, 0.1053, 0.0466, 0.1563, 0.0695, 0.0500]],\n",
      "\n",
      "         [[0.2073, 0.1862, 0.0341, 0.1372, 0.1135, 0.2325, 0.0892],\n",
      "          [0.2546, 0.4109, 0.0048, 0.1203, 0.0361, 0.0615, 0.1119],\n",
      "          [0.1332, 0.2077, 0.0696, 0.3335, 0.0469, 0.0468, 0.1623],\n",
      "          [0.0363, 0.2283, 0.0372, 0.3760, 0.0271, 0.0197, 0.2754]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.6076, 0.3924, 0.0000, 0.0000],\n",
      "          [0.2480, 0.5390, 0.2130, 0.0000],\n",
      "          [0.0240, 0.0707, 0.8779, 0.0275]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.3784, 0.6216, 0.0000, 0.0000],\n",
      "          [0.1905, 0.5025, 0.3070, 0.0000],\n",
      "          [0.2645, 0.0963, 0.3094, 0.3298]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 7])\n",
      "old attention tensor([[[[0.0763, 0.3679, 0.0900, 0.0157, 0.1575, 0.1608, 0.1318],\n",
      "          [0.0152, 0.0902, 0.1189, 0.5208, 0.1162, 0.0748, 0.0637],\n",
      "          [0.2603, 0.0854, 0.0481, 0.0352, 0.2396, 0.2797, 0.0515],\n",
      "          [0.0506, 0.1825, 0.1141, 0.0471, 0.1059, 0.1929, 0.3068]],\n",
      "\n",
      "         [[0.1298, 0.3452, 0.0275, 0.0199, 0.1362, 0.1320, 0.2094],\n",
      "          [0.0555, 0.1334, 0.1264, 0.1610, 0.1101, 0.0859, 0.3277],\n",
      "          [0.3146, 0.1404, 0.0183, 0.0243, 0.3308, 0.0660, 0.1056],\n",
      "          [0.2051, 0.2002, 0.0393, 0.0876, 0.1588, 0.0972, 0.2118]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "predicted trg = ['ich', 'mochten', 'essen', '<eos>']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_count 1    self.capacity  20\n",
      "0  ------------------------------------------------\n",
      "DecoderLayer@trg4\n",
      "[1, 1, 64]\n",
      "src = ['i', 'want', 'to', 'drink', 'water']\n",
      "old attention torch.Size([1, 2, 7, 7])\n",
      "old attention tensor([[[[3.0442e-02, 2.6972e-01, 2.8136e-02, 7.7895e-02, 5.0570e-01,\n",
      "           1.9110e-02, 6.8999e-02],\n",
      "          [8.4978e-02, 4.0985e-02, 4.9900e-02, 3.3892e-03, 8.1898e-01,\n",
      "           7.3003e-04, 1.0359e-03],\n",
      "          [2.8259e-02, 6.4776e-01, 1.5434e-02, 1.7210e-01, 4.6074e-03,\n",
      "           5.1841e-02, 8.0001e-02],\n",
      "          [4.0377e-02, 9.1345e-02, 2.4306e-02, 1.3770e-01, 4.1593e-02,\n",
      "           3.8762e-02, 6.2591e-01],\n",
      "          [3.2263e-03, 6.8367e-02, 5.2556e-02, 1.5770e-02, 6.3062e-03,\n",
      "           1.0245e-01, 7.5133e-01],\n",
      "          [8.5588e-02, 4.2902e-02, 1.5848e-01, 3.4161e-02, 6.3094e-01,\n",
      "           3.8671e-02, 9.2611e-03],\n",
      "          [2.7121e-02, 1.4053e-01, 4.5045e-02, 7.0213e-02, 6.9089e-01,\n",
      "           1.1044e-02, 1.5163e-02]],\n",
      "\n",
      "         [[1.1993e-02, 7.7946e-03, 9.1793e-01, 7.5791e-03, 3.3091e-02,\n",
      "           9.1732e-03, 1.2436e-02],\n",
      "          [7.6535e-02, 3.1127e-01, 2.1580e-01, 1.2878e-02, 1.9827e-01,\n",
      "           1.3363e-02, 1.7189e-01],\n",
      "          [2.0671e-01, 1.8750e-02, 5.1764e-02, 4.4318e-01, 6.5380e-02,\n",
      "           4.8524e-02, 1.6569e-01],\n",
      "          [6.8827e-01, 2.9417e-02, 8.8861e-02, 4.4467e-02, 3.3125e-02,\n",
      "           1.2196e-02, 1.0366e-01],\n",
      "          [2.6879e-01, 4.5071e-01, 9.1407e-02, 5.3963e-02, 2.6645e-02,\n",
      "           1.1995e-02, 9.6494e-02],\n",
      "          [2.8417e-02, 3.6087e-01, 4.1677e-01, 2.8345e-02, 5.1830e-02,\n",
      "           7.1037e-02, 4.2730e-02],\n",
      "          [2.4308e-02, 1.0788e-02, 2.1055e-01, 5.2685e-01, 2.8952e-02,\n",
      "           5.9862e-02, 1.3869e-01]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 7, 7])\n",
      "old attention tensor([[[[0.1019, 0.0556, 0.1170, 0.1837, 0.2536, 0.2180, 0.0703],\n",
      "          [0.0441, 0.0879, 0.0753, 0.2288, 0.1155, 0.3658, 0.0825],\n",
      "          [0.1138, 0.0247, 0.0240, 0.0086, 0.2755, 0.4745, 0.0790],\n",
      "          [0.1278, 0.0066, 0.0076, 0.0032, 0.0988, 0.7514, 0.0045],\n",
      "          [0.2727, 0.0605, 0.0478, 0.0639, 0.0408, 0.4639, 0.0504],\n",
      "          [0.0335, 0.0458, 0.0457, 0.0543, 0.0319, 0.7492, 0.0396],\n",
      "          [0.0361, 0.0265, 0.1609, 0.0196, 0.0726, 0.6669, 0.0174]],\n",
      "\n",
      "         [[0.1907, 0.1659, 0.0793, 0.1199, 0.2505, 0.1162, 0.0776],\n",
      "          [0.0361, 0.1054, 0.2801, 0.1649, 0.2160, 0.0143, 0.1833],\n",
      "          [0.0418, 0.0860, 0.6445, 0.0472, 0.0629, 0.1109, 0.0066],\n",
      "          [0.1029, 0.1366, 0.0810, 0.0998, 0.0728, 0.0753, 0.4316],\n",
      "          [0.0231, 0.2073, 0.4257, 0.1239, 0.0668, 0.0208, 0.1325],\n",
      "          [0.1910, 0.1157, 0.3184, 0.1066, 0.0458, 0.0092, 0.2132],\n",
      "          [0.0222, 0.0311, 0.6890, 0.0968, 0.0277, 0.0129, 0.1202]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 7, 7])\n",
      "old attention tensor([[[[0.0511, 0.1061, 0.0390, 0.0418, 0.5300, 0.1907, 0.0413],\n",
      "          [0.1117, 0.0751, 0.0467, 0.0838, 0.1046, 0.4718, 0.1063],\n",
      "          [0.0649, 0.1299, 0.3327, 0.2270, 0.0214, 0.0477, 0.1764],\n",
      "          [0.0493, 0.0369, 0.2471, 0.0936, 0.0107, 0.1193, 0.4431],\n",
      "          [0.1221, 0.0509, 0.1692, 0.0670, 0.0897, 0.1558, 0.3453],\n",
      "          [0.0309, 0.0638, 0.0385, 0.0346, 0.0154, 0.1170, 0.6998],\n",
      "          [0.1429, 0.0444, 0.5075, 0.1163, 0.0293, 0.0822, 0.0776]],\n",
      "\n",
      "         [[0.0176, 0.0390, 0.0316, 0.0333, 0.8391, 0.0375, 0.0019],\n",
      "          [0.0294, 0.0841, 0.1066, 0.2767, 0.1310, 0.1113, 0.2608],\n",
      "          [0.0737, 0.1356, 0.0598, 0.1222, 0.0074, 0.0265, 0.5749],\n",
      "          [0.1116, 0.1560, 0.1897, 0.1060, 0.0301, 0.0907, 0.3160],\n",
      "          [0.0987, 0.2971, 0.0151, 0.0078, 0.4810, 0.0774, 0.0230],\n",
      "          [0.1184, 0.0276, 0.0571, 0.0262, 0.7266, 0.0181, 0.0260],\n",
      "          [0.1153, 0.1670, 0.1263, 0.1738, 0.0862, 0.2168, 0.1146]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 7])\n",
      "old attention tensor([[[[0.3688, 0.1664, 0.0107, 0.0379, 0.0646, 0.2810, 0.0706]],\n",
      "\n",
      "         [[0.0801, 0.1207, 0.4509, 0.0082, 0.0433, 0.2669, 0.0298]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 7])\n",
      "old attention tensor([[[[0.6252, 0.0925, 0.0863, 0.0073, 0.1250, 0.0546, 0.0091]],\n",
      "\n",
      "         [[0.3348, 0.1305, 0.0281, 0.1013, 0.0625, 0.1848, 0.1580]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 7])\n",
      "old attention tensor([[[[0.0104, 0.9297, 0.0049, 0.0100, 0.0230, 0.0188, 0.0032]],\n",
      "\n",
      "         [[0.0125, 0.4913, 0.0782, 0.1198, 0.0205, 0.0154, 0.2623]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.5428, 0.4572]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0282, 0.9718]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.5428, 0.4572]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0282, 0.9718]]]])\n",
      "old attention torch.Size([1, 2, 2, 7])\n",
      "old attention tensor([[[[0.3688, 0.1664, 0.0107, 0.0379, 0.0646, 0.2810, 0.0706],\n",
      "          [0.0032, 0.0071, 0.9102, 0.0456, 0.0023, 0.0066, 0.0250]],\n",
      "\n",
      "         [[0.0801, 0.1207, 0.4509, 0.0082, 0.0433, 0.2669, 0.0298],\n",
      "          [0.2698, 0.0082, 0.1114, 0.0213, 0.4776, 0.1000, 0.0117]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0079, 0.9921]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.1739, 0.8261]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0079, 0.9921]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.1739, 0.8261]]]])\n",
      "old attention torch.Size([1, 2, 2, 7])\n",
      "old attention tensor([[[[0.6252, 0.0925, 0.0863, 0.0073, 0.1250, 0.0546, 0.0091],\n",
      "          [0.0928, 0.1923, 0.1774, 0.3023, 0.0680, 0.0861, 0.0810]],\n",
      "\n",
      "         [[0.3348, 0.1305, 0.0281, 0.1013, 0.0625, 0.1848, 0.1580],\n",
      "          [0.1259, 0.0878, 0.0238, 0.3751, 0.2801, 0.0567, 0.0506]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.2657, 0.7343]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.5247, 0.4753]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.2657, 0.7343]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.5247, 0.4753]]]])\n",
      "old attention torch.Size([1, 2, 2, 7])\n",
      "old attention tensor([[[[1.0389e-02, 9.2974e-01, 4.9388e-03, 9.9505e-03, 2.3039e-02,\n",
      "           1.8765e-02, 3.1751e-03],\n",
      "          [6.7099e-03, 2.4867e-02, 9.5907e-02, 6.2890e-01, 1.9321e-01,\n",
      "           3.3816e-02, 1.6593e-02]],\n",
      "\n",
      "         [[1.2543e-02, 4.9131e-01, 7.8228e-02, 1.1977e-01, 2.0488e-02,\n",
      "           1.5362e-02, 2.6230e-01],\n",
      "          [5.6632e-04, 4.7939e-03, 1.0089e-01, 8.1452e-01, 1.2067e-02,\n",
      "           4.4892e-02, 2.2268e-02]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.5428, 0.4572, 0.0000],\n",
      "          [0.0250, 0.0402, 0.9348]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.0282, 0.9718, 0.0000],\n",
      "          [0.0938, 0.0120, 0.8942]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 7])\n",
      "old attention tensor([[[[0.4893, 0.1476, 0.0023, 0.0293, 0.1514, 0.1472, 0.0330],\n",
      "          [0.0089, 0.0123, 0.8250, 0.0822, 0.0083, 0.0161, 0.0471],\n",
      "          [0.1054, 0.5991, 0.0175, 0.0717, 0.0309, 0.1204, 0.0550]],\n",
      "\n",
      "         [[0.0183, 0.0499, 0.7364, 0.0317, 0.0106, 0.0946, 0.0586],\n",
      "          [0.3511, 0.0091, 0.1033, 0.0096, 0.4028, 0.1173, 0.0068],\n",
      "          [0.0241, 0.0140, 0.2180, 0.1445, 0.4913, 0.0687, 0.0395]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.0149, 0.9851, 0.0000],\n",
      "          [0.1582, 0.0540, 0.7878]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.1115, 0.8885, 0.0000],\n",
      "          [0.0156, 0.0849, 0.8995]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 7])\n",
      "old attention tensor([[[[0.5462, 0.0431, 0.1765, 0.0113, 0.1456, 0.0549, 0.0225],\n",
      "          [0.1296, 0.2419, 0.1844, 0.1441, 0.1200, 0.1133, 0.0668],\n",
      "          [0.0846, 0.1373, 0.1189, 0.2074, 0.1816, 0.1056, 0.1647]],\n",
      "\n",
      "         [[0.1957, 0.2003, 0.0144, 0.1628, 0.0854, 0.2421, 0.0993],\n",
      "          [0.1329, 0.3771, 0.0030, 0.1834, 0.0796, 0.0991, 0.1249],\n",
      "          [0.0712, 0.2114, 0.0336, 0.3261, 0.1908, 0.0692, 0.0977]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.3650, 0.6350, 0.0000],\n",
      "          [0.1134, 0.7819, 0.1047]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.1843, 0.8157, 0.0000],\n",
      "          [0.0985, 0.7573, 0.1442]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 7])\n",
      "old attention tensor([[[[0.0676, 0.3855, 0.0367, 0.0177, 0.0417, 0.4080, 0.0429],\n",
      "          [0.0115, 0.0717, 0.0531, 0.3466, 0.0503, 0.4375, 0.0292],\n",
      "          [0.2953, 0.1659, 0.0562, 0.0423, 0.1200, 0.2808, 0.0396]],\n",
      "\n",
      "         [[0.0896, 0.3693, 0.0508, 0.0130, 0.0858, 0.0371, 0.3545],\n",
      "          [0.0263, 0.0527, 0.1047, 0.0558, 0.2095, 0.2172, 0.3340],\n",
      "          [0.1139, 0.1364, 0.0292, 0.0166, 0.5050, 0.0638, 0.1352]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5428, 0.4572, 0.0000, 0.0000],\n",
      "          [0.0250, 0.0402, 0.9347, 0.0000],\n",
      "          [0.0347, 0.0580, 0.7842, 0.1231]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0282, 0.9718, 0.0000, 0.0000],\n",
      "          [0.0938, 0.0120, 0.8942, 0.0000],\n",
      "          [0.0429, 0.8831, 0.0424, 0.0316]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 7])\n",
      "old attention tensor([[[[0.5547, 0.1337, 0.0018, 0.0239, 0.1338, 0.1151, 0.0370],\n",
      "          [0.0129, 0.0136, 0.8027, 0.0819, 0.0088, 0.0155, 0.0646],\n",
      "          [0.1369, 0.6122, 0.0114, 0.0552, 0.0267, 0.0958, 0.0617],\n",
      "          [0.0508, 0.3951, 0.0050, 0.0775, 0.0937, 0.2280, 0.1499]],\n",
      "\n",
      "         [[0.0185, 0.0567, 0.6886, 0.0360, 0.0113, 0.1190, 0.0700],\n",
      "          [0.3338, 0.0091, 0.0976, 0.0094, 0.3998, 0.1432, 0.0071],\n",
      "          [0.0197, 0.0133, 0.2048, 0.1505, 0.4880, 0.0819, 0.0418],\n",
      "          [0.2765, 0.0248, 0.3826, 0.0448, 0.0595, 0.1297, 0.0821]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0147, 0.9853, 0.0000, 0.0000],\n",
      "          [0.2216, 0.0422, 0.7362, 0.0000],\n",
      "          [0.0030, 0.0280, 0.2734, 0.6955]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.1056, 0.8944, 0.0000, 0.0000],\n",
      "          [0.0104, 0.0538, 0.9358, 0.0000],\n",
      "          [0.0526, 0.2677, 0.1226, 0.5571]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 7])\n",
      "old attention tensor([[[[0.6832, 0.0204, 0.1544, 0.0077, 0.0840, 0.0401, 0.0102],\n",
      "          [0.1547, 0.1944, 0.2144, 0.1752, 0.0881, 0.1219, 0.0512],\n",
      "          [0.0965, 0.1047, 0.1272, 0.2816, 0.1418, 0.0916, 0.1566],\n",
      "          [0.5641, 0.0842, 0.1635, 0.0229, 0.1126, 0.0381, 0.0146]],\n",
      "\n",
      "         [[0.3043, 0.0975, 0.0206, 0.2002, 0.1294, 0.2032, 0.0448],\n",
      "          [0.2136, 0.2328, 0.0053, 0.2435, 0.1402, 0.0932, 0.0713],\n",
      "          [0.0816, 0.1092, 0.0542, 0.4060, 0.2463, 0.0523, 0.0504],\n",
      "          [0.2364, 0.0985, 0.0134, 0.2625, 0.2155, 0.1202, 0.0536]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.2900, 0.7100, 0.0000, 0.0000],\n",
      "          [0.0757, 0.8007, 0.1236, 0.0000],\n",
      "          [0.0214, 0.0955, 0.5179, 0.3651]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.3857, 0.6143, 0.0000, 0.0000],\n",
      "          [0.1333, 0.6078, 0.2588, 0.0000],\n",
      "          [0.0516, 0.0310, 0.8893, 0.0282]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 7])\n",
      "old attention tensor([[[[0.0760, 0.3164, 0.0611, 0.0202, 0.0831, 0.3760, 0.0673],\n",
      "          [0.0061, 0.0425, 0.0591, 0.4576, 0.0809, 0.3238, 0.0298],\n",
      "          [0.3167, 0.1038, 0.0727, 0.0425, 0.2345, 0.1864, 0.0434],\n",
      "          [0.0189, 0.0404, 0.1050, 0.3000, 0.1401, 0.2476, 0.1480]],\n",
      "\n",
      "         [[0.0785, 0.3981, 0.0869, 0.0267, 0.0555, 0.0404, 0.3138],\n",
      "          [0.0186, 0.0349, 0.1944, 0.1317, 0.1064, 0.2903, 0.2238],\n",
      "          [0.1326, 0.1328, 0.0451, 0.0426, 0.4480, 0.0974, 0.1015],\n",
      "          [0.0997, 0.0961, 0.1453, 0.2432, 0.1670, 0.1166, 0.1321]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5428, 0.4572, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0250, 0.0402, 0.9347, 0.0000, 0.0000],\n",
      "          [0.0347, 0.0580, 0.7842, 0.1231, 0.0000],\n",
      "          [0.0129, 0.0104, 0.0195, 0.0410, 0.9162]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0282, 0.9718, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0938, 0.0120, 0.8942, 0.0000, 0.0000],\n",
      "          [0.0429, 0.8831, 0.0424, 0.0316, 0.0000],\n",
      "          [0.0305, 0.0035, 0.0608, 0.8993, 0.0059]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 7])\n",
      "old attention tensor([[[[0.5422, 0.1491, 0.0009, 0.0205, 0.1552, 0.1039, 0.0282],\n",
      "          [0.0142, 0.0184, 0.7639, 0.1041, 0.0122, 0.0171, 0.0701],\n",
      "          [0.1219, 0.6486, 0.0071, 0.0524, 0.0332, 0.0869, 0.0500],\n",
      "          [0.0444, 0.4518, 0.0026, 0.0698, 0.1080, 0.2056, 0.1179],\n",
      "          [0.1117, 0.0459, 0.1338, 0.1038, 0.3984, 0.1304, 0.0761]],\n",
      "\n",
      "         [[0.0112, 0.0466, 0.7191, 0.0371, 0.0081, 0.1039, 0.0741],\n",
      "          [0.2826, 0.0078, 0.1130, 0.0105, 0.4243, 0.1541, 0.0078],\n",
      "          [0.0155, 0.0140, 0.2242, 0.1911, 0.4169, 0.0825, 0.0557],\n",
      "          [0.2048, 0.0230, 0.4332, 0.0554, 0.0527, 0.1283, 0.1025],\n",
      "          [0.0336, 0.3464, 0.1113, 0.2252, 0.0792, 0.0374, 0.1668]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0282, 0.9718, 0.0000, 0.0000, 0.0000],\n",
      "          [0.2875, 0.0273, 0.6852, 0.0000, 0.0000],\n",
      "          [0.0032, 0.0127, 0.3018, 0.6822, 0.0000],\n",
      "          [0.0941, 0.0910, 0.1577, 0.2433, 0.4139]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0822, 0.9178, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0102, 0.0463, 0.9435, 0.0000, 0.0000],\n",
      "          [0.0454, 0.2576, 0.2819, 0.4151, 0.0000],\n",
      "          [0.0607, 0.2228, 0.1058, 0.0696, 0.5411]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 7])\n",
      "old attention tensor([[[[0.5332, 0.0214, 0.2059, 0.0138, 0.1322, 0.0703, 0.0231],\n",
      "          [0.0859, 0.1439, 0.2468, 0.2149, 0.0935, 0.1498, 0.0651],\n",
      "          [0.0623, 0.0809, 0.1283, 0.2883, 0.1697, 0.0928, 0.1776],\n",
      "          [0.4421, 0.0744, 0.2048, 0.0359, 0.1680, 0.0525, 0.0223],\n",
      "          [0.0429, 0.0522, 0.3282, 0.2230, 0.1924, 0.0612, 0.1001]],\n",
      "\n",
      "         [[0.2747, 0.0822, 0.0400, 0.1688, 0.1699, 0.2273, 0.0371],\n",
      "          [0.2298, 0.2014, 0.0045, 0.2337, 0.1895, 0.0952, 0.0459],\n",
      "          [0.0803, 0.1131, 0.0756, 0.3349, 0.2813, 0.0651, 0.0498],\n",
      "          [0.2394, 0.0902, 0.0158, 0.2229, 0.2607, 0.1308, 0.0401],\n",
      "          [0.0703, 0.0917, 0.1393, 0.3281, 0.1430, 0.1228, 0.1047]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.3938, 0.6062, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0926, 0.7887, 0.1187, 0.0000, 0.0000],\n",
      "          [0.0571, 0.1269, 0.4027, 0.4133, 0.0000],\n",
      "          [0.0437, 0.1948, 0.2601, 0.0544, 0.4470]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.2497, 0.7503, 0.0000, 0.0000, 0.0000],\n",
      "          [0.1325, 0.6226, 0.2450, 0.0000, 0.0000],\n",
      "          [0.1131, 0.0431, 0.8043, 0.0395, 0.0000],\n",
      "          [0.0262, 0.0529, 0.4197, 0.0507, 0.4505]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 7])\n",
      "old attention tensor([[[[0.2179, 0.0972, 0.0635, 0.0087, 0.0415, 0.3285, 0.2427],\n",
      "          [0.0219, 0.0161, 0.0883, 0.2270, 0.0402, 0.4812, 0.1253],\n",
      "          [0.4316, 0.0361, 0.0763, 0.0200, 0.1090, 0.2044, 0.1226],\n",
      "          [0.0435, 0.0135, 0.0986, 0.1029, 0.0573, 0.2553, 0.4288],\n",
      "          [0.1774, 0.0184, 0.0717, 0.0282, 0.0365, 0.1542, 0.5135]],\n",
      "\n",
      "         [[0.4431, 0.2878, 0.0258, 0.0055, 0.0783, 0.0314, 0.1280],\n",
      "          [0.1619, 0.0332, 0.0807, 0.0248, 0.2373, 0.2986, 0.1635],\n",
      "          [0.4943, 0.0794, 0.0140, 0.0062, 0.3168, 0.0452, 0.0440],\n",
      "          [0.5056, 0.0675, 0.0400, 0.0316, 0.2211, 0.0692, 0.0650],\n",
      "          [0.5503, 0.1590, 0.0315, 0.0075, 0.1264, 0.0263, 0.0990]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "predicted trg = ['ich', 'mochten', 'bier', 'trinken', '<eos>']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_count 1    self.capacity  20\n",
      "0  ------------------------------------------------\n",
      "DecoderLayer@trg4\n",
      "[1, 1, 64]\n",
      "src = ['i', 'want', 'to', 'drink', 'beer']\n",
      "old attention torch.Size([1, 2, 7, 7])\n",
      "old attention tensor([[[[7.0617e-03, 6.2566e-02, 6.5268e-03, 1.8069e-02, 1.1731e-01,\n",
      "           7.7246e-01, 1.6006e-02],\n",
      "          [6.8173e-02, 3.2880e-02, 4.0032e-02, 2.7190e-03, 6.5703e-01,\n",
      "           1.9834e-01, 8.3106e-04],\n",
      "          [2.8999e-02, 6.6472e-01, 1.5838e-02, 1.7661e-01, 4.7280e-03,\n",
      "           2.7017e-02, 8.2095e-02],\n",
      "          [4.1186e-02, 9.3175e-02, 2.4793e-02, 1.4046e-01, 4.2426e-02,\n",
      "           1.9505e-02, 6.3845e-01],\n",
      "          [3.5700e-03, 7.5649e-02, 5.8154e-02, 1.7450e-02, 6.9779e-03,\n",
      "           6.8369e-03, 8.3136e-01],\n",
      "          [8.2364e-02, 3.1841e-02, 3.7543e-01, 3.2663e-01, 1.9677e-02,\n",
      "           1.0683e-01, 5.7229e-02],\n",
      "          [1.4495e-02, 7.5107e-02, 2.4075e-02, 3.7526e-02, 3.6925e-01,\n",
      "           4.7144e-01, 8.1039e-03]],\n",
      "\n",
      "         [[1.2064e-02, 7.8408e-03, 9.2338e-01, 7.6240e-03, 3.3287e-02,\n",
      "           3.2985e-03, 1.2509e-02],\n",
      "          [6.0002e-02, 2.4403e-01, 1.6918e-01, 1.0096e-02, 1.5544e-01,\n",
      "           2.2650e-01, 1.3476e-01],\n",
      "          [1.8687e-01, 1.6950e-02, 4.6794e-02, 4.0063e-01, 5.9102e-02,\n",
      "           1.3988e-01, 1.4979e-01],\n",
      "          [6.8670e-01, 2.9350e-02, 8.8659e-02, 4.4366e-02, 3.3050e-02,\n",
      "           1.4448e-02, 1.0343e-01],\n",
      "          [2.7031e-01, 4.5326e-01, 9.1924e-02, 5.4269e-02, 2.6795e-02,\n",
      "           6.4051e-03, 9.7040e-02],\n",
      "          [7.1651e-01, 1.2937e-02, 3.0509e-02, 8.9633e-03, 1.7822e-01,\n",
      "           5.1946e-02, 9.0613e-04],\n",
      "          [2.0995e-02, 9.3180e-03, 1.8185e-01, 4.5505e-01, 2.5006e-02,\n",
      "           1.8798e-01, 1.1979e-01]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 7, 7])\n",
      "old attention tensor([[[[0.1327, 0.0749, 0.1216, 0.2140, 0.2639, 0.1151, 0.0779],\n",
      "          [0.0682, 0.1339, 0.1061, 0.3066, 0.1572, 0.1135, 0.1145],\n",
      "          [0.2177, 0.0419, 0.0518, 0.0165, 0.5033, 0.0223, 0.1467],\n",
      "          [0.5350, 0.0288, 0.0328, 0.0127, 0.3612, 0.0112, 0.0184],\n",
      "          [0.5063, 0.1038, 0.0888, 0.1030, 0.0680, 0.0451, 0.0850],\n",
      "          [0.2210, 0.3096, 0.0298, 0.0635, 0.2440, 0.0512, 0.0808],\n",
      "          [0.1070, 0.0728, 0.4304, 0.0490, 0.2165, 0.0756, 0.0488]],\n",
      "\n",
      "         [[0.1847, 0.1826, 0.0853, 0.1064, 0.2585, 0.1061, 0.0765],\n",
      "          [0.0283, 0.1097, 0.2250, 0.1335, 0.1960, 0.1277, 0.1798],\n",
      "          [0.0412, 0.1076, 0.6249, 0.0442, 0.0631, 0.1115, 0.0074],\n",
      "          [0.1033, 0.1580, 0.0727, 0.1024, 0.0779, 0.0737, 0.4120],\n",
      "          [0.0202, 0.1932, 0.4243, 0.1061, 0.0638, 0.0678, 0.1245],\n",
      "          [0.0900, 0.1889, 0.3631, 0.0633, 0.1475, 0.0901, 0.0571],\n",
      "          [0.0170, 0.0312, 0.6563, 0.0818, 0.0281, 0.0792, 0.1063]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 7, 7])\n",
      "old attention tensor([[[[0.0710, 0.1357, 0.0632, 0.0526, 0.5929, 0.0262, 0.0585],\n",
      "          [0.1760, 0.1124, 0.0881, 0.1274, 0.1988, 0.1401, 0.1573],\n",
      "          [0.0602, 0.1292, 0.3386, 0.2312, 0.0237, 0.0734, 0.1437],\n",
      "          [0.0542, 0.0457, 0.2704, 0.1013, 0.0171, 0.0401, 0.4711],\n",
      "          [0.1214, 0.0435, 0.2069, 0.0630, 0.0882, 0.1117, 0.3653],\n",
      "          [0.3755, 0.1763, 0.1089, 0.0347, 0.0680, 0.0298, 0.2068],\n",
      "          [0.1262, 0.0367, 0.5547, 0.0952, 0.0279, 0.0911, 0.0682]],\n",
      "\n",
      "         [[0.0186, 0.0374, 0.0321, 0.0265, 0.7759, 0.1080, 0.0016],\n",
      "          [0.0373, 0.1060, 0.1353, 0.2356, 0.1468, 0.0435, 0.2955],\n",
      "          [0.0680, 0.1198, 0.0505, 0.1241, 0.0081, 0.0704, 0.5589],\n",
      "          [0.1141, 0.1505, 0.1767, 0.1039, 0.0374, 0.1042, 0.3133],\n",
      "          [0.1151, 0.2747, 0.0182, 0.0100, 0.4931, 0.0635, 0.0256],\n",
      "          [0.1359, 0.0481, 0.0435, 0.0070, 0.5403, 0.2148, 0.0104],\n",
      "          [0.1553, 0.1983, 0.1640, 0.1825, 0.1127, 0.0457, 0.1416]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 7])\n",
      "old attention tensor([[[[0.4665, 0.2011, 0.0136, 0.0495, 0.0901, 0.0884, 0.0909]],\n",
      "\n",
      "         [[0.0954, 0.1580, 0.6370, 0.0112, 0.0479, 0.0154, 0.0351]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 7])\n",
      "old attention tensor([[[[0.6285, 0.0849, 0.0878, 0.0080, 0.1322, 0.0478, 0.0108]],\n",
      "\n",
      "         [[0.3923, 0.1373, 0.0354, 0.1434, 0.0826, 0.0517, 0.1573]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 7])\n",
      "old attention tensor([[[[0.0128, 0.9334, 0.0056, 0.0104, 0.0252, 0.0085, 0.0041]],\n",
      "\n",
      "         [[0.0173, 0.5008, 0.0809, 0.0970, 0.0170, 0.0345, 0.2526]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.5428, 0.4572]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0282, 0.9718]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.5428, 0.4572]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0282, 0.9718]]]])\n",
      "old attention torch.Size([1, 2, 2, 7])\n",
      "old attention tensor([[[[0.4665, 0.2011, 0.0136, 0.0495, 0.0901, 0.0884, 0.0909],\n",
      "          [0.0028, 0.0062, 0.9136, 0.0407, 0.0019, 0.0125, 0.0223]],\n",
      "\n",
      "         [[0.0954, 0.1580, 0.6370, 0.0112, 0.0479, 0.0154, 0.0351],\n",
      "          [0.2833, 0.0092, 0.0871, 0.0235, 0.4910, 0.0944, 0.0115]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0090, 0.9910]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.1394, 0.8606]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0090, 0.9910]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.1394, 0.8606]]]])\n",
      "old attention torch.Size([1, 2, 2, 7])\n",
      "old attention tensor([[[[0.6285, 0.0849, 0.0878, 0.0080, 0.1322, 0.0478, 0.0108],\n",
      "          [0.0838, 0.1737, 0.1704, 0.2616, 0.0698, 0.1747, 0.0661]],\n",
      "\n",
      "         [[0.3923, 0.1373, 0.0354, 0.1434, 0.0826, 0.0517, 0.1573],\n",
      "          [0.0840, 0.0548, 0.0155, 0.2747, 0.2163, 0.3229, 0.0317]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.2584, 0.7416]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.4500, 0.5500]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.2584, 0.7416]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.4500, 0.5500]]]])\n",
      "old attention torch.Size([1, 2, 2, 7])\n",
      "old attention tensor([[[[0.0128, 0.9334, 0.0056, 0.0104, 0.0252, 0.0085, 0.0041],\n",
      "          [0.0076, 0.0143, 0.0994, 0.5354, 0.1783, 0.1459, 0.0191]],\n",
      "\n",
      "         [[0.0173, 0.5008, 0.0809, 0.0970, 0.0170, 0.0345, 0.2526],\n",
      "          [0.0012, 0.0069, 0.1220, 0.7960, 0.0194, 0.0225, 0.0320]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.5428, 0.4572, 0.0000],\n",
      "          [0.0142, 0.0098, 0.9760]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.0282, 0.9718, 0.0000],\n",
      "          [0.7082, 0.0803, 0.2115]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 7])\n",
      "old attention tensor([[[[0.4939, 0.2029, 0.0012, 0.0277, 0.1815, 0.0664, 0.0264],\n",
      "          [0.0075, 0.0151, 0.8036, 0.0921, 0.0083, 0.0315, 0.0418],\n",
      "          [0.0683, 0.0670, 0.1963, 0.1463, 0.3687, 0.0933, 0.0601]],\n",
      "\n",
      "         [[0.0098, 0.0444, 0.8535, 0.0249, 0.0068, 0.0078, 0.0527],\n",
      "          [0.3279, 0.0102, 0.0876, 0.0090, 0.4299, 0.1281, 0.0072],\n",
      "          [0.0429, 0.2733, 0.1653, 0.1869, 0.0911, 0.0883, 0.1523]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.0478, 0.9522, 0.0000],\n",
      "          [0.3117, 0.2051, 0.4832]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.0271, 0.9729, 0.0000],\n",
      "          [0.0518, 0.4351, 0.5131]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 7])\n",
      "old attention tensor([[[[0.4226, 0.0386, 0.1956, 0.0198, 0.1957, 0.0914, 0.0364],\n",
      "          [0.1135, 0.2246, 0.2373, 0.1364, 0.1478, 0.0869, 0.0535],\n",
      "          [0.0285, 0.0551, 0.2098, 0.1173, 0.1686, 0.3536, 0.0671]],\n",
      "\n",
      "         [[0.2987, 0.1017, 0.0620, 0.1892, 0.1693, 0.1230, 0.0562],\n",
      "          [0.1793, 0.1430, 0.0047, 0.2213, 0.1330, 0.2750, 0.0436],\n",
      "          [0.0893, 0.0954, 0.0804, 0.2108, 0.1295, 0.2918, 0.1028]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.3757, 0.6243, 0.0000],\n",
      "          [0.0864, 0.2573, 0.6562]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.0887, 0.9113, 0.0000],\n",
      "          [0.0467, 0.1367, 0.8166]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 7])\n",
      "old attention tensor([[[[0.4590, 0.1977, 0.0349, 0.0044, 0.0311, 0.0938, 0.1790],\n",
      "          [0.1503, 0.0871, 0.1271, 0.1356, 0.0671, 0.2397, 0.1931],\n",
      "          [0.5036, 0.0419, 0.0388, 0.0080, 0.0271, 0.1457, 0.2349]],\n",
      "\n",
      "         [[0.3883, 0.3556, 0.0219, 0.0038, 0.0451, 0.0597, 0.1256],\n",
      "          [0.2269, 0.0654, 0.0621, 0.0117, 0.1869, 0.1909, 0.2561],\n",
      "          [0.4121, 0.2649, 0.0294, 0.0046, 0.0877, 0.0727, 0.1287]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5428, 0.4572, 0.0000, 0.0000],\n",
      "          [0.0142, 0.0098, 0.9760, 0.0000],\n",
      "          [0.0145, 0.0243, 0.9095, 0.0516]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0282, 0.9718, 0.0000, 0.0000],\n",
      "          [0.7082, 0.0803, 0.2115, 0.0000],\n",
      "          [0.0433, 0.8921, 0.0327, 0.0319]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 7])\n",
      "old attention tensor([[[[0.5690, 0.1651, 0.0010, 0.0218, 0.1522, 0.0607, 0.0302],\n",
      "          [0.0108, 0.0151, 0.7870, 0.0874, 0.0084, 0.0350, 0.0563],\n",
      "          [0.0943, 0.0610, 0.1641, 0.1251, 0.3884, 0.0952, 0.0719],\n",
      "          [0.0459, 0.5786, 0.0042, 0.0758, 0.1008, 0.0719, 0.1229]],\n",
      "\n",
      "         [[0.0113, 0.0543, 0.8231, 0.0300, 0.0078, 0.0090, 0.0645],\n",
      "          [0.3314, 0.0104, 0.0843, 0.0087, 0.4333, 0.1247, 0.0072],\n",
      "          [0.0365, 0.3009, 0.1530, 0.1902, 0.0808, 0.0785, 0.1601],\n",
      "          [0.2163, 0.0222, 0.3352, 0.0421, 0.0512, 0.2464, 0.0866]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0356, 0.9644, 0.0000, 0.0000],\n",
      "          [0.2712, 0.2300, 0.4987, 0.0000],\n",
      "          [0.0065, 0.0225, 0.2414, 0.7296]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0353, 0.9647, 0.0000, 0.0000],\n",
      "          [0.0503, 0.4127, 0.5370, 0.0000],\n",
      "          [0.0162, 0.1537, 0.6240, 0.2061]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 7])\n",
      "old attention tensor([[[[0.5657, 0.0228, 0.1754, 0.0142, 0.1231, 0.0797, 0.0191],\n",
      "          [0.1375, 0.1869, 0.2663, 0.1703, 0.1043, 0.0896, 0.0451],\n",
      "          [0.0362, 0.0374, 0.2226, 0.1119, 0.1214, 0.4205, 0.0499],\n",
      "          [0.4206, 0.0807, 0.2117, 0.0325, 0.1518, 0.0884, 0.0143]],\n",
      "\n",
      "         [[0.3432, 0.0491, 0.0581, 0.1861, 0.2124, 0.1264, 0.0246],\n",
      "          [0.2064, 0.0762, 0.0057, 0.2131, 0.1645, 0.3111, 0.0230],\n",
      "          [0.0976, 0.0486, 0.0955, 0.2332, 0.1519, 0.3184, 0.0548],\n",
      "          [0.2200, 0.0400, 0.0145, 0.1623, 0.2327, 0.3105, 0.0200]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.3233, 0.6767, 0.0000, 0.0000],\n",
      "          [0.0390, 0.2047, 0.7563, 0.0000],\n",
      "          [0.0243, 0.0499, 0.6290, 0.2968]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.2280, 0.7720, 0.0000, 0.0000],\n",
      "          [0.0301, 0.0669, 0.9031, 0.0000],\n",
      "          [0.0634, 0.0353, 0.8590, 0.0423]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 7])\n",
      "old attention tensor([[[[0.3948, 0.1429, 0.0577, 0.0070, 0.0545, 0.1112, 0.2318],\n",
      "          [0.0554, 0.0492, 0.1297, 0.2559, 0.1006, 0.2207, 0.1885],\n",
      "          [0.3161, 0.0286, 0.0568, 0.0173, 0.0513, 0.1848, 0.3451],\n",
      "          [0.0846, 0.0199, 0.0894, 0.0731, 0.1001, 0.2931, 0.3398]],\n",
      "\n",
      "         [[0.3326, 0.3883, 0.0517, 0.0118, 0.0366, 0.0538, 0.1253],\n",
      "          [0.1711, 0.0606, 0.1994, 0.0598, 0.1302, 0.1482, 0.2306],\n",
      "          [0.3739, 0.2885, 0.0737, 0.0199, 0.0649, 0.0579, 0.1213],\n",
      "          [0.3992, 0.0925, 0.0741, 0.0630, 0.1054, 0.1973, 0.0685]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "predicted trg = ['ich', 'trinken', 'bier', '<eos>']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_count 1    self.capacity  20\n",
      "0  ------------------------------------------------\n",
      "DecoderLayer@trg4\n",
      "[1, 1, 64]\n",
      "src = ['i', 'want', 'to', 'read', 'book']\n",
      "old attention torch.Size([1, 2, 7, 7])\n",
      "old attention tensor([[[[4.2110e-02, 3.7310e-01, 3.8921e-02, 1.0775e-01, 1.4333e-01,\n",
      "           1.9935e-01, 9.5445e-02],\n",
      "          [3.1618e-02, 1.5250e-02, 1.8566e-02, 1.2610e-03, 3.0672e-02,\n",
      "           9.0225e-01, 3.8543e-04],\n",
      "          [2.4610e-02, 5.6411e-01, 1.3441e-02, 1.4988e-01, 1.5030e-01,\n",
      "           2.7997e-02, 6.9669e-02],\n",
      "          [1.0277e-02, 2.3251e-02, 6.1867e-03, 3.5050e-02, 3.6854e-03,\n",
      "           7.6223e-01, 1.5932e-01],\n",
      "          [8.4879e-03, 1.7495e-04, 3.6307e-05, 2.7650e-04, 1.3620e-03,\n",
      "           9.8840e-01, 1.2664e-03],\n",
      "          [8.3474e-02, 2.1927e-02, 1.4598e-01, 4.2653e-01, 1.1282e-01,\n",
      "           9.1552e-02, 1.1772e-01],\n",
      "          [2.6430e-02, 1.3695e-01, 4.3897e-02, 6.8424e-02, 7.7254e-02,\n",
      "           6.3227e-01, 1.4776e-02]],\n",
      "\n",
      "         [[1.2467e-02, 8.1026e-03, 9.5420e-01, 7.8786e-03, 3.3906e-03,\n",
      "           1.0317e-03, 1.2927e-02],\n",
      "          [8.2666e-02, 3.3620e-01, 2.3308e-01, 1.3909e-02, 2.1626e-02,\n",
      "           1.2686e-01, 1.8566e-01],\n",
      "          [1.8756e-01, 1.7013e-02, 4.6968e-02, 4.0212e-01, 2.4676e-02,\n",
      "           1.7132e-01, 1.5034e-01],\n",
      "          [3.7156e-01, 1.5881e-02, 4.7972e-02, 2.4005e-02, 4.3777e-01,\n",
      "           4.6849e-02, 5.5962e-02],\n",
      "          [1.4332e-01, 5.3845e-03, 4.5599e-01, 8.2371e-03, 3.6337e-03,\n",
      "           1.5865e-02, 3.6757e-01],\n",
      "          [1.5447e-01, 1.3600e-01, 4.3562e-03, 8.0014e-03, 2.1155e-01,\n",
      "           3.4599e-01, 1.3963e-01],\n",
      "          [9.4008e-03, 4.1722e-03, 8.1427e-02, 2.0375e-01, 6.2779e-01,\n",
      "           1.9814e-02, 5.3639e-02]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 7, 7])\n",
      "old attention tensor([[[[0.0929, 0.0465, 0.0927, 0.1556, 0.4544, 0.1094, 0.0485],\n",
      "          [0.0539, 0.1174, 0.0961, 0.2701, 0.1372, 0.2359, 0.0895],\n",
      "          [0.3313, 0.0679, 0.0694, 0.0236, 0.1585, 0.0835, 0.2658],\n",
      "          [0.2349, 0.0153, 0.0196, 0.0084, 0.6837, 0.0253, 0.0129],\n",
      "          [0.1054, 0.0611, 0.0791, 0.0809, 0.5409, 0.0482, 0.0844],\n",
      "          [0.2497, 0.0640, 0.0761, 0.0739, 0.3905, 0.0903, 0.0555],\n",
      "          [0.0404, 0.0315, 0.1669, 0.0207, 0.1292, 0.5924, 0.0189]],\n",
      "\n",
      "         [[0.2101, 0.2044, 0.1085, 0.1500, 0.1100, 0.1079, 0.1092],\n",
      "          [0.0325, 0.0871, 0.2486, 0.1701, 0.1422, 0.1434, 0.1761],\n",
      "          [0.0435, 0.0898, 0.5461, 0.0536, 0.0556, 0.2042, 0.0072],\n",
      "          [0.0835, 0.1107, 0.0750, 0.1166, 0.1190, 0.0656, 0.4297],\n",
      "          [0.1392, 0.1886, 0.3320, 0.1184, 0.0860, 0.0732, 0.0626],\n",
      "          [0.1265, 0.2258, 0.0420, 0.1376, 0.1170, 0.1127, 0.2383],\n",
      "          [0.0195, 0.0256, 0.5857, 0.0933, 0.1094, 0.0525, 0.1141]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 7, 7])\n",
      "old attention tensor([[[[0.1409, 0.2749, 0.0916, 0.1539, 0.0660, 0.1739, 0.0989],\n",
      "          [0.1534, 0.0940, 0.0388, 0.1014, 0.4007, 0.0711, 0.1405],\n",
      "          [0.0442, 0.1710, 0.3443, 0.2375, 0.0269, 0.0500, 0.1261],\n",
      "          [0.0408, 0.0486, 0.1460, 0.1219, 0.0729, 0.1242, 0.4456],\n",
      "          [0.1320, 0.1770, 0.0377, 0.1280, 0.0974, 0.1097, 0.3183],\n",
      "          [0.1355, 0.3385, 0.0924, 0.1169, 0.2073, 0.0207, 0.0888],\n",
      "          [0.2186, 0.0432, 0.3483, 0.1242, 0.1443, 0.0647, 0.0567]],\n",
      "\n",
      "         [[0.1372, 0.1717, 0.2260, 0.1778, 0.2574, 0.0197, 0.0103],\n",
      "          [0.0256, 0.0691, 0.1829, 0.2815, 0.1445, 0.0184, 0.2780],\n",
      "          [0.0493, 0.0635, 0.0207, 0.0664, 0.0696, 0.3901, 0.3403],\n",
      "          [0.1221, 0.1167, 0.1822, 0.1200, 0.1037, 0.0866, 0.2687],\n",
      "          [0.1308, 0.0066, 0.4896, 0.0820, 0.2589, 0.0123, 0.0198],\n",
      "          [0.2085, 0.1056, 0.1858, 0.0589, 0.1268, 0.0213, 0.2930],\n",
      "          [0.1411, 0.1034, 0.2108, 0.1763, 0.2004, 0.0492, 0.1187]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 7])\n",
      "old attention tensor([[[[0.4462, 0.1895, 0.0142, 0.0379, 0.1271, 0.0907, 0.0943]],\n",
      "\n",
      "         [[0.1058, 0.1597, 0.5802, 0.0122, 0.0685, 0.0360, 0.0376]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 7])\n",
      "old attention tensor([[[[0.7001, 0.0984, 0.1279, 0.0107, 0.0264, 0.0275, 0.0089]],\n",
      "\n",
      "         [[0.1908, 0.1017, 0.0215, 0.0646, 0.4078, 0.1030, 0.1106]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 7])\n",
      "old attention tensor([[[[0.0117, 0.9601, 0.0073, 0.0109, 0.0040, 0.0043, 0.0018]],\n",
      "\n",
      "         [[0.0098, 0.4223, 0.0529, 0.1464, 0.0328, 0.0816, 0.2542]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.5428, 0.4572]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0282, 0.9718]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.5428, 0.4572]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0282, 0.9718]]]])\n",
      "old attention torch.Size([1, 2, 2, 7])\n",
      "old attention tensor([[[[0.4462, 0.1895, 0.0142, 0.0379, 0.1271, 0.0907, 0.0943],\n",
      "          [0.0039, 0.0075, 0.8372, 0.0562, 0.0194, 0.0497, 0.0261]],\n",
      "\n",
      "         [[0.1058, 0.1597, 0.5802, 0.0122, 0.0685, 0.0360, 0.0376],\n",
      "          [0.3480, 0.0112, 0.1326, 0.0458, 0.0623, 0.3864, 0.0137]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0100, 0.9900]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.1517, 0.8483]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0100, 0.9900]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.1517, 0.8483]]]])\n",
      "old attention torch.Size([1, 2, 2, 7])\n",
      "old attention tensor([[[[0.7001, 0.0984, 0.1279, 0.0107, 0.0264, 0.0275, 0.0089],\n",
      "          [0.0608, 0.1359, 0.1146, 0.2690, 0.2224, 0.1383, 0.0590]],\n",
      "\n",
      "         [[0.1908, 0.1017, 0.0215, 0.0646, 0.4078, 0.1030, 0.1106],\n",
      "          [0.1175, 0.0909, 0.0264, 0.3606, 0.0494, 0.2831, 0.0720]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.3287, 0.6713]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.2795, 0.7205]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.3287, 0.6713]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.2795, 0.7205]]]])\n",
      "old attention torch.Size([1, 2, 2, 7])\n",
      "old attention tensor([[[[1.1717e-02, 9.6009e-01, 7.3162e-03, 1.0868e-02, 3.9684e-03,\n",
      "           4.2660e-03, 1.7736e-03],\n",
      "          [7.9565e-03, 1.3747e-02, 2.1022e-01, 5.6785e-01, 1.7375e-02,\n",
      "           1.7478e-01, 8.0798e-03]],\n",
      "\n",
      "         [[9.8337e-03, 4.2225e-01, 5.2850e-02, 1.4644e-01, 3.2789e-02,\n",
      "           8.1650e-02, 2.5419e-01],\n",
      "          [6.3250e-04, 6.2369e-03, 7.5236e-02, 7.3794e-01, 5.7820e-03,\n",
      "           1.3693e-01, 3.7244e-02]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [5.4283e-01, 4.5717e-01, 0.0000e+00],\n",
      "          [5.7928e-03, 9.5962e-04, 9.9325e-01]],\n",
      "\n",
      "         [[1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [2.8229e-02, 9.7177e-01, 0.0000e+00],\n",
      "          [2.5488e-03, 1.1255e-01, 8.8490e-01]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 7])\n",
      "old attention tensor([[[[0.5809, 0.2639, 0.0040, 0.0316, 0.0563, 0.0313, 0.0320],\n",
      "          [0.0069, 0.0148, 0.8031, 0.0799, 0.0184, 0.0474, 0.0295],\n",
      "          [0.2263, 0.0610, 0.2415, 0.2272, 0.0677, 0.0969, 0.0795]],\n",
      "\n",
      "         [[0.0403, 0.1147, 0.4541, 0.0239, 0.2788, 0.0204, 0.0677],\n",
      "          [0.7221, 0.0185, 0.0651, 0.0119, 0.0820, 0.0923, 0.0082],\n",
      "          [0.0612, 0.0903, 0.1695, 0.0315, 0.5976, 0.0216, 0.0282]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.0292, 0.9708, 0.0000],\n",
      "          [0.0043, 0.0671, 0.9285]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.0142, 0.9858, 0.0000],\n",
      "          [0.0221, 0.6049, 0.3730]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 7])\n",
      "old attention tensor([[[[0.4279, 0.0458, 0.2799, 0.0816, 0.0455, 0.0810, 0.0384],\n",
      "          [0.0773, 0.1815, 0.1498, 0.3835, 0.0877, 0.0662, 0.0541],\n",
      "          [0.2317, 0.2099, 0.1023, 0.1767, 0.1062, 0.1301, 0.0431]],\n",
      "\n",
      "         [[0.3915, 0.0700, 0.1208, 0.2079, 0.0658, 0.0942, 0.0498],\n",
      "          [0.2338, 0.1392, 0.0196, 0.2034, 0.0373, 0.3007, 0.0660],\n",
      "          [0.1285, 0.2317, 0.0776, 0.2912, 0.0602, 0.0959, 0.1149]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.3421, 0.6579, 0.0000],\n",
      "          [0.1012, 0.3442, 0.5546]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.2823, 0.7177, 0.0000],\n",
      "          [0.0833, 0.0654, 0.8514]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 7])\n",
      "old attention tensor([[[[0.2835, 0.2675, 0.2324, 0.0417, 0.0580, 0.0694, 0.0475],\n",
      "          [0.0164, 0.0478, 0.1795, 0.5531, 0.0198, 0.1676, 0.0158],\n",
      "          [0.0281, 0.0405, 0.2426, 0.3889, 0.0514, 0.1944, 0.0540]],\n",
      "\n",
      "         [[0.0338, 0.4127, 0.0905, 0.3620, 0.0151, 0.0360, 0.0499],\n",
      "          [0.0023, 0.0259, 0.0880, 0.7722, 0.0096, 0.0669, 0.0351],\n",
      "          [0.0102, 0.0632, 0.0554, 0.8099, 0.0038, 0.0400, 0.0174]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [5.4283e-01, 4.5717e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [5.7928e-03, 9.5962e-04, 9.9325e-01, 0.0000e+00],\n",
      "          [3.2158e-02, 5.3844e-02, 8.9735e-01, 1.6650e-02]],\n",
      "\n",
      "         [[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [2.8229e-02, 9.7177e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [2.5488e-03, 1.1255e-01, 8.8490e-01, 0.0000e+00],\n",
      "          [5.3481e-03, 7.5643e-01, 2.1576e-01, 2.2460e-02]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 7])\n",
      "old attention tensor([[[[0.6333, 0.1928, 0.0043, 0.0279, 0.0654, 0.0390, 0.0372],\n",
      "          [0.0058, 0.0086, 0.8280, 0.0609, 0.0176, 0.0501, 0.0289],\n",
      "          [0.2211, 0.0431, 0.2625, 0.1967, 0.0742, 0.1140, 0.0884],\n",
      "          [0.1669, 0.0481, 0.2719, 0.3383, 0.0462, 0.1047, 0.0240]],\n",
      "\n",
      "         [[0.0286, 0.1102, 0.4803, 0.0274, 0.2523, 0.0248, 0.0764],\n",
      "          [0.6504, 0.0205, 0.0783, 0.0160, 0.0860, 0.1382, 0.0105],\n",
      "          [0.0495, 0.0934, 0.1852, 0.0398, 0.5684, 0.0291, 0.0345],\n",
      "          [0.1055, 0.0138, 0.1674, 0.0522, 0.3960, 0.2282, 0.0369]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0224, 0.9776, 0.0000, 0.0000],\n",
      "          [0.0040, 0.0722, 0.9239, 0.0000],\n",
      "          [0.0043, 0.0522, 0.4886, 0.4549]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0184, 0.9816, 0.0000, 0.0000],\n",
      "          [0.0254, 0.5991, 0.3755, 0.0000],\n",
      "          [0.0404, 0.2231, 0.3152, 0.4213]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 7])\n",
      "old attention tensor([[[[0.3934, 0.0382, 0.2781, 0.1067, 0.0480, 0.0905, 0.0450],\n",
      "          [0.0560, 0.1449, 0.1217, 0.4503, 0.0935, 0.0718, 0.0619],\n",
      "          [0.2005, 0.1846, 0.0911, 0.2008, 0.1243, 0.1495, 0.0492],\n",
      "          [0.0832, 0.0835, 0.1545, 0.5009, 0.0528, 0.0906, 0.0346]],\n",
      "\n",
      "         [[0.4444, 0.0644, 0.1038, 0.2051, 0.0590, 0.0811, 0.0424],\n",
      "          [0.2430, 0.1418, 0.0207, 0.2149, 0.0330, 0.2806, 0.0660],\n",
      "          [0.1363, 0.2224, 0.0737, 0.3019, 0.0584, 0.0954, 0.1118],\n",
      "          [0.1538, 0.0745, 0.1051, 0.3049, 0.0545, 0.2053, 0.1019]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.3586, 0.6414, 0.0000, 0.0000],\n",
      "          [0.1303, 0.3410, 0.5287, 0.0000],\n",
      "          [0.0581, 0.1640, 0.5411, 0.2367]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.2762, 0.7238, 0.0000, 0.0000],\n",
      "          [0.1193, 0.0831, 0.7975, 0.0000],\n",
      "          [0.0395, 0.1097, 0.6330, 0.2178]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 7])\n",
      "old attention tensor([[[[0.2726, 0.1538, 0.3427, 0.0323, 0.0759, 0.0714, 0.0512],\n",
      "          [0.0175, 0.0261, 0.2539, 0.4706, 0.0302, 0.1808, 0.0209],\n",
      "          [0.0286, 0.0222, 0.2986, 0.3210, 0.0685, 0.1972, 0.0639],\n",
      "          [0.0936, 0.0213, 0.3795, 0.1998, 0.0786, 0.1811, 0.0462]],\n",
      "\n",
      "         [[0.0328, 0.3406, 0.0891, 0.4302, 0.0154, 0.0429, 0.0491],\n",
      "          [0.0027, 0.0202, 0.0752, 0.7770, 0.0104, 0.0824, 0.0322],\n",
      "          [0.0122, 0.0530, 0.0540, 0.8051, 0.0046, 0.0542, 0.0170],\n",
      "          [0.0133, 0.0479, 0.0651, 0.7087, 0.0102, 0.1221, 0.0327]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [5.4283e-01, 4.5717e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [5.7928e-03, 9.5962e-04, 9.9325e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [3.2158e-02, 5.3844e-02, 8.9735e-01, 1.6650e-02, 0.0000e+00],\n",
      "          [1.8754e-03, 3.6060e-04, 4.1220e-01, 1.1487e-03, 5.8442e-01]],\n",
      "\n",
      "         [[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [2.8229e-02, 9.7177e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [2.5488e-03, 1.1255e-01, 8.8490e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [5.3481e-03, 7.5643e-01, 2.1576e-01, 2.2460e-02, 0.0000e+00],\n",
      "          [9.4989e-04, 4.2061e-02, 4.3012e-01, 5.9595e-02, 4.6727e-01]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 7])\n",
      "old attention tensor([[[[0.6119, 0.2404, 0.0035, 0.0275, 0.0554, 0.0286, 0.0325],\n",
      "          [0.0072, 0.0134, 0.8139, 0.0725, 0.0181, 0.0447, 0.0302],\n",
      "          [0.2528, 0.0623, 0.2217, 0.2088, 0.0725, 0.0952, 0.0868],\n",
      "          [0.1932, 0.0691, 0.2275, 0.3565, 0.0445, 0.0856, 0.0236],\n",
      "          [0.2626, 0.0533, 0.2331, 0.1973, 0.0753, 0.0856, 0.0927]],\n",
      "\n",
      "         [[0.0299, 0.1272, 0.3744, 0.0280, 0.3333, 0.0192, 0.0880],\n",
      "          [0.6723, 0.0228, 0.0625, 0.0148, 0.1171, 0.0992, 0.0113],\n",
      "          [0.0448, 0.0946, 0.1353, 0.0354, 0.6343, 0.0202, 0.0354],\n",
      "          [0.1011, 0.0155, 0.1318, 0.0493, 0.5009, 0.1607, 0.0405],\n",
      "          [0.0487, 0.1017, 0.1032, 0.0345, 0.6562, 0.0198, 0.0358]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0339, 0.9661, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0067, 0.0721, 0.9212, 0.0000, 0.0000],\n",
      "          [0.0072, 0.0474, 0.5379, 0.4075, 0.0000],\n",
      "          [0.0028, 0.0343, 0.3704, 0.1628, 0.4297]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0138, 0.9862, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0251, 0.5606, 0.4144, 0.0000, 0.0000],\n",
      "          [0.0354, 0.2299, 0.3270, 0.4076, 0.0000],\n",
      "          [0.0113, 0.2061, 0.1893, 0.3681, 0.2253]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 7])\n",
      "old attention tensor([[[[0.2594, 0.0347, 0.2820, 0.1817, 0.0531, 0.1173, 0.0719],\n",
      "          [0.0356, 0.1032, 0.1057, 0.5553, 0.0720, 0.0604, 0.0677],\n",
      "          [0.1414, 0.1440, 0.1006, 0.2819, 0.1067, 0.1584, 0.0670],\n",
      "          [0.0509, 0.0600, 0.1403, 0.5864, 0.0416, 0.0814, 0.0394],\n",
      "          [0.1323, 0.1440, 0.0968, 0.2966, 0.1045, 0.1552, 0.0706]],\n",
      "\n",
      "         [[0.4171, 0.0457, 0.1903, 0.2025, 0.0313, 0.0809, 0.0322],\n",
      "          [0.2852, 0.1287, 0.0340, 0.2098, 0.0231, 0.2644, 0.0547],\n",
      "          [0.1520, 0.1756, 0.1374, 0.3096, 0.0378, 0.0949, 0.0927],\n",
      "          [0.1702, 0.0623, 0.1729, 0.2931, 0.0340, 0.1857, 0.0818],\n",
      "          [0.1377, 0.1509, 0.1691, 0.3241, 0.0333, 0.0966, 0.0884]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4211, 0.5789, 0.0000, 0.0000, 0.0000],\n",
      "          [0.1787, 0.3359, 0.4854, 0.0000, 0.0000],\n",
      "          [0.0957, 0.1448, 0.5359, 0.2236, 0.0000],\n",
      "          [0.1040, 0.1640, 0.2942, 0.1692, 0.2686]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4195, 0.5805, 0.0000, 0.0000, 0.0000],\n",
      "          [0.1994, 0.0704, 0.7302, 0.0000, 0.0000],\n",
      "          [0.0842, 0.0887, 0.6706, 0.1564, 0.0000],\n",
      "          [0.1101, 0.0426, 0.4377, 0.0596, 0.3500]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 7])\n",
      "old attention tensor([[[[0.2667, 0.0482, 0.3223, 0.0384, 0.0833, 0.1249, 0.1162],\n",
      "          [0.0229, 0.0134, 0.2480, 0.3672, 0.0389, 0.2579, 0.0518],\n",
      "          [0.0366, 0.0123, 0.2568, 0.2372, 0.0697, 0.2635, 0.1240],\n",
      "          [0.0939, 0.0097, 0.3109, 0.1540, 0.0879, 0.2421, 0.1015],\n",
      "          [0.0350, 0.0119, 0.2396, 0.2516, 0.0642, 0.2756, 0.1222]],\n",
      "\n",
      "         [[0.0949, 0.3489, 0.0924, 0.3744, 0.0229, 0.0381, 0.0284],\n",
      "          [0.0135, 0.0386, 0.0873, 0.7380, 0.0215, 0.0746, 0.0265],\n",
      "          [0.0545, 0.0967, 0.0766, 0.6919, 0.0109, 0.0531, 0.0163],\n",
      "          [0.0566, 0.0783, 0.0762, 0.6529, 0.0180, 0.0944, 0.0237],\n",
      "          [0.0494, 0.0889, 0.0821, 0.7006, 0.0101, 0.0534, 0.0155]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "predicted trg = ['ich', 'lesen', 'zeitung', 'lesen', '<eos>']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_count 1    self.capacity  20\n",
      "0  ------------------------------------------------\n",
      "DecoderLayer@trg4\n",
      "[1, 1, 64]\n",
      "src = ['i', 'want', 'to', 'read', 'newspaper']\n",
      "old attention torch.Size([1, 2, 7, 7])\n",
      "old attention tensor([[[[1.6357e-02, 1.4493e-01, 1.5118e-02, 4.1855e-02, 5.5674e-02,\n",
      "           6.8899e-01, 3.7075e-02],\n",
      "          [1.3308e-01, 6.4186e-02, 7.8147e-02, 5.3077e-03, 1.2910e-01,\n",
      "           5.8856e-01, 1.6223e-03],\n",
      "          [2.3102e-02, 5.2955e-01, 1.2617e-02, 1.4069e-01, 1.4109e-01,\n",
      "           8.7549e-02, 6.5401e-02],\n",
      "          [1.8179e-02, 4.1126e-02, 1.0943e-02, 6.1998e-02, 6.5189e-03,\n",
      "           5.7943e-01, 2.8181e-01],\n",
      "          [3.5514e-02, 7.3201e-04, 1.5191e-04, 1.1569e-03, 5.6989e-03,\n",
      "           9.5145e-01, 5.2987e-03],\n",
      "          [2.6561e-01, 3.7154e-02, 4.4110e-01, 3.7559e-02, 1.8371e-01,\n",
      "           1.2975e-02, 2.1894e-02],\n",
      "          [1.0794e-02, 5.5928e-02, 1.7927e-02, 2.7944e-02, 3.1550e-02,\n",
      "           8.4982e-01, 6.0346e-03]],\n",
      "\n",
      "         [[1.1807e-02, 7.6738e-03, 9.0371e-01, 7.4617e-03, 3.2112e-03,\n",
      "           5.3890e-02, 1.2243e-02],\n",
      "          [7.1567e-02, 2.9106e-01, 2.0179e-01, 1.2042e-02, 1.8722e-02,\n",
      "           2.4409e-01, 1.6073e-01],\n",
      "          [2.2230e-01, 2.0164e-02, 5.5666e-02, 4.7659e-01, 2.9246e-02,\n",
      "           1.7854e-02, 1.7819e-01],\n",
      "          [3.2520e-01, 1.3899e-02, 4.1986e-02, 2.1010e-02, 3.8315e-01,\n",
      "           1.6577e-01, 4.8980e-02],\n",
      "          [1.3471e-01, 5.0610e-03, 4.2860e-01, 7.7422e-03, 3.4154e-03,\n",
      "           7.4995e-02, 3.4549e-01],\n",
      "          [2.1951e-03, 4.1519e-02, 6.3690e-01, 2.7981e-02, 2.0468e-01,\n",
      "           3.4624e-02, 5.2096e-02],\n",
      "          [9.4234e-03, 4.1822e-03, 8.1622e-02, 2.0424e-01, 6.2930e-01,\n",
      "           1.7462e-02, 5.3768e-02]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 7, 7])\n",
      "old attention tensor([[[[0.0688, 0.0401, 0.0869, 0.1459, 0.3601, 0.2493, 0.0489],\n",
      "          [0.0551, 0.1200, 0.0942, 0.2680, 0.1489, 0.2020, 0.1119],\n",
      "          [0.3024, 0.0674, 0.0568, 0.0236, 0.1311, 0.1680, 0.2507],\n",
      "          [0.2027, 0.0129, 0.0140, 0.0070, 0.6309, 0.1213, 0.0112],\n",
      "          [0.1062, 0.0618, 0.0732, 0.0828, 0.4789, 0.1089, 0.0882],\n",
      "          [0.0612, 0.0845, 0.3307, 0.1744, 0.0269, 0.2622, 0.0600],\n",
      "          [0.0547, 0.0454, 0.2119, 0.0311, 0.1943, 0.4313, 0.0314]],\n",
      "\n",
      "         [[0.2269, 0.2229, 0.1110, 0.1678, 0.0914, 0.0669, 0.1131],\n",
      "          [0.0272, 0.0749, 0.1893, 0.1337, 0.1057, 0.3399, 0.1293],\n",
      "          [0.0555, 0.1000, 0.6416, 0.0719, 0.0641, 0.0594, 0.0075],\n",
      "          [0.0454, 0.0681, 0.0464, 0.0719, 0.0669, 0.4768, 0.2244],\n",
      "          [0.1276, 0.1676, 0.2383, 0.1067, 0.0671, 0.2454, 0.0472],\n",
      "          [0.7002, 0.0353, 0.1046, 0.1110, 0.0181, 0.0103, 0.0204],\n",
      "          [0.0207, 0.0264, 0.5220, 0.0970, 0.1013, 0.1281, 0.1046]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 7, 7])\n",
      "old attention tensor([[[[0.1530, 0.3376, 0.0926, 0.1504, 0.0921, 0.0943, 0.0801],\n",
      "          [0.1224, 0.0849, 0.0287, 0.0698, 0.3245, 0.2763, 0.0935],\n",
      "          [0.0518, 0.1613, 0.3379, 0.1957, 0.0272, 0.1304, 0.0956],\n",
      "          [0.0295, 0.0387, 0.1149, 0.0992, 0.0610, 0.2940, 0.3627],\n",
      "          [0.1338, 0.1463, 0.0385, 0.1091, 0.0925, 0.2292, 0.2506],\n",
      "          [0.0579, 0.0239, 0.1771, 0.1241, 0.0183, 0.3986, 0.2001],\n",
      "          [0.2106, 0.0497, 0.3496, 0.1299, 0.1358, 0.0704, 0.0538]],\n",
      "\n",
      "         [[0.1320, 0.1271, 0.2571, 0.2028, 0.2265, 0.0431, 0.0115],\n",
      "          [0.0236, 0.0486, 0.1293, 0.2877, 0.1415, 0.1134, 0.2560],\n",
      "          [0.0604, 0.1197, 0.0263, 0.1148, 0.1103, 0.0741, 0.4944],\n",
      "          [0.0818, 0.1005, 0.1281, 0.1085, 0.0782, 0.2701, 0.2328],\n",
      "          [0.1287, 0.0065, 0.4463, 0.0964, 0.2220, 0.0802, 0.0199],\n",
      "          [0.2056, 0.0763, 0.0663, 0.1022, 0.3712, 0.0670, 0.1114],\n",
      "          [0.1199, 0.0917, 0.1991, 0.1866, 0.1652, 0.1228, 0.1147]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 7])\n",
      "old attention tensor([[[[0.4611, 0.2228, 0.0136, 0.0342, 0.1356, 0.0502, 0.0826]],\n",
      "\n",
      "         [[0.0853, 0.1051, 0.6228, 0.0089, 0.0542, 0.0946, 0.0292]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 7])\n",
      "old attention tensor([[[[0.6459, 0.0986, 0.1419, 0.0089, 0.0299, 0.0643, 0.0104]],\n",
      "\n",
      "         [[0.1378, 0.0976, 0.0219, 0.0580, 0.2948, 0.2871, 0.1028]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 7])\n",
      "old attention tensor([[[[0.0110, 0.9608, 0.0078, 0.0121, 0.0030, 0.0029, 0.0024]],\n",
      "\n",
      "         [[0.0078, 0.3924, 0.0491, 0.1802, 0.0292, 0.0642, 0.2771]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.5428, 0.4572]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0282, 0.9718]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.5428, 0.4572]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0282, 0.9718]]]])\n",
      "old attention torch.Size([1, 2, 2, 7])\n",
      "old attention tensor([[[[0.4611, 0.2228, 0.0136, 0.0342, 0.1356, 0.0502, 0.0826],\n",
      "          [0.0043, 0.0069, 0.8597, 0.0627, 0.0160, 0.0241, 0.0263]],\n",
      "\n",
      "         [[0.0853, 0.1051, 0.6228, 0.0089, 0.0542, 0.0946, 0.0292],\n",
      "          [0.3147, 0.0104, 0.1120, 0.0301, 0.0781, 0.4411, 0.0135]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0086, 0.9914]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.2040, 0.7960]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0086, 0.9914]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.2040, 0.7960]]]])\n",
      "old attention torch.Size([1, 2, 2, 7])\n",
      "old attention tensor([[[[0.6459, 0.0986, 0.1419, 0.0089, 0.0299, 0.0643, 0.0104],\n",
      "          [0.0759, 0.1609, 0.0958, 0.2941, 0.2476, 0.0490, 0.0766]],\n",
      "\n",
      "         [[0.1378, 0.0976, 0.0219, 0.0580, 0.2948, 0.2871, 0.1028],\n",
      "          [0.1810, 0.1209, 0.0328, 0.4285, 0.0735, 0.0725, 0.0908]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.3277, 0.6723]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.3063, 0.6937]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.3277, 0.6723]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.3063, 0.6937]]]])\n",
      "old attention torch.Size([1, 2, 2, 7])\n",
      "old attention tensor([[[[1.0984e-02, 9.6083e-01, 7.8493e-03, 1.2107e-02, 3.0021e-03,\n",
      "           2.8607e-03, 2.3626e-03],\n",
      "          [7.9075e-03, 2.3300e-02, 1.4947e-01, 7.7903e-01, 1.7192e-02,\n",
      "           1.3352e-02, 9.7446e-03]],\n",
      "\n",
      "         [[7.8316e-03, 3.9240e-01, 4.9124e-02, 1.8018e-01, 2.9176e-02,\n",
      "           6.4212e-02, 2.7707e-01],\n",
      "          [4.8758e-04, 4.8552e-03, 5.5480e-02, 8.7202e-01, 3.8050e-03,\n",
      "           3.7317e-02, 2.6036e-02]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [5.4283e-01, 4.5717e-01, 0.0000e+00],\n",
      "          [5.7928e-03, 9.5962e-04, 9.9325e-01]],\n",
      "\n",
      "         [[1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [2.8229e-02, 9.7177e-01, 0.0000e+00],\n",
      "          [2.5488e-03, 1.1255e-01, 8.8490e-01]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 7])\n",
      "old attention tensor([[[[0.5558, 0.2919, 0.0038, 0.0288, 0.0638, 0.0258, 0.0301],\n",
      "          [0.0077, 0.0134, 0.8218, 0.0856, 0.0149, 0.0270, 0.0297],\n",
      "          [0.2235, 0.0555, 0.2419, 0.2256, 0.0722, 0.0947, 0.0864]],\n",
      "\n",
      "         [[0.0307, 0.0729, 0.4592, 0.0176, 0.2025, 0.1678, 0.0493],\n",
      "          [0.6653, 0.0161, 0.0668, 0.0085, 0.1025, 0.1328, 0.0079],\n",
      "          [0.0567, 0.0753, 0.1661, 0.0277, 0.5116, 0.1366, 0.0260]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.0241, 0.9759, 0.0000],\n",
      "          [0.0078, 0.1074, 0.8848]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.0211, 0.9789, 0.0000],\n",
      "          [0.0355, 0.5869, 0.3776]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 7])\n",
      "old attention tensor([[[[0.4108, 0.0679, 0.2606, 0.0918, 0.0514, 0.0677, 0.0498],\n",
      "          [0.0915, 0.1886, 0.1282, 0.3761, 0.0944, 0.0568, 0.0644],\n",
      "          [0.2848, 0.2283, 0.0978, 0.1815, 0.1084, 0.0491, 0.0500]],\n",
      "\n",
      "         [[0.2356, 0.0563, 0.1383, 0.1882, 0.0579, 0.2783, 0.0453],\n",
      "          [0.3309, 0.1759, 0.0318, 0.2478, 0.0581, 0.0669, 0.0884],\n",
      "          [0.0966, 0.1814, 0.1017, 0.2637, 0.0499, 0.1976, 0.1092]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.3087, 0.6913, 0.0000],\n",
      "          [0.0967, 0.3956, 0.5077]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.3197, 0.6803, 0.0000],\n",
      "          [0.0972, 0.0459, 0.8568]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 7])\n",
      "old attention tensor([[[[0.2039, 0.3003, 0.1681, 0.0378, 0.0415, 0.1762, 0.0722],\n",
      "          [0.0227, 0.0732, 0.1411, 0.6853, 0.0242, 0.0285, 0.0251],\n",
      "          [0.0300, 0.0610, 0.1777, 0.4240, 0.0634, 0.1418, 0.1020]],\n",
      "\n",
      "         [[0.0307, 0.2459, 0.0754, 0.5181, 0.0106, 0.0585, 0.0607],\n",
      "          [0.0024, 0.0176, 0.0600, 0.8591, 0.0057, 0.0235, 0.0316],\n",
      "          [0.0114, 0.0408, 0.0395, 0.8725, 0.0024, 0.0166, 0.0168]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [5.4283e-01, 4.5717e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [5.7928e-03, 9.5962e-04, 9.9325e-01, 0.0000e+00],\n",
      "          [3.2158e-02, 5.3844e-02, 8.9735e-01, 1.6650e-02]],\n",
      "\n",
      "         [[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [2.8229e-02, 9.7177e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [2.5488e-03, 1.1255e-01, 8.8490e-01, 0.0000e+00],\n",
      "          [5.3481e-03, 7.5643e-01, 2.1576e-01, 2.2460e-02]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 7])\n",
      "old attention tensor([[[[0.6056, 0.2215, 0.0040, 0.0247, 0.0750, 0.0348, 0.0344],\n",
      "          [0.0065, 0.0082, 0.8450, 0.0650, 0.0146, 0.0313, 0.0293],\n",
      "          [0.2181, 0.0404, 0.2569, 0.1903, 0.0797, 0.1200, 0.0947],\n",
      "          [0.1684, 0.0472, 0.2813, 0.3701, 0.0468, 0.0590, 0.0272]],\n",
      "\n",
      "         [[0.0220, 0.0717, 0.4666, 0.0202, 0.1882, 0.1740, 0.0573],\n",
      "          [0.6086, 0.0183, 0.0772, 0.0116, 0.1115, 0.1624, 0.0105],\n",
      "          [0.0457, 0.0787, 0.1712, 0.0346, 0.4911, 0.1466, 0.0322],\n",
      "          [0.0693, 0.0109, 0.1057, 0.0305, 0.2933, 0.4651, 0.0252]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0169, 0.9831, 0.0000, 0.0000],\n",
      "          [0.0070, 0.1090, 0.8840, 0.0000],\n",
      "          [0.0065, 0.0748, 0.4937, 0.4250]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0275, 0.9725, 0.0000, 0.0000],\n",
      "          [0.0400, 0.5666, 0.3934, 0.0000],\n",
      "          [0.0552, 0.2231, 0.3149, 0.4068]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 7])\n",
      "old attention tensor([[[[0.3842, 0.0591, 0.2577, 0.1224, 0.0563, 0.0619, 0.0584],\n",
      "          [0.0639, 0.1511, 0.1019, 0.4657, 0.0972, 0.0487, 0.0716],\n",
      "          [0.2479, 0.2073, 0.0872, 0.2198, 0.1324, 0.0468, 0.0585],\n",
      "          [0.1087, 0.0879, 0.1294, 0.5531, 0.0589, 0.0229, 0.0391]],\n",
      "\n",
      "         [[0.2633, 0.0530, 0.1250, 0.1844, 0.0531, 0.2823, 0.0389],\n",
      "          [0.3411, 0.1765, 0.0330, 0.2527, 0.0509, 0.0602, 0.0856],\n",
      "          [0.1041, 0.1797, 0.1002, 0.2787, 0.0499, 0.1795, 0.1080],\n",
      "          [0.1498, 0.0835, 0.1508, 0.3606, 0.0595, 0.0800, 0.1159]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.3261, 0.6739, 0.0000, 0.0000],\n",
      "          [0.1157, 0.3757, 0.5086, 0.0000],\n",
      "          [0.0500, 0.1646, 0.5973, 0.1881]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.3086, 0.6914, 0.0000, 0.0000],\n",
      "          [0.1507, 0.0589, 0.7904, 0.0000],\n",
      "          [0.0464, 0.0875, 0.6850, 0.1811]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 7])\n",
      "old attention tensor([[[[0.1888, 0.1792, 0.2409, 0.0279, 0.0534, 0.2329, 0.0769],\n",
      "          [0.0207, 0.0423, 0.1958, 0.6338, 0.0352, 0.0406, 0.0315],\n",
      "          [0.0276, 0.0332, 0.2070, 0.3682, 0.0787, 0.1745, 0.1108],\n",
      "          [0.0926, 0.0356, 0.2862, 0.2269, 0.0932, 0.1788, 0.0867]],\n",
      "\n",
      "         [[0.0287, 0.2028, 0.0684, 0.5671, 0.0096, 0.0715, 0.0520],\n",
      "          [0.0024, 0.0129, 0.0448, 0.8859, 0.0051, 0.0254, 0.0236],\n",
      "          [0.0121, 0.0327, 0.0344, 0.8859, 0.0024, 0.0194, 0.0132],\n",
      "          [0.0121, 0.0281, 0.0394, 0.8610, 0.0053, 0.0300, 0.0241]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [5.4283e-01, 4.5717e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [5.7928e-03, 9.5962e-04, 9.9325e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [3.2158e-02, 5.3844e-02, 8.9735e-01, 1.6650e-02, 0.0000e+00],\n",
      "          [1.8754e-03, 3.6060e-04, 4.1220e-01, 1.1487e-03, 5.8442e-01]],\n",
      "\n",
      "         [[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [2.8229e-02, 9.7177e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [2.5488e-03, 1.1255e-01, 8.8490e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [5.3481e-03, 7.5643e-01, 2.1576e-01, 2.2460e-02, 0.0000e+00],\n",
      "          [9.4989e-04, 4.2061e-02, 4.3012e-01, 5.9595e-02, 4.6727e-01]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 7])\n",
      "old attention tensor([[[[0.5780, 0.2688, 0.0034, 0.0248, 0.0635, 0.0306, 0.0309],\n",
      "          [0.0079, 0.0123, 0.8250, 0.0769, 0.0147, 0.0325, 0.0308],\n",
      "          [0.2421, 0.0564, 0.2156, 0.2008, 0.0765, 0.1153, 0.0932],\n",
      "          [0.1884, 0.0651, 0.2331, 0.3860, 0.0442, 0.0564, 0.0267],\n",
      "          [0.2457, 0.0468, 0.2248, 0.1895, 0.0781, 0.1158, 0.0993]],\n",
      "\n",
      "         [[0.0246, 0.0865, 0.3899, 0.0228, 0.2576, 0.1498, 0.0688],\n",
      "          [0.6198, 0.0195, 0.0616, 0.0108, 0.1460, 0.1315, 0.0108],\n",
      "          [0.0434, 0.0819, 0.1328, 0.0332, 0.5610, 0.1137, 0.0339],\n",
      "          [0.0705, 0.0127, 0.0895, 0.0315, 0.3820, 0.3851, 0.0287],\n",
      "          [0.0480, 0.0890, 0.1013, 0.0325, 0.5876, 0.1067, 0.0349]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0239, 0.9761, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0114, 0.1145, 0.8741, 0.0000, 0.0000],\n",
      "          [0.0107, 0.0690, 0.5354, 0.3849, 0.0000],\n",
      "          [0.0047, 0.0537, 0.3590, 0.1651, 0.4176]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0221, 0.9779, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0410, 0.5173, 0.4417, 0.0000, 0.0000],\n",
      "          [0.0492, 0.2300, 0.3161, 0.4047, 0.0000],\n",
      "          [0.0181, 0.1908, 0.2042, 0.3395, 0.2474]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 7])\n",
      "old attention tensor([[[[0.2602, 0.0535, 0.2559, 0.2171, 0.0591, 0.0679, 0.0864],\n",
      "          [0.0420, 0.1090, 0.0877, 0.5729, 0.0731, 0.0420, 0.0734],\n",
      "          [0.1776, 0.1649, 0.0983, 0.3188, 0.1113, 0.0527, 0.0763],\n",
      "          [0.0700, 0.0641, 0.1177, 0.6385, 0.0461, 0.0217, 0.0419],\n",
      "          [0.1664, 0.1634, 0.0947, 0.3384, 0.1089, 0.0483, 0.0797]],\n",
      "\n",
      "         [[0.2639, 0.0384, 0.2309, 0.1896, 0.0323, 0.2133, 0.0317],\n",
      "          [0.3838, 0.1524, 0.0551, 0.2461, 0.0364, 0.0558, 0.0705],\n",
      "          [0.1162, 0.1366, 0.1820, 0.2847, 0.0348, 0.1558, 0.0899],\n",
      "          [0.1597, 0.0658, 0.2454, 0.3286, 0.0381, 0.0702, 0.0923],\n",
      "          [0.1056, 0.1149, 0.2188, 0.2945, 0.0302, 0.1522, 0.0838]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4094, 0.5906, 0.0000, 0.0000, 0.0000],\n",
      "          [0.1870, 0.3460, 0.4670, 0.0000, 0.0000],\n",
      "          [0.1009, 0.1582, 0.5553, 0.1856, 0.0000],\n",
      "          [0.1144, 0.1745, 0.3001, 0.1375, 0.2735]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4788, 0.5212, 0.0000, 0.0000, 0.0000],\n",
      "          [0.2447, 0.0524, 0.7029, 0.0000, 0.0000],\n",
      "          [0.1026, 0.0654, 0.7056, 0.1265, 0.0000],\n",
      "          [0.1386, 0.0330, 0.4326, 0.0494, 0.3464]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 7])\n",
      "old attention tensor([[[[0.1641, 0.0489, 0.1968, 0.0298, 0.0570, 0.3620, 0.1415],\n",
      "          [0.0305, 0.0248, 0.2044, 0.5062, 0.0536, 0.0935, 0.0871],\n",
      "          [0.0358, 0.0184, 0.1750, 0.2408, 0.0833, 0.2604, 0.1863],\n",
      "          [0.0853, 0.0151, 0.2095, 0.1468, 0.0967, 0.2773, 0.1692],\n",
      "          [0.0351, 0.0183, 0.1656, 0.2637, 0.0785, 0.2525, 0.1863]],\n",
      "\n",
      "         [[0.1039, 0.2336, 0.0724, 0.4844, 0.0160, 0.0552, 0.0345],\n",
      "          [0.0147, 0.0250, 0.0562, 0.8432, 0.0122, 0.0256, 0.0231],\n",
      "          [0.0640, 0.0653, 0.0520, 0.7727, 0.0065, 0.0236, 0.0159],\n",
      "          [0.0639, 0.0509, 0.0509, 0.7760, 0.0105, 0.0270, 0.0208],\n",
      "          [0.0566, 0.0588, 0.0546, 0.7866, 0.0059, 0.0226, 0.0148]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "predicted trg = ['ich', 'lesen', 'zeitung', 'lesen', '<eos>']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_count 1    self.capacity  20\n",
      "0  ------------------------------------------------\n",
      "DecoderLayer@trg4\n",
      "[1, 1, 64]\n",
      "src = ['i', 'can', 'eat', 'bread']\n",
      "old attention torch.Size([1, 2, 6, 6])\n",
      "old attention tensor([[[[3.0191e-03, 2.6749e-02, 9.3236e-01, 2.3894e-02, 5.5697e-03,\n",
      "           8.4044e-03],\n",
      "          [1.0534e-01, 5.0805e-02, 7.7098e-01, 1.2436e-02, 5.9253e-02,\n",
      "           1.1882e-03],\n",
      "          [1.0971e-02, 4.8005e-02, 1.3551e-02, 1.1113e-02, 8.9543e-01,\n",
      "           2.0926e-02],\n",
      "          [1.6021e-01, 8.4516e-02, 2.8349e-02, 3.1632e-02, 1.1233e-01,\n",
      "           5.8297e-01],\n",
      "          [1.8860e-01, 2.2311e-01, 2.5135e-01, 2.7473e-01, 5.5230e-02,\n",
      "           6.9836e-03],\n",
      "          [1.4613e-02, 6.7941e-02, 6.7614e-01, 7.5423e-02, 1.5669e-01,\n",
      "           9.1945e-03]],\n",
      "\n",
      "         [[9.3827e-02, 6.0981e-02, 4.9924e-01, 2.9327e-02, 2.2300e-01,\n",
      "           9.3625e-02],\n",
      "          [1.5967e-02, 6.4939e-02, 6.7347e-01, 2.0412e-02, 1.8483e-01,\n",
      "           4.0382e-02],\n",
      "          [5.9674e-03, 9.1749e-02, 8.3403e-01, 8.2615e-03, 5.9753e-02,\n",
      "           2.3569e-04],\n",
      "          [3.7802e-02, 4.0983e-02, 6.1975e-02, 4.8240e-02, 3.3171e-02,\n",
      "           7.7783e-01],\n",
      "          [3.7170e-02, 1.0048e-02, 1.5885e-01, 7.3103e-01, 4.3904e-02,\n",
      "           1.8994e-02],\n",
      "          [9.7523e-02, 4.6333e-02, 9.8372e-02, 1.6332e-01, 1.3693e-01,\n",
      "           4.5752e-01]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 6, 6])\n",
      "old attention tensor([[[[0.1034, 0.0688, 0.4843, 0.0999, 0.1321, 0.1117],\n",
      "          [0.0815, 0.1781, 0.2876, 0.1744, 0.0987, 0.1797],\n",
      "          [0.3093, 0.2218, 0.0397, 0.1109, 0.1782, 0.1400],\n",
      "          [0.0237, 0.1450, 0.0772, 0.5250, 0.0796, 0.1495],\n",
      "          [0.1379, 0.3875, 0.0899, 0.1267, 0.0820, 0.1759],\n",
      "          [0.0885, 0.0713, 0.6728, 0.0910, 0.0291, 0.0473]],\n",
      "\n",
      "         [[0.1741, 0.1796, 0.3925, 0.1161, 0.0264, 0.1114],\n",
      "          [0.0115, 0.0440, 0.0427, 0.5060, 0.2766, 0.1191],\n",
      "          [0.5204, 0.0583, 0.2192, 0.0219, 0.0823, 0.0979],\n",
      "          [0.0874, 0.2536, 0.0882, 0.1675, 0.2451, 0.1583],\n",
      "          [0.0280, 0.1502, 0.0756, 0.0393, 0.5821, 0.1249],\n",
      "          [0.0306, 0.0584, 0.0623, 0.4831, 0.1088, 0.2568]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 6, 6])\n",
      "old attention tensor([[[[0.0925, 0.1743, 0.2265, 0.2329, 0.2170, 0.0569],\n",
      "          [0.1559, 0.0927, 0.1485, 0.4382, 0.0851, 0.0795],\n",
      "          [0.0857, 0.1063, 0.0115, 0.0297, 0.2986, 0.4682],\n",
      "          [0.0887, 0.0797, 0.1334, 0.5766, 0.0866, 0.0349],\n",
      "          [0.4397, 0.0136, 0.0793, 0.4411, 0.0172, 0.0091],\n",
      "          [0.1800, 0.0394, 0.0401, 0.6549, 0.0313, 0.0543]],\n",
      "\n",
      "         [[0.0402, 0.0780, 0.7380, 0.1071, 0.0309, 0.0059],\n",
      "          [0.0167, 0.0980, 0.0055, 0.1858, 0.3436, 0.3505],\n",
      "          [0.0290, 0.0287, 0.8008, 0.0272, 0.1041, 0.0102],\n",
      "          [0.0380, 0.0738, 0.1021, 0.3258, 0.2881, 0.1722],\n",
      "          [0.0499, 0.1852, 0.2240, 0.3754, 0.1305, 0.0351],\n",
      "          [0.1531, 0.3546, 0.0174, 0.0699, 0.2602, 0.1448]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 6])\n",
      "old attention tensor([[[[0.2579, 0.1267, 0.0271, 0.2580, 0.2883, 0.0419]],\n",
      "\n",
      "         [[0.2261, 0.2838, 0.1206, 0.2331, 0.0897, 0.0468]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 6])\n",
      "old attention tensor([[[[0.5073, 0.0507, 0.2962, 0.0727, 0.0646, 0.0084]],\n",
      "\n",
      "         [[0.3243, 0.0908, 0.0615, 0.2001, 0.1842, 0.1392]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 6])\n",
      "old attention tensor([[[[0.0066, 0.9135, 0.0415, 0.0184, 0.0164, 0.0036]],\n",
      "\n",
      "         [[0.0149, 0.4923, 0.0102, 0.0488, 0.0670, 0.3667]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.5428, 0.4572]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0282, 0.9718]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.5428, 0.4572]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0282, 0.9718]]]])\n",
      "old attention torch.Size([1, 2, 2, 6])\n",
      "old attention tensor([[[[0.2579, 0.1267, 0.0271, 0.2580, 0.2883, 0.0419],\n",
      "          [0.0622, 0.1040, 0.1047, 0.1539, 0.0384, 0.5367]],\n",
      "\n",
      "         [[0.2261, 0.2838, 0.1206, 0.2331, 0.0897, 0.0468],\n",
      "          [0.0362, 0.0013, 0.9379, 0.0199, 0.0030, 0.0017]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0111, 0.9889]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.1960, 0.8040]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0111, 0.9889]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.1960, 0.8040]]]])\n",
      "old attention torch.Size([1, 2, 2, 6])\n",
      "old attention tensor([[[[0.5073, 0.0507, 0.2962, 0.0727, 0.0646, 0.0084],\n",
      "          [0.0514, 0.1397, 0.0805, 0.6143, 0.0506, 0.0636]],\n",
      "\n",
      "         [[0.3243, 0.0908, 0.0615, 0.2001, 0.1842, 0.1392],\n",
      "          [0.1056, 0.0608, 0.5481, 0.0305, 0.2215, 0.0336]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.4201, 0.5799]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0856, 0.9144]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.4201, 0.5799]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0856, 0.9144]]]])\n",
      "old attention torch.Size([1, 2, 2, 6])\n",
      "old attention tensor([[[[0.0066, 0.9135, 0.0415, 0.0184, 0.0164, 0.0036],\n",
      "          [0.0364, 0.0382, 0.2035, 0.4548, 0.1650, 0.1022]],\n",
      "\n",
      "         [[0.0149, 0.4923, 0.0102, 0.0488, 0.0670, 0.3667],\n",
      "          [0.0108, 0.0717, 0.0887, 0.1297, 0.1811, 0.5181]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.5428, 0.4572, 0.0000],\n",
      "          [0.0148, 0.0673, 0.9179]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.0282, 0.9718, 0.0000],\n",
      "          [0.0045, 0.0503, 0.9452]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 6])\n",
      "old attention tensor([[[[0.1238, 0.1186, 0.0076, 0.2558, 0.4828, 0.0115],\n",
      "          [0.0486, 0.1370, 0.1192, 0.1226, 0.0702, 0.5024],\n",
      "          [0.0105, 0.3485, 0.0198, 0.1152, 0.4349, 0.0711]],\n",
      "\n",
      "         [[0.0836, 0.2546, 0.0572, 0.3068, 0.1154, 0.1824],\n",
      "          [0.0528, 0.0018, 0.9215, 0.0173, 0.0054, 0.0012],\n",
      "          [0.1445, 0.1981, 0.0597, 0.2461, 0.0783, 0.2732]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.0790, 0.9210, 0.0000],\n",
      "          [0.0723, 0.1021, 0.8256]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.0569, 0.9431, 0.0000],\n",
      "          [0.2024, 0.2442, 0.5534]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 6])\n",
      "old attention tensor([[[[0.3580, 0.0517, 0.2926, 0.0655, 0.1941, 0.0382],\n",
      "          [0.0730, 0.2704, 0.1372, 0.3140, 0.1534, 0.0519],\n",
      "          [0.0454, 0.2006, 0.3534, 0.1265, 0.1733, 0.1007]],\n",
      "\n",
      "         [[0.3103, 0.0788, 0.0378, 0.1410, 0.3329, 0.0992],\n",
      "          [0.2003, 0.1627, 0.0632, 0.0395, 0.4492, 0.0851],\n",
      "          [0.0528, 0.4392, 0.0062, 0.0162, 0.3299, 0.1557]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.5784, 0.4216, 0.0000],\n",
      "          [0.2977, 0.4938, 0.2086]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.0985, 0.9014, 0.0000],\n",
      "          [0.0638, 0.4079, 0.5283]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 6])\n",
      "old attention tensor([[[[0.0315, 0.6677, 0.0419, 0.0952, 0.1120, 0.0517],\n",
      "          [0.0229, 0.5209, 0.0509, 0.1712, 0.1417, 0.0925],\n",
      "          [0.0746, 0.3784, 0.0629, 0.1726, 0.2229, 0.0886]],\n",
      "\n",
      "         [[0.0544, 0.2266, 0.0121, 0.1052, 0.3486, 0.2530],\n",
      "          [0.0234, 0.0703, 0.0408, 0.0702, 0.3893, 0.4060],\n",
      "          [0.0672, 0.0775, 0.0179, 0.1229, 0.4962, 0.2183]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [5.4283e-01, 4.5717e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [1.4779e-02, 6.7309e-02, 9.1791e-01, 0.0000e+00],\n",
      "          [7.2777e-02, 6.2127e-01, 2.8582e-01, 2.0138e-02]],\n",
      "\n",
      "         [[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [2.8229e-02, 9.7177e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [4.4961e-03, 5.0291e-02, 9.4521e-01, 0.0000e+00],\n",
      "          [1.3696e-03, 2.7979e-03, 3.5044e-04, 9.9548e-01]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 6])\n",
      "old attention tensor([[[[0.1690, 0.1162, 0.0122, 0.2069, 0.4865, 0.0093],\n",
      "          [0.0592, 0.1281, 0.1990, 0.0921, 0.0617, 0.4600],\n",
      "          [0.0114, 0.3631, 0.0311, 0.0849, 0.4520, 0.0574],\n",
      "          [0.1379, 0.0317, 0.4243, 0.2400, 0.0600, 0.1061]],\n",
      "\n",
      "         [[0.0438, 0.2517, 0.0246, 0.3898, 0.1026, 0.1876],\n",
      "          [0.0527, 0.0026, 0.8989, 0.0362, 0.0079, 0.0017],\n",
      "          [0.0741, 0.2013, 0.0230, 0.3338, 0.0668, 0.3010],\n",
      "          [0.0541, 0.5116, 0.0608, 0.1970, 0.0840, 0.0925]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0927, 0.9073, 0.0000, 0.0000],\n",
      "          [0.1084, 0.1047, 0.7869, 0.0000],\n",
      "          [0.0704, 0.2388, 0.1468, 0.5439]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0305, 0.9695, 0.0000, 0.0000],\n",
      "          [0.1452, 0.2906, 0.5642, 0.0000],\n",
      "          [0.0071, 0.6338, 0.3230, 0.0360]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 6])\n",
      "old attention tensor([[[[0.4584, 0.0172, 0.2580, 0.0598, 0.1740, 0.0326],\n",
      "          [0.0682, 0.1569, 0.1197, 0.4535, 0.1450, 0.0567],\n",
      "          [0.0417, 0.1236, 0.3774, 0.1586, 0.1735, 0.1253],\n",
      "          [0.2911, 0.1137, 0.3180, 0.0997, 0.1088, 0.0687]],\n",
      "\n",
      "         [[0.4661, 0.0292, 0.0295, 0.1934, 0.2499, 0.0320],\n",
      "          [0.3123, 0.0823, 0.0550, 0.0460, 0.4741, 0.0303],\n",
      "          [0.0792, 0.4155, 0.0056, 0.0241, 0.3783, 0.0974],\n",
      "          [0.1016, 0.1322, 0.0507, 0.0710, 0.4480, 0.1965]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5683, 0.4317, 0.0000, 0.0000],\n",
      "          [0.1637, 0.6900, 0.1464, 0.0000],\n",
      "          [0.0603, 0.1460, 0.7554, 0.0383]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0809, 0.9191, 0.0000, 0.0000],\n",
      "          [0.0415, 0.2484, 0.7101, 0.0000],\n",
      "          [0.0833, 0.2320, 0.3931, 0.2917]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 6])\n",
      "old attention tensor([[[[0.0751, 0.2853, 0.0937, 0.2299, 0.2010, 0.1151],\n",
      "          [0.0280, 0.1459, 0.0819, 0.3875, 0.1873, 0.1695],\n",
      "          [0.1191, 0.0860, 0.0835, 0.2783, 0.2837, 0.1493],\n",
      "          [0.0444, 0.1238, 0.0653, 0.1735, 0.1864, 0.4066]],\n",
      "\n",
      "         [[0.1111, 0.3450, 0.0165, 0.1371, 0.2237, 0.1666],\n",
      "          [0.0471, 0.0842, 0.0680, 0.1030, 0.2734, 0.4244],\n",
      "          [0.1955, 0.0969, 0.0259, 0.2111, 0.3247, 0.1459],\n",
      "          [0.0752, 0.1159, 0.1032, 0.1140, 0.4580, 0.1337]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "predicted trg = ['ich', 'konnen', 'essen', '<eos>']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_count 1    self.capacity  20\n",
      "0  ------------------------------------------------\n",
      "DecoderLayer@trg4\n",
      "[1, 1, 64]\n",
      "src = ['i', 'can', 'eat', 'apple']\n",
      "old attention torch.Size([1, 2, 6, 6])\n",
      "old attention tensor([[[[3.0208e-03, 2.6764e-02, 9.3288e-01, 2.3908e-02, 5.0168e-03,\n",
      "           8.4091e-03],\n",
      "          [1.1159e-01, 5.3820e-02, 8.1673e-01, 1.3174e-02, 3.4313e-03,\n",
      "           1.2587e-03],\n",
      "          [8.6450e-02, 3.7826e-01, 1.0678e-01, 8.7570e-02, 1.7605e-01,\n",
      "           1.6489e-01],\n",
      "          [1.5837e-01, 8.3545e-02, 2.8023e-02, 3.1269e-02, 1.2252e-01,\n",
      "           5.7627e-01],\n",
      "          [5.2676e-02, 2.8824e-01, 2.3646e-01, 1.5832e-01, 6.6443e-02,\n",
      "           1.9786e-01],\n",
      "          [1.6738e-02, 7.7822e-02, 7.7447e-01, 8.6391e-02, 3.4046e-02,\n",
      "           1.0532e-02]],\n",
      "\n",
      "         [[1.1511e-01, 7.4817e-02, 6.1251e-01, 3.5981e-02, 4.6708e-02,\n",
      "           1.1487e-01],\n",
      "          [1.8867e-02, 7.6732e-02, 7.9576e-01, 2.4118e-02, 3.6805e-02,\n",
      "           4.7715e-02],\n",
      "          [6.3010e-03, 9.6878e-02, 8.8065e-01, 8.7233e-03, 7.1977e-03,\n",
      "           2.4887e-04],\n",
      "          [3.8856e-02, 4.2126e-02, 6.3703e-02, 4.9586e-02, 6.2062e-03,\n",
      "           7.9952e-01],\n",
      "          [1.1016e-03, 1.6625e-01, 1.3093e-03, 1.2869e-02, 9.6806e-03,\n",
      "           8.0879e-01],\n",
      "          [6.8145e-02, 3.2376e-02, 6.8738e-02, 1.1412e-01, 3.9692e-01,\n",
      "           3.1970e-01]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 6, 6])\n",
      "old attention tensor([[[[0.0957, 0.0627, 0.4660, 0.0975, 0.1753, 0.1028],\n",
      "          [0.0713, 0.1747, 0.2871, 0.1647, 0.1109, 0.1913],\n",
      "          [0.1429, 0.1023, 0.0226, 0.0471, 0.6196, 0.0656],\n",
      "          [0.0254, 0.1319, 0.0750, 0.5316, 0.0718, 0.1644],\n",
      "          [0.1015, 0.2492, 0.0905, 0.2088, 0.0299, 0.3202],\n",
      "          [0.0770, 0.0635, 0.6293, 0.0788, 0.1021, 0.0492]],\n",
      "\n",
      "         [[0.1781, 0.1686, 0.3779, 0.1123, 0.0661, 0.0971],\n",
      "          [0.0140, 0.0440, 0.0553, 0.6975, 0.0411, 0.1480],\n",
      "          [0.5168, 0.0567, 0.2236, 0.0278, 0.0754, 0.0998],\n",
      "          [0.0801, 0.2198, 0.0829, 0.1739, 0.2910, 0.1522],\n",
      "          [0.0705, 0.0771, 0.0253, 0.0049, 0.7462, 0.0760],\n",
      "          [0.0332, 0.0543, 0.0749, 0.4702, 0.1025, 0.2649]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 6, 6])\n",
      "old attention tensor([[[[0.0856, 0.1748, 0.2264, 0.1813, 0.2933, 0.0385],\n",
      "          [0.0956, 0.0577, 0.0885, 0.2807, 0.4477, 0.0298],\n",
      "          [0.1458, 0.1739, 0.0170, 0.0587, 0.0540, 0.5506],\n",
      "          [0.0559, 0.0580, 0.0848, 0.5246, 0.2611, 0.0156],\n",
      "          [0.0561, 0.0236, 0.0741, 0.4353, 0.3982, 0.0125],\n",
      "          [0.1335, 0.0255, 0.0237, 0.4399, 0.3600, 0.0174]],\n",
      "\n",
      "         [[0.0364, 0.0709, 0.6651, 0.0897, 0.1328, 0.0052],\n",
      "          [0.0198, 0.1392, 0.0080, 0.2738, 0.1193, 0.4398],\n",
      "          [0.0227, 0.0308, 0.8530, 0.0280, 0.0522, 0.0133],\n",
      "          [0.0381, 0.0766, 0.1282, 0.3386, 0.2625, 0.1559],\n",
      "          [0.0458, 0.0434, 0.1400, 0.1502, 0.4712, 0.1493],\n",
      "          [0.1595, 0.4497, 0.0250, 0.1063, 0.0972, 0.1621]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 6])\n",
      "old attention tensor([[[[0.3005, 0.2007, 0.0370, 0.3041, 0.0927, 0.0650]],\n",
      "\n",
      "         [[0.1419, 0.1720, 0.0781, 0.1407, 0.4366, 0.0307]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 6])\n",
      "old attention tensor([[[[0.5189, 0.0484, 0.2907, 0.0709, 0.0644, 0.0066]],\n",
      "\n",
      "         [[0.3338, 0.1231, 0.0636, 0.1885, 0.1601, 0.1309]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 6])\n",
      "old attention tensor([[[[0.0072, 0.9004, 0.0621, 0.0173, 0.0098, 0.0031]],\n",
      "\n",
      "         [[0.0095, 0.3874, 0.0076, 0.0426, 0.2457, 0.3071]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.5428, 0.4572]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0282, 0.9718]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.5428, 0.4572]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0282, 0.9718]]]])\n",
      "old attention torch.Size([1, 2, 2, 6])\n",
      "old attention tensor([[[[3.0053e-01, 2.0065e-01, 3.7022e-02, 3.0407e-01, 9.2702e-02,\n",
      "           6.5029e-02],\n",
      "          [4.0308e-02, 5.7749e-02, 5.1913e-02, 8.3833e-02, 5.0540e-01,\n",
      "           2.6080e-01]],\n",
      "\n",
      "         [[1.4190e-01, 1.7202e-01, 7.8082e-02, 1.4067e-01, 4.3663e-01,\n",
      "           3.0690e-02],\n",
      "          [2.5939e-02, 9.3150e-04, 9.5141e-01, 1.2893e-02, 7.1806e-03,\n",
      "           1.6468e-03]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0084, 0.9916]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.2263, 0.7737]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0084, 0.9916]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.2263, 0.7737]]]])\n",
      "old attention torch.Size([1, 2, 2, 6])\n",
      "old attention tensor([[[[0.5189, 0.0484, 0.2907, 0.0709, 0.0644, 0.0066],\n",
      "          [0.0481, 0.0937, 0.0611, 0.5322, 0.2288, 0.0360]],\n",
      "\n",
      "         [[0.3338, 0.1231, 0.0636, 0.1885, 0.1601, 0.1309],\n",
      "          [0.1202, 0.0732, 0.6592, 0.0315, 0.0794, 0.0365]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.3978, 0.6022]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.1347, 0.8653]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.3978, 0.6022]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.1347, 0.8653]]]])\n",
      "old attention torch.Size([1, 2, 2, 6])\n",
      "old attention tensor([[[[0.0072, 0.9004, 0.0621, 0.0173, 0.0098, 0.0031],\n",
      "          [0.0235, 0.0490, 0.1873, 0.2547, 0.4333, 0.0522]],\n",
      "\n",
      "         [[0.0095, 0.3874, 0.0076, 0.0426, 0.2457, 0.3071],\n",
      "          [0.0092, 0.1049, 0.1093, 0.1085, 0.0668, 0.6011]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.5428, 0.4572, 0.0000],\n",
      "          [0.0148, 0.0673, 0.9179]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.0282, 0.9718, 0.0000],\n",
      "          [0.0045, 0.0503, 0.9452]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 6])\n",
      "old attention tensor([[[[0.2142, 0.2549, 0.0151, 0.4511, 0.0375, 0.0273],\n",
      "          [0.0316, 0.0800, 0.0692, 0.0740, 0.4608, 0.2843],\n",
      "          [0.0172, 0.4672, 0.0367, 0.2136, 0.1202, 0.1452]],\n",
      "\n",
      "         [[0.0570, 0.1707, 0.0384, 0.1861, 0.4184, 0.1293],\n",
      "          [0.0378, 0.0013, 0.9412, 0.0110, 0.0078, 0.0010],\n",
      "          [0.0750, 0.0968, 0.0327, 0.1185, 0.5545, 0.1225]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.0556, 0.9444, 0.0000],\n",
      "          [0.0693, 0.1388, 0.7919]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.0638, 0.9362, 0.0000],\n",
      "          [0.2078, 0.2174, 0.5748]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 6])\n",
      "old attention tensor([[[[0.4330, 0.0592, 0.3263, 0.0877, 0.0596, 0.0343],\n",
      "          [0.0742, 0.1779, 0.1147, 0.4008, 0.2003, 0.0321],\n",
      "          [0.0510, 0.1827, 0.3540, 0.1949, 0.1458, 0.0716]],\n",
      "\n",
      "         [[0.3090, 0.1100, 0.0483, 0.1437, 0.2977, 0.0912],\n",
      "          [0.3016, 0.3136, 0.1071, 0.0563, 0.1108, 0.1107],\n",
      "          [0.0700, 0.6691, 0.0089, 0.0235, 0.0380, 0.1906]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.6308, 0.3692, 0.0000],\n",
      "          [0.3340, 0.3948, 0.2712]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.1658, 0.8342, 0.0000],\n",
      "          [0.0972, 0.3577, 0.5451]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 6])\n",
      "old attention tensor([[[[0.0171, 0.6471, 0.0466, 0.0634, 0.2000, 0.0258],\n",
      "          [0.0152, 0.4400, 0.0444, 0.1119, 0.3466, 0.0420],\n",
      "          [0.0265, 0.2158, 0.0317, 0.0747, 0.6218, 0.0296]],\n",
      "\n",
      "         [[0.0322, 0.2514, 0.0135, 0.1260, 0.2539, 0.3229],\n",
      "          [0.0174, 0.1100, 0.0565, 0.0921, 0.1841, 0.5399],\n",
      "          [0.0559, 0.1370, 0.0316, 0.1850, 0.1762, 0.4142]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [5.4283e-01, 4.5717e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [1.4779e-02, 6.7309e-02, 9.1791e-01, 0.0000e+00],\n",
      "          [7.2777e-02, 6.2127e-01, 2.8582e-01, 2.0138e-02]],\n",
      "\n",
      "         [[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [2.8229e-02, 9.7177e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [4.4961e-03, 5.0291e-02, 9.4521e-01, 0.0000e+00],\n",
      "          [1.3696e-03, 2.7979e-03, 3.5044e-04, 9.9548e-01]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 6])\n",
      "old attention tensor([[[[0.3003, 0.2518, 0.0242, 0.3742, 0.0280, 0.0215],\n",
      "          [0.0428, 0.0806, 0.1236, 0.0615, 0.4213, 0.2702],\n",
      "          [0.0209, 0.5193, 0.0627, 0.1779, 0.0940, 0.1251],\n",
      "          [0.1333, 0.0287, 0.3831, 0.2252, 0.1335, 0.0961]],\n",
      "\n",
      "         [[0.0290, 0.1580, 0.0149, 0.2231, 0.4469, 0.1280],\n",
      "          [0.0396, 0.0019, 0.9193, 0.0234, 0.0141, 0.0017],\n",
      "          [0.0335, 0.0820, 0.0102, 0.1355, 0.6239, 0.1149],\n",
      "          [0.0403, 0.3340, 0.0343, 0.0958, 0.4252, 0.0704]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0638, 0.9362, 0.0000, 0.0000],\n",
      "          [0.1081, 0.1375, 0.7544, 0.0000],\n",
      "          [0.0571, 0.3599, 0.1256, 0.4574]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0345, 0.9655, 0.0000, 0.0000],\n",
      "          [0.1464, 0.2637, 0.5898, 0.0000],\n",
      "          [0.0074, 0.5990, 0.3645, 0.0291]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 6])\n",
      "old attention tensor([[[[0.5530, 0.0189, 0.2809, 0.0791, 0.0407, 0.0275],\n",
      "          [0.0656, 0.0933, 0.0880, 0.5267, 0.1979, 0.0284],\n",
      "          [0.0428, 0.1181, 0.3622, 0.2486, 0.1343, 0.0940],\n",
      "          [0.3636, 0.1132, 0.2660, 0.1534, 0.0555, 0.0483]],\n",
      "\n",
      "         [[0.3642, 0.0302, 0.0335, 0.1696, 0.3777, 0.0248],\n",
      "          [0.4620, 0.1634, 0.1133, 0.0718, 0.1456, 0.0440],\n",
      "          [0.1033, 0.6330, 0.0090, 0.0388, 0.0664, 0.1494],\n",
      "          [0.1666, 0.2379, 0.1014, 0.1286, 0.0740, 0.2916]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.6650, 0.3350, 0.0000, 0.0000],\n",
      "          [0.2283, 0.5304, 0.2413, 0.0000],\n",
      "          [0.0407, 0.0801, 0.8530, 0.0261]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.1174, 0.8826, 0.0000, 0.0000],\n",
      "          [0.0627, 0.2056, 0.7317, 0.0000],\n",
      "          [0.1149, 0.2844, 0.2788, 0.3219]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 6])\n",
      "old attention tensor([[[[0.0354, 0.3354, 0.1171, 0.1559, 0.3025, 0.0538],\n",
      "          [0.0159, 0.1658, 0.0779, 0.2315, 0.4412, 0.0676],\n",
      "          [0.0370, 0.0613, 0.0442, 0.1168, 0.6942, 0.0465],\n",
      "          [0.0268, 0.1526, 0.0863, 0.1445, 0.3893, 0.2005]],\n",
      "\n",
      "         [[0.0602, 0.3933, 0.0187, 0.1595, 0.1577, 0.2106],\n",
      "          [0.0270, 0.1317, 0.0943, 0.1160, 0.1215, 0.5096],\n",
      "          [0.1508, 0.1651, 0.0418, 0.2682, 0.1047, 0.2694],\n",
      "          [0.0598, 0.1896, 0.1824, 0.1813, 0.1136, 0.2733]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "predicted trg = ['ich', 'konnen', 'essen', '<eos>']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_count 1    self.capacity  20\n",
      "0  ------------------------------------------------\n",
      "DecoderLayer@trg4\n",
      "[1, 1, 64]\n",
      "src = ['i', 'can', 'drink', 'water']\n",
      "old attention torch.Size([1, 2, 6, 6])\n",
      "old attention tensor([[[[2.9060e-03, 2.5747e-02, 8.9744e-01, 6.4493e-02, 1.3272e-03,\n",
      "           8.0896e-03],\n",
      "          [4.2115e-02, 2.0312e-02, 3.0824e-01, 6.2854e-01, 3.1667e-04,\n",
      "           4.7504e-04],\n",
      "          [7.5037e-02, 3.2833e-01, 9.2682e-02, 2.6880e-01, 9.2032e-02,\n",
      "           1.4312e-01],\n",
      "          [2.1084e-03, 6.4318e-02, 1.6925e-02, 4.8627e-03, 8.5027e-02,\n",
      "           8.2676e-01],\n",
      "          [8.4584e-02, 2.8736e-02, 9.4543e-02, 7.5840e-01, 2.7317e-02,\n",
      "           6.4152e-03],\n",
      "          [1.1261e-02, 5.2359e-02, 5.2107e-01, 4.0490e-01, 3.3207e-03,\n",
      "           7.0858e-03]],\n",
      "\n",
      "         [[8.4997e-02, 5.5242e-02, 4.5226e-01, 2.7438e-01, 4.8309e-02,\n",
      "           8.4814e-02],\n",
      "          [1.9098e-02, 7.7671e-02, 8.0550e-01, 4.6356e-02, 3.0713e-03,\n",
      "           4.8299e-02],\n",
      "          [6.1295e-03, 9.4240e-02, 8.5668e-01, 4.1544e-02, 1.1654e-03,\n",
      "           2.4209e-04],\n",
      "          [2.8748e-01, 4.4214e-01, 1.6138e-01, 2.4098e-02, 2.8475e-02,\n",
      "           5.6426e-02],\n",
      "          [4.5468e-02, 5.7026e-01, 1.1703e-01, 9.8420e-02, 7.0534e-02,\n",
      "           9.8291e-02],\n",
      "          [8.7790e-02, 4.1709e-02, 8.8553e-02, 5.7951e-02, 3.1214e-01,\n",
      "           4.1185e-01]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 6, 6])\n",
      "old attention tensor([[[[0.0762, 0.0499, 0.3749, 0.1657, 0.2493, 0.0839],\n",
      "          [0.0561, 0.1290, 0.2175, 0.0927, 0.3760, 0.1287],\n",
      "          [0.2241, 0.1762, 0.0316, 0.0944, 0.3567, 0.1170],\n",
      "          [0.2684, 0.0578, 0.0423, 0.0240, 0.5496, 0.0579],\n",
      "          [0.0327, 0.0655, 0.0600, 0.0307, 0.7757, 0.0354],\n",
      "          [0.0402, 0.0322, 0.3172, 0.0588, 0.5322, 0.0194]],\n",
      "\n",
      "         [[0.1446, 0.1647, 0.2922, 0.2182, 0.0974, 0.0830],\n",
      "          [0.0461, 0.1579, 0.1398, 0.2464, 0.0203, 0.3895],\n",
      "          [0.3250, 0.0389, 0.1418, 0.1307, 0.2875, 0.0760],\n",
      "          [0.0482, 0.4539, 0.1133, 0.1234, 0.0509, 0.2103],\n",
      "          [0.2719, 0.1947, 0.0428, 0.0709, 0.0199, 0.3998],\n",
      "          [0.0753, 0.1430, 0.1358, 0.1007, 0.0397, 0.5055]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 6, 6])\n",
      "old attention tensor([[[[0.0473, 0.1401, 0.1025, 0.5161, 0.1551, 0.0390],\n",
      "          [0.0957, 0.0641, 0.0725, 0.1260, 0.5459, 0.0957],\n",
      "          [0.1055, 0.2102, 0.0193, 0.1303, 0.0639, 0.4708],\n",
      "          [0.1341, 0.0512, 0.0237, 0.1133, 0.1319, 0.5458],\n",
      "          [0.0278, 0.0719, 0.0108, 0.0193, 0.1336, 0.7366],\n",
      "          [0.3468, 0.1451, 0.0787, 0.0610, 0.1416, 0.2267]],\n",
      "\n",
      "         [[0.0107, 0.0363, 0.1521, 0.7725, 0.0264, 0.0020],\n",
      "          [0.0381, 0.1930, 0.0124, 0.1432, 0.1880, 0.4252],\n",
      "          [0.0317, 0.0390, 0.5929, 0.2991, 0.0260, 0.0115],\n",
      "          [0.0640, 0.3284, 0.2860, 0.2310, 0.0668, 0.0239],\n",
      "          [0.0842, 0.0186, 0.2108, 0.6578, 0.0140, 0.0145],\n",
      "          [0.1698, 0.2831, 0.0285, 0.0594, 0.3223, 0.1368]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 6])\n",
      "old attention tensor([[[[0.4022, 0.1244, 0.0493, 0.0608, 0.3110, 0.0524]],\n",
      "\n",
      "         [[0.1683, 0.2179, 0.0863, 0.0983, 0.3801, 0.0490]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 6])\n",
      "old attention tensor([[[[0.4828, 0.0781, 0.2959, 0.0980, 0.0371, 0.0080]],\n",
      "\n",
      "         [[0.4463, 0.0597, 0.1076, 0.0807, 0.1979, 0.1078]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 6])\n",
      "old attention tensor([[[[0.0093, 0.8514, 0.0586, 0.0409, 0.0366, 0.0033]],\n",
      "\n",
      "         [[0.0161, 0.5295, 0.0235, 0.0236, 0.0446, 0.3627]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.5428, 0.4572]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0282, 0.9718]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.5428, 0.4572]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0282, 0.9718]]]])\n",
      "old attention torch.Size([1, 2, 2, 6])\n",
      "old attention tensor([[[[0.4022, 0.1244, 0.0493, 0.0608, 0.3110, 0.0524],\n",
      "          [0.0586, 0.1002, 0.1273, 0.0469, 0.0814, 0.5856]],\n",
      "\n",
      "         [[0.1683, 0.2179, 0.0863, 0.0983, 0.3801, 0.0490],\n",
      "          [0.0436, 0.0016, 0.8165, 0.1147, 0.0210, 0.0026]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0121, 0.9879]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.1941, 0.8059]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0121, 0.9879]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.1941, 0.8059]]]])\n",
      "old attention torch.Size([1, 2, 2, 6])\n",
      "old attention tensor([[[[0.4828, 0.0781, 0.2959, 0.0980, 0.0371, 0.0080],\n",
      "          [0.1003, 0.2913, 0.1784, 0.1547, 0.1303, 0.1451]],\n",
      "\n",
      "         [[0.4463, 0.0597, 0.1076, 0.0807, 0.1979, 0.1078],\n",
      "          [0.1254, 0.0458, 0.5076, 0.2417, 0.0501, 0.0295]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.3755, 0.6245]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.2485, 0.7515]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.3755, 0.6245]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.2485, 0.7515]]]])\n",
      "old attention torch.Size([1, 2, 2, 6])\n",
      "old attention tensor([[[[0.0093, 0.8514, 0.0586, 0.0409, 0.0366, 0.0033],\n",
      "          [0.0179, 0.0259, 0.1797, 0.6100, 0.1076, 0.0589]],\n",
      "\n",
      "         [[0.0161, 0.5295, 0.0235, 0.0236, 0.0446, 0.3627],\n",
      "          [0.0061, 0.0587, 0.0932, 0.0795, 0.4269, 0.3356]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.5428, 0.4572, 0.0000],\n",
      "          [0.0148, 0.0673, 0.9179]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.0282, 0.9718, 0.0000],\n",
      "          [0.0045, 0.0503, 0.9452]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 6])\n",
      "old attention tensor([[[[0.3800, 0.2009, 0.0238, 0.1147, 0.2581, 0.0225],\n",
      "          [0.0477, 0.1248, 0.1359, 0.0673, 0.1142, 0.5101],\n",
      "          [0.0198, 0.3091, 0.0289, 0.1876, 0.3976, 0.0571]],\n",
      "\n",
      "         [[0.0755, 0.2127, 0.0648, 0.0619, 0.3708, 0.2142],\n",
      "          [0.0751, 0.0026, 0.7243, 0.1536, 0.0422, 0.0021],\n",
      "          [0.1226, 0.1719, 0.0602, 0.3166, 0.1348, 0.1939]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.0832, 0.9168, 0.0000],\n",
      "          [0.0577, 0.0650, 0.8772]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.0582, 0.9418, 0.0000],\n",
      "          [0.2503, 0.2621, 0.4876]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 6])\n",
      "old attention tensor([[[[0.3768, 0.0741, 0.2778, 0.1672, 0.0733, 0.0307],\n",
      "          [0.0869, 0.3979, 0.1239, 0.1709, 0.1497, 0.0707],\n",
      "          [0.0443, 0.2028, 0.3048, 0.2564, 0.0905, 0.1012]],\n",
      "\n",
      "         [[0.4456, 0.0485, 0.0585, 0.1104, 0.2736, 0.0634],\n",
      "          [0.3514, 0.1491, 0.1253, 0.1391, 0.1581, 0.0770],\n",
      "          [0.1300, 0.4456, 0.0126, 0.0620, 0.2570, 0.0929]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.3772, 0.6228, 0.0000],\n",
      "          [0.1084, 0.8152, 0.0764]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.1371, 0.8629, 0.0000],\n",
      "          [0.0727, 0.4199, 0.5074]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 6])\n",
      "old attention tensor([[[[0.0454, 0.2542, 0.0642, 0.0755, 0.5274, 0.0333],\n",
      "          [0.0171, 0.1017, 0.0519, 0.1548, 0.6316, 0.0429],\n",
      "          [0.0692, 0.0784, 0.0731, 0.1324, 0.6170, 0.0299]],\n",
      "\n",
      "         [[0.0796, 0.3917, 0.0560, 0.0734, 0.0731, 0.3262],\n",
      "          [0.0197, 0.0478, 0.1294, 0.1230, 0.2995, 0.3807],\n",
      "          [0.1183, 0.1274, 0.1183, 0.2069, 0.1018, 0.3272]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5428, 0.4572, 0.0000, 0.0000],\n",
      "          [0.0148, 0.0673, 0.9179, 0.0000],\n",
      "          [0.7683, 0.0971, 0.0621, 0.0725]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0282, 0.9718, 0.0000, 0.0000],\n",
      "          [0.0045, 0.0503, 0.9452, 0.0000],\n",
      "          [0.0166, 0.0637, 0.0226, 0.8972]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 6])\n",
      "old attention tensor([[[[0.4504, 0.1577, 0.0278, 0.1410, 0.2025, 0.0206],\n",
      "          [0.0564, 0.1017, 0.1655, 0.0840, 0.0926, 0.4996],\n",
      "          [0.0227, 0.2702, 0.0349, 0.2638, 0.3531, 0.0553],\n",
      "          [0.3876, 0.2494, 0.0389, 0.0548, 0.1588, 0.1106]],\n",
      "\n",
      "         [[0.0841, 0.2288, 0.0424, 0.0519, 0.4166, 0.1762],\n",
      "          [0.1098, 0.0036, 0.6510, 0.1727, 0.0606, 0.0023],\n",
      "          [0.1453, 0.1975, 0.0380, 0.2946, 0.1588, 0.1657],\n",
      "          [0.1051, 0.0933, 0.2889, 0.3087, 0.0808, 0.1232]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0633, 0.9367, 0.0000, 0.0000],\n",
      "          [0.0387, 0.0549, 0.9064, 0.0000],\n",
      "          [0.0158, 0.4242, 0.3550, 0.2050]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0443, 0.9557, 0.0000, 0.0000],\n",
      "          [0.2356, 0.2617, 0.5028, 0.0000],\n",
      "          [0.0117, 0.6913, 0.2194, 0.0776]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 6])\n",
      "old attention tensor([[[[0.4536, 0.0491, 0.2485, 0.1352, 0.0898, 0.0238],\n",
      "          [0.1114, 0.3286, 0.1228, 0.1458, 0.2262, 0.0652],\n",
      "          [0.0578, 0.1886, 0.3246, 0.2193, 0.1283, 0.0814],\n",
      "          [0.3659, 0.1266, 0.2494, 0.2122, 0.0336, 0.0123]],\n",
      "\n",
      "         [[0.4967, 0.0253, 0.0902, 0.1491, 0.2033, 0.0353],\n",
      "          [0.3754, 0.0941, 0.1838, 0.1790, 0.1186, 0.0490],\n",
      "          [0.1285, 0.4762, 0.0157, 0.0712, 0.2377, 0.0708],\n",
      "          [0.4850, 0.0177, 0.1329, 0.2180, 0.0795, 0.0670]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.3091, 0.6909, 0.0000, 0.0000],\n",
      "          [0.0516, 0.8550, 0.0934, 0.0000],\n",
      "          [0.0427, 0.3154, 0.3540, 0.2879]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.1896, 0.8104, 0.0000, 0.0000],\n",
      "          [0.0547, 0.2346, 0.7107, 0.0000],\n",
      "          [0.0439, 0.1278, 0.7877, 0.0406]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 6])\n",
      "old attention tensor([[[[0.0709, 0.3351, 0.1231, 0.1084, 0.3001, 0.0624],\n",
      "          [0.0194, 0.1270, 0.0953, 0.2643, 0.4209, 0.0731],\n",
      "          [0.0988, 0.0794, 0.1348, 0.1917, 0.4443, 0.0511],\n",
      "          [0.0584, 0.1040, 0.1044, 0.1282, 0.3898, 0.2152]],\n",
      "\n",
      "         [[0.0545, 0.5348, 0.0510, 0.0464, 0.0610, 0.2523],\n",
      "          [0.0144, 0.0594, 0.1193, 0.0757, 0.3612, 0.3699],\n",
      "          [0.1212, 0.1806, 0.1052, 0.1625, 0.1059, 0.3245],\n",
      "          [0.0241, 0.0333, 0.5696, 0.1262, 0.0859, 0.1609]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [5.4283e-01, 4.5717e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [1.4779e-02, 6.7309e-02, 9.1791e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [7.6828e-01, 9.7135e-02, 6.2055e-02, 7.2535e-02, 0.0000e+00],\n",
      "          [1.3430e-02, 1.0824e-02, 1.2962e-02, 8.1701e-03, 9.5461e-01]],\n",
      "\n",
      "         [[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [2.8229e-02, 9.7177e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [4.4961e-03, 5.0291e-02, 9.4521e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [1.6551e-02, 6.3697e-02, 2.2577e-02, 8.9717e-01, 0.0000e+00],\n",
      "          [7.0464e-03, 8.0078e-04, 1.4002e-03, 9.8939e-01, 1.3670e-03]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 6])\n",
      "old attention tensor([[[[0.4438, 0.1746, 0.0251, 0.1544, 0.1866, 0.0154],\n",
      "          [0.0595, 0.1234, 0.1713, 0.1005, 0.0937, 0.4515],\n",
      "          [0.0224, 0.2986, 0.0319, 0.2881, 0.3177, 0.0413],\n",
      "          [0.3879, 0.2774, 0.0363, 0.0599, 0.1500, 0.0885],\n",
      "          [0.0643, 0.0597, 0.2409, 0.4371, 0.1330, 0.0651]],\n",
      "\n",
      "         [[0.0622, 0.2232, 0.0337, 0.0463, 0.3987, 0.2358],\n",
      "          [0.0945, 0.0035, 0.6511, 0.1833, 0.0647, 0.0029],\n",
      "          [0.1093, 0.1980, 0.0315, 0.2702, 0.1553, 0.2356],\n",
      "          [0.0873, 0.0976, 0.2578, 0.3045, 0.0828, 0.1700],\n",
      "          [0.0804, 0.4603, 0.0393, 0.1440, 0.0844, 0.1916]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.1074, 0.8926, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0567, 0.0306, 0.9126, 0.0000, 0.0000],\n",
      "          [0.0195, 0.3433, 0.4147, 0.2225, 0.0000],\n",
      "          [0.1777, 0.0805, 0.2242, 0.1747, 0.3429]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0351, 0.9649, 0.0000, 0.0000, 0.0000],\n",
      "          [0.2566, 0.2713, 0.4722, 0.0000, 0.0000],\n",
      "          [0.0129, 0.6839, 0.2369, 0.0662, 0.0000],\n",
      "          [0.0416, 0.3076, 0.1004, 0.1820, 0.3684]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 6])\n",
      "old attention tensor([[[[0.3746, 0.0443, 0.2060, 0.1854, 0.1364, 0.0532],\n",
      "          [0.0708, 0.2625, 0.0796, 0.1629, 0.3229, 0.1013],\n",
      "          [0.0406, 0.1408, 0.2386, 0.2803, 0.1550, 0.1448],\n",
      "          [0.3107, 0.1084, 0.2210, 0.3038, 0.0385, 0.0177],\n",
      "          [0.0453, 0.0943, 0.1712, 0.3278, 0.1241, 0.2373]],\n",
      "\n",
      "         [[0.4504, 0.0272, 0.0673, 0.2002, 0.2256, 0.0293],\n",
      "          [0.3981, 0.0880, 0.1179, 0.2306, 0.1318, 0.0334],\n",
      "          [0.1072, 0.4821, 0.0109, 0.0848, 0.2590, 0.0560],\n",
      "          [0.4904, 0.0177, 0.0776, 0.2655, 0.0904, 0.0584],\n",
      "          [0.2272, 0.0839, 0.0522, 0.2952, 0.2061, 0.1354]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.2940, 0.7060, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0486, 0.9109, 0.0406, 0.0000, 0.0000],\n",
      "          [0.0596, 0.4113, 0.2634, 0.2657, 0.0000],\n",
      "          [0.0675, 0.3301, 0.1032, 0.1036, 0.3956]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.1100, 0.8900, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0803, 0.3990, 0.5207, 0.0000, 0.0000],\n",
      "          [0.0582, 0.2154, 0.6797, 0.0467, 0.0000],\n",
      "          [0.0335, 0.0865, 0.4941, 0.0294, 0.3565]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 6])\n",
      "old attention tensor([[[[0.1674, 0.0967, 0.0987, 0.0582, 0.3334, 0.2457],\n",
      "          [0.0383, 0.0201, 0.0523, 0.0766, 0.5361, 0.2767],\n",
      "          [0.2115, 0.0204, 0.1026, 0.0906, 0.4005, 0.1743],\n",
      "          [0.0870, 0.0123, 0.0442, 0.0306, 0.2812, 0.5447],\n",
      "          [0.1393, 0.0174, 0.0437, 0.0442, 0.1355, 0.6199]],\n",
      "\n",
      "         [[0.3125, 0.4252, 0.0634, 0.0604, 0.0439, 0.0946],\n",
      "          [0.1294, 0.0433, 0.2194, 0.1326, 0.3020, 0.1734],\n",
      "          [0.5068, 0.0942, 0.1085, 0.1552, 0.0513, 0.0840],\n",
      "          [0.1577, 0.0236, 0.5692, 0.1556, 0.0425, 0.0515],\n",
      "          [0.4109, 0.1818, 0.1790, 0.1058, 0.0412, 0.0813]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "predicted trg = ['ich', 'konnen', 'wasser', 'trinken', '<eos>']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_count 1    self.capacity  20\n",
      "0  ------------------------------------------------\n",
      "DecoderLayer@trg4\n",
      "[1, 1, 64]\n",
      "src = ['i', 'can', 'drink', 'beer']\n",
      "old attention torch.Size([1, 2, 6, 6])\n",
      "old attention tensor([[[[2.3627e-03, 2.0934e-02, 7.2966e-01, 5.2435e-02, 1.8803e-01,\n",
      "           6.5772e-03],\n",
      "          [3.8047e-02, 1.8350e-02, 2.7847e-01, 5.6782e-01, 9.6883e-02,\n",
      "           4.2915e-04],\n",
      "          [6.3601e-02, 2.7829e-01, 7.8557e-02, 2.2784e-01, 2.3041e-01,\n",
      "           1.2131e-01],\n",
      "          [2.2927e-03, 6.9942e-02, 1.8405e-02, 5.2878e-03, 5.0349e-03,\n",
      "           8.9904e-01],\n",
      "          [2.0415e-01, 5.3489e-02, 3.2580e-01, 9.0989e-02, 1.6708e-01,\n",
      "           1.5850e-01],\n",
      "          [9.5604e-03, 4.4451e-02, 4.4237e-01, 3.4375e-01, 1.5385e-01,\n",
      "           6.0156e-03]],\n",
      "\n",
      "         [[8.7720e-02, 5.7012e-02, 4.6674e-01, 2.8317e-01, 1.7822e-02,\n",
      "           8.7531e-02],\n",
      "          [1.7960e-02, 7.3045e-02, 7.5753e-01, 4.3595e-02, 6.2446e-02,\n",
      "           4.5422e-02],\n",
      "          [6.1004e-03, 9.3794e-02, 8.5262e-01, 4.1347e-02, 5.8992e-03,\n",
      "           2.4094e-04],\n",
      "          [2.9170e-01, 4.4862e-01, 1.6375e-01, 2.4452e-02, 1.4232e-02,\n",
      "           5.7253e-02],\n",
      "          [7.3464e-01, 1.3100e-02, 3.4788e-02, 1.7496e-01, 4.1015e-02,\n",
      "           1.4957e-03],\n",
      "          [4.8262e-02, 2.2929e-02, 4.8682e-02, 3.1858e-02, 6.2185e-01,\n",
      "           2.2641e-01]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 6, 6])\n",
      "old attention tensor([[[[0.1017, 0.0691, 0.4341, 0.1837, 0.1131, 0.0982],\n",
      "          [0.0889, 0.1801, 0.2951, 0.1226, 0.1366, 0.1765],\n",
      "          [0.2475, 0.1878, 0.0314, 0.0955, 0.3259, 0.1120],\n",
      "          [0.5776, 0.1241, 0.0864, 0.0481, 0.0511, 0.1127],\n",
      "          [0.2091, 0.3844, 0.0503, 0.1705, 0.0842, 0.1014],\n",
      "          [0.0891, 0.0602, 0.6305, 0.1330, 0.0469, 0.0404]],\n",
      "\n",
      "         [[0.1333, 0.1677, 0.3243, 0.2122, 0.0817, 0.0808],\n",
      "          [0.0302, 0.1533, 0.1200, 0.2220, 0.1466, 0.3279],\n",
      "          [0.3648, 0.0532, 0.1864, 0.1495, 0.1444, 0.1016],\n",
      "          [0.0402, 0.4013, 0.1043, 0.1158, 0.1541, 0.1842],\n",
      "          [0.0893, 0.2296, 0.2656, 0.2003, 0.0951, 0.1201],\n",
      "          [0.0471, 0.1252, 0.1060, 0.0912, 0.2254, 0.4052]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 6, 6])\n",
      "old attention tensor([[[[0.0614, 0.1797, 0.1199, 0.5572, 0.0258, 0.0559],\n",
      "          [0.1670, 0.1167, 0.1498, 0.2566, 0.1436, 0.1663],\n",
      "          [0.1193, 0.1883, 0.0211, 0.1634, 0.0847, 0.4232],\n",
      "          [0.1371, 0.0471, 0.0254, 0.1331, 0.0909, 0.5663],\n",
      "          [0.4035, 0.2229, 0.0260, 0.0821, 0.0246, 0.2409],\n",
      "          [0.2968, 0.1178, 0.0703, 0.0642, 0.2179, 0.2330]],\n",
      "\n",
      "         [[0.0108, 0.0326, 0.1652, 0.6949, 0.0947, 0.0019],\n",
      "          [0.0532, 0.2273, 0.0160, 0.1787, 0.0459, 0.4789],\n",
      "          [0.0328, 0.0288, 0.5288, 0.3068, 0.0948, 0.0079],\n",
      "          [0.0803, 0.3201, 0.2961, 0.2315, 0.0476, 0.0244],\n",
      "          [0.0746, 0.0275, 0.3559, 0.3894, 0.1440, 0.0086],\n",
      "          [0.2470, 0.3823, 0.0406, 0.0815, 0.0551, 0.1935]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 6])\n",
      "old attention tensor([[[[0.5349, 0.1541, 0.0564, 0.0793, 0.1095, 0.0658]],\n",
      "\n",
      "         [[0.2485, 0.3610, 0.1319, 0.1375, 0.0478, 0.0733]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 6])\n",
      "old attention tensor([[[[0.4581, 0.0642, 0.3073, 0.1135, 0.0482, 0.0087]],\n",
      "\n",
      "         [[0.5105, 0.0595, 0.1451, 0.0916, 0.0989, 0.0945]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 6])\n",
      "old attention tensor([[[[0.0131, 0.8305, 0.0771, 0.0503, 0.0235, 0.0055]],\n",
      "\n",
      "         [[0.0221, 0.5551, 0.0242, 0.0192, 0.0471, 0.3322]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.5428, 0.4572]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0282, 0.9718]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.5428, 0.4572]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0282, 0.9718]]]])\n",
      "old attention torch.Size([1, 2, 2, 6])\n",
      "old attention tensor([[[[0.5349, 0.1541, 0.0564, 0.0793, 0.1095, 0.0658],\n",
      "          [0.0492, 0.0931, 0.1229, 0.0406, 0.2102, 0.4840]],\n",
      "\n",
      "         [[0.2485, 0.3610, 0.1319, 0.1375, 0.0478, 0.0733],\n",
      "          [0.0476, 0.0016, 0.7922, 0.1365, 0.0187, 0.0033]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0151, 0.9849]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.1725, 0.8275]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0151, 0.9849]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.1725, 0.8275]]]])\n",
      "old attention torch.Size([1, 2, 2, 6])\n",
      "old attention tensor([[[[0.4581, 0.0642, 0.3073, 0.1135, 0.0482, 0.0087],\n",
      "          [0.0865, 0.2329, 0.1502, 0.1573, 0.2482, 0.1249]],\n",
      "\n",
      "         [[0.5105, 0.0595, 0.1451, 0.0916, 0.0989, 0.0945],\n",
      "          [0.0926, 0.0317, 0.3956, 0.1818, 0.2767, 0.0216]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.3714, 0.6286]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.1766, 0.8234]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.3714, 0.6286]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.1766, 0.8234]]]])\n",
      "old attention torch.Size([1, 2, 2, 6])\n",
      "old attention tensor([[[[0.0131, 0.8305, 0.0771, 0.0503, 0.0235, 0.0055],\n",
      "          [0.0171, 0.0136, 0.1496, 0.4575, 0.3060, 0.0562]],\n",
      "\n",
      "         [[0.0221, 0.5551, 0.0242, 0.0192, 0.0471, 0.3322],\n",
      "          [0.0131, 0.1069, 0.1216, 0.1242, 0.0922, 0.5419]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.5428, 0.4572, 0.0000],\n",
      "          [0.0148, 0.0673, 0.9179]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.0282, 0.9718, 0.0000],\n",
      "          [0.0045, 0.0503, 0.9452]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 6])\n",
      "old attention tensor([[[[0.4829, 0.2365, 0.0271, 0.1387, 0.0891, 0.0257],\n",
      "          [0.0426, 0.1183, 0.1412, 0.0623, 0.1885, 0.4470],\n",
      "          [0.0326, 0.4541, 0.0457, 0.2914, 0.0921, 0.0841]],\n",
      "\n",
      "         [[0.1049, 0.3528, 0.0913, 0.0931, 0.0445, 0.3133],\n",
      "          [0.0758, 0.0026, 0.7289, 0.1689, 0.0212, 0.0027],\n",
      "          [0.1229, 0.1800, 0.0626, 0.3579, 0.0811, 0.1955]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.0898, 0.9102, 0.0000],\n",
      "          [0.0553, 0.0794, 0.8653]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.0546, 0.9454, 0.0000],\n",
      "          [0.2242, 0.3169, 0.4589]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 6])\n",
      "old attention tensor([[[[0.3199, 0.0587, 0.2836, 0.1804, 0.1265, 0.0308],\n",
      "          [0.0861, 0.3572, 0.1350, 0.2046, 0.1477, 0.0694],\n",
      "          [0.0456, 0.1826, 0.3017, 0.2985, 0.0717, 0.0998]],\n",
      "\n",
      "         [[0.4456, 0.0411, 0.0620, 0.1146, 0.2927, 0.0439],\n",
      "          [0.2210, 0.0902, 0.0933, 0.0912, 0.4633, 0.0410],\n",
      "          [0.1324, 0.3866, 0.0151, 0.0626, 0.3372, 0.0662]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.3913, 0.6087, 0.0000],\n",
      "          [0.1378, 0.7357, 0.1265]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.1303, 0.8697, 0.0000],\n",
      "          [0.0586, 0.4078, 0.5335]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 6])\n",
      "old attention tensor([[[[0.0903, 0.2742, 0.1238, 0.1281, 0.2920, 0.0916],\n",
      "          [0.0300, 0.1037, 0.0862, 0.2253, 0.4659, 0.0887],\n",
      "          [0.0609, 0.0425, 0.0579, 0.0964, 0.7084, 0.0339]],\n",
      "\n",
      "         [[0.1172, 0.4333, 0.0550, 0.0528, 0.0578, 0.2839],\n",
      "          [0.0473, 0.0943, 0.1411, 0.1312, 0.0957, 0.4903],\n",
      "          [0.1593, 0.1673, 0.1036, 0.1549, 0.1110, 0.3039]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5428, 0.4572, 0.0000, 0.0000],\n",
      "          [0.0148, 0.0673, 0.9179, 0.0000],\n",
      "          [0.1503, 0.2513, 0.0657, 0.5328]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0282, 0.9718, 0.0000, 0.0000],\n",
      "          [0.0045, 0.0503, 0.9452, 0.0000],\n",
      "          [0.0441, 0.9079, 0.0155, 0.0325]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 6])\n",
      "old attention tensor([[[[0.5675, 0.1750, 0.0281, 0.1206, 0.0828, 0.0259],\n",
      "          [0.0516, 0.0909, 0.1473, 0.0546, 0.1833, 0.4723],\n",
      "          [0.0426, 0.4145, 0.0490, 0.3081, 0.0950, 0.0909],\n",
      "          [0.0454, 0.6414, 0.0324, 0.0975, 0.0755, 0.1079]],\n",
      "\n",
      "         [[0.0968, 0.3687, 0.0735, 0.0833, 0.0465, 0.3312],\n",
      "          [0.0783, 0.0027, 0.7173, 0.1757, 0.0231, 0.0028],\n",
      "          [0.1107, 0.2015, 0.0454, 0.3439, 0.0798, 0.2187],\n",
      "          [0.3155, 0.0267, 0.1897, 0.1208, 0.2111, 0.1361]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0842, 0.9158, 0.0000, 0.0000],\n",
      "          [0.0530, 0.1084, 0.8386, 0.0000],\n",
      "          [0.0075, 0.0260, 0.2672, 0.6993]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0680, 0.9320, 0.0000, 0.0000],\n",
      "          [0.2688, 0.2681, 0.4631, 0.0000],\n",
      "          [0.0471, 0.2415, 0.2338, 0.4777]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 6])\n",
      "old attention tensor([[[[0.4255, 0.0379, 0.2630, 0.1292, 0.1244, 0.0201],\n",
      "          [0.1134, 0.3255, 0.1404, 0.1781, 0.1715, 0.0711],\n",
      "          [0.0598, 0.1754, 0.3274, 0.2660, 0.0754, 0.0961],\n",
      "          [0.2870, 0.1095, 0.2431, 0.2006, 0.1386, 0.0212]],\n",
      "\n",
      "         [[0.4595, 0.0131, 0.1088, 0.1371, 0.2639, 0.0176],\n",
      "          [0.2161, 0.0432, 0.1710, 0.1109, 0.4352, 0.0237],\n",
      "          [0.1491, 0.2769, 0.0321, 0.0797, 0.4128, 0.0493],\n",
      "          [0.2323, 0.0188, 0.1348, 0.1321, 0.4642, 0.0179]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.3774, 0.6226, 0.0000, 0.0000],\n",
      "          [0.0832, 0.7348, 0.1820, 0.0000],\n",
      "          [0.0802, 0.1927, 0.3445, 0.3827]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.1920, 0.8080, 0.0000, 0.0000],\n",
      "          [0.0646, 0.2633, 0.6721, 0.0000],\n",
      "          [0.0639, 0.0994, 0.7476, 0.0891]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 6])\n",
      "old attention tensor([[[[0.0541, 0.1769, 0.1894, 0.1934, 0.2715, 0.1147],\n",
      "          [0.0136, 0.0602, 0.1045, 0.3296, 0.4100, 0.0821],\n",
      "          [0.0308, 0.0197, 0.0677, 0.1295, 0.7179, 0.0344],\n",
      "          [0.0125, 0.0299, 0.1202, 0.2348, 0.4455, 0.1572]],\n",
      "\n",
      "         [[0.0732, 0.5088, 0.0640, 0.0438, 0.0430, 0.2671],\n",
      "          [0.0405, 0.1149, 0.1345, 0.1164, 0.0826, 0.5111],\n",
      "          [0.1547, 0.1984, 0.1034, 0.1498, 0.0975, 0.2962],\n",
      "          [0.0686, 0.1593, 0.3109, 0.1331, 0.1556, 0.1725]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5428, 0.4572, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0148, 0.0673, 0.9179, 0.0000, 0.0000],\n",
      "          [0.1503, 0.2513, 0.0657, 0.5328, 0.0000],\n",
      "          [0.0130, 0.0105, 0.0125, 0.0413, 0.9227]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0282, 0.9718, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0045, 0.0503, 0.9452, 0.0000, 0.0000],\n",
      "          [0.0441, 0.9079, 0.0155, 0.0325, 0.0000],\n",
      "          [0.0323, 0.0037, 0.0064, 0.9514, 0.0063]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 6])\n",
      "old attention tensor([[[[0.5543, 0.1899, 0.0252, 0.1347, 0.0773, 0.0186],\n",
      "          [0.0526, 0.1087, 0.1556, 0.0664, 0.1983, 0.4185],\n",
      "          [0.0384, 0.4341, 0.0433, 0.3362, 0.0854, 0.0626],\n",
      "          [0.0412, 0.6782, 0.0289, 0.1063, 0.0686, 0.0768],\n",
      "          [0.0809, 0.0730, 0.2697, 0.4078, 0.0848, 0.0839]],\n",
      "\n",
      "         [[0.0701, 0.3593, 0.0546, 0.0696, 0.0524, 0.3940],\n",
      "          [0.0676, 0.0026, 0.7122, 0.1840, 0.0303, 0.0033],\n",
      "          [0.0826, 0.2027, 0.0351, 0.3012, 0.1002, 0.2781],\n",
      "          [0.2528, 0.0280, 0.1566, 0.1122, 0.2726, 0.1778],\n",
      "          [0.0613, 0.3829, 0.0463, 0.1456, 0.1396, 0.2244]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.1291, 0.8709, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0629, 0.0561, 0.8811, 0.0000, 0.0000],\n",
      "          [0.0094, 0.0180, 0.3022, 0.6705, 0.0000],\n",
      "          [0.1283, 0.0821, 0.1745, 0.2766, 0.3385]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0522, 0.9478, 0.0000, 0.0000, 0.0000],\n",
      "          [0.2719, 0.2648, 0.4633, 0.0000, 0.0000],\n",
      "          [0.0456, 0.2740, 0.2794, 0.4010, 0.0000],\n",
      "          [0.0565, 0.3332, 0.1147, 0.1400, 0.3556]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 6])\n",
      "old attention tensor([[[[0.3758, 0.0374, 0.2219, 0.1812, 0.1367, 0.0470],\n",
      "          [0.0835, 0.3102, 0.1049, 0.2162, 0.1725, 0.1126],\n",
      "          [0.0468, 0.1450, 0.2565, 0.3235, 0.0768, 0.1515],\n",
      "          [0.2446, 0.0932, 0.2010, 0.2663, 0.1620, 0.0330],\n",
      "          [0.0245, 0.0565, 0.1018, 0.1819, 0.5172, 0.1179]],\n",
      "\n",
      "         [[0.4351, 0.0161, 0.0682, 0.1792, 0.2849, 0.0164],\n",
      "          [0.2127, 0.0425, 0.0893, 0.1168, 0.5231, 0.0155],\n",
      "          [0.1242, 0.3246, 0.0170, 0.0844, 0.4093, 0.0406],\n",
      "          [0.2334, 0.0203, 0.0739, 0.1529, 0.5059, 0.0136],\n",
      "          [0.1345, 0.0482, 0.0326, 0.1647, 0.5549, 0.0651]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.3588, 0.6412, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0941, 0.8110, 0.0949, 0.0000, 0.0000],\n",
      "          [0.1285, 0.2191, 0.2857, 0.3666, 0.0000],\n",
      "          [0.0901, 0.2872, 0.1517, 0.0652, 0.4057]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.1457, 0.8543, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0852, 0.4062, 0.5086, 0.0000, 0.0000],\n",
      "          [0.0924, 0.1003, 0.7084, 0.0989, 0.0000],\n",
      "          [0.0270, 0.0931, 0.4002, 0.0895, 0.3902]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 6])\n",
      "old attention tensor([[[[0.1319, 0.0601, 0.1246, 0.0811, 0.2209, 0.3814],\n",
      "          [0.0367, 0.0197, 0.0724, 0.1237, 0.3487, 0.3988],\n",
      "          [0.0915, 0.0108, 0.0646, 0.0717, 0.6105, 0.1509],\n",
      "          [0.0304, 0.0088, 0.0671, 0.0749, 0.2839, 0.5349],\n",
      "          [0.0880, 0.0118, 0.0371, 0.0465, 0.2373, 0.5794]],\n",
      "\n",
      "         [[0.3883, 0.3527, 0.0711, 0.0492, 0.0450, 0.0936],\n",
      "          [0.2259, 0.0785, 0.2112, 0.1551, 0.1127, 0.2167],\n",
      "          [0.5175, 0.1042, 0.0964, 0.1211, 0.0751, 0.0858],\n",
      "          [0.2950, 0.0906, 0.3067, 0.1250, 0.1302, 0.0526],\n",
      "          [0.5073, 0.1672, 0.1128, 0.0788, 0.0540, 0.0799]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "predicted trg = ['ich', 'konnen', 'bier', 'trinken', '<eos>']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_count 1    self.capacity  20\n",
      "0  ------------------------------------------------\n",
      "DecoderLayer@trg4\n",
      "[1, 1, 64]\n",
      "src = ['i', 'can', 'read', 'book']\n",
      "old attention torch.Size([1, 2, 6, 6])\n",
      "old attention tensor([[[[3.0353e-03, 2.6893e-02, 9.3737e-01, 1.3802e-02, 1.0454e-02,\n",
      "           8.4495e-03],\n",
      "          [2.8335e-02, 1.3666e-02, 2.0739e-01, 4.2566e-02, 7.0772e-01,\n",
      "           3.1961e-04],\n",
      "          [2.8280e-02, 1.2374e-01, 3.4930e-02, 1.8910e-01, 5.7001e-01,\n",
      "           5.3939e-02],\n",
      "          [9.2517e-03, 2.7452e-04, 4.7023e-02, 2.7457e-03, 9.3788e-01,\n",
      "           2.8286e-03],\n",
      "          [1.0823e-01, 1.9268e-02, 5.3812e-01, 6.4516e-02, 1.5357e-01,\n",
      "           1.1630e-01],\n",
      "          [1.5026e-02, 6.9864e-02, 6.9528e-01, 5.9654e-02, 1.5072e-01,\n",
      "           9.4547e-03]],\n",
      "\n",
      "         [[1.1978e-01, 7.7851e-02, 6.3736e-01, 3.8115e-02, 7.3662e-03,\n",
      "           1.1953e-01],\n",
      "          [1.9443e-02, 7.9075e-02, 8.2006e-01, 4.7660e-03, 2.7481e-02,\n",
      "           4.9172e-02],\n",
      "          [6.3668e-03, 9.7889e-02, 8.8985e-01, 3.7894e-04, 5.2681e-03,\n",
      "           2.5146e-04],\n",
      "          [2.3945e-01, 8.2514e-03, 1.0470e-01, 1.0285e-02, 1.8820e-02,\n",
      "           6.1849e-01],\n",
      "          [5.2837e-02, 4.5943e-02, 6.5048e-01, 5.2823e-02, 1.2652e-01,\n",
      "           7.1397e-02],\n",
      "          [1.3433e-02, 6.3818e-03, 1.3550e-02, 8.6315e-01, 4.0467e-02,\n",
      "           6.3017e-02]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 6, 6])\n",
      "old attention tensor([[[[0.0755, 0.0421, 0.3169, 0.3521, 0.1555, 0.0579],\n",
      "          [0.0680, 0.1515, 0.2189, 0.0994, 0.3329, 0.1293],\n",
      "          [0.3220, 0.2290, 0.0387, 0.1099, 0.1722, 0.1283],\n",
      "          [0.1521, 0.0797, 0.0615, 0.5313, 0.0873, 0.0882],\n",
      "          [0.2387, 0.0708, 0.1495, 0.3510, 0.1102, 0.0797],\n",
      "          [0.0376, 0.0253, 0.2470, 0.0801, 0.5960, 0.0141]],\n",
      "\n",
      "         [[0.1620, 0.1902, 0.3418, 0.1014, 0.0829, 0.1217],\n",
      "          [0.0339, 0.1173, 0.1097, 0.2256, 0.1657, 0.3478],\n",
      "          [0.4761, 0.0583, 0.2105, 0.0438, 0.0976, 0.1137],\n",
      "          [0.2208, 0.3686, 0.1018, 0.1216, 0.1110, 0.0762],\n",
      "          [0.0904, 0.2037, 0.1123, 0.1408, 0.1078, 0.3450],\n",
      "          [0.0398, 0.0829, 0.0771, 0.2963, 0.1314, 0.3724]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 6, 6])\n",
      "old attention tensor([[[[0.1373, 0.3652, 0.1976, 0.0505, 0.1523, 0.0971],\n",
      "          [0.1711, 0.1111, 0.1096, 0.3651, 0.1320, 0.1112],\n",
      "          [0.1281, 0.2190, 0.0162, 0.1020, 0.0629, 0.4718],\n",
      "          [0.1295, 0.2187, 0.0430, 0.0879, 0.1088, 0.4121],\n",
      "          [0.1919, 0.4596, 0.0083, 0.1965, 0.0374, 0.1063],\n",
      "          [0.4420, 0.1080, 0.0660, 0.1393, 0.1261, 0.1187]],\n",
      "\n",
      "         [[0.0552, 0.0992, 0.6733, 0.1541, 0.0102, 0.0081],\n",
      "          [0.0386, 0.1556, 0.0155, 0.1703, 0.0304, 0.5897],\n",
      "          [0.0341, 0.0238, 0.8497, 0.0674, 0.0174, 0.0076],\n",
      "          [0.1398, 0.0067, 0.4325, 0.3683, 0.0135, 0.0392],\n",
      "          [0.1786, 0.0585, 0.3989, 0.1195, 0.0136, 0.2308],\n",
      "          [0.2456, 0.2446, 0.0412, 0.2029, 0.0799, 0.1858]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 6])\n",
      "old attention tensor([[[[0.4933, 0.1552, 0.0631, 0.1311, 0.1016, 0.0557]],\n",
      "\n",
      "         [[0.2629, 0.3283, 0.1458, 0.1319, 0.0748, 0.0563]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 6])\n",
      "old attention tensor([[[[0.5319, 0.0822, 0.3305, 0.0285, 0.0205, 0.0065]],\n",
      "\n",
      "         [[0.2498, 0.0482, 0.0551, 0.4038, 0.1457, 0.0974]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 6])\n",
      "old attention tensor([[[[0.0132, 0.9263, 0.0437, 0.0065, 0.0084, 0.0019]],\n",
      "\n",
      "         [[0.0133, 0.4266, 0.0192, 0.0410, 0.1308, 0.3691]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.5428, 0.4572]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0282, 0.9718]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.5428, 0.4572]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0282, 0.9718]]]])\n",
      "old attention torch.Size([1, 2, 2, 6])\n",
      "old attention tensor([[[[0.4933, 0.1552, 0.0631, 0.1311, 0.1016, 0.0557],\n",
      "          [0.0342, 0.0557, 0.0673, 0.1685, 0.3538, 0.3206]],\n",
      "\n",
      "         [[0.2629, 0.3283, 0.1458, 0.1319, 0.0748, 0.0563],\n",
      "          [0.0571, 0.0023, 0.8630, 0.0094, 0.0653, 0.0029]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0119, 0.9881]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.1281, 0.8719]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0119, 0.9881]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.1281, 0.8719]]]])\n",
      "old attention torch.Size([1, 2, 2, 6])\n",
      "old attention tensor([[[[0.5319, 0.0822, 0.3305, 0.0285, 0.0205, 0.0065],\n",
      "          [0.0495, 0.1499, 0.0876, 0.3499, 0.2706, 0.0924]],\n",
      "\n",
      "         [[0.2498, 0.0482, 0.0551, 0.4038, 0.1457, 0.0974],\n",
      "          [0.1123, 0.0502, 0.5331, 0.0366, 0.2238, 0.0441]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.3624, 0.6376]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0896, 0.9104]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.3624, 0.6376]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0896, 0.9104]]]])\n",
      "old attention torch.Size([1, 2, 2, 6])\n",
      "old attention tensor([[[[0.0132, 0.9263, 0.0437, 0.0065, 0.0084, 0.0019],\n",
      "          [0.0246, 0.0265, 0.2610, 0.0913, 0.5498, 0.0468]],\n",
      "\n",
      "         [[0.0133, 0.4266, 0.0192, 0.0410, 0.1308, 0.3691],\n",
      "          [0.0038, 0.0445, 0.0641, 0.0472, 0.5375, 0.3029]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.5428, 0.4572, 0.0000],\n",
      "          [0.0148, 0.0673, 0.9179]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.0282, 0.9718, 0.0000],\n",
      "          [0.0045, 0.0503, 0.9452]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 6])\n",
      "old attention tensor([[[[0.5114, 0.2518, 0.0331, 0.0938, 0.0857, 0.0242],\n",
      "          [0.0276, 0.0760, 0.0669, 0.1356, 0.3988, 0.2950],\n",
      "          [0.0324, 0.5882, 0.0472, 0.0928, 0.0943, 0.1452]],\n",
      "\n",
      "         [[0.0864, 0.2496, 0.0772, 0.3185, 0.1145, 0.1538],\n",
      "          [0.0964, 0.0032, 0.8506, 0.0061, 0.0415, 0.0022],\n",
      "          [0.1578, 0.2296, 0.0895, 0.1211, 0.1394, 0.2627]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.1205, 0.8795, 0.0000],\n",
      "          [0.0891, 0.0374, 0.8735]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.0334, 0.9666, 0.0000],\n",
      "          [0.2056, 0.2591, 0.5353]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 6])\n",
      "old attention tensor([[[[0.3440, 0.0867, 0.3003, 0.1693, 0.0602, 0.0395],\n",
      "          [0.0477, 0.2778, 0.0769, 0.4172, 0.1253, 0.0551],\n",
      "          [0.0255, 0.1570, 0.1895, 0.2246, 0.2748, 0.1286]],\n",
      "\n",
      "         [[0.1949, 0.0519, 0.0271, 0.5948, 0.0711, 0.0602],\n",
      "          [0.1513, 0.0954, 0.0553, 0.3332, 0.2932, 0.0716],\n",
      "          [0.0417, 0.2187, 0.0050, 0.6399, 0.0222, 0.0724]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.4813, 0.5187, 0.0000],\n",
      "          [0.2926, 0.5907, 0.1167]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.1194, 0.8806, 0.0000],\n",
      "          [0.1025, 0.6032, 0.2943]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 6])\n",
      "old attention tensor([[[[0.1639, 0.5023, 0.1128, 0.1517, 0.0327, 0.0366],\n",
      "          [0.0798, 0.3707, 0.1229, 0.2301, 0.1387, 0.0578],\n",
      "          [0.2577, 0.2571, 0.1398, 0.2657, 0.0392, 0.0406]],\n",
      "\n",
      "         [[0.0747, 0.1901, 0.0516, 0.2295, 0.1580, 0.2961],\n",
      "          [0.0158, 0.0373, 0.0927, 0.2259, 0.3489, 0.2794],\n",
      "          [0.0615, 0.0652, 0.1018, 0.3597, 0.2103, 0.2016]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5428, 0.4572, 0.0000, 0.0000],\n",
      "          [0.0148, 0.0673, 0.9179, 0.0000],\n",
      "          [0.0509, 0.2400, 0.0550, 0.6541]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0282, 0.9718, 0.0000, 0.0000],\n",
      "          [0.0045, 0.0503, 0.9452, 0.0000],\n",
      "          [0.2908, 0.1379, 0.0290, 0.5423]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 6])\n",
      "old attention tensor([[[[0.5313, 0.2485, 0.0321, 0.0804, 0.0806, 0.0271],\n",
      "          [0.0273, 0.0734, 0.0664, 0.1173, 0.3771, 0.3384],\n",
      "          [0.0313, 0.5864, 0.0460, 0.0785, 0.0880, 0.1698],\n",
      "          [0.4173, 0.0995, 0.1312, 0.1254, 0.1966, 0.0300]],\n",
      "\n",
      "         [[0.1108, 0.2613, 0.0609, 0.3620, 0.0846, 0.1203],\n",
      "          [0.1426, 0.0038, 0.8073, 0.0077, 0.0365, 0.0020],\n",
      "          [0.2165, 0.2497, 0.0730, 0.1405, 0.1063, 0.2140],\n",
      "          [0.3802, 0.0278, 0.3176, 0.0462, 0.2014, 0.0268]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0509, 0.9491, 0.0000, 0.0000],\n",
      "          [0.0489, 0.0586, 0.8925, 0.0000],\n",
      "          [0.0177, 0.1448, 0.7518, 0.0857]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0452, 0.9548, 0.0000, 0.0000],\n",
      "          [0.2782, 0.1860, 0.5358, 0.0000],\n",
      "          [0.0328, 0.5935, 0.1789, 0.1947]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 6])\n",
      "old attention tensor([[[[0.3726, 0.0694, 0.3465, 0.1227, 0.0528, 0.0360],\n",
      "          [0.0549, 0.2780, 0.0960, 0.3658, 0.1448, 0.0605],\n",
      "          [0.0244, 0.1479, 0.2209, 0.1804, 0.3057, 0.1207],\n",
      "          [0.1220, 0.0538, 0.1969, 0.4290, 0.1391, 0.0592]],\n",
      "\n",
      "         [[0.2163, 0.0549, 0.0587, 0.5302, 0.0689, 0.0710],\n",
      "          [0.1461, 0.0992, 0.1220, 0.2628, 0.2963, 0.0736],\n",
      "          [0.0380, 0.2727, 0.0087, 0.5749, 0.0190, 0.0868],\n",
      "          [0.2562, 0.0755, 0.0304, 0.3521, 0.1499, 0.1359]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5649, 0.4351, 0.0000, 0.0000],\n",
      "          [0.3498, 0.5059, 0.1443, 0.0000],\n",
      "          [0.2332, 0.1739, 0.2693, 0.3235]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0991, 0.9009, 0.0000, 0.0000],\n",
      "          [0.0748, 0.5255, 0.3996, 0.0000],\n",
      "          [0.0236, 0.6066, 0.1699, 0.2000]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 6])\n",
      "old attention tensor([[[[0.1202, 0.6414, 0.0846, 0.1072, 0.0215, 0.0252],\n",
      "          [0.0606, 0.4193, 0.1206, 0.2169, 0.1366, 0.0459],\n",
      "          [0.2223, 0.3181, 0.1430, 0.2464, 0.0368, 0.0334],\n",
      "          [0.2505, 0.2988, 0.1236, 0.2337, 0.0596, 0.0337]],\n",
      "\n",
      "         [[0.0573, 0.2455, 0.0312, 0.1595, 0.1274, 0.3790],\n",
      "          [0.0094, 0.0404, 0.0689, 0.1564, 0.3487, 0.3762],\n",
      "          [0.0410, 0.0737, 0.0747, 0.2738, 0.2236, 0.3132],\n",
      "          [0.0249, 0.1060, 0.0831, 0.2055, 0.3008, 0.2797]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [5.4283e-01, 4.5717e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [1.4779e-02, 6.7309e-02, 9.1791e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [5.0924e-02, 2.3997e-01, 5.4981e-02, 6.5413e-01, 0.0000e+00],\n",
      "          [3.1574e-03, 6.0708e-04, 5.2880e-03, 7.0641e-03, 9.8388e-01]],\n",
      "\n",
      "         [[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [2.8229e-02, 9.7177e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [4.4961e-03, 5.0291e-02, 9.4521e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [2.9080e-01, 1.3787e-01, 2.9016e-02, 5.4231e-01, 0.0000e+00],\n",
      "          [1.7542e-03, 7.7674e-02, 3.1632e-02, 2.6033e-02, 8.6291e-01]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 6])\n",
      "old attention tensor([[[[0.5592, 0.2839, 0.0284, 0.0607, 0.0484, 0.0193],\n",
      "          [0.0347, 0.1064, 0.0747, 0.1176, 0.3264, 0.3402],\n",
      "          [0.0314, 0.7071, 0.0384, 0.0565, 0.0496, 0.1170],\n",
      "          [0.4944, 0.1181, 0.1255, 0.1042, 0.1357, 0.0221],\n",
      "          [0.2910, 0.0739, 0.2166, 0.1004, 0.1468, 0.1713]],\n",
      "\n",
      "         [[0.0931, 0.2515, 0.0297, 0.4639, 0.0523, 0.1095],\n",
      "          [0.2012, 0.0048, 0.7435, 0.0137, 0.0344, 0.0023],\n",
      "          [0.2017, 0.2721, 0.0361, 0.2048, 0.0688, 0.2164],\n",
      "          [0.4550, 0.0336, 0.2303, 0.0739, 0.1766, 0.0305],\n",
      "          [0.0858, 0.1343, 0.0201, 0.6889, 0.0395, 0.0314]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0653, 0.9347, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0964, 0.0537, 0.8498, 0.0000, 0.0000],\n",
      "          [0.0183, 0.1273, 0.7826, 0.0717, 0.0000],\n",
      "          [0.0015, 0.0316, 0.0867, 0.0355, 0.8447]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0257, 0.9743, 0.0000, 0.0000, 0.0000],\n",
      "          [0.2664, 0.1515, 0.5821, 0.0000, 0.0000],\n",
      "          [0.0209, 0.6475, 0.1505, 0.1812, 0.0000],\n",
      "          [0.0225, 0.2542, 0.2060, 0.2306, 0.2866]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 6])\n",
      "old attention tensor([[[[0.3230, 0.0491, 0.3666, 0.1205, 0.0673, 0.0735],\n",
      "          [0.0371, 0.2575, 0.0812, 0.3589, 0.1629, 0.1024],\n",
      "          [0.0134, 0.1031, 0.1796, 0.1473, 0.3477, 0.2089],\n",
      "          [0.0898, 0.0375, 0.1847, 0.4236, 0.1652, 0.0991],\n",
      "          [0.1222, 0.1675, 0.1694, 0.2828, 0.2023, 0.0558]],\n",
      "\n",
      "         [[0.4135, 0.0458, 0.1838, 0.2266, 0.0728, 0.0575],\n",
      "          [0.2015, 0.0896, 0.2833, 0.1015, 0.2767, 0.0474],\n",
      "          [0.0591, 0.4531, 0.0244, 0.3379, 0.0167, 0.1088],\n",
      "          [0.4405, 0.0657, 0.0621, 0.1690, 0.1507, 0.1120],\n",
      "          [0.1281, 0.2079, 0.2786, 0.1666, 0.0874, 0.1314]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5325, 0.4675, 0.0000, 0.0000, 0.0000],\n",
      "          [0.2445, 0.6043, 0.1513, 0.0000, 0.0000],\n",
      "          [0.1650, 0.1268, 0.3434, 0.3648, 0.0000],\n",
      "          [0.1107, 0.0996, 0.2475, 0.3368, 0.2054]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0895, 0.9105, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0612, 0.3377, 0.6011, 0.0000, 0.0000],\n",
      "          [0.0122, 0.4878, 0.2603, 0.2398, 0.0000],\n",
      "          [0.0225, 0.0861, 0.4355, 0.0683, 0.3876]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 6])\n",
      "old attention tensor([[[[0.2647, 0.3153, 0.1546, 0.1323, 0.0459, 0.0872],\n",
      "          [0.0573, 0.1411, 0.1544, 0.2190, 0.3064, 0.1218],\n",
      "          [0.2774, 0.0979, 0.1981, 0.2662, 0.0715, 0.0889],\n",
      "          [0.2904, 0.0864, 0.1661, 0.2526, 0.1240, 0.0805],\n",
      "          [0.0382, 0.0648, 0.2394, 0.2317, 0.1838, 0.2421]],\n",
      "\n",
      "         [[0.1340, 0.4728, 0.0375, 0.1305, 0.0652, 0.1600],\n",
      "          [0.0209, 0.0604, 0.1108, 0.1996, 0.3414, 0.2669],\n",
      "          [0.1271, 0.1336, 0.1071, 0.3108, 0.1557, 0.1657],\n",
      "          [0.0571, 0.1647, 0.1076, 0.2446, 0.2577, 0.1683],\n",
      "          [0.0930, 0.1493, 0.2053, 0.0987, 0.3098, 0.1440]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "predicted trg = ['ich', 'konnen', 'buch', 'lesen', '<eos>']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_count 1    self.capacity  20\n",
      "0  ------------------------------------------------\n",
      "DecoderLayer@trg4\n",
      "[1, 1, 64]\n",
      "src = ['i', 'can', 'read', 'newspaper']\n",
      "old attention torch.Size([1, 2, 6, 6])\n",
      "old attention tensor([[[[2.8038e-03, 2.4842e-02, 8.6588e-01, 1.2749e-02, 8.5923e-02,\n",
      "           7.8051e-03],\n",
      "          [7.0493e-02, 3.3999e-02, 5.1594e-01, 1.0589e-01, 2.7288e-01,\n",
      "           7.9514e-04],\n",
      "          [2.6855e-02, 1.1751e-01, 3.3170e-02, 1.7958e-01, 5.9167e-01,\n",
      "           5.1221e-02],\n",
      "          [3.4177e-02, 1.0141e-03, 1.7371e-01, 1.0143e-02, 7.7051e-01,\n",
      "           1.0449e-02],\n",
      "          [5.4907e-01, 5.2055e-02, 9.1473e-02, 2.3730e-01, 3.8967e-02,\n",
      "           3.1140e-02],\n",
      "          [1.1276e-02, 5.2426e-02, 5.2174e-01, 4.4764e-02, 3.6270e-01,\n",
      "           7.0948e-03]],\n",
      "\n",
      "         [[8.5628e-02, 5.5652e-02, 4.5562e-01, 2.7246e-02, 2.9041e-01,\n",
      "           8.5444e-02],\n",
      "          [1.8811e-02, 7.6505e-02, 7.9341e-01, 4.6111e-03, 5.9093e-02,\n",
      "           4.7573e-02],\n",
      "          [6.3657e-03, 9.7873e-02, 8.8970e-01, 3.7888e-04, 5.4354e-03,\n",
      "           2.5142e-04],\n",
      "          [2.2474e-01, 7.7443e-03, 9.8269e-02, 9.6525e-03, 7.9126e-02,\n",
      "           5.8047e-01],\n",
      "          [7.7696e-03, 1.4514e-01, 2.3937e-02, 4.7632e-01, 1.9921e-01,\n",
      "           1.4762e-01],\n",
      "          [1.3591e-02, 6.4569e-03, 1.3709e-02, 8.7330e-01, 2.9181e-02,\n",
      "           6.3759e-02]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 6, 6])\n",
      "old attention tensor([[[[0.0514, 0.0361, 0.2614, 0.2839, 0.3101, 0.0572],\n",
      "          [0.0676, 0.1557, 0.2586, 0.1137, 0.2429, 0.1615],\n",
      "          [0.2514, 0.2119, 0.0380, 0.0913, 0.2632, 0.1442],\n",
      "          [0.1577, 0.0931, 0.0763, 0.4647, 0.1045, 0.1037],\n",
      "          [0.0923, 0.1377, 0.2148, 0.0304, 0.4350, 0.0899],\n",
      "          [0.0539, 0.0414, 0.4248, 0.1305, 0.3218, 0.0275]],\n",
      "\n",
      "         [[0.1652, 0.2133, 0.3712, 0.0808, 0.0511, 0.1185],\n",
      "          [0.0249, 0.0973, 0.0967, 0.1608, 0.3775, 0.2428],\n",
      "          [0.5321, 0.0579, 0.2442, 0.0347, 0.0386, 0.0926],\n",
      "          [0.1568, 0.2498, 0.0783, 0.0753, 0.3955, 0.0443],\n",
      "          [0.8661, 0.0467, 0.0166, 0.0176, 0.0231, 0.0298],\n",
      "          [0.0397, 0.0829, 0.0959, 0.2493, 0.2191, 0.3131]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 6, 6])\n",
      "old attention tensor([[[[0.1374, 0.3919, 0.2459, 0.0614, 0.0871, 0.0763],\n",
      "          [0.1031, 0.0660, 0.0620, 0.1984, 0.5211, 0.0495],\n",
      "          [0.1378, 0.2270, 0.0144, 0.0973, 0.1236, 0.3998],\n",
      "          [0.1255, 0.1433, 0.0408, 0.0722, 0.3321, 0.2861],\n",
      "          [0.0503, 0.0354, 0.0882, 0.0149, 0.5381, 0.2731],\n",
      "          [0.4200, 0.1018, 0.0629, 0.1119, 0.2080, 0.0952]],\n",
      "\n",
      "         [[0.0686, 0.0882, 0.6224, 0.1789, 0.0324, 0.0095],\n",
      "          [0.0302, 0.1003, 0.0090, 0.1769, 0.1899, 0.4937],\n",
      "          [0.0276, 0.0166, 0.8338, 0.0888, 0.0273, 0.0060],\n",
      "          [0.1472, 0.0068, 0.3645, 0.3650, 0.0756, 0.0410],\n",
      "          [0.1673, 0.0541, 0.2374, 0.3034, 0.1289, 0.1089],\n",
      "          [0.1927, 0.2175, 0.0293, 0.1789, 0.2006, 0.1811]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 6])\n",
      "old attention tensor([[[[0.4826, 0.1841, 0.0777, 0.1529, 0.0430, 0.0597]],\n",
      "\n",
      "         [[0.2494, 0.2393, 0.1637, 0.1123, 0.1880, 0.0474]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 6])\n",
      "old attention tensor([[[[0.5053, 0.0805, 0.3298, 0.0305, 0.0460, 0.0079]],\n",
      "\n",
      "         [[0.1888, 0.0531, 0.0498, 0.3277, 0.2775, 0.1031]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 6])\n",
      "old attention tensor([[[[0.0103, 0.9518, 0.0285, 0.0037, 0.0038, 0.0019]],\n",
      "\n",
      "         [[0.0097, 0.4477, 0.0169, 0.0355, 0.1106, 0.3797]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.5428, 0.4572]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0282, 0.9718]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.5428, 0.4572]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0282, 0.9718]]]])\n",
      "old attention torch.Size([1, 2, 2, 6])\n",
      "old attention tensor([[[[0.4826, 0.1841, 0.0777, 0.1529, 0.0430, 0.0597],\n",
      "          [0.0506, 0.0703, 0.0797, 0.1746, 0.2300, 0.3949]],\n",
      "\n",
      "         [[0.2494, 0.2393, 0.1637, 0.1123, 0.1880, 0.0474],\n",
      "          [0.0515, 0.0019, 0.8401, 0.0121, 0.0920, 0.0025]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0081, 0.9919]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.1416, 0.8584]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0081, 0.9919]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.1416, 0.8584]]]])\n",
      "old attention torch.Size([1, 2, 2, 6])\n",
      "old attention tensor([[[[0.5053, 0.0805, 0.3298, 0.0305, 0.0460, 0.0079],\n",
      "          [0.0686, 0.1901, 0.0905, 0.3712, 0.1814, 0.0983]],\n",
      "\n",
      "         [[0.1888, 0.0531, 0.0498, 0.3277, 0.2775, 0.1031],\n",
      "          [0.1435, 0.0656, 0.6266, 0.0468, 0.0672, 0.0504]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.3863, 0.6137]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0839, 0.9161]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.3863, 0.6137]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0839, 0.9161]]]])\n",
      "old attention torch.Size([1, 2, 2, 6])\n",
      "old attention tensor([[[[0.0103, 0.9518, 0.0285, 0.0037, 0.0038, 0.0019],\n",
      "          [0.0500, 0.0724, 0.4475, 0.2099, 0.1292, 0.0911]],\n",
      "\n",
      "         [[0.0097, 0.4477, 0.0169, 0.0355, 0.1106, 0.3797],\n",
      "          [0.0053, 0.0602, 0.0933, 0.0702, 0.3780, 0.3930]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [5.4283e-01, 4.5717e-01, 0.0000e+00],\n",
      "          [5.7928e-03, 9.5962e-04, 9.9325e-01]],\n",
      "\n",
      "         [[1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [2.8229e-02, 9.7177e-01, 0.0000e+00],\n",
      "          [2.5488e-03, 1.1255e-01, 8.8490e-01]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 6])\n",
      "old attention tensor([[[[0.5997, 0.2560, 0.0367, 0.0685, 0.0201, 0.0189],\n",
      "          [0.0773, 0.1234, 0.1142, 0.1242, 0.1993, 0.3616],\n",
      "          [0.3462, 0.0838, 0.2113, 0.1057, 0.1028, 0.1503]],\n",
      "\n",
      "         [[0.0810, 0.1266, 0.0250, 0.3876, 0.3121, 0.0677],\n",
      "          [0.2108, 0.0046, 0.7091, 0.0252, 0.0483, 0.0019],\n",
      "          [0.0831, 0.0938, 0.0165, 0.5866, 0.1954, 0.0246]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.0286, 0.9714, 0.0000],\n",
      "          [0.0027, 0.0820, 0.9153]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.0217, 0.9783, 0.0000],\n",
      "          [0.0365, 0.5307, 0.4328]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 6])\n",
      "old attention tensor([[[[0.3566, 0.0673, 0.3410, 0.0922, 0.0746, 0.0683],\n",
      "          [0.0940, 0.2872, 0.1092, 0.2080, 0.2052, 0.0963],\n",
      "          [0.2246, 0.2033, 0.1906, 0.2072, 0.1079, 0.0664]],\n",
      "\n",
      "         [[0.2639, 0.0276, 0.3934, 0.0442, 0.2311, 0.0398],\n",
      "          [0.2114, 0.0729, 0.5861, 0.0343, 0.0529, 0.0424],\n",
      "          [0.1198, 0.1240, 0.4715, 0.0422, 0.1562, 0.0863]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.3462, 0.6538, 0.0000],\n",
      "          [0.1561, 0.4261, 0.4178]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.1017, 0.8983, 0.0000],\n",
      "          [0.0534, 0.1292, 0.8174]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 6])\n",
      "old attention tensor([[[[0.1718, 0.2845, 0.2243, 0.0452, 0.1689, 0.1054],\n",
      "          [0.0489, 0.2018, 0.3864, 0.1360, 0.1101, 0.1167],\n",
      "          [0.0231, 0.0733, 0.3906, 0.1182, 0.1652, 0.2295]],\n",
      "\n",
      "         [[0.0350, 0.5816, 0.0335, 0.0276, 0.1549, 0.1674],\n",
      "          [0.0127, 0.1656, 0.0979, 0.0653, 0.2666, 0.3920],\n",
      "          [0.0473, 0.3797, 0.1401, 0.0306, 0.1951, 0.2072]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [5.4283e-01, 4.5717e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [5.7928e-03, 9.5962e-04, 9.9325e-01, 0.0000e+00],\n",
      "          [3.2158e-02, 5.3844e-02, 8.9735e-01, 1.6650e-02]],\n",
      "\n",
      "         [[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [2.8229e-02, 9.7177e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [2.5488e-03, 1.1255e-01, 8.8490e-01, 0.0000e+00],\n",
      "          [5.3481e-03, 7.5643e-01, 2.1576e-01, 2.2460e-02]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 6])\n",
      "old attention tensor([[[[0.6448, 0.1837, 0.0422, 0.0802, 0.0253, 0.0237],\n",
      "          [0.0664, 0.0733, 0.1130, 0.1232, 0.2201, 0.4040],\n",
      "          [0.3203, 0.0559, 0.2213, 0.1113, 0.1183, 0.1729],\n",
      "          [0.4008, 0.1172, 0.1571, 0.0998, 0.1494, 0.0757]],\n",
      "\n",
      "         [[0.0601, 0.1295, 0.0211, 0.3613, 0.3427, 0.0854],\n",
      "          [0.1811, 0.0050, 0.7287, 0.0251, 0.0575, 0.0025],\n",
      "          [0.0681, 0.1012, 0.0157, 0.5624, 0.2197, 0.0329],\n",
      "          [0.0531, 0.0085, 0.1350, 0.2177, 0.5614, 0.0243]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0217, 0.9783, 0.0000, 0.0000],\n",
      "          [0.0024, 0.0882, 0.9094, 0.0000],\n",
      "          [0.0031, 0.0675, 0.4757, 0.4538]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0274, 0.9726, 0.0000, 0.0000],\n",
      "          [0.0433, 0.5214, 0.4354, 0.0000],\n",
      "          [0.0492, 0.1965, 0.3452, 0.4091]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 6])\n",
      "old attention tensor([[[[0.3671, 0.0669, 0.2763, 0.1101, 0.0797, 0.0997],\n",
      "          [0.0777, 0.2635, 0.0874, 0.2384, 0.2078, 0.1252],\n",
      "          [0.2066, 0.1889, 0.1621, 0.2493, 0.1145, 0.0786],\n",
      "          [0.1532, 0.1367, 0.3304, 0.1661, 0.0956, 0.1181]],\n",
      "\n",
      "         [[0.2671, 0.0241, 0.4562, 0.0324, 0.1900, 0.0303],\n",
      "          [0.2090, 0.0759, 0.5990, 0.0286, 0.0462, 0.0413],\n",
      "          [0.1261, 0.1202, 0.5017, 0.0381, 0.1354, 0.0785],\n",
      "          [0.2503, 0.1023, 0.3270, 0.0800, 0.1120, 0.1284]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.3678, 0.6322, 0.0000, 0.0000],\n",
      "          [0.1952, 0.4064, 0.3984, 0.0000],\n",
      "          [0.0968, 0.2187, 0.4658, 0.2187]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.1041, 0.8959, 0.0000, 0.0000],\n",
      "          [0.0771, 0.1682, 0.7547, 0.0000],\n",
      "          [0.0294, 0.1698, 0.5813, 0.2194]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 6])\n",
      "old attention tensor([[[[0.1681, 0.1745, 0.2851, 0.0547, 0.2028, 0.1147],\n",
      "          [0.0468, 0.1131, 0.4053, 0.1699, 0.1319, 0.1330],\n",
      "          [0.0227, 0.0430, 0.3817, 0.1374, 0.1808, 0.2344],\n",
      "          [0.0714, 0.0474, 0.2960, 0.1636, 0.2143, 0.2073]],\n",
      "\n",
      "         [[0.0330, 0.5499, 0.0440, 0.0296, 0.1855, 0.1579],\n",
      "          [0.0145, 0.1500, 0.1436, 0.0721, 0.3035, 0.3162],\n",
      "          [0.0510, 0.3097, 0.2124, 0.0337, 0.2209, 0.1723],\n",
      "          [0.0360, 0.1979, 0.2354, 0.0510, 0.2379, 0.2417]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [5.4283e-01, 4.5717e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [5.7928e-03, 9.5962e-04, 9.9325e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [3.2158e-02, 5.3844e-02, 8.9735e-01, 1.6650e-02, 0.0000e+00],\n",
      "          [3.6128e-02, 4.9387e-02, 8.7688e-01, 1.8669e-02, 1.8932e-02]],\n",
      "\n",
      "         [[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [2.8229e-02, 9.7177e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [2.5488e-03, 1.1255e-01, 8.8490e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [5.3481e-03, 7.5643e-01, 2.1576e-01, 2.2460e-02, 0.0000e+00],\n",
      "          [4.9602e-03, 7.1897e-01, 2.2742e-01, 2.6056e-02, 2.2597e-02]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 6])\n",
      "old attention tensor([[[[0.6545, 0.1471, 0.0477, 0.0918, 0.0304, 0.0284],\n",
      "          [0.0598, 0.0520, 0.1118, 0.1239, 0.2311, 0.4214],\n",
      "          [0.2981, 0.0436, 0.2259, 0.1166, 0.1290, 0.1869],\n",
      "          [0.3866, 0.0897, 0.1657, 0.1068, 0.1672, 0.0841],\n",
      "          [0.3550, 0.0815, 0.1631, 0.1213, 0.1820, 0.0971]],\n",
      "\n",
      "         [[0.0494, 0.1325, 0.0192, 0.3371, 0.3591, 0.1027],\n",
      "          [0.1661, 0.0058, 0.7308, 0.0264, 0.0675, 0.0034],\n",
      "          [0.0603, 0.1079, 0.0156, 0.5380, 0.2368, 0.0413],\n",
      "          [0.0440, 0.0086, 0.1229, 0.2049, 0.5908, 0.0287],\n",
      "          [0.0395, 0.0095, 0.1162, 0.2192, 0.5835, 0.0320]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0196, 0.9804, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0023, 0.0911, 0.9066, 0.0000, 0.0000],\n",
      "          [0.0027, 0.0768, 0.4569, 0.4636, 0.0000],\n",
      "          [0.0018, 0.0462, 0.3220, 0.3109, 0.3191]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0345, 0.9655, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0524, 0.5044, 0.4432, 0.0000, 0.0000],\n",
      "          [0.0522, 0.1908, 0.3420, 0.4149, 0.0000],\n",
      "          [0.0428, 0.1239, 0.2397, 0.2857, 0.3079]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 6])\n",
      "old attention tensor([[[[0.3517, 0.0646, 0.2275, 0.1313, 0.0864, 0.1384],\n",
      "          [0.0691, 0.2363, 0.0780, 0.2648, 0.2092, 0.1426],\n",
      "          [0.1895, 0.1740, 0.1450, 0.2822, 0.1202, 0.0891],\n",
      "          [0.1475, 0.1334, 0.2933, 0.1860, 0.1011, 0.1386],\n",
      "          [0.1460, 0.1333, 0.2923, 0.1955, 0.0941, 0.1389]],\n",
      "\n",
      "         [[0.2671, 0.0234, 0.5036, 0.0260, 0.1546, 0.0254],\n",
      "          [0.2167, 0.0822, 0.5877, 0.0276, 0.0438, 0.0420],\n",
      "          [0.1325, 0.1223, 0.5145, 0.0371, 0.1194, 0.0743],\n",
      "          [0.2535, 0.1054, 0.3368, 0.0754, 0.1020, 0.1269],\n",
      "          [0.2438, 0.1006, 0.3574, 0.0717, 0.1077, 0.1189]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.3968, 0.6032, 0.0000, 0.0000, 0.0000],\n",
      "          [0.2359, 0.3813, 0.3827, 0.0000, 0.0000],\n",
      "          [0.1164, 0.2145, 0.4306, 0.2385, 0.0000],\n",
      "          [0.0904, 0.1797, 0.3321, 0.1887, 0.2092]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.1265, 0.8735, 0.0000, 0.0000, 0.0000],\n",
      "          [0.1092, 0.1937, 0.6971, 0.0000, 0.0000],\n",
      "          [0.0382, 0.1881, 0.5191, 0.2545, 0.0000],\n",
      "          [0.0303, 0.1480, 0.4159, 0.2037, 0.2021]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 6])\n",
      "old attention tensor([[[[0.1580, 0.1082, 0.3139, 0.0673, 0.2246, 0.1279],\n",
      "          [0.0466, 0.0752, 0.3876, 0.1960, 0.1479, 0.1467],\n",
      "          [0.0234, 0.0307, 0.3542, 0.1528, 0.1955, 0.2434],\n",
      "          [0.0710, 0.0325, 0.2801, 0.1861, 0.2223, 0.2081],\n",
      "          [0.0738, 0.0343, 0.2805, 0.1829, 0.2267, 0.2018]],\n",
      "\n",
      "         [[0.0368, 0.5151, 0.0562, 0.0349, 0.2094, 0.1476],\n",
      "          [0.0179, 0.1380, 0.1775, 0.0809, 0.3206, 0.2651],\n",
      "          [0.0566, 0.2663, 0.2574, 0.0379, 0.2324, 0.1494],\n",
      "          [0.0410, 0.1720, 0.2719, 0.0561, 0.2571, 0.2018],\n",
      "          [0.0429, 0.1703, 0.2669, 0.0555, 0.2585, 0.2060]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 6, 6])\n",
      "old attention tensor([[[[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [5.4283e-01, 4.5717e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [5.7928e-03, 9.5962e-04, 9.9325e-01, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [3.2158e-02, 5.3844e-02, 8.9735e-01, 1.6650e-02, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [3.6128e-02, 4.9387e-02, 8.7688e-01, 1.8669e-02, 1.8932e-02,\n",
      "           0.0000e+00],\n",
      "          [1.2729e-03, 2.8046e-04, 3.4820e-01, 8.8923e-04, 8.4617e-04,\n",
      "           6.4851e-01]],\n",
      "\n",
      "         [[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [2.8229e-02, 9.7177e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [2.5488e-03, 1.1255e-01, 8.8490e-01, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [5.3481e-03, 7.5643e-01, 2.1576e-01, 2.2460e-02, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [4.9602e-03, 7.1897e-01, 2.2742e-01, 2.6056e-02, 2.2597e-02,\n",
      "           0.0000e+00],\n",
      "          [8.1239e-04, 4.7695e-02, 4.0934e-01, 5.2178e-02, 5.4492e-02,\n",
      "           4.3548e-01]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 6, 6])\n",
      "old attention tensor([[[[0.6413, 0.1890, 0.0421, 0.0764, 0.0272, 0.0240],\n",
      "          [0.0677, 0.0746, 0.1094, 0.1161, 0.2318, 0.4003],\n",
      "          [0.3245, 0.0602, 0.2146, 0.1074, 0.1241, 0.1692],\n",
      "          [0.4089, 0.1199, 0.1513, 0.0936, 0.1535, 0.0728],\n",
      "          [0.3786, 0.1097, 0.1505, 0.1075, 0.1687, 0.0850],\n",
      "          [0.3286, 0.0508, 0.2256, 0.1024, 0.1231, 0.1694]],\n",
      "\n",
      "         [[0.0523, 0.1403, 0.0142, 0.4062, 0.2880, 0.0991],\n",
      "          [0.2153, 0.0071, 0.6680, 0.0389, 0.0670, 0.0037],\n",
      "          [0.0595, 0.1077, 0.0112, 0.5975, 0.1859, 0.0383],\n",
      "          [0.0506, 0.0102, 0.0980, 0.2752, 0.5352, 0.0307],\n",
      "          [0.0451, 0.0112, 0.0925, 0.2913, 0.5258, 0.0340],\n",
      "          [0.0720, 0.1254, 0.0110, 0.5865, 0.1660, 0.0392]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 6, 6])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0278, 0.9722, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0034, 0.0867, 0.9099, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0039, 0.0647, 0.4903, 0.4411, 0.0000, 0.0000],\n",
      "          [0.0027, 0.0407, 0.3440, 0.3018, 0.3108, 0.0000],\n",
      "          [0.0013, 0.0367, 0.3389, 0.1393, 0.1380, 0.3457]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0261, 0.9739, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0501, 0.4783, 0.4715, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0477, 0.1892, 0.3370, 0.4261, 0.0000, 0.0000],\n",
      "          [0.0390, 0.1220, 0.2324, 0.2943, 0.3123, 0.0000],\n",
      "          [0.0139, 0.1430, 0.1476, 0.2640, 0.2737, 0.1579]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 6, 6])\n",
      "old attention tensor([[[[0.2884, 0.0622, 0.2334, 0.1410, 0.0920, 0.1829],\n",
      "          [0.0629, 0.2237, 0.0787, 0.2481, 0.2116, 0.1750],\n",
      "          [0.1718, 0.1686, 0.1502, 0.2669, 0.1255, 0.1170],\n",
      "          [0.1299, 0.1282, 0.2931, 0.1789, 0.1034, 0.1665],\n",
      "          [0.1285, 0.1270, 0.2919, 0.1871, 0.0972, 0.1684],\n",
      "          [0.1717, 0.1770, 0.1441, 0.2630, 0.1219, 0.1223]],\n",
      "\n",
      "         [[0.2503, 0.0181, 0.5673, 0.0166, 0.1266, 0.0210],\n",
      "          [0.2032, 0.0632, 0.6490, 0.0178, 0.0356, 0.0312],\n",
      "          [0.1271, 0.0986, 0.5816, 0.0255, 0.1048, 0.0624],\n",
      "          [0.2536, 0.0905, 0.4094, 0.0520, 0.0897, 0.1050],\n",
      "          [0.2425, 0.0852, 0.4306, 0.0497, 0.0943, 0.0977],\n",
      "          [0.1170, 0.0955, 0.5837, 0.0251, 0.1107, 0.0678]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 6, 6])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4588, 0.5412, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.2803, 0.3501, 0.3696, 0.0000, 0.0000, 0.0000],\n",
      "          [0.1716, 0.1790, 0.4347, 0.2147, 0.0000, 0.0000],\n",
      "          [0.1359, 0.1524, 0.3440, 0.1739, 0.1937, 0.0000],\n",
      "          [0.1488, 0.1633, 0.2043, 0.1398, 0.1515, 0.1922]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.1970, 0.8030, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.1529, 0.1642, 0.6829, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0646, 0.1602, 0.5784, 0.1969, 0.0000, 0.0000],\n",
      "          [0.0539, 0.1312, 0.4806, 0.1647, 0.1697, 0.0000],\n",
      "          [0.0752, 0.0873, 0.3534, 0.0896, 0.0975, 0.2970]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 6, 6])\n",
      "old attention tensor([[[[0.1269, 0.0483, 0.2306, 0.0594, 0.2916, 0.2432],\n",
      "          [0.0433, 0.0450, 0.3297, 0.1600, 0.1804, 0.2417],\n",
      "          [0.0237, 0.0195, 0.2772, 0.1193, 0.2190, 0.3414],\n",
      "          [0.0583, 0.0175, 0.2090, 0.1405, 0.2502, 0.3245],\n",
      "          [0.0595, 0.0185, 0.2074, 0.1361, 0.2572, 0.3214],\n",
      "          [0.0230, 0.0187, 0.2672, 0.1158, 0.2222, 0.3530]],\n",
      "\n",
      "         [[0.0943, 0.5520, 0.0838, 0.0406, 0.1447, 0.0845],\n",
      "          [0.0475, 0.1887, 0.2213, 0.1008, 0.2523, 0.1894],\n",
      "          [0.1190, 0.3091, 0.2622, 0.0434, 0.1666, 0.0997],\n",
      "          [0.1028, 0.2180, 0.3090, 0.0609, 0.1800, 0.1292],\n",
      "          [0.1053, 0.2166, 0.3071, 0.0592, 0.1816, 0.1301],\n",
      "          [0.1204, 0.3076, 0.2615, 0.0424, 0.1651, 0.1029]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "predicted trg = ['ich', 'lesen', 'zeitung', 'zeitung', 'lesen', '<eos>']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_count 1    self.capacity  20\n",
      "0  ------------------------------------------------\n",
      "DecoderLayer@trg4\n",
      "[1, 1, 64]\n",
      "src = ['we', 'want', 'to', 'eat', 'bread']\n",
      "old attention torch.Size([1, 2, 7, 7])\n",
      "old attention tensor([[[[0.0613, 0.0675, 0.0567, 0.1569, 0.3632, 0.1555, 0.1390],\n",
      "          [0.0017, 0.0027, 0.0022, 0.6864, 0.0091, 0.0429, 0.2551],\n",
      "          [0.0494, 0.1081, 0.0270, 0.3011, 0.3589, 0.0155, 0.1399],\n",
      "          [0.0414, 0.0026, 0.0249, 0.1413, 0.1092, 0.0381, 0.6424],\n",
      "          [0.2181, 0.0551, 0.0075, 0.0148, 0.0429, 0.1021, 0.5596],\n",
      "          [0.1516, 0.0071, 0.6209, 0.0113, 0.1357, 0.0659, 0.0075],\n",
      "          [0.0389, 0.0063, 0.0647, 0.1008, 0.1703, 0.5973, 0.0218]],\n",
      "\n",
      "         [[0.0101, 0.1626, 0.7753, 0.0064, 0.0027, 0.0324, 0.0105],\n",
      "          [0.0672, 0.0102, 0.3593, 0.2224, 0.0452, 0.2211, 0.0747],\n",
      "          [0.1443, 0.0050, 0.0361, 0.3093, 0.3428, 0.0469, 0.1156],\n",
      "          [0.5497, 0.0480, 0.0710, 0.0355, 0.2110, 0.0020, 0.0828],\n",
      "          [0.0310, 0.0550, 0.0310, 0.0145, 0.0366, 0.0233, 0.8084],\n",
      "          [0.0328, 0.0045, 0.0063, 0.0017, 0.9001, 0.0453, 0.0093],\n",
      "          [0.0247, 0.0229, 0.2139, 0.5352, 0.0261, 0.0364, 0.1409]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 7, 7])\n",
      "old attention tensor([[[[0.1228, 0.0317, 0.1646, 0.2899, 0.1590, 0.1365, 0.0955],\n",
      "          [0.0569, 0.0818, 0.2796, 0.1197, 0.0351, 0.0879, 0.3389],\n",
      "          [0.1502, 0.1520, 0.0374, 0.0143, 0.3425, 0.1759, 0.1277],\n",
      "          [0.4050, 0.1451, 0.0357, 0.0175, 0.2893, 0.0808, 0.0266],\n",
      "          [0.0270, 0.0565, 0.0151, 0.1075, 0.5807, 0.0843, 0.1289],\n",
      "          [0.1549, 0.1009, 0.1482, 0.2164, 0.1329, 0.0730, 0.1737],\n",
      "          [0.0955, 0.0653, 0.5098, 0.0623, 0.1390, 0.0476, 0.0805]],\n",
      "\n",
      "         [[0.2464, 0.2124, 0.1017, 0.1648, 0.1226, 0.0409, 0.1113],\n",
      "          [0.0480, 0.2727, 0.1809, 0.1861, 0.1277, 0.1688, 0.0159],\n",
      "          [0.0378, 0.0736, 0.5405, 0.0623, 0.1503, 0.1282, 0.0073],\n",
      "          [0.0512, 0.0407, 0.0589, 0.1035, 0.2252, 0.2645, 0.2560],\n",
      "          [0.1293, 0.0789, 0.0650, 0.1123, 0.1610, 0.1919, 0.2615],\n",
      "          [0.0387, 0.1183, 0.1392, 0.0925, 0.0393, 0.4694, 0.1027],\n",
      "          [0.0140, 0.0137, 0.6031, 0.0928, 0.1445, 0.0420, 0.0898]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 7, 7])\n",
      "old attention tensor([[[[0.0920, 0.4285, 0.0751, 0.0621, 0.1646, 0.1261, 0.0517],\n",
      "          [0.1116, 0.0855, 0.1682, 0.1250, 0.1357, 0.2392, 0.1347],\n",
      "          [0.0491, 0.0335, 0.2204, 0.1692, 0.2647, 0.1263, 0.1369],\n",
      "          [0.0374, 0.0193, 0.1506, 0.1043, 0.1415, 0.0741, 0.4727],\n",
      "          [0.1019, 0.0638, 0.0394, 0.0501, 0.6292, 0.0667, 0.0488],\n",
      "          [0.2571, 0.1611, 0.1679, 0.0110, 0.3884, 0.0082, 0.0063],\n",
      "          [0.0889, 0.2196, 0.2554, 0.0837, 0.3045, 0.0101, 0.0377]],\n",
      "\n",
      "         [[0.0822, 0.0124, 0.2568, 0.4043, 0.1953, 0.0437, 0.0053],\n",
      "          [0.0591, 0.0574, 0.0432, 0.2349, 0.4204, 0.1166, 0.0684],\n",
      "          [0.0635, 0.0819, 0.0202, 0.0682, 0.0573, 0.1442, 0.5647],\n",
      "          [0.0782, 0.0718, 0.1204, 0.1004, 0.1263, 0.2353, 0.2676],\n",
      "          [0.0185, 0.0334, 0.4428, 0.3288, 0.0686, 0.0689, 0.0391],\n",
      "          [0.1102, 0.0244, 0.1233, 0.2410, 0.3592, 0.1252, 0.0167],\n",
      "          [0.1068, 0.0448, 0.1665, 0.3593, 0.0833, 0.1330, 0.1063]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 7])\n",
      "old attention tensor([[[[0.1581, 0.4923, 0.0042, 0.0128, 0.1524, 0.1381, 0.0421]],\n",
      "\n",
      "         [[0.0643, 0.3458, 0.4793, 0.0043, 0.0649, 0.0232, 0.0182]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 7])\n",
      "old attention tensor([[[[0.2990, 0.6025, 0.0356, 0.0023, 0.0253, 0.0314, 0.0039]],\n",
      "\n",
      "         [[0.0202, 0.9365, 0.0025, 0.0062, 0.0107, 0.0092, 0.0147]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 7])\n",
      "old attention tensor([[[[0.1179, 0.4213, 0.0585, 0.1256, 0.0975, 0.1096, 0.0696]],\n",
      "\n",
      "         [[0.0245, 0.0348, 0.0786, 0.1858, 0.0913, 0.1384, 0.4465]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0548, 0.9452]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0098, 0.9902]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0548, 0.9452]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0098, 0.9902]]]])\n",
      "old attention torch.Size([1, 2, 2, 7])\n",
      "old attention tensor([[[[1.5806e-01, 4.9230e-01, 4.2229e-03, 1.2775e-02, 1.5236e-01,\n",
      "           1.3814e-01, 4.2143e-02],\n",
      "          [5.9703e-03, 3.7053e-03, 9.1645e-01, 4.1087e-02, 1.0325e-02,\n",
      "           5.4794e-04, 2.1920e-02]],\n",
      "\n",
      "         [[6.4274e-02, 3.4582e-01, 4.7933e-01, 4.2610e-03, 6.4925e-02,\n",
      "           2.3176e-02, 1.8215e-02],\n",
      "          [1.6278e-01, 1.1784e-02, 6.0675e-01, 1.0395e-01, 7.5247e-02,\n",
      "           1.4773e-02, 2.4717e-02]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0177, 0.9823]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.6283, 0.3717]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0177, 0.9823]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.6283, 0.3717]]]])\n",
      "old attention torch.Size([1, 2, 2, 7])\n",
      "old attention tensor([[[[0.2990, 0.6025, 0.0356, 0.0023, 0.0253, 0.0314, 0.0039],\n",
      "          [0.1315, 0.0853, 0.0404, 0.3047, 0.3804, 0.0209, 0.0367]],\n",
      "\n",
      "         [[0.0202, 0.9365, 0.0025, 0.0062, 0.0107, 0.0092, 0.0147],\n",
      "          [0.1980, 0.0894, 0.0188, 0.2181, 0.0641, 0.3342, 0.0773]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.3547, 0.6453]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.2785, 0.7215]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.3547, 0.6453]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.2785, 0.7215]]]])\n",
      "old attention torch.Size([1, 2, 2, 7])\n",
      "old attention tensor([[[[1.1789e-01, 4.2130e-01, 5.8525e-02, 1.2561e-01, 9.7456e-02,\n",
      "           1.0961e-01, 6.9611e-02],\n",
      "          [9.3476e-03, 1.3893e-01, 1.0178e-01, 6.5222e-01, 4.9078e-02,\n",
      "           3.7327e-02, 1.1312e-02]],\n",
      "\n",
      "         [[2.4486e-02, 3.4829e-02, 7.8647e-02, 1.8579e-01, 9.1321e-02,\n",
      "           1.3841e-01, 4.4652e-01],\n",
      "          [2.9995e-04, 5.1219e-04, 2.4030e-02, 9.5269e-01, 7.1472e-03,\n",
      "           5.1568e-03, 1.0159e-02]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.0548, 0.9452, 0.0000],\n",
      "          [0.0258, 0.0118, 0.9625]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.0098, 0.9902, 0.0000],\n",
      "          [0.0926, 0.0244, 0.8830]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 7])\n",
      "old attention tensor([[[[0.2045, 0.3592, 0.0026, 0.0102, 0.2423, 0.1509, 0.0303],\n",
      "          [0.0266, 0.0428, 0.6990, 0.1017, 0.0459, 0.0067, 0.0772],\n",
      "          [0.1705, 0.1835, 0.0621, 0.1439, 0.2308, 0.0412, 0.1680]],\n",
      "\n",
      "         [[0.0193, 0.0989, 0.7812, 0.0195, 0.0477, 0.0095, 0.0239],\n",
      "          [0.1653, 0.0448, 0.6537, 0.0389, 0.0605, 0.0202, 0.0167],\n",
      "          [0.0335, 0.0284, 0.4388, 0.1571, 0.1067, 0.2006, 0.0350]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.0256, 0.9744, 0.0000],\n",
      "          [0.1499, 0.0885, 0.7615]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.7454, 0.2546, 0.0000],\n",
      "          [0.0158, 0.0329, 0.9513]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 7])\n",
      "old attention tensor([[[[0.3799, 0.4170, 0.0844, 0.0070, 0.0406, 0.0625, 0.0086],\n",
      "          [0.4136, 0.1982, 0.0413, 0.0241, 0.2681, 0.0440, 0.0106],\n",
      "          [0.1240, 0.2669, 0.0973, 0.2213, 0.0942, 0.1015, 0.0948]],\n",
      "\n",
      "         [[0.0218, 0.9192, 0.0016, 0.0128, 0.0080, 0.0225, 0.0140],\n",
      "          [0.1159, 0.3524, 0.0048, 0.0769, 0.0194, 0.2088, 0.2218],\n",
      "          [0.1039, 0.0456, 0.0229, 0.2275, 0.0301, 0.4709, 0.0991]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.1449, 0.8551, 0.0000],\n",
      "          [0.4242, 0.5017, 0.0741]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.1045, 0.8955, 0.0000],\n",
      "          [0.1034, 0.7827, 0.1139]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 7])\n",
      "old attention tensor([[[[0.0990, 0.1496, 0.1669, 0.1178, 0.1704, 0.1110, 0.1852],\n",
      "          [0.0725, 0.0699, 0.0953, 0.3682, 0.1115, 0.1050, 0.1776],\n",
      "          [0.1924, 0.1078, 0.0909, 0.2161, 0.1846, 0.1438, 0.0643]],\n",
      "\n",
      "         [[0.0434, 0.0322, 0.0379, 0.0268, 0.0856, 0.3676, 0.4065],\n",
      "          [0.0344, 0.0171, 0.0433, 0.1779, 0.1129, 0.3181, 0.2963],\n",
      "          [0.0115, 0.0101, 0.0052, 0.0087, 0.0370, 0.8883, 0.0392]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0548, 0.9452, 0.0000, 0.0000],\n",
      "          [0.0258, 0.0118, 0.9625, 0.0000],\n",
      "          [0.0585, 0.0416, 0.0147, 0.8852]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0098, 0.9902, 0.0000, 0.0000],\n",
      "          [0.0926, 0.0244, 0.8830, 0.0000],\n",
      "          [0.6875, 0.0780, 0.2291, 0.0055]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 7])\n",
      "old attention tensor([[[[0.2313, 0.4131, 0.0014, 0.0069, 0.2124, 0.1180, 0.0169],\n",
      "          [0.0353, 0.0594, 0.6941, 0.0990, 0.0493, 0.0052, 0.0577],\n",
      "          [0.2307, 0.2493, 0.0377, 0.1147, 0.2313, 0.0339, 0.1024],\n",
      "          [0.0714, 0.1602, 0.0095, 0.3663, 0.1226, 0.1105, 0.1595]],\n",
      "\n",
      "         [[0.0266, 0.2326, 0.6054, 0.0213, 0.0628, 0.0194, 0.0319],\n",
      "          [0.2289, 0.0893, 0.5251, 0.0358, 0.0699, 0.0340, 0.0171],\n",
      "          [0.0363, 0.0555, 0.2369, 0.1375, 0.1119, 0.3857, 0.0362],\n",
      "          [0.4206, 0.1065, 0.1056, 0.0375, 0.0776, 0.2284, 0.0237]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0293, 0.9707, 0.0000, 0.0000],\n",
      "          [0.2210, 0.0814, 0.6977, 0.0000],\n",
      "          [0.0101, 0.5981, 0.0669, 0.3250]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.7637, 0.2363, 0.0000, 0.0000],\n",
      "          [0.0119, 0.0238, 0.9643, 0.0000],\n",
      "          [0.0503, 0.5094, 0.1062, 0.3341]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 7])\n",
      "old attention tensor([[[[0.4086, 0.3977, 0.0705, 0.0065, 0.0242, 0.0790, 0.0135],\n",
      "          [0.4815, 0.1664, 0.0337, 0.0247, 0.2248, 0.0536, 0.0153],\n",
      "          [0.1279, 0.1687, 0.0860, 0.2781, 0.0664, 0.1111, 0.1618],\n",
      "          [0.3726, 0.0885, 0.0764, 0.0279, 0.3757, 0.0501, 0.0088]],\n",
      "\n",
      "         [[0.0239, 0.9151, 0.0044, 0.0143, 0.0116, 0.0191, 0.0116],\n",
      "          [0.1407, 0.3443, 0.0091, 0.0729, 0.0245, 0.1997, 0.2088],\n",
      "          [0.1093, 0.0324, 0.0605, 0.2473, 0.0342, 0.4222, 0.0941],\n",
      "          [0.0478, 0.6140, 0.0129, 0.0488, 0.0164, 0.0754, 0.1848]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0961, 0.9039, 0.0000, 0.0000],\n",
      "          [0.3632, 0.5722, 0.0646, 0.0000],\n",
      "          [0.1542, 0.2840, 0.2290, 0.3328]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0624, 0.9376, 0.0000, 0.0000],\n",
      "          [0.0477, 0.8400, 0.1123, 0.0000],\n",
      "          [0.0543, 0.2271, 0.5748, 0.1438]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 7])\n",
      "old attention tensor([[[[0.1388, 0.0887, 0.1271, 0.0855, 0.2040, 0.1096, 0.2463],\n",
      "          [0.0850, 0.0389, 0.0611, 0.3592, 0.1264, 0.1120, 0.2174],\n",
      "          [0.2781, 0.0552, 0.0626, 0.1515, 0.2167, 0.1511, 0.0848],\n",
      "          [0.0285, 0.0164, 0.0691, 0.4893, 0.0601, 0.0713, 0.2654]],\n",
      "\n",
      "         [[0.0824, 0.0645, 0.0372, 0.0217, 0.1659, 0.2963, 0.3321],\n",
      "          [0.0550, 0.0324, 0.0454, 0.1909, 0.1977, 0.2198, 0.2588],\n",
      "          [0.0232, 0.0254, 0.0046, 0.0055, 0.0705, 0.8429, 0.0278],\n",
      "          [0.1068, 0.0543, 0.0391, 0.0658, 0.1791, 0.3354, 0.2195]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0548, 0.9452, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0258, 0.0118, 0.9625, 0.0000, 0.0000],\n",
      "          [0.0585, 0.0416, 0.0147, 0.8852, 0.0000],\n",
      "          [0.0841, 0.4123, 0.0460, 0.4263, 0.0313]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0098, 0.9902, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0926, 0.0244, 0.8830, 0.0000, 0.0000],\n",
      "          [0.6875, 0.0780, 0.2291, 0.0055, 0.0000],\n",
      "          [0.0019, 0.0118, 0.0035, 0.0233, 0.9596]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 7])\n",
      "old attention tensor([[[[0.2614, 0.3801, 0.0010, 0.0070, 0.1867, 0.1488, 0.0150],\n",
      "          [0.0387, 0.0526, 0.6910, 0.1144, 0.0422, 0.0060, 0.0551],\n",
      "          [0.2649, 0.2216, 0.0339, 0.1341, 0.1999, 0.0460, 0.0996],\n",
      "          [0.0769, 0.1376, 0.0084, 0.3920, 0.1031, 0.1348, 0.1473],\n",
      "          [0.1537, 0.0155, 0.5437, 0.0639, 0.1588, 0.0141, 0.0503]],\n",
      "\n",
      "         [[0.0149, 0.2141, 0.6285, 0.0246, 0.0659, 0.0171, 0.0349],\n",
      "          [0.1454, 0.0848, 0.5940, 0.0450, 0.0791, 0.0323, 0.0194],\n",
      "          [0.0199, 0.0497, 0.2322, 0.1750, 0.1219, 0.3582, 0.0431],\n",
      "          [0.3012, 0.1178, 0.1272, 0.0568, 0.1020, 0.2610, 0.0339],\n",
      "          [0.0185, 0.4567, 0.3935, 0.0097, 0.0605, 0.0304, 0.0307]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0314, 0.9686, 0.0000, 0.0000, 0.0000],\n",
      "          [0.2682, 0.0674, 0.6644, 0.0000, 0.0000],\n",
      "          [0.0121, 0.5543, 0.0867, 0.3470, 0.0000],\n",
      "          [0.0567, 0.1370, 0.1916, 0.1782, 0.4366]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.7270, 0.2730, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0105, 0.0231, 0.9664, 0.0000, 0.0000],\n",
      "          [0.0362, 0.4896, 0.1369, 0.3373, 0.0000],\n",
      "          [0.0204, 0.4686, 0.4031, 0.0415, 0.0665]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 7])\n",
      "old attention tensor([[[[0.3384, 0.5431, 0.0397, 0.0053, 0.0141, 0.0515, 0.0079],\n",
      "          [0.4332, 0.2117, 0.0276, 0.0360, 0.2357, 0.0430, 0.0128],\n",
      "          [0.0990, 0.1853, 0.0650, 0.3926, 0.0545, 0.0778, 0.1259],\n",
      "          [0.3557, 0.1307, 0.0677, 0.0365, 0.3574, 0.0443, 0.0076],\n",
      "          [0.2385, 0.5981, 0.0419, 0.0227, 0.0383, 0.0414, 0.0191]],\n",
      "\n",
      "         [[0.0744, 0.7880, 0.0219, 0.0285, 0.0457, 0.0308, 0.0107],\n",
      "          [0.2727, 0.1597, 0.0226, 0.0908, 0.0506, 0.2443, 0.1593],\n",
      "          [0.1530, 0.0081, 0.1318, 0.2446, 0.0537, 0.3593, 0.0495],\n",
      "          [0.1132, 0.3852, 0.0553, 0.0938, 0.0464, 0.1145, 0.1915],\n",
      "          [0.0569, 0.0267, 0.1416, 0.4234, 0.0491, 0.1467, 0.1557]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0723, 0.9277, 0.0000, 0.0000, 0.0000],\n",
      "          [0.2888, 0.6283, 0.0829, 0.0000, 0.0000],\n",
      "          [0.1040, 0.1991, 0.3376, 0.3592, 0.0000],\n",
      "          [0.0285, 0.1054, 0.6876, 0.1278, 0.0507]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0636, 0.9364, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0355, 0.7643, 0.2002, 0.0000, 0.0000],\n",
      "          [0.0303, 0.0829, 0.8047, 0.0820, 0.0000],\n",
      "          [0.0613, 0.1026, 0.4342, 0.1600, 0.2419]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 7])\n",
      "old attention tensor([[[[0.1884, 0.0520, 0.1301, 0.0217, 0.2428, 0.0975, 0.2675],\n",
      "          [0.1257, 0.0199, 0.0627, 0.2200, 0.1610, 0.1251, 0.2855],\n",
      "          [0.4137, 0.0286, 0.0585, 0.0467, 0.2380, 0.1279, 0.0867],\n",
      "          [0.0398, 0.0083, 0.0858, 0.2928, 0.0733, 0.0834, 0.4167],\n",
      "          [0.0570, 0.0343, 0.0998, 0.0515, 0.0739, 0.0686, 0.6149]],\n",
      "\n",
      "         [[0.2325, 0.1025, 0.0214, 0.0125, 0.2136, 0.2055, 0.2121],\n",
      "          [0.1660, 0.0414, 0.0330, 0.1913, 0.2878, 0.1095, 0.1710],\n",
      "          [0.0881, 0.0490, 0.0026, 0.0040, 0.1135, 0.7286, 0.0141],\n",
      "          [0.3424, 0.0770, 0.0224, 0.0497, 0.2108, 0.1749, 0.1230],\n",
      "          [0.1970, 0.0626, 0.0239, 0.0499, 0.1582, 0.3810, 0.1274]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "predicted trg = ['wir', 'mochten', 'brot', 'essen', '<eos>']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_count 1    self.capacity  20\n",
      "0  ------------------------------------------------\n",
      "DecoderLayer@trg4\n",
      "[1, 1, 64]\n",
      "src = ['we', 'want', 'to', 'eat', 'apple']\n",
      "old attention torch.Size([1, 2, 7, 7])\n",
      "old attention tensor([[[[0.0623, 0.0686, 0.0576, 0.1594, 0.3689, 0.1422, 0.1412],\n",
      "          [0.0018, 0.0028, 0.0023, 0.7137, 0.0094, 0.0049, 0.2652],\n",
      "          [0.0492, 0.1075, 0.0268, 0.2994, 0.3569, 0.0210, 0.1392],\n",
      "          [0.0377, 0.0024, 0.0227, 0.1285, 0.0993, 0.1256, 0.5840],\n",
      "          [0.2236, 0.0565, 0.0077, 0.0151, 0.0439, 0.0794, 0.5738],\n",
      "          [0.0511, 0.1208, 0.3088, 0.0658, 0.0826, 0.0848, 0.2861],\n",
      "          [0.0718, 0.0116, 0.1192, 0.1859, 0.3140, 0.2573, 0.0401]],\n",
      "\n",
      "         [[0.0104, 0.1671, 0.7967, 0.0066, 0.0028, 0.0057, 0.0108],\n",
      "          [0.0828, 0.0125, 0.4427, 0.2740, 0.0557, 0.0403, 0.0920],\n",
      "          [0.1425, 0.0050, 0.0357, 0.3055, 0.3386, 0.0586, 0.1142],\n",
      "          [0.5440, 0.0475, 0.0702, 0.0351, 0.2088, 0.0123, 0.0819],\n",
      "          [0.0317, 0.0562, 0.0317, 0.0148, 0.0374, 0.0025, 0.8257],\n",
      "          [0.0010, 0.0014, 0.0106, 0.4321, 0.0284, 0.0155, 0.5111],\n",
      "          [0.0235, 0.0218, 0.2037, 0.5098, 0.0248, 0.0821, 0.1342]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 7, 7])\n",
      "old attention tensor([[[[0.1180, 0.0257, 0.1393, 0.2871, 0.1472, 0.2000, 0.0825],\n",
      "          [0.0569, 0.0843, 0.2579, 0.1176, 0.0331, 0.1022, 0.3480],\n",
      "          [0.1760, 0.1721, 0.0399, 0.0166, 0.3676, 0.0835, 0.1444],\n",
      "          [0.4372, 0.1756, 0.0372, 0.0204, 0.2796, 0.0178, 0.0322],\n",
      "          [0.0320, 0.0555, 0.0147, 0.1175, 0.5591, 0.0818, 0.1394],\n",
      "          [0.1605, 0.1172, 0.0237, 0.0455, 0.2941, 0.0343, 0.3246],\n",
      "          [0.0794, 0.0613, 0.4466, 0.0572, 0.1146, 0.1647, 0.0762]],\n",
      "\n",
      "         [[0.2487, 0.1914, 0.0928, 0.1693, 0.1180, 0.0807, 0.0992],\n",
      "          [0.0498, 0.3089, 0.1847, 0.2173, 0.1370, 0.0859, 0.0164],\n",
      "          [0.0264, 0.0658, 0.3978, 0.0499, 0.1096, 0.3451, 0.0055],\n",
      "          [0.0567, 0.0528, 0.0644, 0.1224, 0.2360, 0.1634, 0.3044],\n",
      "          [0.1143, 0.0784, 0.0624, 0.1164, 0.1475, 0.2432, 0.2377],\n",
      "          [0.0619, 0.0106, 0.2163, 0.1061, 0.0072, 0.5420, 0.0559],\n",
      "          [0.0154, 0.0141, 0.5699, 0.0938, 0.1455, 0.0702, 0.0912]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 7, 7])\n",
      "old attention tensor([[[[0.0961, 0.4190, 0.0700, 0.0583, 0.1559, 0.1594, 0.0414],\n",
      "          [0.1169, 0.0866, 0.1792, 0.0793, 0.1506, 0.2967, 0.0908],\n",
      "          [0.0520, 0.0366, 0.2671, 0.1832, 0.2627, 0.0603, 0.1381],\n",
      "          [0.0349, 0.0159, 0.1584, 0.0895, 0.1520, 0.1085, 0.4408],\n",
      "          [0.0685, 0.0590, 0.0311, 0.0347, 0.5810, 0.1980, 0.0277],\n",
      "          [0.0529, 0.1135, 0.0378, 0.0216, 0.4692, 0.2950, 0.0099],\n",
      "          [0.0857, 0.1711, 0.2142, 0.0534, 0.2914, 0.1659, 0.0183]],\n",
      "\n",
      "         [[0.0570, 0.0127, 0.2635, 0.3423, 0.1405, 0.1799, 0.0041],\n",
      "          [0.0402, 0.0591, 0.0458, 0.2363, 0.3552, 0.2110, 0.0524],\n",
      "          [0.0525, 0.0732, 0.0179, 0.0899, 0.0634, 0.0491, 0.6540],\n",
      "          [0.0676, 0.0735, 0.1033, 0.1035, 0.1335, 0.2945, 0.2242],\n",
      "          [0.0151, 0.0338, 0.3795, 0.3244, 0.0691, 0.1505, 0.0276],\n",
      "          [0.0194, 0.0300, 0.2837, 0.3821, 0.0635, 0.1864, 0.0348],\n",
      "          [0.0886, 0.0503, 0.1640, 0.4201, 0.0900, 0.0990, 0.0879]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 7])\n",
      "old attention tensor([[[[0.1567, 0.5934, 0.0036, 0.0148, 0.1376, 0.0493, 0.0447]],\n",
      "\n",
      "         [[0.0568, 0.2916, 0.4321, 0.0039, 0.0581, 0.1416, 0.0158]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 7])\n",
      "old attention tensor([[[[0.3143, 0.5699, 0.0421, 0.0027, 0.0295, 0.0383, 0.0032]],\n",
      "\n",
      "         [[0.0224, 0.9348, 0.0024, 0.0064, 0.0105, 0.0094, 0.0141]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 7])\n",
      "old attention tensor([[[[0.1237, 0.4440, 0.0616, 0.1450, 0.0984, 0.0706, 0.0568]],\n",
      "\n",
      "         [[0.0162, 0.0221, 0.0618, 0.1902, 0.0727, 0.3130, 0.3239]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0548, 0.9452]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0098, 0.9902]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0548, 0.9452]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0098, 0.9902]]]])\n",
      "old attention torch.Size([1, 2, 2, 7])\n",
      "old attention tensor([[[[0.1567, 0.5934, 0.0036, 0.0148, 0.1376, 0.0493, 0.0447],\n",
      "          [0.0076, 0.0034, 0.8866, 0.0367, 0.0102, 0.0343, 0.0212]],\n",
      "\n",
      "         [[0.0568, 0.2916, 0.4321, 0.0039, 0.0581, 0.1416, 0.0158],\n",
      "          [0.1809, 0.0138, 0.5570, 0.1022, 0.0890, 0.0243, 0.0328]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0140, 0.9860]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.6338, 0.3662]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0140, 0.9860]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.6338, 0.3662]]]])\n",
      "old attention torch.Size([1, 2, 2, 7])\n",
      "old attention tensor([[[[0.3143, 0.5699, 0.0421, 0.0027, 0.0295, 0.0383, 0.0032],\n",
      "          [0.1264, 0.0716, 0.0310, 0.2438, 0.3489, 0.1516, 0.0267]],\n",
      "\n",
      "         [[0.0224, 0.9348, 0.0024, 0.0064, 0.0105, 0.0094, 0.0141],\n",
      "          [0.3083, 0.1247, 0.0298, 0.2784, 0.0894, 0.0598, 0.1095]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.3269, 0.6731]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.4022, 0.5978]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.3269, 0.6731]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.4022, 0.5978]]]])\n",
      "old attention torch.Size([1, 2, 2, 7])\n",
      "old attention tensor([[[[1.2371e-01, 4.4401e-01, 6.1568e-02, 1.4496e-01, 9.8376e-02,\n",
      "           7.0611e-02, 5.6767e-02],\n",
      "          [1.1387e-02, 1.3277e-01, 9.3501e-02, 6.6875e-01, 4.4470e-02,\n",
      "           3.7177e-02, 1.1938e-02]],\n",
      "\n",
      "         [[1.6235e-02, 2.2129e-02, 6.1813e-02, 1.9020e-01, 7.2692e-02,\n",
      "           3.1304e-01, 3.2389e-01],\n",
      "          [3.2859e-04, 5.5576e-04, 1.9582e-02, 9.5594e-01, 5.9784e-03,\n",
      "           5.2291e-03, 1.2388e-02]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.0548, 0.9452, 0.0000],\n",
      "          [0.0258, 0.0118, 0.9625]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.0098, 0.9902, 0.0000],\n",
      "          [0.0926, 0.0244, 0.8830]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 7])\n",
      "old attention tensor([[[[0.2194, 0.4509, 0.0024, 0.0122, 0.2470, 0.0343, 0.0339],\n",
      "          [0.0307, 0.0411, 0.6320, 0.0928, 0.0411, 0.0865, 0.0757],\n",
      "          [0.1688, 0.1738, 0.0462, 0.1439, 0.2053, 0.1274, 0.1346]],\n",
      "\n",
      "         [[0.0184, 0.0957, 0.7138, 0.0203, 0.0468, 0.0806, 0.0244],\n",
      "          [0.1713, 0.0469, 0.6216, 0.0358, 0.0671, 0.0380, 0.0192],\n",
      "          [0.0366, 0.0363, 0.4394, 0.1906, 0.1431, 0.1055, 0.0486]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.0285, 0.9715, 0.0000],\n",
      "          [0.1421, 0.1094, 0.7486]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.7096, 0.2904, 0.0000],\n",
      "          [0.0178, 0.0376, 0.9446]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 7])\n",
      "old attention tensor([[[[0.3882, 0.4109, 0.0829, 0.0078, 0.0566, 0.0480, 0.0056],\n",
      "          [0.3494, 0.1649, 0.0338, 0.0188, 0.2748, 0.1522, 0.0062],\n",
      "          [0.1551, 0.2632, 0.0754, 0.1977, 0.1415, 0.1069, 0.0601]],\n",
      "\n",
      "         [[0.0220, 0.9313, 0.0014, 0.0116, 0.0072, 0.0129, 0.0137],\n",
      "          [0.1647, 0.4335, 0.0058, 0.0963, 0.0241, 0.0265, 0.2490],\n",
      "          [0.2233, 0.0970, 0.0319, 0.3375, 0.0556, 0.0539, 0.2008]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.1557, 0.8443, 0.0000],\n",
      "          [0.3802, 0.4835, 0.1363]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.2248, 0.7752, 0.0000],\n",
      "          [0.1972, 0.6778, 0.1250]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 7])\n",
      "old attention tensor([[[[0.0677, 0.1316, 0.1490, 0.1258, 0.1410, 0.2578, 0.1270],\n",
      "          [0.0577, 0.0650, 0.0782, 0.4094, 0.0946, 0.1876, 0.1076],\n",
      "          [0.1384, 0.1059, 0.0717, 0.2174, 0.1583, 0.2708, 0.0374]],\n",
      "\n",
      "         [[0.0332, 0.0278, 0.0537, 0.0806, 0.1009, 0.2524, 0.4515],\n",
      "          [0.0242, 0.0147, 0.0522, 0.3613, 0.0991, 0.1656, 0.2830],\n",
      "          [0.0618, 0.0567, 0.0446, 0.1298, 0.2500, 0.1525, 0.3045]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0548, 0.9452, 0.0000, 0.0000],\n",
      "          [0.0258, 0.0118, 0.9625, 0.0000],\n",
      "          [0.6654, 0.0528, 0.1374, 0.1444]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0098, 0.9902, 0.0000, 0.0000],\n",
      "          [0.0926, 0.0244, 0.8830, 0.0000],\n",
      "          [0.2559, 0.6501, 0.0332, 0.0608]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 7])\n",
      "old attention tensor([[[[0.2065, 0.4834, 0.0018, 0.0109, 0.2339, 0.0341, 0.0294],\n",
      "          [0.0291, 0.0432, 0.6218, 0.0973, 0.0393, 0.0958, 0.0735],\n",
      "          [0.1597, 0.1851, 0.0415, 0.1495, 0.1952, 0.1413, 0.1278],\n",
      "          [0.2096, 0.1710, 0.0847, 0.0379, 0.2755, 0.1761, 0.0452]],\n",
      "\n",
      "         [[0.0185, 0.1199, 0.6830, 0.0208, 0.0508, 0.0842, 0.0228],\n",
      "          [0.1890, 0.0576, 0.5822, 0.0385, 0.0748, 0.0393, 0.0185],\n",
      "          [0.0396, 0.0466, 0.3807, 0.2119, 0.1623, 0.1112, 0.0478],\n",
      "          [0.2338, 0.2766, 0.1862, 0.0575, 0.1225, 0.0387, 0.0846]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0227, 0.9773, 0.0000, 0.0000],\n",
      "          [0.2161, 0.1522, 0.6317, 0.0000],\n",
      "          [0.0059, 0.0419, 0.0374, 0.9148]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.6686, 0.3314, 0.0000, 0.0000],\n",
      "          [0.0082, 0.0243, 0.9675, 0.0000],\n",
      "          [0.1387, 0.3191, 0.1283, 0.4139]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 7])\n",
      "old attention tensor([[[[0.4313, 0.4365, 0.0553, 0.0054, 0.0294, 0.0367, 0.0055],\n",
      "          [0.4224, 0.1626, 0.0236, 0.0165, 0.2111, 0.1575, 0.0064],\n",
      "          [0.1898, 0.2642, 0.0586, 0.1958, 0.1051, 0.1128, 0.0738],\n",
      "          [0.5822, 0.1676, 0.0271, 0.0117, 0.1256, 0.0761, 0.0098]],\n",
      "\n",
      "         [[0.0339, 0.8919, 0.0036, 0.0117, 0.0156, 0.0318, 0.0116],\n",
      "          [0.2336, 0.3266, 0.0109, 0.0954, 0.0420, 0.0486, 0.2428],\n",
      "          [0.2808, 0.0458, 0.0564, 0.2997, 0.0845, 0.0860, 0.1467],\n",
      "          [0.1036, 0.3120, 0.0634, 0.2621, 0.0416, 0.0595, 0.1578]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.1431, 0.8569, 0.0000, 0.0000],\n",
      "          [0.3778, 0.4970, 0.1253, 0.0000],\n",
      "          [0.0418, 0.1681, 0.3703, 0.4198]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.1448, 0.8552, 0.0000, 0.0000],\n",
      "          [0.0883, 0.7986, 0.1131, 0.0000],\n",
      "          [0.0193, 0.1886, 0.6411, 0.1509]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 7])\n",
      "old attention tensor([[[[0.0869, 0.0956, 0.1029, 0.0801, 0.1754, 0.2296, 0.2296],\n",
      "          [0.0669, 0.0481, 0.0531, 0.3509, 0.1145, 0.1664, 0.2001],\n",
      "          [0.1893, 0.0741, 0.0469, 0.1476, 0.2150, 0.2662, 0.0609],\n",
      "          [0.0465, 0.0360, 0.0689, 0.1473, 0.0778, 0.1693, 0.4542]],\n",
      "\n",
      "         [[0.0712, 0.0476, 0.0420, 0.0650, 0.2054, 0.3095, 0.2593],\n",
      "          [0.0549, 0.0240, 0.0392, 0.3392, 0.1911, 0.1943, 0.1573],\n",
      "          [0.1243, 0.0894, 0.0227, 0.0725, 0.4599, 0.1185, 0.1128],\n",
      "          [0.1687, 0.0641, 0.0307, 0.0455, 0.1982, 0.2842, 0.2087]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0548, 0.9452, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0258, 0.0118, 0.9625, 0.0000, 0.0000],\n",
      "          [0.6654, 0.0528, 0.1374, 0.1444, 0.0000],\n",
      "          [0.0399, 0.1957, 0.0218, 0.7277, 0.0149]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0098, 0.9902, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0926, 0.0244, 0.8830, 0.0000, 0.0000],\n",
      "          [0.2559, 0.6501, 0.0332, 0.0608, 0.0000],\n",
      "          [0.0019, 0.0118, 0.0035, 0.0245, 0.9584]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 7])\n",
      "old attention tensor([[[[0.2510, 0.4696, 0.0013, 0.0109, 0.2161, 0.0259, 0.0251],\n",
      "          [0.0334, 0.0396, 0.6354, 0.1095, 0.0350, 0.0794, 0.0677],\n",
      "          [0.2012, 0.1767, 0.0372, 0.1715, 0.1812, 0.1142, 0.1180],\n",
      "          [0.2687, 0.1653, 0.0766, 0.0433, 0.2605, 0.1441, 0.0416],\n",
      "          [0.0988, 0.0098, 0.5521, 0.0590, 0.1297, 0.0926, 0.0581]],\n",
      "\n",
      "         [[0.0106, 0.1242, 0.6686, 0.0244, 0.0535, 0.0932, 0.0256],\n",
      "          [0.1270, 0.0601, 0.6189, 0.0469, 0.0830, 0.0434, 0.0207],\n",
      "          [0.0216, 0.0458, 0.3315, 0.2575, 0.1687, 0.1198, 0.0551],\n",
      "          [0.1432, 0.3059, 0.1796, 0.0766, 0.1411, 0.0456, 0.1081],\n",
      "          [0.0183, 0.2947, 0.4579, 0.0125, 0.0538, 0.1345, 0.0283]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0234, 0.9766, 0.0000, 0.0000, 0.0000],\n",
      "          [0.2421, 0.1110, 0.6469, 0.0000, 0.0000],\n",
      "          [0.0083, 0.0438, 0.0581, 0.8898, 0.0000],\n",
      "          [0.0278, 0.1242, 0.1052, 0.4488, 0.2940]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.6269, 0.3731, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0071, 0.0211, 0.9718, 0.0000, 0.0000],\n",
      "          [0.0732, 0.2118, 0.1719, 0.5431, 0.0000],\n",
      "          [0.0091, 0.2120, 0.2102, 0.5431, 0.0256]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 7])\n",
      "old attention tensor([[[[0.3371, 0.5736, 0.0361, 0.0053, 0.0199, 0.0243, 0.0037],\n",
      "          [0.3664, 0.1942, 0.0202, 0.0251, 0.2275, 0.1607, 0.0060],\n",
      "          [0.1394, 0.2699, 0.0458, 0.2943, 0.0959, 0.0903, 0.0644],\n",
      "          [0.5017, 0.2316, 0.0257, 0.0175, 0.1381, 0.0762, 0.0091],\n",
      "          [0.2325, 0.6399, 0.0264, 0.0184, 0.0478, 0.0264, 0.0086]],\n",
      "\n",
      "         [[0.0849, 0.7167, 0.0163, 0.0214, 0.0514, 0.0989, 0.0105],\n",
      "          [0.3650, 0.1623, 0.0257, 0.1105, 0.0732, 0.0779, 0.1854],\n",
      "          [0.3100, 0.0118, 0.1188, 0.2664, 0.1117, 0.0998, 0.0816],\n",
      "          [0.1344, 0.1127, 0.1776, 0.3160, 0.0670, 0.0927, 0.0996],\n",
      "          [0.0916, 0.0357, 0.1118, 0.4262, 0.0830, 0.0655, 0.1862]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.1208, 0.8792, 0.0000, 0.0000, 0.0000],\n",
      "          [0.3267, 0.5380, 0.1353, 0.0000, 0.0000],\n",
      "          [0.0223, 0.0899, 0.3985, 0.4893, 0.0000],\n",
      "          [0.0248, 0.0565, 0.5607, 0.3217, 0.0363]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.1388, 0.8612, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0683, 0.7283, 0.2035, 0.0000, 0.0000],\n",
      "          [0.0078, 0.0657, 0.8535, 0.0730, 0.0000],\n",
      "          [0.0721, 0.0927, 0.2918, 0.3323, 0.2111]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 7])\n",
      "old attention tensor([[[[0.1060, 0.0582, 0.1315, 0.0283, 0.2144, 0.1630, 0.2986],\n",
      "          [0.0985, 0.0273, 0.0625, 0.2284, 0.1557, 0.1487, 0.2788],\n",
      "          [0.2971, 0.0403, 0.0526, 0.0544, 0.2650, 0.2233, 0.0673],\n",
      "          [0.0524, 0.0122, 0.0540, 0.0607, 0.0747, 0.1217, 0.6242],\n",
      "          [0.0418, 0.0484, 0.0912, 0.0834, 0.0839, 0.1107, 0.5406]],\n",
      "\n",
      "         [[0.1951, 0.0903, 0.0320, 0.0446, 0.2448, 0.2247, 0.1685],\n",
      "          [0.1400, 0.0319, 0.0301, 0.3465, 0.2293, 0.1206, 0.1016],\n",
      "          [0.2823, 0.1168, 0.0098, 0.0360, 0.4694, 0.0473, 0.0386],\n",
      "          [0.4630, 0.1052, 0.0174, 0.0270, 0.1620, 0.1405, 0.0849],\n",
      "          [0.2233, 0.0806, 0.0342, 0.1915, 0.2044, 0.1449, 0.1212]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "predicted trg = ['wir', 'mochten', 'apfel', 'essen', '<eos>']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_count 1    self.capacity  20\n",
      "0  ------------------------------------------------\n",
      "DecoderLayer@trg4\n",
      "[1, 1, 64]\n",
      "src = ['we', 'want', 'to', 'drink', 'water']\n",
      "old attention torch.Size([1, 2, 7, 7])\n",
      "old attention tensor([[[[0.0399, 0.0439, 0.0368, 0.1020, 0.6621, 0.0250, 0.0903],\n",
      "          [0.0018, 0.0028, 0.0023, 0.7182, 0.0034, 0.0046, 0.2669],\n",
      "          [0.0683, 0.1493, 0.0373, 0.4157, 0.0111, 0.1252, 0.1932],\n",
      "          [0.0443, 0.0028, 0.0267, 0.1511, 0.0456, 0.0425, 0.6869],\n",
      "          [0.0031, 0.1011, 0.0507, 0.0152, 0.0061, 0.0988, 0.7249],\n",
      "          [0.0794, 0.1124, 0.1470, 0.0317, 0.5851, 0.0359, 0.0086],\n",
      "          [0.0314, 0.0051, 0.0521, 0.0813, 0.7998, 0.0128, 0.0176]],\n",
      "\n",
      "         [[0.0101, 0.1625, 0.7748, 0.0064, 0.0279, 0.0077, 0.0105],\n",
      "          [0.0151, 0.0023, 0.0809, 0.0501, 0.7971, 0.0378, 0.0168],\n",
      "          [0.2091, 0.0073, 0.0524, 0.4483, 0.0661, 0.0491, 0.1676],\n",
      "          [0.6678, 0.0583, 0.0862, 0.0431, 0.0321, 0.0118, 0.1006],\n",
      "          [0.4560, 0.0680, 0.1551, 0.0916, 0.0452, 0.0204, 0.1637],\n",
      "          [0.0191, 0.5712, 0.2796, 0.0190, 0.0348, 0.0477, 0.0287],\n",
      "          [0.0240, 0.0223, 0.2081, 0.5207, 0.0286, 0.0592, 0.1371]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 7, 7])\n",
      "old attention tensor([[[[0.0998, 0.0267, 0.1032, 0.2096, 0.2401, 0.2484, 0.0722],\n",
      "          [0.0248, 0.0406, 0.1245, 0.0521, 0.0385, 0.5629, 0.1566],\n",
      "          [0.0985, 0.1050, 0.0251, 0.0092, 0.1924, 0.4963, 0.0736],\n",
      "          [0.0992, 0.0337, 0.0068, 0.0036, 0.0811, 0.7705, 0.0051],\n",
      "          [0.2205, 0.1039, 0.0467, 0.0758, 0.0336, 0.4624, 0.0570],\n",
      "          [0.0345, 0.0517, 0.0479, 0.0598, 0.0326, 0.7239, 0.0496],\n",
      "          [0.0316, 0.0237, 0.1357, 0.0180, 0.0625, 0.7067, 0.0219]],\n",
      "\n",
      "         [[0.1890, 0.1698, 0.0747, 0.1304, 0.2645, 0.0973, 0.0743],\n",
      "          [0.0629, 0.4090, 0.2132, 0.2086, 0.0432, 0.0427, 0.0203],\n",
      "          [0.0355, 0.0816, 0.6263, 0.0580, 0.0718, 0.1195, 0.0073],\n",
      "          [0.0962, 0.0696, 0.0774, 0.1295, 0.0719, 0.0705, 0.4849],\n",
      "          [0.0269, 0.0534, 0.4837, 0.1664, 0.0814, 0.0235, 0.1647],\n",
      "          [0.2221, 0.0332, 0.3151, 0.1106, 0.0565, 0.0096, 0.2529],\n",
      "          [0.0198, 0.0170, 0.6877, 0.1131, 0.0238, 0.0108, 0.1279]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 7, 7])\n",
      "old attention tensor([[[[0.0436, 0.2203, 0.0355, 0.0274, 0.4901, 0.1535, 0.0297],\n",
      "          [0.0474, 0.0305, 0.0727, 0.0397, 0.5159, 0.2286, 0.0651],\n",
      "          [0.0664, 0.0756, 0.3827, 0.2144, 0.0187, 0.0533, 0.1889],\n",
      "          [0.0412, 0.0171, 0.1964, 0.0885, 0.0074, 0.0747, 0.5747],\n",
      "          [0.1067, 0.0657, 0.1532, 0.0638, 0.0876, 0.1324, 0.3906],\n",
      "          [0.0270, 0.0174, 0.0355, 0.0330, 0.0149, 0.0950, 0.7771],\n",
      "          [0.1128, 0.1960, 0.3808, 0.1367, 0.0237, 0.0640, 0.0860]],\n",
      "\n",
      "         [[0.0122, 0.0039, 0.0246, 0.0366, 0.9012, 0.0204, 0.0012],\n",
      "          [0.0404, 0.0540, 0.0268, 0.1581, 0.5220, 0.1321, 0.0666],\n",
      "          [0.0805, 0.0726, 0.0472, 0.0989, 0.0065, 0.0342, 0.6600],\n",
      "          [0.1084, 0.1053, 0.1773, 0.1276, 0.0318, 0.0902, 0.3595],\n",
      "          [0.1233, 0.0827, 0.0203, 0.0121, 0.6546, 0.0829, 0.0241],\n",
      "          [0.0849, 0.0207, 0.0750, 0.0314, 0.7509, 0.0180, 0.0191],\n",
      "          [0.1307, 0.0563, 0.1422, 0.2357, 0.0820, 0.2310, 0.1221]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 7])\n",
      "old attention tensor([[[[0.1946, 0.5574, 0.0056, 0.0196, 0.0286, 0.1581, 0.0361]],\n",
      "\n",
      "         [[0.0613, 0.3971, 0.2909, 0.0044, 0.0320, 0.1950, 0.0193]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 7])\n",
      "old attention tensor([[[[0.1731, 0.7394, 0.0229, 0.0019, 0.0451, 0.0160, 0.0016]],\n",
      "\n",
      "         [[0.0229, 0.9354, 0.0028, 0.0075, 0.0047, 0.0151, 0.0116]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 7])\n",
      "old attention tensor([[[[0.0693, 0.6111, 0.0262, 0.0797, 0.0899, 0.1012, 0.0226]],\n",
      "\n",
      "         [[0.0265, 0.0448, 0.1195, 0.2538, 0.0540, 0.0315, 0.4699]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0548, 0.9452]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0098, 0.9902]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0548, 0.9452]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0098, 0.9902]]]])\n",
      "old attention torch.Size([1, 2, 2, 7])\n",
      "old attention tensor([[[[0.1946, 0.5574, 0.0056, 0.0196, 0.0286, 0.1581, 0.0361],\n",
      "          [0.0067, 0.0037, 0.9075, 0.0333, 0.0023, 0.0187, 0.0277]],\n",
      "\n",
      "         [[0.0613, 0.3971, 0.2909, 0.0044, 0.0320, 0.1950, 0.0193],\n",
      "          [0.1072, 0.0070, 0.6422, 0.0671, 0.0639, 0.0918, 0.0208]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0313, 0.9687]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.6205, 0.3795]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0313, 0.9687]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.6205, 0.3795]]]])\n",
      "old attention torch.Size([1, 2, 2, 7])\n",
      "old attention tensor([[[[0.1731, 0.7394, 0.0229, 0.0019, 0.0451, 0.0160, 0.0016],\n",
      "          [0.1715, 0.1960, 0.0910, 0.3317, 0.0849, 0.0792, 0.0457]],\n",
      "\n",
      "         [[0.0229, 0.9354, 0.0028, 0.0075, 0.0047, 0.0151, 0.0116],\n",
      "          [0.1884, 0.1266, 0.0337, 0.2705, 0.2072, 0.1184, 0.0551]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.3628, 0.6372]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.3770, 0.6230]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.3628, 0.6372]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.3770, 0.6230]]]])\n",
      "old attention torch.Size([1, 2, 2, 7])\n",
      "old attention tensor([[[[6.9262e-02, 6.1111e-01, 2.6184e-02, 7.9653e-02, 8.9911e-02,\n",
      "           1.0125e-01, 2.2638e-02],\n",
      "          [4.6729e-03, 1.4403e-01, 7.8344e-02, 5.5330e-01, 2.0045e-01,\n",
      "           1.4383e-02, 4.8182e-03]],\n",
      "\n",
      "         [[2.6528e-02, 4.4785e-02, 1.1954e-01, 2.5381e-01, 5.3968e-02,\n",
      "           3.1471e-02, 4.6990e-01],\n",
      "          [1.4185e-04, 2.1738e-04, 4.4994e-02, 9.2637e-01, 4.5277e-03,\n",
      "           1.2388e-02, 1.1362e-02]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.0548, 0.9452, 0.0000],\n",
      "          [0.0258, 0.0118, 0.9625]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.0098, 0.9902, 0.0000],\n",
      "          [0.0926, 0.0244, 0.8830]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 7])\n",
      "old attention tensor([[[[0.2874, 0.4940, 0.0036, 0.0180, 0.0619, 0.1052, 0.0298],\n",
      "          [0.0276, 0.0406, 0.6552, 0.0819, 0.0069, 0.1081, 0.0796],\n",
      "          [0.1944, 0.2085, 0.0570, 0.1284, 0.0367, 0.2370, 0.1380]],\n",
      "\n",
      "         [[0.0213, 0.0962, 0.6792, 0.0218, 0.0100, 0.1333, 0.0383],\n",
      "          [0.1293, 0.0343, 0.6269, 0.0308, 0.0880, 0.0744, 0.0162],\n",
      "          [0.0255, 0.0204, 0.3404, 0.1011, 0.3608, 0.1256, 0.0262]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.0332, 0.9668, 0.0000],\n",
      "          [0.2857, 0.0890, 0.6253]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.8820, 0.1180, 0.0000],\n",
      "          [0.0187, 0.0178, 0.9635]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 7])\n",
      "old attention tensor([[[[0.2506, 0.5681, 0.0628, 0.0062, 0.0897, 0.0189, 0.0037],\n",
      "          [0.3330, 0.3816, 0.0448, 0.0254, 0.1339, 0.0728, 0.0085],\n",
      "          [0.0769, 0.3234, 0.0876, 0.2219, 0.1519, 0.0719, 0.0664]],\n",
      "\n",
      "         [[0.0268, 0.9263, 0.0012, 0.0127, 0.0063, 0.0215, 0.0052],\n",
      "          [0.1514, 0.4092, 0.0074, 0.1256, 0.0650, 0.1306, 0.1108],\n",
      "          [0.1411, 0.0389, 0.0355, 0.3547, 0.2998, 0.0753, 0.0547]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.1148, 0.8852, 0.0000],\n",
      "          [0.3187, 0.5670, 0.1144]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.1251, 0.8749, 0.0000],\n",
      "          [0.1202, 0.7437, 0.1361]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 7])\n",
      "old attention tensor([[[[0.0375, 0.2702, 0.0649, 0.0661, 0.0765, 0.4633, 0.0215],\n",
      "          [0.0307, 0.0675, 0.0683, 0.2690, 0.1242, 0.4141, 0.0262],\n",
      "          [0.1436, 0.1487, 0.0775, 0.1530, 0.2516, 0.2125, 0.0132]],\n",
      "\n",
      "         [[0.0343, 0.0343, 0.1213, 0.0471, 0.1038, 0.0483, 0.6109],\n",
      "          [0.0189, 0.0057, 0.1079, 0.2568, 0.1799, 0.1216, 0.3091],\n",
      "          [0.0270, 0.0294, 0.0400, 0.0551, 0.6115, 0.1037, 0.1333]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0548, 0.9452, 0.0000, 0.0000],\n",
      "          [0.0258, 0.0118, 0.9625, 0.0000],\n",
      "          [0.4886, 0.0246, 0.4407, 0.0461]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0098, 0.9902, 0.0000, 0.0000],\n",
      "          [0.0926, 0.0244, 0.8830, 0.0000],\n",
      "          [0.0152, 0.0315, 0.1299, 0.8234]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 7])\n",
      "old attention tensor([[[[0.3050, 0.4960, 0.0029, 0.0197, 0.0739, 0.0787, 0.0238],\n",
      "          [0.0246, 0.0343, 0.6967, 0.0933, 0.0066, 0.0796, 0.0648],\n",
      "          [0.2168, 0.2111, 0.0525, 0.1687, 0.0450, 0.1855, 0.1204],\n",
      "          [0.4102, 0.2026, 0.0286, 0.0459, 0.0413, 0.0882, 0.1833]],\n",
      "\n",
      "         [[0.0275, 0.1334, 0.5756, 0.0282, 0.0112, 0.1784, 0.0456],\n",
      "          [0.1742, 0.0416, 0.5348, 0.0371, 0.1044, 0.0913, 0.0166],\n",
      "          [0.0279, 0.0218, 0.2231, 0.1236, 0.4320, 0.1466, 0.0251],\n",
      "          [0.1245, 0.1243, 0.2451, 0.0704, 0.2375, 0.1028, 0.0955]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0192, 0.9808, 0.0000, 0.0000],\n",
      "          [0.3079, 0.1114, 0.5807, 0.0000],\n",
      "          [0.0045, 0.1461, 0.7394, 0.1101]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.8880, 0.1120, 0.0000, 0.0000],\n",
      "          [0.0064, 0.0058, 0.9878, 0.0000],\n",
      "          [0.0423, 0.6853, 0.1415, 0.1310]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 7])\n",
      "old attention tensor([[[[0.2146, 0.6510, 0.0557, 0.0043, 0.0539, 0.0182, 0.0022],\n",
      "          [0.3208, 0.4271, 0.0441, 0.0225, 0.0965, 0.0833, 0.0058],\n",
      "          [0.0737, 0.3374, 0.0916, 0.2584, 0.1137, 0.0692, 0.0560],\n",
      "          [0.5034, 0.2188, 0.0743, 0.0075, 0.1790, 0.0157, 0.0012]],\n",
      "\n",
      "         [[0.0290, 0.9282, 0.0026, 0.0091, 0.0094, 0.0181, 0.0034],\n",
      "          [0.1707, 0.3944, 0.0129, 0.0895, 0.0893, 0.1492, 0.0942],\n",
      "          [0.1319, 0.0223, 0.0615, 0.2285, 0.4727, 0.0561, 0.0270],\n",
      "          [0.1626, 0.5461, 0.0145, 0.1481, 0.0737, 0.0329, 0.0222]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0639, 0.9361, 0.0000, 0.0000],\n",
      "          [0.2182, 0.6079, 0.1739, 0.0000],\n",
      "          [0.0364, 0.2606, 0.5767, 0.1263]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0805, 0.9195, 0.0000, 0.0000],\n",
      "          [0.0661, 0.7551, 0.1788, 0.0000],\n",
      "          [0.0440, 0.0591, 0.8558, 0.0411]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 7])\n",
      "old attention tensor([[[[0.0681, 0.4848, 0.0688, 0.0414, 0.0625, 0.2306, 0.0439],\n",
      "          [0.0561, 0.1133, 0.0685, 0.2906, 0.1543, 0.2672, 0.0501],\n",
      "          [0.2727, 0.1731, 0.0784, 0.0937, 0.2812, 0.0858, 0.0152],\n",
      "          [0.0208, 0.1539, 0.1716, 0.3119, 0.0415, 0.2210, 0.0794]],\n",
      "\n",
      "         [[0.0637, 0.1068, 0.1180, 0.0713, 0.0785, 0.0491, 0.5125],\n",
      "          [0.0238, 0.0110, 0.0882, 0.4488, 0.1017, 0.1071, 0.2193],\n",
      "          [0.0478, 0.1055, 0.0344, 0.0736, 0.5461, 0.1124, 0.0801],\n",
      "          [0.0607, 0.0311, 0.1840, 0.0304, 0.2971, 0.1276, 0.2691]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [5.4816e-02, 9.4518e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [2.5767e-02, 1.1756e-02, 9.6248e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [4.8859e-01, 2.4625e-02, 4.4065e-01, 4.6130e-02, 0.0000e+00],\n",
      "          [1.3242e-02, 1.7397e-02, 2.0030e-02, 8.0559e-03, 9.4127e-01]],\n",
      "\n",
      "         [[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [9.8231e-03, 9.9018e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [9.2640e-02, 2.4357e-02, 8.8300e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [1.5189e-02, 3.1518e-02, 1.2994e-01, 8.2335e-01, 0.0000e+00],\n",
      "          [6.9598e-03, 5.8020e-04, 1.3882e-02, 9.7723e-01, 1.3502e-03]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 7])\n",
      "old attention tensor([[[[0.2845, 0.5368, 0.0012, 0.0147, 0.0805, 0.0658, 0.0165],\n",
      "          [0.0309, 0.0498, 0.6164, 0.1172, 0.0095, 0.1033, 0.0728],\n",
      "          [0.2182, 0.2472, 0.0295, 0.1581, 0.0626, 0.1812, 0.1032],\n",
      "          [0.4216, 0.2308, 0.0159, 0.0413, 0.0496, 0.0840, 0.1569],\n",
      "          [0.0803, 0.1181, 0.2323, 0.1052, 0.3066, 0.0909, 0.0665]],\n",
      "\n",
      "         [[0.0163, 0.1601, 0.5875, 0.0297, 0.0079, 0.1462, 0.0523],\n",
      "          [0.1221, 0.0497, 0.6020, 0.0416, 0.0883, 0.0775, 0.0187],\n",
      "          [0.0209, 0.0334, 0.2407, 0.1671, 0.3668, 0.1324, 0.0388],\n",
      "          [0.0870, 0.1578, 0.2538, 0.0838, 0.2070, 0.0890, 0.1216],\n",
      "          [0.0537, 0.3402, 0.1129, 0.2277, 0.0895, 0.0620, 0.1139]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0195, 0.9805, 0.0000, 0.0000, 0.0000],\n",
      "          [0.3346, 0.0732, 0.5922, 0.0000, 0.0000],\n",
      "          [0.0054, 0.1125, 0.7811, 0.1010, 0.0000],\n",
      "          [0.0836, 0.1008, 0.1346, 0.1530, 0.5280]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.9330, 0.0670, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0078, 0.0075, 0.9847, 0.0000, 0.0000],\n",
      "          [0.0359, 0.6576, 0.2075, 0.0989, 0.0000],\n",
      "          [0.0545, 0.0084, 0.1047, 0.1617, 0.6707]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 7])\n",
      "old attention tensor([[[[0.2244, 0.5333, 0.0979, 0.0082, 0.0967, 0.0330, 0.0065],\n",
      "          [0.3141, 0.3339, 0.0524, 0.0259, 0.1480, 0.1184, 0.0073],\n",
      "          [0.0506, 0.1635, 0.1228, 0.3239, 0.1638, 0.0785, 0.0969],\n",
      "          [0.4460, 0.1554, 0.0972, 0.0084, 0.2746, 0.0169, 0.0014],\n",
      "          [0.0431, 0.0414, 0.3727, 0.2285, 0.2285, 0.0441, 0.0419]],\n",
      "\n",
      "         [[0.0714, 0.7928, 0.0139, 0.0238, 0.0374, 0.0534, 0.0073],\n",
      "          [0.2129, 0.1795, 0.0207, 0.0950, 0.1483, 0.2430, 0.1006],\n",
      "          [0.1094, 0.0062, 0.0981, 0.1906, 0.5038, 0.0655, 0.0264],\n",
      "          [0.2380, 0.3099, 0.0278, 0.2108, 0.1424, 0.0464, 0.0246],\n",
      "          [0.1228, 0.0223, 0.2263, 0.1840, 0.1909, 0.1716, 0.0820]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0545, 0.9455, 0.0000, 0.0000, 0.0000],\n",
      "          [0.2461, 0.5834, 0.1705, 0.0000, 0.0000],\n",
      "          [0.0415, 0.3843, 0.4765, 0.0978, 0.0000],\n",
      "          [0.0461, 0.0674, 0.2894, 0.0410, 0.5561]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0260, 0.9740, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0453, 0.8222, 0.1325, 0.0000, 0.0000],\n",
      "          [0.0583, 0.0636, 0.8493, 0.0288, 0.0000],\n",
      "          [0.0042, 0.0971, 0.6645, 0.0047, 0.2295]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 7])\n",
      "old attention tensor([[[[0.2217, 0.1233, 0.0723, 0.0114, 0.0362, 0.3519, 0.1833],\n",
      "          [0.1400, 0.0213, 0.0587, 0.0632, 0.0678, 0.4639, 0.1852],\n",
      "          [0.5558, 0.0478, 0.0719, 0.0243, 0.1355, 0.1146, 0.0502],\n",
      "          [0.0523, 0.0360, 0.1909, 0.0643, 0.0155, 0.3338, 0.3070],\n",
      "          [0.1334, 0.0219, 0.0741, 0.0867, 0.0328, 0.1231, 0.5279]],\n",
      "\n",
      "         [[0.3834, 0.3280, 0.0194, 0.0071, 0.0795, 0.0250, 0.1577],\n",
      "          [0.3867, 0.0582, 0.0239, 0.0660, 0.2491, 0.0996, 0.1165],\n",
      "          [0.2829, 0.3096, 0.0062, 0.0050, 0.3360, 0.0359, 0.0244],\n",
      "          [0.3780, 0.0747, 0.0269, 0.0018, 0.3745, 0.0567, 0.0873],\n",
      "          [0.3338, 0.4277, 0.0328, 0.0083, 0.0956, 0.0186, 0.0832]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "predicted trg = ['wir', 'mochten', 'wasser', 'trinken', '<eos>']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_count 1    self.capacity  20\n",
      "0  ------------------------------------------------\n",
      "DecoderLayer@trg4\n",
      "[1, 1, 64]\n",
      "src = ['we', 'want', 'to', 'drink', 'beer']\n",
      "old attention torch.Size([1, 2, 7, 7])\n",
      "old attention tensor([[[[0.0075, 0.0082, 0.0069, 0.0191, 0.1241, 0.8172, 0.0169],\n",
      "          [0.0017, 0.0027, 0.0023, 0.7040, 0.0033, 0.0242, 0.2617],\n",
      "          [0.0727, 0.1591, 0.0397, 0.4429, 0.0119, 0.0678, 0.2059],\n",
      "          [0.0453, 0.0028, 0.0273, 0.1545, 0.0467, 0.0214, 0.7021],\n",
      "          [0.0034, 0.1115, 0.0559, 0.0168, 0.0067, 0.0066, 0.7991],\n",
      "          [0.0835, 0.0182, 0.3807, 0.3312, 0.0200, 0.1083, 0.0580],\n",
      "          [0.0156, 0.0025, 0.0260, 0.0405, 0.3982, 0.5084, 0.0087]],\n",
      "\n",
      "         [[0.0102, 0.1633, 0.7787, 0.0064, 0.0281, 0.0028, 0.0105],\n",
      "          [0.0152, 0.0023, 0.0811, 0.0502, 0.7990, 0.0355, 0.0169],\n",
      "          [0.1888, 0.0066, 0.0473, 0.4048, 0.0597, 0.1413, 0.1514],\n",
      "          [0.6663, 0.0582, 0.0860, 0.0430, 0.0321, 0.0140, 0.1004],\n",
      "          [0.4604, 0.0687, 0.1566, 0.0924, 0.0456, 0.0109, 0.1653],\n",
      "          [0.6672, 0.0809, 0.0284, 0.0083, 0.1660, 0.0484, 0.0008],\n",
      "          [0.0208, 0.0193, 0.1800, 0.4505, 0.0248, 0.1861, 0.1186]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 7, 7])\n",
      "old attention tensor([[[[0.1278, 0.0336, 0.1131, 0.2466, 0.2620, 0.1304, 0.0865],\n",
      "          [0.0564, 0.0786, 0.3013, 0.1129, 0.0907, 0.0214, 0.3386],\n",
      "          [0.1980, 0.1913, 0.0534, 0.0184, 0.3669, 0.0228, 0.1492],\n",
      "          [0.4581, 0.1348, 0.0308, 0.0155, 0.3244, 0.0146, 0.0219],\n",
      "          [0.4226, 0.1773, 0.0871, 0.1204, 0.0537, 0.0453, 0.0936],\n",
      "          [0.2676, 0.1198, 0.0336, 0.0793, 0.3200, 0.0703, 0.1095],\n",
      "          [0.1004, 0.0668, 0.4157, 0.0493, 0.2073, 0.0902, 0.0705]],\n",
      "\n",
      "         [[0.1774, 0.1823, 0.0752, 0.1133, 0.2620, 0.1174, 0.0723],\n",
      "          [0.0584, 0.4038, 0.2087, 0.1902, 0.0436, 0.0739, 0.0214],\n",
      "          [0.0370, 0.0991, 0.6167, 0.0515, 0.0706, 0.1169, 0.0083],\n",
      "          [0.0977, 0.0844, 0.0701, 0.1315, 0.0738, 0.0776, 0.4649],\n",
      "          [0.0226, 0.0527, 0.4758, 0.1356, 0.0755, 0.0841, 0.1537],\n",
      "          [0.1097, 0.0414, 0.4175, 0.0964, 0.1615, 0.1027, 0.0709],\n",
      "          [0.0149, 0.0167, 0.6715, 0.0895, 0.0227, 0.0799, 0.1048]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 7, 7])\n",
      "old attention tensor([[[[0.0547, 0.3098, 0.0480, 0.0291, 0.5044, 0.0147, 0.0392],\n",
      "          [0.0536, 0.0344, 0.0890, 0.0420, 0.6629, 0.0479, 0.0701],\n",
      "          [0.0659, 0.0660, 0.3775, 0.2323, 0.0198, 0.0629, 0.1756],\n",
      "          [0.0462, 0.0201, 0.2048, 0.0888, 0.0113, 0.0320, 0.5968],\n",
      "          [0.1042, 0.0616, 0.1889, 0.0575, 0.0870, 0.0853, 0.4155],\n",
      "          [0.4010, 0.0529, 0.1175, 0.0271, 0.0711, 0.0192, 0.3112],\n",
      "          [0.0951, 0.2119, 0.4214, 0.0982, 0.0217, 0.0784, 0.0734]],\n",
      "\n",
      "         [[0.0114, 0.0032, 0.0245, 0.0257, 0.8184, 0.1159, 0.0010],\n",
      "          [0.0453, 0.0461, 0.0235, 0.1008, 0.5094, 0.2143, 0.0605],\n",
      "          [0.0739, 0.0759, 0.0450, 0.1008, 0.0074, 0.0691, 0.6279],\n",
      "          [0.1090, 0.1139, 0.1799, 0.1235, 0.0399, 0.1026, 0.3313],\n",
      "          [0.1297, 0.0837, 0.0225, 0.0137, 0.6343, 0.0917, 0.0244],\n",
      "          [0.1161, 0.0382, 0.0458, 0.0065, 0.5616, 0.2241, 0.0077],\n",
      "          [0.1673, 0.0667, 0.2001, 0.2422, 0.1180, 0.0496, 0.1562]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 7])\n",
      "old attention tensor([[[[0.2292, 0.6187, 0.0056, 0.0224, 0.0339, 0.0477, 0.0424]],\n",
      "\n",
      "         [[0.0680, 0.4558, 0.4063, 0.0057, 0.0342, 0.0086, 0.0214]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 7])\n",
      "old attention tensor([[[[0.1943, 0.7155, 0.0237, 0.0019, 0.0469, 0.0157, 0.0020]],\n",
      "\n",
      "         [[0.0306, 0.9342, 0.0034, 0.0104, 0.0062, 0.0030, 0.0122]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 7])\n",
      "old attention tensor([[[[0.0916, 0.6060, 0.0335, 0.0912, 0.1067, 0.0404, 0.0306]],\n",
      "\n",
      "         [[0.0418, 0.0694, 0.1375, 0.1849, 0.0454, 0.0769, 0.4441]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0548, 0.9452]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0098, 0.9902]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0548, 0.9452]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0098, 0.9902]]]])\n",
      "old attention torch.Size([1, 2, 2, 7])\n",
      "old attention tensor([[[[0.2292, 0.6187, 0.0056, 0.0224, 0.0339, 0.0477, 0.0424],\n",
      "          [0.0046, 0.0026, 0.9396, 0.0242, 0.0019, 0.0076, 0.0196]],\n",
      "\n",
      "         [[0.0680, 0.4558, 0.4063, 0.0057, 0.0342, 0.0086, 0.0214],\n",
      "          [0.1186, 0.0075, 0.6555, 0.0722, 0.0641, 0.0543, 0.0278]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0261, 0.9739]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.5831, 0.4169]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0261, 0.9739]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.5831, 0.4169]]]])\n",
      "old attention torch.Size([1, 2, 2, 7])\n",
      "old attention tensor([[[[0.1943, 0.7155, 0.0237, 0.0019, 0.0469, 0.0157, 0.0020],\n",
      "          [0.1694, 0.1707, 0.0871, 0.3137, 0.0986, 0.1191, 0.0414]],\n",
      "\n",
      "         [[0.0306, 0.9342, 0.0034, 0.0104, 0.0062, 0.0030, 0.0122],\n",
      "          [0.1478, 0.0626, 0.0219, 0.2204, 0.2256, 0.2883, 0.0335]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.3541, 0.6459]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.3119, 0.6881]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.3541, 0.6459]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.3119, 0.6881]]]])\n",
      "old attention torch.Size([1, 2, 2, 7])\n",
      "old attention tensor([[[[9.1582e-02, 6.0603e-01, 3.3495e-02, 9.1153e-02, 1.0673e-01,\n",
      "           4.0367e-02, 3.0640e-02],\n",
      "          [4.9656e-03, 1.1383e-01, 8.5869e-02, 5.3108e-01, 1.7556e-01,\n",
      "           8.2524e-02, 6.1633e-03]],\n",
      "\n",
      "         [[4.1840e-02, 6.9350e-02, 1.3754e-01, 1.8486e-01, 4.5377e-02,\n",
      "           7.6912e-02, 4.4411e-01],\n",
      "          [2.6386e-04, 4.8913e-04, 5.4742e-02, 9.0748e-01, 6.8582e-03,\n",
      "           1.5151e-02, 1.5018e-02]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.0548, 0.9452, 0.0000],\n",
      "          [0.0258, 0.0118, 0.9625]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.0098, 0.9902, 0.0000],\n",
      "          [0.0926, 0.0244, 0.8830]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 7])\n",
      "old attention tensor([[[[0.3126, 0.4983, 0.0032, 0.0174, 0.0648, 0.0741, 0.0295],\n",
      "          [0.0226, 0.0340, 0.7643, 0.0725, 0.0070, 0.0291, 0.0704],\n",
      "          [0.1961, 0.2097, 0.0716, 0.1292, 0.0413, 0.2247, 0.1273]],\n",
      "\n",
      "         [[0.0205, 0.0914, 0.8112, 0.0216, 0.0092, 0.0081, 0.0380],\n",
      "          [0.1419, 0.0384, 0.6415, 0.0365, 0.0874, 0.0323, 0.0220],\n",
      "          [0.0243, 0.0199, 0.2832, 0.0856, 0.3914, 0.1711, 0.0245]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.0298, 0.9702, 0.0000],\n",
      "          [0.2200, 0.0740, 0.7059]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.8775, 0.1225, 0.0000],\n",
      "          [0.0156, 0.0179, 0.9666]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 7])\n",
      "old attention tensor([[[[0.3054, 0.4912, 0.0585, 0.0058, 0.0917, 0.0431, 0.0041],\n",
      "          [0.3778, 0.3502, 0.0463, 0.0244, 0.1490, 0.0439, 0.0083],\n",
      "          [0.0772, 0.2708, 0.0829, 0.2147, 0.1967, 0.0890, 0.0686]],\n",
      "\n",
      "         [[0.0509, 0.8997, 0.0019, 0.0212, 0.0130, 0.0078, 0.0056],\n",
      "          [0.1796, 0.3064, 0.0076, 0.1492, 0.0882, 0.1738, 0.0952],\n",
      "          [0.0930, 0.0161, 0.0245, 0.2516, 0.2064, 0.3827, 0.0257]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.0994, 0.9006, 0.0000],\n",
      "          [0.3048, 0.5742, 0.1209]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.0670, 0.9330, 0.0000],\n",
      "          [0.0825, 0.8032, 0.1143]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 7])\n",
      "old attention tensor([[[[0.1053, 0.3321, 0.1244, 0.0929, 0.1178, 0.1512, 0.0763],\n",
      "          [0.0629, 0.0631, 0.0839, 0.2668, 0.1492, 0.3149, 0.0591],\n",
      "          [0.1672, 0.0792, 0.0529, 0.0711, 0.1530, 0.4614, 0.0154]],\n",
      "\n",
      "         [[0.0826, 0.0902, 0.1180, 0.0200, 0.0869, 0.0653, 0.5369],\n",
      "          [0.0530, 0.0173, 0.0962, 0.1106, 0.1900, 0.2141, 0.3189],\n",
      "          [0.0434, 0.0622, 0.0244, 0.0172, 0.4293, 0.3172, 0.1063]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0548, 0.9452, 0.0000, 0.0000],\n",
      "          [0.0258, 0.0118, 0.9625, 0.0000],\n",
      "          [0.0361, 0.0190, 0.8167, 0.1282]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0098, 0.9902, 0.0000, 0.0000],\n",
      "          [0.0926, 0.0244, 0.8830, 0.0000],\n",
      "          [0.0519, 0.8587, 0.0513, 0.0382]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 7])\n",
      "old attention tensor([[[[0.3400, 0.4906, 0.0021, 0.0145, 0.0617, 0.0615, 0.0295],\n",
      "          [0.0345, 0.0477, 0.6993, 0.0811, 0.0087, 0.0329, 0.0958],\n",
      "          [0.2474, 0.2356, 0.0421, 0.1062, 0.0403, 0.1951, 0.1333],\n",
      "          [0.1028, 0.1532, 0.0214, 0.1043, 0.1307, 0.1752, 0.3124]],\n",
      "\n",
      "         [[0.0218, 0.1094, 0.7668, 0.0277, 0.0105, 0.0103, 0.0536],\n",
      "          [0.1386, 0.0424, 0.6245, 0.0416, 0.0898, 0.0355, 0.0276],\n",
      "          [0.0210, 0.0206, 0.2494, 0.0962, 0.3939, 0.1886, 0.0304],\n",
      "          [0.2251, 0.0281, 0.4601, 0.0311, 0.0491, 0.1477, 0.0589]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0247, 0.9753, 0.0000, 0.0000],\n",
      "          [0.2599, 0.0901, 0.6500, 0.0000],\n",
      "          [0.0036, 0.0534, 0.2689, 0.6741]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.8737, 0.1263, 0.0000, 0.0000],\n",
      "          [0.0126, 0.0120, 0.9753, 0.0000],\n",
      "          [0.0915, 0.0481, 0.1093, 0.7511]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 7])\n",
      "old attention tensor([[[[0.4115, 0.4279, 0.0552, 0.0049, 0.0578, 0.0405, 0.0022],\n",
      "          [0.4649, 0.2859, 0.0504, 0.0303, 0.1161, 0.0451, 0.0073],\n",
      "          [0.0927, 0.1874, 0.0900, 0.3202, 0.1464, 0.0957, 0.0675],\n",
      "          [0.4474, 0.1961, 0.1297, 0.0302, 0.1242, 0.0666, 0.0057]],\n",
      "\n",
      "         [[0.0922, 0.8272, 0.0040, 0.0338, 0.0262, 0.0134, 0.0030],\n",
      "          [0.2164, 0.2184, 0.0125, 0.1625, 0.1184, 0.2115, 0.0604],\n",
      "          [0.0811, 0.0058, 0.0342, 0.2333, 0.2322, 0.4038, 0.0096],\n",
      "          [0.2341, 0.1519, 0.0140, 0.1740, 0.1927, 0.2195, 0.0138]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0719, 0.9281, 0.0000, 0.0000],\n",
      "          [0.2386, 0.5682, 0.1932, 0.0000],\n",
      "          [0.0266, 0.0506, 0.5585, 0.3643]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.1074, 0.8926, 0.0000, 0.0000],\n",
      "          [0.0822, 0.7069, 0.2109, 0.0000],\n",
      "          [0.0172, 0.0211, 0.9402, 0.0215]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 7])\n",
      "old attention tensor([[[[0.0800, 0.3811, 0.1429, 0.0620, 0.1124, 0.1111, 0.1105],\n",
      "          [0.0409, 0.0530, 0.0790, 0.2525, 0.1807, 0.3166, 0.0773],\n",
      "          [0.1599, 0.0644, 0.0521, 0.0410, 0.1851, 0.4796, 0.0179],\n",
      "          [0.0073, 0.0343, 0.0992, 0.4644, 0.0919, 0.1682, 0.1347]],\n",
      "\n",
      "         [[0.0908, 0.1693, 0.1897, 0.0337, 0.0530, 0.0507, 0.4127],\n",
      "          [0.0523, 0.0296, 0.1450, 0.2773, 0.1111, 0.1622, 0.2225],\n",
      "          [0.0501, 0.1355, 0.0273, 0.0372, 0.3368, 0.3562, 0.0569],\n",
      "          [0.0588, 0.0491, 0.1869, 0.2637, 0.1010, 0.2188, 0.1216]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0548, 0.9452, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0258, 0.0118, 0.9625, 0.0000, 0.0000],\n",
      "          [0.0361, 0.0190, 0.8167, 0.1282, 0.0000],\n",
      "          [0.0128, 0.0168, 0.0194, 0.0407, 0.9103]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0098, 0.9902, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0926, 0.0244, 0.8830, 0.0000, 0.0000],\n",
      "          [0.0519, 0.8587, 0.0513, 0.0382, 0.0000],\n",
      "          [0.0305, 0.0025, 0.0609, 0.9001, 0.0059]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 7])\n",
      "old attention tensor([[[[0.3195, 0.5296, 0.0009, 0.0111, 0.0664, 0.0528, 0.0198],\n",
      "          [0.0397, 0.0631, 0.6436, 0.1019, 0.0115, 0.0387, 0.1015],\n",
      "          [0.2417, 0.2649, 0.0243, 0.1080, 0.0542, 0.1978, 0.1091],\n",
      "          [0.0992, 0.1715, 0.0112, 0.1028, 0.1694, 0.1795, 0.2663],\n",
      "          [0.1004, 0.1379, 0.1796, 0.0800, 0.2933, 0.1251, 0.0838]],\n",
      "\n",
      "         [[0.0126, 0.1241, 0.7641, 0.0268, 0.0071, 0.0093, 0.0560],\n",
      "          [0.0971, 0.0473, 0.6718, 0.0435, 0.0748, 0.0369, 0.0287],\n",
      "          [0.0146, 0.0273, 0.2384, 0.1179, 0.3339, 0.2289, 0.0390],\n",
      "          [0.1620, 0.0337, 0.4759, 0.0352, 0.0408, 0.1813, 0.0710],\n",
      "          [0.0452, 0.3050, 0.1553, 0.2016, 0.0812, 0.0822, 0.1294]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0244, 0.9756, 0.0000, 0.0000, 0.0000],\n",
      "          [0.3188, 0.0615, 0.6197, 0.0000, 0.0000],\n",
      "          [0.0035, 0.0361, 0.3011, 0.6593, 0.0000],\n",
      "          [0.0554, 0.0715, 0.1739, 0.2842, 0.4149]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.9225, 0.0775, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0095, 0.0092, 0.9813, 0.0000, 0.0000],\n",
      "          [0.0831, 0.0387, 0.2980, 0.5802, 0.0000],\n",
      "          [0.0882, 0.0161, 0.1139, 0.1002, 0.6817]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 7])\n",
      "old attention tensor([[[[0.3964, 0.3610, 0.0858, 0.0080, 0.0978, 0.0446, 0.0064],\n",
      "          [0.4661, 0.2265, 0.0556, 0.0312, 0.1714, 0.0405, 0.0087],\n",
      "          [0.0589, 0.1022, 0.1047, 0.3491, 0.1903, 0.0960, 0.0989],\n",
      "          [0.3994, 0.1417, 0.1629, 0.0375, 0.1813, 0.0692, 0.0079],\n",
      "          [0.0322, 0.0145, 0.1835, 0.1117, 0.1150, 0.5203, 0.0228]],\n",
      "\n",
      "         [[0.1732, 0.6388, 0.0177, 0.0565, 0.0725, 0.0361, 0.0054],\n",
      "          [0.2460, 0.0970, 0.0160, 0.1395, 0.1467, 0.2987, 0.0561],\n",
      "          [0.0728, 0.0021, 0.0556, 0.1805, 0.2251, 0.4529, 0.0110],\n",
      "          [0.2439, 0.0643, 0.0173, 0.1461, 0.2290, 0.2886, 0.0107],\n",
      "          [0.1045, 0.0104, 0.1509, 0.2178, 0.1168, 0.3529, 0.0465]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0807, 0.9193, 0.0000, 0.0000, 0.0000],\n",
      "          [0.2709, 0.5365, 0.1926, 0.0000, 0.0000],\n",
      "          [0.0563, 0.0511, 0.4731, 0.4195, 0.0000],\n",
      "          [0.0391, 0.0721, 0.2627, 0.0545, 0.5716]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0391, 0.9609, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0608, 0.7775, 0.1617, 0.0000, 0.0000],\n",
      "          [0.0295, 0.0252, 0.9193, 0.0259, 0.0000],\n",
      "          [0.0041, 0.0712, 0.5970, 0.0271, 0.3007]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 7])\n",
      "old attention tensor([[[[0.2276, 0.0811, 0.1107, 0.0143, 0.0421, 0.0835, 0.4405],\n",
      "          [0.1277, 0.0145, 0.0732, 0.0631, 0.0767, 0.2685, 0.3763],\n",
      "          [0.3628, 0.0289, 0.0628, 0.0168, 0.0947, 0.3476, 0.0864],\n",
      "          [0.0170, 0.0093, 0.0832, 0.1406, 0.0392, 0.1359, 0.5748],\n",
      "          [0.0860, 0.0108, 0.0676, 0.0502, 0.0248, 0.1246, 0.6359]],\n",
      "\n",
      "         [[0.4289, 0.3990, 0.0222, 0.0027, 0.0401, 0.0351, 0.0719],\n",
      "          [0.4543, 0.0936, 0.0254, 0.0209, 0.1398, 0.2058, 0.0602],\n",
      "          [0.2709, 0.4002, 0.0062, 0.0024, 0.1681, 0.1357, 0.0166],\n",
      "          [0.3992, 0.1709, 0.0353, 0.0249, 0.1231, 0.2067, 0.0400],\n",
      "          [0.3574, 0.5068, 0.0247, 0.0021, 0.0441, 0.0259, 0.0390]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "predicted trg = ['wir', 'mochten', 'bier', 'trinken', '<eos>']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_count 1    self.capacity  20\n",
      "0  ------------------------------------------------\n",
      "DecoderLayer@trg4\n",
      "[1, 1, 64]\n",
      "src = ['we', 'want', 'to', 'read', 'book']\n",
      "old attention torch.Size([1, 2, 7, 7])\n",
      "old attention tensor([[[[6.2546e-02, 6.8860e-02, 5.7809e-02, 1.6004e-01, 2.1288e-01,\n",
      "           2.9609e-01, 1.4176e-01],\n",
      "          [1.6633e-03, 2.5970e-03, 2.1705e-03, 6.7114e-01, 5.3566e-02,\n",
      "           1.9442e-02, 2.4942e-01],\n",
      "          [5.0254e-02, 1.0991e-01, 2.7446e-02, 3.0605e-01, 3.0691e-01,\n",
      "           5.7169e-02, 1.4227e-01],\n",
      "          [1.0515e-02, 6.5638e-04, 6.3298e-03, 3.5861e-02, 3.7707e-03,\n",
      "           7.7986e-01, 1.6300e-01],\n",
      "          [8.4881e-03, 1.4917e-04, 3.6308e-05, 2.7650e-04, 1.3621e-03,\n",
      "           9.8842e-01, 1.2664e-03],\n",
      "          [2.3692e-02, 7.2239e-01, 4.1433e-02, 1.2106e-01, 3.2022e-02,\n",
      "           2.5985e-02, 3.3412e-02],\n",
      "          [3.0472e-02, 4.9342e-03, 5.0612e-02, 7.8890e-02, 8.9071e-02,\n",
      "           7.2898e-01, 1.7036e-02]],\n",
      "\n",
      "         [[1.0458e-02, 1.6790e-01, 8.0047e-01, 6.6093e-03, 2.8443e-03,\n",
      "           8.6550e-04, 1.0844e-02],\n",
      "          [7.3366e-02, 1.1115e-02, 3.9243e-01, 2.4292e-01, 1.3296e-01,\n",
      "           6.5610e-02, 8.1593e-02],\n",
      "          [1.8954e-01, 6.6221e-03, 4.7465e-02, 4.0637e-01, 2.4937e-02,\n",
      "           1.7313e-01, 1.5193e-01],\n",
      "          [3.6551e-01, 3.1913e-02, 4.7190e-02, 2.3614e-02, 4.3064e-01,\n",
      "           4.6086e-02, 5.5050e-02],\n",
      "          [1.3526e-01, 6.1327e-02, 4.3035e-01, 7.7738e-03, 3.4294e-03,\n",
      "           1.4973e-02, 3.4690e-01],\n",
      "          [1.6748e-01, 6.3244e-02, 4.7230e-03, 8.6752e-03, 2.2936e-01,\n",
      "           3.7513e-01, 1.5139e-01],\n",
      "          [9.3582e-03, 8.6831e-03, 8.1058e-02, 2.0283e-01, 6.2495e-01,\n",
      "           1.9724e-02, 5.3396e-02]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 7, 7])\n",
      "old attention tensor([[[[0.0909, 0.0194, 0.0892, 0.1803, 0.4534, 0.1172, 0.0495],\n",
      "          [0.0486, 0.0756, 0.2325, 0.0891, 0.1932, 0.1080, 0.2530],\n",
      "          [0.2363, 0.2703, 0.0586, 0.0201, 0.1353, 0.0779, 0.2015],\n",
      "          [0.1956, 0.0762, 0.0165, 0.0075, 0.6711, 0.0204, 0.0127],\n",
      "          [0.0900, 0.1412, 0.0700, 0.0873, 0.4635, 0.0449, 0.1031],\n",
      "          [0.1989, 0.1334, 0.0777, 0.0863, 0.3559, 0.0900, 0.0578],\n",
      "          [0.0353, 0.0203, 0.1494, 0.0198, 0.1284, 0.6234, 0.0234]],\n",
      "\n",
      "         [[0.2129, 0.1884, 0.1000, 0.1679, 0.1186, 0.1031, 0.1092],\n",
      "          [0.0581, 0.2992, 0.2707, 0.2590, 0.0171, 0.0724, 0.0236],\n",
      "          [0.0344, 0.0729, 0.5340, 0.0588, 0.0662, 0.2262, 0.0074],\n",
      "          [0.0742, 0.0515, 0.0770, 0.1452, 0.1515, 0.0692, 0.4315],\n",
      "          [0.1333, 0.0745, 0.3949, 0.1492, 0.0935, 0.0872, 0.0675],\n",
      "          [0.1346, 0.1591, 0.0489, 0.1453, 0.1456, 0.1208, 0.2459],\n",
      "          [0.0156, 0.0138, 0.5944, 0.1014, 0.1178, 0.0490, 0.1080]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 7, 7])\n",
      "old attention tensor([[[[0.1081, 0.4420, 0.0847, 0.1093, 0.0531, 0.1326, 0.0704],\n",
      "          [0.0911, 0.0677, 0.1578, 0.1118, 0.1519, 0.2791, 0.1406],\n",
      "          [0.0602, 0.0743, 0.4074, 0.2362, 0.0267, 0.0477, 0.1476],\n",
      "          [0.0382, 0.0166, 0.1259, 0.1163, 0.0532, 0.0960, 0.5537],\n",
      "          [0.1107, 0.1782, 0.0399, 0.1431, 0.0765, 0.1293, 0.3222],\n",
      "          [0.1686, 0.1461, 0.1412, 0.1393, 0.2254, 0.0200, 0.1595],\n",
      "          [0.1384, 0.2375, 0.2833, 0.1310, 0.0921, 0.0599, 0.0578]],\n",
      "\n",
      "         [[0.1163, 0.0323, 0.2397, 0.2439, 0.3467, 0.0130, 0.0081],\n",
      "          [0.1197, 0.1234, 0.0605, 0.2518, 0.2748, 0.0325, 0.1372],\n",
      "          [0.0484, 0.0437, 0.0143, 0.0448, 0.0793, 0.4479, 0.3217],\n",
      "          [0.1174, 0.1335, 0.1613, 0.1272, 0.1237, 0.0658, 0.2712],\n",
      "          [0.1037, 0.0717, 0.4899, 0.0685, 0.2440, 0.0093, 0.0128],\n",
      "          [0.1634, 0.3084, 0.1377, 0.0437, 0.1246, 0.0143, 0.2080],\n",
      "          [0.1384, 0.0627, 0.2147, 0.2185, 0.2140, 0.0361, 0.1156]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 7])\n",
      "old attention tensor([[[[0.2493, 0.5569, 0.0080, 0.0239, 0.0653, 0.0502, 0.0463]],\n",
      "\n",
      "         [[0.0691, 0.5135, 0.3256, 0.0052, 0.0464, 0.0201, 0.0201]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 7])\n",
      "old attention tensor([[[[0.2680, 0.6530, 0.0513, 0.0039, 0.0116, 0.0099, 0.0024]],\n",
      "\n",
      "         [[0.0269, 0.8790, 0.0050, 0.0098, 0.0477, 0.0149, 0.0167]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 7])\n",
      "old attention tensor([[[[0.1092, 0.6727, 0.0503, 0.0931, 0.0339, 0.0237, 0.0172]],\n",
      "\n",
      "         [[0.0189, 0.0147, 0.0732, 0.2357, 0.0510, 0.1573, 0.4492]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0548, 0.9452]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0098, 0.9902]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0548, 0.9452]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0098, 0.9902]]]])\n",
      "old attention torch.Size([1, 2, 2, 7])\n",
      "old attention tensor([[[[0.2493, 0.5569, 0.0080, 0.0239, 0.0653, 0.0502, 0.0463],\n",
      "          [0.0078, 0.0046, 0.8281, 0.0381, 0.0166, 0.0770, 0.0278]],\n",
      "\n",
      "         [[0.0691, 0.5135, 0.3256, 0.0052, 0.0464, 0.0201, 0.0201],\n",
      "          [0.0700, 0.0047, 0.3038, 0.0528, 0.0613, 0.4938, 0.0137]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0579, 0.9421]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.4694, 0.5306]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0579, 0.9421]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.4694, 0.5306]]]])\n",
      "old attention torch.Size([1, 2, 2, 7])\n",
      "old attention tensor([[[[0.2680, 0.6530, 0.0513, 0.0039, 0.0116, 0.0099, 0.0024],\n",
      "          [0.1086, 0.0803, 0.0728, 0.4832, 0.1037, 0.1071, 0.0444]],\n",
      "\n",
      "         [[0.0269, 0.8790, 0.0050, 0.0098, 0.0477, 0.0149, 0.0167],\n",
      "          [0.1545, 0.0575, 0.0267, 0.2432, 0.0361, 0.4215, 0.0604]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.3469, 0.6531]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.2931, 0.7069]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.3469, 0.6531]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.2931, 0.7069]]]])\n",
      "old attention torch.Size([1, 2, 2, 7])\n",
      "old attention tensor([[[[1.0917e-01, 6.7270e-01, 5.0260e-02, 9.3074e-02, 3.3885e-02,\n",
      "           2.3737e-02, 1.7176e-02],\n",
      "          [1.0497e-02, 2.0073e-01, 1.6643e-01, 5.2622e-01, 1.0819e-02,\n",
      "           8.0444e-02, 4.8572e-03]],\n",
      "\n",
      "         [[1.8915e-02, 1.4706e-02, 7.3188e-02, 2.3566e-01, 5.0999e-02,\n",
      "           1.5732e-01, 4.4922e-01],\n",
      "          [2.5714e-04, 1.8297e-04, 2.9174e-02, 8.8059e-01, 1.4646e-03,\n",
      "           7.0703e-02, 1.7627e-02]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.0548, 0.9452, 0.0000],\n",
      "          [0.0058, 0.0035, 0.9907]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.0098, 0.9902, 0.0000],\n",
      "          [0.0028, 0.0164, 0.9808]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 7])\n",
      "old attention tensor([[[[0.3651, 0.4865, 0.0059, 0.0244, 0.0595, 0.0312, 0.0275],\n",
      "          [0.0279, 0.0317, 0.6850, 0.0840, 0.0227, 0.0956, 0.0531],\n",
      "          [0.1577, 0.1521, 0.2870, 0.1570, 0.0663, 0.1104, 0.0695]],\n",
      "\n",
      "         [[0.0428, 0.2215, 0.4685, 0.0139, 0.1908, 0.0195, 0.0430],\n",
      "          [0.1667, 0.0511, 0.2680, 0.0253, 0.1646, 0.3064, 0.0179],\n",
      "          [0.0630, 0.0548, 0.2285, 0.0268, 0.5794, 0.0223, 0.0252]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.1063, 0.8937, 0.0000],\n",
      "          [0.0079, 0.0286, 0.9635]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.5210, 0.4790, 0.0000],\n",
      "          [0.0570, 0.1998, 0.7431]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 7])\n",
      "old attention tensor([[[[0.1945, 0.5731, 0.0979, 0.0777, 0.0121, 0.0369, 0.0078],\n",
      "          [0.2292, 0.2996, 0.0827, 0.2597, 0.0539, 0.0537, 0.0214],\n",
      "          [0.1873, 0.4049, 0.0655, 0.1932, 0.0560, 0.0781, 0.0149]],\n",
      "\n",
      "         [[0.2409, 0.4780, 0.0822, 0.0981, 0.0237, 0.0635, 0.0136],\n",
      "          [0.2697, 0.0893, 0.0638, 0.1717, 0.0354, 0.3084, 0.0616],\n",
      "          [0.2179, 0.1075, 0.1211, 0.3138, 0.0451, 0.1469, 0.0476]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.2547, 0.7453, 0.0000],\n",
      "          [0.1891, 0.2534, 0.5576]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.2014, 0.7986, 0.0000],\n",
      "          [0.1387, 0.2445, 0.6167]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 7])\n",
      "old attention tensor([[[[6.2374e-02, 7.6281e-01, 8.6078e-02, 4.2205e-02, 6.8685e-03,\n",
      "           3.1335e-02, 8.3280e-03],\n",
      "          [5.0280e-02, 3.3044e-01, 1.2024e-01, 3.6693e-01, 1.3134e-02,\n",
      "           1.0587e-01, 1.3099e-02],\n",
      "          [8.8586e-03, 9.8608e-02, 1.2676e-01, 5.6402e-01, 8.2113e-03,\n",
      "           1.7774e-01, 1.5802e-02]],\n",
      "\n",
      "         [[6.3221e-03, 5.5268e-03, 4.9432e-02, 8.3800e-01, 5.6764e-03,\n",
      "           4.6083e-02, 4.8960e-02],\n",
      "          [1.0911e-03, 5.5562e-04, 2.0143e-02, 9.3901e-01, 1.5452e-03,\n",
      "           2.7125e-02, 1.0526e-02],\n",
      "          [1.1143e-03, 7.9584e-04, 1.7410e-02, 9.5148e-01, 6.3976e-04,\n",
      "           2.1745e-02, 6.8156e-03]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0548, 0.9452, 0.0000, 0.0000],\n",
      "          [0.0058, 0.0035, 0.9907, 0.0000],\n",
      "          [0.0332, 0.0224, 0.9272, 0.0172]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0098, 0.9902, 0.0000, 0.0000],\n",
      "          [0.0028, 0.0164, 0.9808, 0.0000],\n",
      "          [0.0159, 0.2746, 0.6426, 0.0669]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 7])\n",
      "old attention tensor([[[[0.3381, 0.5299, 0.0048, 0.0189, 0.0527, 0.0309, 0.0247],\n",
      "          [0.0260, 0.0341, 0.6861, 0.0744, 0.0214, 0.1050, 0.0530],\n",
      "          [0.1522, 0.1693, 0.2792, 0.1412, 0.0649, 0.1222, 0.0710],\n",
      "          [0.1301, 0.0588, 0.3412, 0.2566, 0.0533, 0.1369, 0.0231]],\n",
      "\n",
      "         [[0.0312, 0.1869, 0.4983, 0.0167, 0.1899, 0.0246, 0.0525],\n",
      "          [0.1212, 0.0393, 0.2574, 0.0288, 0.1514, 0.3819, 0.0199],\n",
      "          [0.0491, 0.0464, 0.2342, 0.0341, 0.5756, 0.0293, 0.0314],\n",
      "          [0.1067, 0.0059, 0.2110, 0.0442, 0.3406, 0.2598, 0.0318]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0954, 0.9046, 0.0000, 0.0000],\n",
      "          [0.0068, 0.0299, 0.9633, 0.0000],\n",
      "          [0.0051, 0.0169, 0.4059, 0.5721]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5633, 0.4367, 0.0000, 0.0000],\n",
      "          [0.0702, 0.2238, 0.7060, 0.0000],\n",
      "          [0.0724, 0.0731, 0.3120, 0.5425]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 7])\n",
      "old attention tensor([[[[0.2299, 0.4342, 0.1302, 0.1202, 0.0185, 0.0547, 0.0123],\n",
      "          [0.2259, 0.2049, 0.0833, 0.3104, 0.0784, 0.0689, 0.0282],\n",
      "          [0.1987, 0.2742, 0.0681, 0.2393, 0.0907, 0.1079, 0.0211],\n",
      "          [0.0835, 0.0855, 0.1133, 0.6093, 0.0335, 0.0640, 0.0109]],\n",
      "\n",
      "         [[0.2500, 0.4955, 0.0694, 0.0981, 0.0221, 0.0525, 0.0124],\n",
      "          [0.2707, 0.0799, 0.0592, 0.1872, 0.0370, 0.2982, 0.0679],\n",
      "          [0.2346, 0.0941, 0.1068, 0.3258, 0.0489, 0.1362, 0.0537],\n",
      "          [0.2217, 0.0623, 0.1121, 0.2459, 0.0398, 0.2762, 0.0421]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.3032, 0.6968, 0.0000, 0.0000],\n",
      "          [0.2285, 0.2155, 0.5560, 0.0000],\n",
      "          [0.1103, 0.1338, 0.4926, 0.2633]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.1764, 0.8236, 0.0000, 0.0000],\n",
      "          [0.1268, 0.2176, 0.6556, 0.0000],\n",
      "          [0.0492, 0.1823, 0.4936, 0.2749]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 7])\n",
      "old attention tensor([[[[7.2141e-02, 6.8418e-01, 1.5156e-01, 3.2066e-02, 1.1830e-02,\n",
      "           3.5356e-02, 1.2870e-02],\n",
      "          [5.2619e-02, 2.3448e-01, 1.8335e-01, 3.5088e-01, 2.5743e-02,\n",
      "           1.2901e-01, 2.3927e-02],\n",
      "          [1.0160e-02, 7.3382e-02, 1.9021e-01, 4.7637e-01, 1.5807e-02,\n",
      "           2.0844e-01, 2.5631e-02],\n",
      "          [3.8180e-02, 1.9567e-01, 2.4770e-01, 3.3048e-01, 2.4875e-02,\n",
      "           1.4580e-01, 1.7293e-02]],\n",
      "\n",
      "         [[8.8537e-03, 7.1991e-03, 5.0659e-02, 8.3444e-01, 6.0823e-03,\n",
      "           4.8288e-02, 4.4476e-02],\n",
      "          [1.8707e-03, 8.3016e-04, 2.2340e-02, 9.2724e-01, 2.0233e-03,\n",
      "           3.5164e-02, 1.0534e-02],\n",
      "          [2.0694e-03, 1.3280e-03, 1.9806e-02, 9.3789e-01, 9.4925e-04,\n",
      "           3.0628e-02, 7.3280e-03],\n",
      "          [2.3585e-03, 2.2498e-03, 2.7077e-02, 8.8258e-01, 2.2964e-03,\n",
      "           6.7954e-02, 1.5481e-02]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [5.4816e-02, 9.4518e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [5.7779e-03, 3.5214e-03, 9.9070e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [3.3226e-02, 2.2414e-02, 9.2716e-01, 1.7204e-02, 0.0000e+00],\n",
      "          [1.8739e-03, 1.1628e-03, 4.1187e-01, 1.1477e-03, 5.8395e-01]],\n",
      "\n",
      "         [[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [9.8231e-03, 9.9018e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [2.8250e-03, 1.6355e-02, 9.8082e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [1.5928e-02, 2.7463e-01, 6.4256e-01, 6.6889e-02, 0.0000e+00],\n",
      "          [9.8456e-04, 7.1017e-03, 4.4582e-01, 6.1770e-02, 4.8433e-01]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 7])\n",
      "old attention tensor([[[[0.3429, 0.5480, 0.0035, 0.0190, 0.0440, 0.0218, 0.0208],\n",
      "          [0.0347, 0.0465, 0.6467, 0.0944, 0.0233, 0.0971, 0.0573],\n",
      "          [0.1784, 0.2029, 0.2297, 0.1579, 0.0629, 0.0999, 0.0683],\n",
      "          [0.1594, 0.0743, 0.2828, 0.2961, 0.0526, 0.1121, 0.0228],\n",
      "          [0.1886, 0.1737, 0.2461, 0.1540, 0.0674, 0.0941, 0.0761]],\n",
      "\n",
      "         [[0.0312, 0.2253, 0.3845, 0.0172, 0.2604, 0.0189, 0.0623],\n",
      "          [0.1291, 0.0510, 0.2239, 0.0313, 0.2214, 0.3184, 0.0249],\n",
      "          [0.0427, 0.0490, 0.1636, 0.0304, 0.6617, 0.0202, 0.0323],\n",
      "          [0.1026, 0.0072, 0.1617, 0.0438, 0.4580, 0.1898, 0.0369],\n",
      "          [0.0470, 0.0498, 0.1272, 0.0305, 0.6919, 0.0200, 0.0337]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.1298, 0.8702, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0103, 0.0308, 0.9589, 0.0000, 0.0000],\n",
      "          [0.0079, 0.0167, 0.4782, 0.4971, 0.0000],\n",
      "          [0.0039, 0.0125, 0.3637, 0.2069, 0.4130]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5801, 0.4199, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0656, 0.2012, 0.7332, 0.0000, 0.0000],\n",
      "          [0.0651, 0.0633, 0.3341, 0.5375, 0.0000],\n",
      "          [0.0179, 0.0472, 0.2045, 0.4861, 0.2443]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 7])\n",
      "old attention tensor([[[[0.1716, 0.3633, 0.1490, 0.1960, 0.0240, 0.0732, 0.0229],\n",
      "          [0.1521, 0.1659, 0.0865, 0.4151, 0.0696, 0.0723, 0.0383],\n",
      "          [0.1456, 0.2350, 0.0761, 0.3172, 0.0836, 0.1128, 0.0297],\n",
      "          [0.0479, 0.0598, 0.0997, 0.6964, 0.0278, 0.0552, 0.0133],\n",
      "          [0.1423, 0.2041, 0.0773, 0.3476, 0.0823, 0.1151, 0.0313]],\n",
      "\n",
      "         [[0.3141, 0.2599, 0.1825, 0.1400, 0.0194, 0.0685, 0.0156],\n",
      "          [0.3021, 0.0465, 0.1071, 0.1899, 0.0281, 0.2644, 0.0618],\n",
      "          [0.2368, 0.0498, 0.1868, 0.3212, 0.0346, 0.1211, 0.0496],\n",
      "          [0.2334, 0.0336, 0.1937, 0.2375, 0.0279, 0.2344, 0.0395],\n",
      "          [0.2114, 0.0456, 0.2172, 0.3288, 0.0299, 0.1217, 0.0453]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.3798, 0.6202, 0.0000, 0.0000, 0.0000],\n",
      "          [0.2669, 0.2095, 0.5236, 0.0000, 0.0000],\n",
      "          [0.1499, 0.1221, 0.4823, 0.2458, 0.0000],\n",
      "          [0.1424, 0.1036, 0.2938, 0.1957, 0.2645]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.2137, 0.7863, 0.0000, 0.0000, 0.0000],\n",
      "          [0.1750, 0.2424, 0.5827, 0.0000, 0.0000],\n",
      "          [0.0813, 0.1988, 0.5339, 0.1861, 0.0000],\n",
      "          [0.1015, 0.1504, 0.3664, 0.0729, 0.3088]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 7])\n",
      "old attention tensor([[[[0.1278, 0.4009, 0.2364, 0.0469, 0.0270, 0.1011, 0.0600],\n",
      "          [0.0633, 0.1407, 0.1931, 0.2821, 0.0363, 0.2104, 0.0740],\n",
      "          [0.0174, 0.0487, 0.1966, 0.3373, 0.0255, 0.2995, 0.0749],\n",
      "          [0.0446, 0.1030, 0.2396, 0.2761, 0.0363, 0.2418, 0.0586],\n",
      "          [0.0165, 0.0479, 0.1792, 0.3540, 0.0233, 0.3056, 0.0735]],\n",
      "\n",
      "         [[0.0499, 0.0454, 0.0664, 0.7446, 0.0151, 0.0447, 0.0339],\n",
      "          [0.0125, 0.0055, 0.0310, 0.8995, 0.0056, 0.0363, 0.0095],\n",
      "          [0.0166, 0.0122, 0.0344, 0.8894, 0.0037, 0.0346, 0.0091],\n",
      "          [0.0159, 0.0150, 0.0380, 0.8501, 0.0058, 0.0621, 0.0131],\n",
      "          [0.0149, 0.0120, 0.0373, 0.8880, 0.0035, 0.0355, 0.0089]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "predicted trg = ['wir', 'lesen', 'zeitung', 'lesen', '<eos>']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_count 1    self.capacity  20\n",
      "0  ------------------------------------------------\n",
      "DecoderLayer@trg4\n",
      "[1, 1, 64]\n",
      "src = ['we', 'want', 'to', 'read', 'newspaper']\n",
      "old attention torch.Size([1, 2, 7, 7])\n",
      "old attention tensor([[[[1.8735e-02, 2.0626e-02, 1.7316e-02, 4.7940e-02, 6.3768e-02,\n",
      "           7.8915e-01, 4.2464e-02],\n",
      "          [3.4601e-04, 5.4025e-04, 4.5152e-04, 1.3962e-01, 1.1143e-02,\n",
      "           7.9601e-01, 5.1888e-02],\n",
      "          [4.4344e-02, 9.6982e-02, 2.4218e-02, 2.7005e-01, 2.7082e-01,\n",
      "           1.6805e-01, 1.2553e-01],\n",
      "          [1.8936e-02, 1.1821e-03, 1.1399e-02, 6.4581e-02, 6.7905e-03,\n",
      "           6.0357e-01, 2.9355e-01],\n",
      "          [3.5518e-02, 6.2420e-04, 1.5193e-04, 1.1570e-03, 5.6995e-03,\n",
      "           9.5155e-01, 5.2993e-03],\n",
      "          [2.0483e-01, 2.5747e-01, 3.4017e-01, 2.8965e-02, 1.4167e-01,\n",
      "           1.0006e-02, 1.6884e-02],\n",
      "          [1.1412e-02, 1.8479e-03, 1.8954e-02, 2.9545e-02, 3.3358e-02,\n",
      "           8.9850e-01, 6.3803e-03]],\n",
      "\n",
      "         [[9.9901e-03, 1.6039e-01, 7.6464e-01, 6.3134e-03, 2.7170e-03,\n",
      "           4.5597e-02, 1.0359e-02],\n",
      "          [2.6593e-03, 4.0287e-04, 1.4225e-02, 8.8050e-03, 4.8195e-03,\n",
      "           9.6613e-01, 2.9575e-03],\n",
      "          [2.2509e-01, 7.8638e-03, 5.6365e-02, 4.8257e-01, 2.9613e-02,\n",
      "           1.8079e-02, 1.8042e-01],\n",
      "          [3.2056e-01, 2.7988e-02, 4.1387e-02, 2.0710e-02, 3.7768e-01,\n",
      "           1.6340e-01, 4.8280e-02],\n",
      "          [1.2756e-01, 5.7838e-02, 4.0586e-01, 7.3315e-03, 3.2342e-03,\n",
      "           7.1017e-02, 3.2716e-01],\n",
      "          [2.0007e-03, 1.2639e-01, 5.8051e-01, 2.5503e-02, 1.8656e-01,\n",
      "           3.1558e-02, 4.7483e-02],\n",
      "          [9.3806e-03, 8.7039e-03, 8.1252e-02, 2.0332e-01, 6.2644e-01,\n",
      "           1.7382e-02, 5.3523e-02]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 7, 7])\n",
      "old attention tensor([[[[0.0669, 0.0149, 0.0777, 0.1658, 0.3506, 0.2753, 0.0488],\n",
      "          [0.0384, 0.0620, 0.1611, 0.0716, 0.1616, 0.2772, 0.2281],\n",
      "          [0.2188, 0.2542, 0.0530, 0.0224, 0.1179, 0.1345, 0.1991],\n",
      "          [0.1700, 0.0681, 0.0132, 0.0076, 0.6158, 0.1129, 0.0123],\n",
      "          [0.0920, 0.1394, 0.0718, 0.0927, 0.3995, 0.0918, 0.1128],\n",
      "          [0.0522, 0.1294, 0.2957, 0.1590, 0.0274, 0.2631, 0.0732],\n",
      "          [0.0521, 0.0333, 0.1965, 0.0333, 0.1992, 0.4415, 0.0441]],\n",
      "\n",
      "         [[0.2298, 0.2137, 0.1040, 0.1826, 0.0978, 0.0611, 0.1110],\n",
      "          [0.0528, 0.3127, 0.2062, 0.2525, 0.0129, 0.1446, 0.0182],\n",
      "          [0.0426, 0.0970, 0.6240, 0.0805, 0.0766, 0.0714, 0.0079],\n",
      "          [0.0398, 0.0320, 0.0442, 0.0830, 0.0861, 0.4975, 0.2175],\n",
      "          [0.1239, 0.0705, 0.2884, 0.1339, 0.0777, 0.2554, 0.0501],\n",
      "          [0.6682, 0.0567, 0.1055, 0.1133, 0.0231, 0.0139, 0.0191],\n",
      "          [0.0168, 0.0154, 0.5218, 0.1056, 0.1146, 0.1361, 0.0897]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 7, 7])\n",
      "old attention tensor([[[[0.1204, 0.4580, 0.0873, 0.1206, 0.0747, 0.0726, 0.0663],\n",
      "          [0.1099, 0.0838, 0.2032, 0.1357, 0.1929, 0.1141, 0.1604],\n",
      "          [0.0582, 0.0744, 0.4033, 0.1992, 0.0256, 0.1249, 0.1143],\n",
      "          [0.0285, 0.0150, 0.0977, 0.0953, 0.0448, 0.2766, 0.4421],\n",
      "          [0.1126, 0.1753, 0.0405, 0.1266, 0.0690, 0.2234, 0.2527],\n",
      "          [0.0619, 0.0996, 0.2264, 0.1035, 0.0141, 0.3132, 0.1813],\n",
      "          [0.1423, 0.2192, 0.2810, 0.1496, 0.0814, 0.0667, 0.0597]],\n",
      "\n",
      "         [[0.1075, 0.0287, 0.2678, 0.2734, 0.2810, 0.0338, 0.0078],\n",
      "          [0.1002, 0.1248, 0.0608, 0.2632, 0.2598, 0.0712, 0.1200],\n",
      "          [0.0672, 0.0612, 0.0222, 0.0945, 0.1423, 0.0896, 0.5229],\n",
      "          [0.0843, 0.0865, 0.1234, 0.1152, 0.1041, 0.2816, 0.2048],\n",
      "          [0.0960, 0.0640, 0.4843, 0.0869, 0.1924, 0.0626, 0.0137],\n",
      "          [0.2014, 0.0190, 0.0692, 0.1394, 0.3834, 0.0923, 0.0953],\n",
      "          [0.1134, 0.0539, 0.1998, 0.2250, 0.1604, 0.1514, 0.0961]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 7])\n",
      "old attention tensor([[[[0.2584, 0.5608, 0.0082, 0.0226, 0.0732, 0.0310, 0.0459]],\n",
      "\n",
      "         [[0.0661, 0.4024, 0.4004, 0.0056, 0.0473, 0.0602, 0.0181]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 7])\n",
      "old attention tensor([[[[0.2889, 0.5968, 0.0630, 0.0041, 0.0173, 0.0259, 0.0039]],\n",
      "\n",
      "         [[0.0226, 0.8686, 0.0058, 0.0097, 0.0388, 0.0375, 0.0171]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 7])\n",
      "old attention tensor([[[[0.1471, 0.5219, 0.0755, 0.1533, 0.0383, 0.0284, 0.0356]],\n",
      "\n",
      "         [[0.0166, 0.0196, 0.0713, 0.2708, 0.0468, 0.1032, 0.4717]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0548, 0.9452]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0098, 0.9902]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0548, 0.9452]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0098, 0.9902]]]])\n",
      "old attention torch.Size([1, 2, 2, 7])\n",
      "old attention tensor([[[[0.2584, 0.5608, 0.0082, 0.0226, 0.0732, 0.0310, 0.0459],\n",
      "          [0.0101, 0.0058, 0.8603, 0.0443, 0.0182, 0.0268, 0.0345]],\n",
      "\n",
      "         [[0.0661, 0.4024, 0.4004, 0.0056, 0.0473, 0.0602, 0.0181],\n",
      "          [0.1490, 0.0117, 0.3962, 0.0842, 0.1288, 0.2053, 0.0249]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0544, 0.9456]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.5091, 0.4909]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0544, 0.9456]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.5091, 0.4909]]]])\n",
      "old attention torch.Size([1, 2, 2, 7])\n",
      "old attention tensor([[[[0.2889, 0.5968, 0.0630, 0.0041, 0.0173, 0.0259, 0.0039],\n",
      "          [0.1333, 0.0851, 0.0665, 0.5016, 0.1088, 0.0429, 0.0618]],\n",
      "\n",
      "         [[0.0226, 0.8686, 0.0058, 0.0097, 0.0388, 0.0375, 0.0171],\n",
      "          [0.2474, 0.1034, 0.0390, 0.3940, 0.0688, 0.0527, 0.0948]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.3289, 0.6711]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.2839, 0.7161]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.3289, 0.6711]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.2839, 0.7161]]]])\n",
      "old attention torch.Size([1, 2, 2, 7])\n",
      "old attention tensor([[[[1.4706e-01, 5.2186e-01, 7.5547e-02, 1.5327e-01, 3.8271e-02,\n",
      "           2.8360e-02, 3.5633e-02],\n",
      "          [9.8606e-03, 1.5983e-01, 1.4433e-01, 6.5706e-01, 9.9216e-03,\n",
      "           1.2148e-02, 6.8536e-03]],\n",
      "\n",
      "         [[1.6555e-02, 1.9615e-02, 7.1277e-02, 2.7084e-01, 4.6847e-02,\n",
      "           1.0317e-01, 4.7170e-01],\n",
      "          [1.8338e-04, 1.6365e-04, 1.6629e-02, 9.6134e-01, 7.5003e-04,\n",
      "           9.9812e-03, 1.0949e-02]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.0548, 0.9452, 0.0000],\n",
      "          [0.0058, 0.0035, 0.9907]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.0098, 0.9902, 0.0000],\n",
      "          [0.0028, 0.0164, 0.9808]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 7])\n",
      "old attention tensor([[[[0.3783, 0.4535, 0.0064, 0.0242, 0.0764, 0.0280, 0.0333],\n",
      "          [0.0348, 0.0364, 0.7045, 0.0990, 0.0232, 0.0400, 0.0621],\n",
      "          [0.1670, 0.1491, 0.2783, 0.1513, 0.0769, 0.0900, 0.0874]],\n",
      "\n",
      "         [[0.0426, 0.1815, 0.4914, 0.0147, 0.1647, 0.0715, 0.0336],\n",
      "          [0.2116, 0.0663, 0.2730, 0.0267, 0.2304, 0.1722, 0.0198],\n",
      "          [0.0727, 0.0525, 0.2260, 0.0292, 0.5228, 0.0718, 0.0250]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.0911, 0.9089, 0.0000],\n",
      "          [0.0128, 0.0563, 0.9309]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.5209, 0.4791, 0.0000],\n",
      "          [0.0667, 0.2242, 0.7091]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 7])\n",
      "old attention tensor([[[[0.1992, 0.6084, 0.0789, 0.0730, 0.0140, 0.0165, 0.0100],\n",
      "          [0.2566, 0.2793, 0.0776, 0.2697, 0.0569, 0.0332, 0.0267],\n",
      "          [0.2284, 0.4301, 0.0586, 0.1798, 0.0573, 0.0270, 0.0188]],\n",
      "\n",
      "         [[0.1639, 0.4889, 0.0986, 0.1008, 0.0247, 0.1068, 0.0163],\n",
      "          [0.3424, 0.1267, 0.0869, 0.2377, 0.0564, 0.0605, 0.0894],\n",
      "          [0.1786, 0.1035, 0.1439, 0.3159, 0.0457, 0.1583, 0.0541]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.2224, 0.7776, 0.0000],\n",
      "          [0.1892, 0.2993, 0.5115]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.1918, 0.8082, 0.0000],\n",
      "          [0.1371, 0.2231, 0.6398]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 7])\n",
      "old attention tensor([[[[9.6718e-02, 5.8537e-01, 1.4423e-01, 7.6248e-02, 1.0952e-02,\n",
      "           5.6334e-02, 3.0143e-02],\n",
      "          [5.6966e-02, 2.2553e-01, 1.2992e-01, 4.9571e-01, 1.8644e-02,\n",
      "           4.3533e-02, 2.9693e-02],\n",
      "          [1.1903e-02, 7.9496e-02, 1.3257e-01, 6.8252e-01, 1.4632e-02,\n",
      "           3.9573e-02, 3.9305e-02]],\n",
      "\n",
      "         [[1.0728e-02, 9.7392e-03, 3.6184e-02, 8.5392e-01, 4.3551e-03,\n",
      "           2.8681e-02, 5.6396e-02],\n",
      "          [1.5908e-03, 9.7925e-04, 1.2727e-02, 9.6845e-01, 1.0518e-03,\n",
      "           5.0742e-03, 1.0128e-02],\n",
      "          [2.3356e-03, 1.6928e-03, 1.3613e-02, 9.6758e-01, 5.6455e-04,\n",
      "           5.9331e-03, 8.2832e-03]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0548, 0.9452, 0.0000, 0.0000],\n",
      "          [0.0058, 0.0035, 0.9907, 0.0000],\n",
      "          [0.0332, 0.0224, 0.9272, 0.0172]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0098, 0.9902, 0.0000, 0.0000],\n",
      "          [0.0028, 0.0164, 0.9808, 0.0000],\n",
      "          [0.0159, 0.2746, 0.6426, 0.0669]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 7])\n",
      "old attention tensor([[[[0.3457, 0.5034, 0.0050, 0.0183, 0.0684, 0.0296, 0.0295],\n",
      "          [0.0328, 0.0409, 0.7067, 0.0877, 0.0225, 0.0470, 0.0624],\n",
      "          [0.1598, 0.1698, 0.2663, 0.1334, 0.0759, 0.1068, 0.0880],\n",
      "          [0.1485, 0.0614, 0.3587, 0.2889, 0.0596, 0.0532, 0.0296]],\n",
      "\n",
      "         [[0.0308, 0.1587, 0.5028, 0.0170, 0.1644, 0.0844, 0.0419],\n",
      "          [0.1673, 0.0581, 0.2754, 0.0320, 0.2343, 0.2082, 0.0247],\n",
      "          [0.0563, 0.0460, 0.2228, 0.0357, 0.5219, 0.0853, 0.0319],\n",
      "          [0.0995, 0.0068, 0.1588, 0.0354, 0.3106, 0.3617, 0.0271]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0821, 0.9179, 0.0000, 0.0000],\n",
      "          [0.0110, 0.0554, 0.9336, 0.0000],\n",
      "          [0.0071, 0.0259, 0.4053, 0.5618]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5755, 0.4245, 0.0000, 0.0000],\n",
      "          [0.0814, 0.2401, 0.6785, 0.0000],\n",
      "          [0.0789, 0.0749, 0.3070, 0.5393]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 7])\n",
      "old attention tensor([[[[0.2358, 0.5071, 0.1001, 0.1009, 0.0207, 0.0210, 0.0145],\n",
      "          [0.2571, 0.2031, 0.0771, 0.3117, 0.0809, 0.0369, 0.0331],\n",
      "          [0.2490, 0.3199, 0.0614, 0.2171, 0.0942, 0.0326, 0.0258],\n",
      "          [0.1086, 0.1021, 0.1049, 0.6176, 0.0370, 0.0154, 0.0143]],\n",
      "\n",
      "         [[0.1540, 0.5286, 0.0797, 0.0938, 0.0222, 0.1080, 0.0136],\n",
      "          [0.3382, 0.1192, 0.0771, 0.2505, 0.0584, 0.0619, 0.0947],\n",
      "          [0.1848, 0.0920, 0.1253, 0.3247, 0.0505, 0.1625, 0.0602],\n",
      "          [0.2284, 0.0927, 0.1594, 0.3357, 0.0579, 0.0649, 0.0609]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.2654, 0.7346, 0.0000, 0.0000],\n",
      "          [0.2180, 0.2472, 0.5348, 0.0000],\n",
      "          [0.1065, 0.1599, 0.5032, 0.2303]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.1778, 0.8222, 0.0000, 0.0000],\n",
      "          [0.1444, 0.2101, 0.6455, 0.0000],\n",
      "          [0.0505, 0.1777, 0.5644, 0.2074]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 7])\n",
      "old attention tensor([[[[8.7081e-02, 4.8752e-01, 2.1695e-01, 5.1402e-02, 1.7345e-02,\n",
      "           9.7621e-02, 4.2080e-02],\n",
      "          [5.1044e-02, 1.6739e-01, 1.7389e-01, 4.4188e-01, 3.3415e-02,\n",
      "           8.0725e-02, 5.1668e-02],\n",
      "          [1.3036e-02, 6.6115e-02, 1.8455e-01, 5.8034e-01, 2.7244e-02,\n",
      "           6.8578e-02, 6.0136e-02],\n",
      "          [4.1956e-02, 1.6273e-01, 2.1395e-01, 4.3064e-01, 3.6476e-02,\n",
      "           6.9396e-02, 4.4857e-02]],\n",
      "\n",
      "         [[1.3094e-02, 1.0898e-02, 3.3323e-02, 8.5844e-01, 3.8902e-03,\n",
      "           3.6103e-02, 4.4252e-02],\n",
      "          [2.2282e-03, 1.2174e-03, 1.1842e-02, 9.6884e-01, 1.0859e-03,\n",
      "           6.6309e-03, 8.1573e-03],\n",
      "          [3.9494e-03, 2.5256e-03, 1.3814e-02, 9.6287e-01, 7.1966e-04,\n",
      "           8.6589e-03, 7.4669e-03],\n",
      "          [3.1276e-03, 3.6108e-03, 1.4345e-02, 9.5478e-01, 1.2733e-03,\n",
      "           1.1693e-02, 1.1173e-02]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [5.4816e-02, 9.4518e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [5.7779e-03, 3.5214e-03, 9.9070e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [3.3226e-02, 2.2414e-02, 9.2716e-01, 1.7204e-02, 0.0000e+00],\n",
      "          [1.8739e-03, 1.1628e-03, 4.1187e-01, 1.1477e-03, 5.8395e-01]],\n",
      "\n",
      "         [[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [9.8231e-03, 9.9018e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [2.8250e-03, 1.6355e-02, 9.8082e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [1.5928e-02, 2.7463e-01, 6.4256e-01, 6.6889e-02, 0.0000e+00],\n",
      "          [9.8456e-04, 7.1017e-03, 4.4582e-01, 6.1770e-02, 4.8433e-01]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 7])\n",
      "old attention tensor([[[[0.3549, 0.5119, 0.0039, 0.0192, 0.0584, 0.0259, 0.0259],\n",
      "          [0.0421, 0.0522, 0.6551, 0.1102, 0.0237, 0.0501, 0.0666],\n",
      "          [0.1818, 0.1924, 0.2182, 0.1493, 0.0720, 0.1019, 0.0845],\n",
      "          [0.1732, 0.0718, 0.2908, 0.3279, 0.0566, 0.0511, 0.0287],\n",
      "          [0.1880, 0.1634, 0.2316, 0.1449, 0.0760, 0.1035, 0.0927]],\n",
      "\n",
      "         [[0.0313, 0.1907, 0.4049, 0.0183, 0.2257, 0.0793, 0.0498],\n",
      "          [0.1604, 0.0665, 0.2214, 0.0319, 0.3041, 0.1883, 0.0274],\n",
      "          [0.0497, 0.0486, 0.1625, 0.0330, 0.6025, 0.0708, 0.0329],\n",
      "          [0.0928, 0.0078, 0.1218, 0.0348, 0.3993, 0.3134, 0.0301],\n",
      "          [0.0552, 0.0495, 0.1261, 0.0330, 0.6332, 0.0687, 0.0343]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.1120, 0.8880, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0174, 0.0608, 0.9218, 0.0000, 0.0000],\n",
      "          [0.0112, 0.0262, 0.4778, 0.4848, 0.0000],\n",
      "          [0.0065, 0.0239, 0.3524, 0.2072, 0.4100]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5801, 0.4199, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0773, 0.2179, 0.7047, 0.0000, 0.0000],\n",
      "          [0.0699, 0.0679, 0.3133, 0.5490, 0.0000],\n",
      "          [0.0231, 0.0553, 0.2128, 0.4460, 0.2629]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 7])\n",
      "old attention tensor([[[[0.1741, 0.4556, 0.1137, 0.1787, 0.0253, 0.0272, 0.0254],\n",
      "          [0.1760, 0.1750, 0.0755, 0.4259, 0.0695, 0.0360, 0.0421],\n",
      "          [0.1833, 0.2862, 0.0688, 0.3046, 0.0859, 0.0359, 0.0353],\n",
      "          [0.0678, 0.0773, 0.0903, 0.7024, 0.0311, 0.0144, 0.0168],\n",
      "          [0.1791, 0.2491, 0.0707, 0.3429, 0.0857, 0.0346, 0.0378]],\n",
      "\n",
      "         [[0.2019, 0.2636, 0.2182, 0.1393, 0.0213, 0.1379, 0.0178],\n",
      "          [0.3507, 0.0663, 0.1430, 0.2445, 0.0429, 0.0668, 0.0858],\n",
      "          [0.1741, 0.0462, 0.2233, 0.3114, 0.0346, 0.1562, 0.0542],\n",
      "          [0.2234, 0.0465, 0.2737, 0.3003, 0.0373, 0.0661, 0.0527],\n",
      "          [0.1578, 0.0424, 0.2573, 0.3165, 0.0296, 0.1482, 0.0484]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.3788, 0.6212, 0.0000, 0.0000, 0.0000],\n",
      "          [0.2926, 0.2277, 0.4797, 0.0000, 0.0000],\n",
      "          [0.1598, 0.1470, 0.4701, 0.2231, 0.0000],\n",
      "          [0.1632, 0.1185, 0.2836, 0.1723, 0.2623]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.2351, 0.7649, 0.0000, 0.0000, 0.0000],\n",
      "          [0.2113, 0.2333, 0.5553, 0.0000, 0.0000],\n",
      "          [0.1009, 0.2006, 0.5589, 0.1396, 0.0000],\n",
      "          [0.1234, 0.1500, 0.3589, 0.0598, 0.3078]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 7])\n",
      "old attention tensor([[[[0.1185, 0.2453, 0.2306, 0.0527, 0.0309, 0.2097, 0.1123],\n",
      "          [0.0634, 0.1041, 0.1684, 0.3098, 0.0486, 0.1660, 0.1397],\n",
      "          [0.0235, 0.0504, 0.1825, 0.4020, 0.0447, 0.1446, 0.1522],\n",
      "          [0.0571, 0.0906, 0.2063, 0.2954, 0.0569, 0.1559, 0.1378],\n",
      "          [0.0229, 0.0500, 0.1686, 0.4252, 0.0415, 0.1404, 0.1514]],\n",
      "\n",
      "         [[0.0756, 0.0612, 0.0449, 0.7305, 0.0107, 0.0402, 0.0370],\n",
      "          [0.0196, 0.0094, 0.0193, 0.9284, 0.0037, 0.0098, 0.0097],\n",
      "          [0.0330, 0.0213, 0.0258, 0.8918, 0.0031, 0.0142, 0.0109],\n",
      "          [0.0288, 0.0286, 0.0253, 0.8845, 0.0042, 0.0157, 0.0129],\n",
      "          [0.0301, 0.0205, 0.0273, 0.8952, 0.0028, 0.0135, 0.0106]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "predicted trg = ['wir', 'lesen', 'zeitung', 'lesen', '<eos>']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_count 1    self.capacity  20\n",
      "0  ------------------------------------------------\n",
      "DecoderLayer@trg4\n",
      "[1, 1, 64]\n",
      "src = ['we', 'can', 'eat', 'bread']\n",
      "old attention torch.Size([1, 2, 6, 6])\n",
      "old attention tensor([[[[3.0915e-03, 3.4036e-03, 9.5473e-01, 2.4468e-02, 5.7033e-03,\n",
      "           8.6060e-03],\n",
      "          [5.2619e-03, 8.2156e-03, 2.8448e-03, 2.3516e-02, 1.6984e-01,\n",
      "           7.9032e-01],\n",
      "          [1.0137e-02, 1.2041e-01, 1.2520e-02, 1.0268e-02, 8.2733e-01,\n",
      "           1.9334e-02],\n",
      "          [1.6503e-01, 5.6973e-02, 2.9202e-02, 3.2584e-02, 1.1571e-01,\n",
      "           6.0051e-01],\n",
      "          [2.4120e-01, 6.4300e-03, 3.2145e-01, 3.5135e-01, 7.0633e-02,\n",
      "           8.9314e-03],\n",
      "          [1.5624e-02, 3.4402e-03, 7.2293e-01, 8.0642e-02, 1.6753e-01,\n",
      "           9.8307e-03]],\n",
      "\n",
      "         [[3.8369e-02, 6.1600e-01, 2.0416e-01, 1.1993e-02, 9.1193e-02,\n",
      "           3.8287e-02],\n",
      "          [1.7040e-02, 2.5814e-03, 9.0011e-01, 1.1913e-02, 5.1461e-02,\n",
      "           1.6897e-02],\n",
      "          [6.5438e-03, 4.0335e-03, 9.1458e-01, 9.0594e-03, 6.5524e-02,\n",
      "           2.5845e-04],\n",
      "          [3.6952e-02, 6.2526e-02, 6.0582e-02, 4.7157e-02, 3.2426e-02,\n",
      "           7.6036e-01],\n",
      "          [3.7295e-02, 6.7189e-03, 1.5939e-01, 7.3349e-01, 4.4051e-02,\n",
      "           1.9058e-02],\n",
      "          [9.3466e-02, 8.6007e-02, 9.4280e-02, 1.5653e-01, 1.3124e-01,\n",
      "           4.3848e-01]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 6, 6])\n",
      "old attention tensor([[[[0.0994, 0.0474, 0.4739, 0.1228, 0.1379, 0.1187],\n",
      "          [0.0840, 0.1721, 0.0554, 0.0719, 0.1377, 0.4790],\n",
      "          [0.2747, 0.2097, 0.0351, 0.1234, 0.1969, 0.1602],\n",
      "          [0.0254, 0.1034, 0.0660, 0.5197, 0.0804, 0.2050],\n",
      "          [0.1841, 0.1490, 0.1209, 0.1968, 0.1100, 0.2391],\n",
      "          [0.0784, 0.0659, 0.6698, 0.0985, 0.0253, 0.0621]],\n",
      "\n",
      "         [[0.1537, 0.2222, 0.3613, 0.1226, 0.0326, 0.1077],\n",
      "          [0.0386, 0.3986, 0.0783, 0.2291, 0.2282, 0.0272],\n",
      "          [0.4328, 0.1118, 0.2407, 0.0259, 0.0887, 0.1001],\n",
      "          [0.0829, 0.1514, 0.0903, 0.1649, 0.3285, 0.1819],\n",
      "          [0.0237, 0.1080, 0.0768, 0.0411, 0.6233, 0.1271],\n",
      "          [0.0309, 0.0351, 0.0806, 0.4701, 0.1112, 0.2721]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 6, 6])\n",
      "old attention tensor([[[[0.0723, 0.3838, 0.1749, 0.1791, 0.1534, 0.0366],\n",
      "          [0.1017, 0.0953, 0.1426, 0.2072, 0.3204, 0.1327],\n",
      "          [0.1154, 0.0169, 0.0212, 0.0509, 0.3031, 0.4925],\n",
      "          [0.0799, 0.0458, 0.1560, 0.5867, 0.1003, 0.0313],\n",
      "          [0.2873, 0.2300, 0.0492, 0.4148, 0.0125, 0.0062],\n",
      "          [0.1287, 0.2799, 0.0337, 0.4841, 0.0265, 0.0470]],\n",
      "\n",
      "         [[0.0465, 0.0108, 0.7033, 0.1919, 0.0403, 0.0073],\n",
      "          [0.0608, 0.0796, 0.1158, 0.4585, 0.1681, 0.1173],\n",
      "          [0.0247, 0.0065, 0.8336, 0.0380, 0.0891, 0.0079],\n",
      "          [0.0377, 0.1012, 0.1194, 0.2989, 0.2462, 0.1966],\n",
      "          [0.0675, 0.0278, 0.3477, 0.4185, 0.1102, 0.0284],\n",
      "          [0.2093, 0.1183, 0.0285, 0.1540, 0.2966, 0.1934]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 6])\n",
      "old attention tensor([[[[0.1529, 0.4433, 0.0179, 0.1557, 0.1989, 0.0312]],\n",
      "\n",
      "         [[0.1317, 0.6192, 0.0504, 0.1277, 0.0470, 0.0240]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 6])\n",
      "old attention tensor([[[[0.2349, 0.5530, 0.1420, 0.0401, 0.0271, 0.0029]],\n",
      "\n",
      "         [[0.0170, 0.9523, 0.0037, 0.0107, 0.0087, 0.0077]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 6])\n",
      "old attention tensor([[[[0.0763, 0.4716, 0.1819, 0.1117, 0.1109, 0.0476]],\n",
      "\n",
      "         [[0.0310, 0.0515, 0.0193, 0.1040, 0.1658, 0.6284]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0548, 0.9452]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0098, 0.9902]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0548, 0.9452]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0098, 0.9902]]]])\n",
      "old attention torch.Size([1, 2, 2, 6])\n",
      "old attention tensor([[[[0.1529, 0.4433, 0.0179, 0.1557, 0.1989, 0.0312],\n",
      "          [0.0969, 0.0450, 0.3164, 0.1646, 0.0071, 0.3699]],\n",
      "\n",
      "         [[0.1317, 0.6192, 0.0504, 0.1277, 0.0470, 0.0240],\n",
      "          [0.1273, 0.0070, 0.8023, 0.0396, 0.0076, 0.0162]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0174, 0.9826]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.5739, 0.4261]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0174, 0.9826]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.5739, 0.4261]]]])\n",
      "old attention torch.Size([1, 2, 2, 6])\n",
      "old attention tensor([[[[0.2349, 0.5530, 0.1420, 0.0401, 0.0271, 0.0029],\n",
      "          [0.1395, 0.1013, 0.1210, 0.5588, 0.0306, 0.0488]],\n",
      "\n",
      "         [[0.0170, 0.9523, 0.0037, 0.0107, 0.0087, 0.0077],\n",
      "          [0.0797, 0.0499, 0.6845, 0.0434, 0.1250, 0.0175]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.5808, 0.4192]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0785, 0.9215]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.5808, 0.4192]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0785, 0.9215]]]])\n",
      "old attention torch.Size([1, 2, 2, 6])\n",
      "old attention tensor([[[[0.0763, 0.4716, 0.1819, 0.1117, 0.1109, 0.0476],\n",
      "          [0.0287, 0.3707, 0.2062, 0.2213, 0.1149, 0.0582]],\n",
      "\n",
      "         [[0.0310, 0.0515, 0.0193, 0.1040, 0.1658, 0.6284],\n",
      "          [0.0114, 0.0195, 0.0783, 0.1099, 0.1704, 0.6105]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.0548, 0.9452, 0.0000],\n",
      "          [0.0140, 0.1149, 0.8711]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.0098, 0.9902, 0.0000],\n",
      "          [0.0047, 0.0052, 0.9901]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 6])\n",
      "old attention tensor([[[[0.1569, 0.2934, 0.0210, 0.2553, 0.2488, 0.0247],\n",
      "          [0.0913, 0.1112, 0.1349, 0.1823, 0.0259, 0.4544],\n",
      "          [0.0284, 0.0819, 0.0837, 0.1929, 0.3436, 0.2695]],\n",
      "\n",
      "         [[0.0872, 0.5528, 0.0449, 0.1715, 0.0522, 0.0914],\n",
      "          [0.1387, 0.0379, 0.7683, 0.0285, 0.0139, 0.0126],\n",
      "          [0.1894, 0.3421, 0.0563, 0.1794, 0.0463, 0.1866]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.0253, 0.9747, 0.0000],\n",
      "          [0.0416, 0.4488, 0.5095]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.7086, 0.2914, 0.0000],\n",
      "          [0.4260, 0.0559, 0.5182]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 6])\n",
      "old attention tensor([[[[0.2126, 0.4497, 0.1975, 0.0721, 0.0600, 0.0081],\n",
      "          [0.2112, 0.1977, 0.2540, 0.2964, 0.0353, 0.0054],\n",
      "          [0.0505, 0.1544, 0.4655, 0.1961, 0.0922, 0.0414]],\n",
      "\n",
      "         [[0.0339, 0.9243, 0.0048, 0.0183, 0.0151, 0.0035],\n",
      "          [0.1552, 0.5260, 0.0933, 0.0367, 0.1297, 0.0591],\n",
      "          [0.1283, 0.3749, 0.0204, 0.0348, 0.3053, 0.1364]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.2634, 0.7366, 0.0000],\n",
      "          [0.3496, 0.4291, 0.2213]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.0629, 0.9371, 0.0000],\n",
      "          [0.0359, 0.2952, 0.6689]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 6])\n",
      "old attention tensor([[[[0.0635, 0.3260, 0.1489, 0.1866, 0.1842, 0.0908],\n",
      "          [0.0822, 0.2368, 0.1370, 0.1466, 0.2328, 0.1646],\n",
      "          [0.0811, 0.1268, 0.1458, 0.2191, 0.2641, 0.1631]],\n",
      "\n",
      "         [[0.0321, 0.0544, 0.0211, 0.1508, 0.3184, 0.4232],\n",
      "          [0.0222, 0.0286, 0.0373, 0.1456, 0.3626, 0.4037],\n",
      "          [0.0400, 0.0369, 0.0339, 0.1611, 0.4430, 0.2852]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [5.4816e-02, 9.4518e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [1.4026e-02, 1.1485e-01, 8.7112e-01, 0.0000e+00],\n",
      "          [1.0585e-01, 4.4915e-01, 4.1571e-01, 2.9289e-02]],\n",
      "\n",
      "         [[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [9.8231e-03, 9.9018e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [4.7095e-03, 5.2001e-03, 9.9009e-01, 0.0000e+00],\n",
      "          [1.3612e-03, 8.8639e-03, 3.4831e-04, 9.8943e-01]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 6])\n",
      "old attention tensor([[[[0.1829, 0.2833, 0.0263, 0.2155, 0.2748, 0.0173],\n",
      "          [0.1106, 0.1105, 0.1929, 0.1650, 0.0271, 0.3940],\n",
      "          [0.0314, 0.0750, 0.1188, 0.1600, 0.4130, 0.2018],\n",
      "          [0.1151, 0.0172, 0.5490, 0.1922, 0.0248, 0.1017]],\n",
      "\n",
      "         [[0.0503, 0.5549, 0.0212, 0.2179, 0.0497, 0.1060],\n",
      "          [0.1373, 0.0557, 0.7119, 0.0541, 0.0198, 0.0212],\n",
      "          [0.1025, 0.3494, 0.0226, 0.2467, 0.0429, 0.2359],\n",
      "          [0.0699, 0.6863, 0.0436, 0.1133, 0.0444, 0.0425]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0328, 0.9672, 0.0000, 0.0000],\n",
      "          [0.0570, 0.4385, 0.5045, 0.0000],\n",
      "          [0.0632, 0.3210, 0.1582, 0.4577]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.7006, 0.2994, 0.0000, 0.0000],\n",
      "          [0.3726, 0.0410, 0.5864, 0.0000],\n",
      "          [0.0139, 0.3919, 0.5435, 0.0507]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 6])\n",
      "old attention tensor([[[[0.1922, 0.6065, 0.1160, 0.0413, 0.0387, 0.0053],\n",
      "          [0.2194, 0.2398, 0.2056, 0.3017, 0.0280, 0.0055],\n",
      "          [0.0441, 0.1844, 0.4346, 0.2002, 0.0833, 0.0533],\n",
      "          [0.1881, 0.5186, 0.1796, 0.0702, 0.0317, 0.0118]],\n",
      "\n",
      "         [[0.1045, 0.7999, 0.0093, 0.0647, 0.0194, 0.0022],\n",
      "          [0.3178, 0.2355, 0.1702, 0.0797, 0.1583, 0.0384],\n",
      "          [0.2511, 0.1951, 0.0319, 0.0723, 0.3461, 0.1035],\n",
      "          [0.1809, 0.1086, 0.1528, 0.1557, 0.3001, 0.1019]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.2128, 0.7872, 0.0000, 0.0000],\n",
      "          [0.2993, 0.4477, 0.2530, 0.0000],\n",
      "          [0.0708, 0.1056, 0.7214, 0.1022]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0506, 0.9494, 0.0000, 0.0000],\n",
      "          [0.0183, 0.1902, 0.7915, 0.0000],\n",
      "          [0.0561, 0.1790, 0.4992, 0.2657]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 6])\n",
      "old attention tensor([[[[0.0646, 0.2217, 0.1912, 0.2481, 0.1610, 0.1134],\n",
      "          [0.0721, 0.1248, 0.1696, 0.1439, 0.2212, 0.2684],\n",
      "          [0.0696, 0.0435, 0.1552, 0.2470, 0.2349, 0.2499],\n",
      "          [0.0289, 0.1792, 0.1211, 0.1333, 0.1410, 0.3966]],\n",
      "\n",
      "         [[0.0917, 0.0937, 0.0274, 0.2102, 0.2465, 0.3304],\n",
      "          [0.0610, 0.0388, 0.0669, 0.2091, 0.2525, 0.3717],\n",
      "          [0.1346, 0.0663, 0.0397, 0.2230, 0.3366, 0.1999],\n",
      "          [0.0506, 0.0416, 0.1762, 0.1467, 0.3456, 0.2393]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "predicted trg = ['wir', 'konnen', 'essen', '<eos>']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_count 1    self.capacity  20\n",
      "0  ------------------------------------------------\n",
      "DecoderLayer@trg4\n",
      "[1, 1, 64]\n",
      "src = ['we', 'can', 'eat', 'apple']\n",
      "old attention torch.Size([1, 2, 6, 6])\n",
      "old attention tensor([[[[3.0933e-03, 3.4055e-03, 9.5527e-01, 2.4481e-02, 5.1372e-03,\n",
      "           8.6109e-03],\n",
      "          [6.1997e-03, 9.6799e-03, 3.3519e-03, 2.7708e-02, 2.1882e-02,\n",
      "           9.3118e-01],\n",
      "          [5.2438e-02, 6.2287e-01, 6.4768e-02, 5.3117e-02, 1.0679e-01,\n",
      "           1.0002e-01],\n",
      "          [1.6307e-01, 5.6300e-02, 2.8856e-02, 3.2199e-02, 1.2617e-01,\n",
      "           5.9341e-01],\n",
      "          [6.7275e-02, 9.0975e-02, 3.0199e-01, 2.0220e-01, 8.4857e-02,\n",
      "           2.5270e-01],\n",
      "          [1.8078e-02, 3.9806e-03, 8.3649e-01, 9.3309e-02, 3.6772e-02,\n",
      "           1.1375e-02]],\n",
      "\n",
      "         [[4.1508e-02, 6.6640e-01, 2.2086e-01, 1.2974e-02, 1.6842e-02,\n",
      "           4.1419e-02],\n",
      "          [1.7821e-02, 2.6998e-03, 9.4138e-01, 1.2459e-02, 7.9661e-03,\n",
      "           1.7672e-02],\n",
      "          [6.9470e-03, 4.2821e-03, 9.7094e-01, 9.6177e-03, 7.9357e-03,\n",
      "           2.7438e-04],\n",
      "          [3.7959e-02, 6.4229e-02, 6.2233e-02, 4.8441e-02, 6.0630e-03,\n",
      "           7.8107e-01],\n",
      "          [1.3179e-03, 2.5710e-03, 1.5664e-03, 1.5396e-02, 1.1581e-02,\n",
      "           9.6757e-01],\n",
      "          [6.6139e-02, 6.0861e-02, 6.6715e-02, 1.1076e-01, 3.8524e-01,\n",
      "           3.1028e-01]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 6, 6])\n",
      "old attention tensor([[[[0.0938, 0.0373, 0.4258, 0.1219, 0.2143, 0.1068],\n",
      "          [0.0740, 0.1628, 0.0632, 0.0693, 0.1712, 0.4596],\n",
      "          [0.1057, 0.0649, 0.0157, 0.0446, 0.7100, 0.0591],\n",
      "          [0.0291, 0.0954, 0.0712, 0.5075, 0.0855, 0.2112],\n",
      "          [0.1135, 0.1172, 0.0993, 0.2381, 0.0338, 0.3981],\n",
      "          [0.0689, 0.0661, 0.6303, 0.0824, 0.0887, 0.0636]],\n",
      "\n",
      "         [[0.1663, 0.2131, 0.3382, 0.1281, 0.0553, 0.0990],\n",
      "          [0.0469, 0.4734, 0.0863, 0.2647, 0.0954, 0.0333],\n",
      "          [0.4201, 0.1441, 0.2391, 0.0302, 0.0726, 0.0939],\n",
      "          [0.0813, 0.1716, 0.1032, 0.2086, 0.2495, 0.1858],\n",
      "          [0.0670, 0.0127, 0.0239, 0.0060, 0.8009, 0.0896],\n",
      "          [0.0332, 0.0362, 0.1011, 0.4627, 0.0927, 0.2741]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 6, 6])\n",
      "old attention tensor([[[[0.0636, 0.3315, 0.1900, 0.1683, 0.2155, 0.0311],\n",
      "          [0.1067, 0.0932, 0.1421, 0.2158, 0.3498, 0.0924],\n",
      "          [0.1776, 0.0330, 0.0331, 0.0943, 0.1079, 0.5541],\n",
      "          [0.0537, 0.0406, 0.1085, 0.5050, 0.2788, 0.0134],\n",
      "          [0.0464, 0.1078, 0.0829, 0.4232, 0.3310, 0.0087],\n",
      "          [0.1047, 0.2027, 0.0225, 0.3940, 0.2576, 0.0184]],\n",
      "\n",
      "         [[0.0498, 0.0162, 0.6005, 0.1886, 0.1383, 0.0065],\n",
      "          [0.0486, 0.0859, 0.0945, 0.4134, 0.2651, 0.0925],\n",
      "          [0.0209, 0.0088, 0.8731, 0.0407, 0.0471, 0.0095],\n",
      "          [0.0366, 0.1295, 0.1247, 0.3174, 0.2395, 0.1523],\n",
      "          [0.0403, 0.0892, 0.1101, 0.1997, 0.4465, 0.1142],\n",
      "          [0.2215, 0.1612, 0.0334, 0.2161, 0.1659, 0.2019]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 6])\n",
      "old attention tensor([[[[0.1601, 0.5440, 0.0208, 0.1701, 0.0624, 0.0425]],\n",
      "\n",
      "         [[0.1058, 0.4681, 0.0406, 0.0900, 0.2762, 0.0193]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 6])\n",
      "old attention tensor([[[[0.2702, 0.4908, 0.1477, 0.0459, 0.0427, 0.0027]],\n",
      "\n",
      "         [[0.0186, 0.9468, 0.0041, 0.0108, 0.0115, 0.0082]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 6])\n",
      "old attention tensor([[[[0.0735, 0.4941, 0.2126, 0.1008, 0.0857, 0.0333]],\n",
      "\n",
      "         [[0.0181, 0.0263, 0.0138, 0.0809, 0.4190, 0.4419]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0548, 0.9452]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0098, 0.9902]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0548, 0.9452]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0098, 0.9902]]]])\n",
      "old attention torch.Size([1, 2, 2, 6])\n",
      "old attention tensor([[[[0.1601, 0.5440, 0.0208, 0.1701, 0.0624, 0.0425],\n",
      "          [0.0867, 0.0293, 0.1905, 0.0954, 0.3650, 0.2331]],\n",
      "\n",
      "         [[0.1058, 0.4681, 0.0406, 0.0900, 0.2762, 0.0193],\n",
      "          [0.0947, 0.0061, 0.8477, 0.0306, 0.0066, 0.0143]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0118, 0.9882]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.6087, 0.3913]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0118, 0.9882]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.6087, 0.3913]]]])\n",
      "old attention torch.Size([1, 2, 2, 6])\n",
      "old attention tensor([[[[0.2702, 0.4908, 0.1477, 0.0459, 0.0427, 0.0027],\n",
      "          [0.1173, 0.0758, 0.0790, 0.4290, 0.2698, 0.0290]],\n",
      "\n",
      "         [[0.0186, 0.9468, 0.0041, 0.0108, 0.0115, 0.0082],\n",
      "          [0.0820, 0.0550, 0.7587, 0.0445, 0.0398, 0.0199]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.5462, 0.4538]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.1192, 0.8808]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.5462, 0.4538]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.1192, 0.8808]]]])\n",
      "old attention torch.Size([1, 2, 2, 6])\n",
      "old attention tensor([[[[0.0735, 0.4941, 0.2126, 0.1008, 0.0857, 0.0333],\n",
      "          [0.0230, 0.3250, 0.2058, 0.1542, 0.2552, 0.0367]],\n",
      "\n",
      "         [[0.0181, 0.0263, 0.0138, 0.0809, 0.4190, 0.4419],\n",
      "          [0.0109, 0.0239, 0.0915, 0.1122, 0.1198, 0.6418]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.0548, 0.9452, 0.0000],\n",
      "          [0.0140, 0.1149, 0.8711]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.0098, 0.9902, 0.0000],\n",
      "          [0.0047, 0.0052, 0.9901]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 6])\n",
      "old attention tensor([[[[0.1793, 0.3849, 0.0277, 0.3164, 0.0554, 0.0364],\n",
      "          [0.0732, 0.0776, 0.0876, 0.1075, 0.3420, 0.3122],\n",
      "          [0.0278, 0.0955, 0.1025, 0.2301, 0.2368, 0.3074]],\n",
      "\n",
      "         [[0.0726, 0.4829, 0.0397, 0.1212, 0.2031, 0.0804],\n",
      "          [0.1031, 0.0313, 0.8261, 0.0199, 0.0099, 0.0097],\n",
      "          [0.1289, 0.2439, 0.0408, 0.1189, 0.3582, 0.1092]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.0210, 0.9790, 0.0000],\n",
      "          [0.0341, 0.6056, 0.3604]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.7106, 0.2894, 0.0000],\n",
      "          [0.4347, 0.0590, 0.5064]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 6])\n",
      "old attention tensor([[[[0.2197, 0.4500, 0.1876, 0.0917, 0.0441, 0.0069],\n",
      "          [0.1859, 0.1457, 0.1759, 0.2919, 0.1972, 0.0035],\n",
      "          [0.0576, 0.1262, 0.3894, 0.2553, 0.1442, 0.0273]],\n",
      "\n",
      "         [[0.0350, 0.9037, 0.0062, 0.0179, 0.0334, 0.0038],\n",
      "          [0.1722, 0.5577, 0.1060, 0.0419, 0.0553, 0.0670],\n",
      "          [0.1558, 0.5025, 0.0285, 0.0473, 0.1062, 0.1597]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.2927, 0.7073, 0.0000],\n",
      "          [0.3441, 0.3670, 0.2890]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.1080, 0.8920, 0.0000],\n",
      "          [0.0655, 0.3227, 0.6118]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 6])\n",
      "old attention tensor([[[[0.0368, 0.2749, 0.1439, 0.1304, 0.3761, 0.0378],\n",
      "          [0.0516, 0.1936, 0.1004, 0.1165, 0.4690, 0.0688],\n",
      "          [0.0269, 0.0664, 0.0661, 0.0918, 0.7034, 0.0454]],\n",
      "\n",
      "         [[0.0176, 0.0342, 0.0193, 0.1572, 0.3691, 0.4026],\n",
      "          [0.0130, 0.0226, 0.0389, 0.1523, 0.3618, 0.4114],\n",
      "          [0.0306, 0.0375, 0.0439, 0.1969, 0.2592, 0.4318]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [5.4816e-02, 9.4518e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [1.4026e-02, 1.1485e-01, 8.7112e-01, 0.0000e+00],\n",
      "          [1.0585e-01, 4.4915e-01, 4.1571e-01, 2.9289e-02]],\n",
      "\n",
      "         [[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [9.8231e-03, 9.9018e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [4.7095e-03, 5.2001e-03, 9.9009e-01, 0.0000e+00],\n",
      "          [1.3612e-03, 8.8639e-03, 3.4831e-04, 9.8943e-01]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 6])\n",
      "old attention tensor([[[[0.2235, 0.3892, 0.0365, 0.2844, 0.0399, 0.0265],\n",
      "          [0.0970, 0.0814, 0.1327, 0.1036, 0.3027, 0.2826],\n",
      "          [0.0367, 0.1023, 0.1723, 0.2290, 0.1942, 0.2656],\n",
      "          [0.1075, 0.0138, 0.4976, 0.1709, 0.1174, 0.0927]],\n",
      "\n",
      "         [[0.0400, 0.4681, 0.0166, 0.1420, 0.2443, 0.0890],\n",
      "          [0.1080, 0.0494, 0.7680, 0.0388, 0.0185, 0.0173],\n",
      "          [0.0608, 0.2203, 0.0130, 0.1372, 0.4499, 0.1187],\n",
      "          [0.0577, 0.5327, 0.0298, 0.0726, 0.2690, 0.0383]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0247, 0.9753, 0.0000, 0.0000],\n",
      "          [0.0456, 0.5798, 0.3746, 0.0000],\n",
      "          [0.0535, 0.3514, 0.1381, 0.4570]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.6903, 0.3097, 0.0000, 0.0000],\n",
      "          [0.3679, 0.0434, 0.5887, 0.0000],\n",
      "          [0.0154, 0.4121, 0.5385, 0.0339]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 6])\n",
      "old attention tensor([[[[0.1998, 0.5976, 0.1131, 0.0597, 0.0247, 0.0050],\n",
      "          [0.1833, 0.1691, 0.1422, 0.3093, 0.1926, 0.0035],\n",
      "          [0.0497, 0.1497, 0.3577, 0.2700, 0.1355, 0.0374],\n",
      "          [0.2006, 0.5201, 0.1396, 0.0975, 0.0326, 0.0096]],\n",
      "\n",
      "         [[0.0915, 0.7343, 0.0123, 0.0562, 0.1035, 0.0022],\n",
      "          [0.3079, 0.2559, 0.2073, 0.0835, 0.0977, 0.0478],\n",
      "          [0.2701, 0.2449, 0.0495, 0.0906, 0.2168, 0.1280],\n",
      "          [0.2066, 0.1361, 0.2206, 0.1931, 0.1257, 0.1179]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.2421, 0.7579, 0.0000, 0.0000],\n",
      "          [0.3130, 0.3548, 0.3322, 0.0000],\n",
      "          [0.0639, 0.0761, 0.7736, 0.0863]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0928, 0.9072, 0.0000, 0.0000],\n",
      "          [0.0421, 0.2297, 0.7282, 0.0000],\n",
      "          [0.0800, 0.2091, 0.3879, 0.3230]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 6])\n",
      "old attention tensor([[[[0.0338, 0.2018, 0.2437, 0.1783, 0.2983, 0.0442],\n",
      "          [0.0506, 0.1160, 0.1555, 0.1404, 0.4249, 0.1126],\n",
      "          [0.0224, 0.0266, 0.0823, 0.1111, 0.6835, 0.0742],\n",
      "          [0.0218, 0.2143, 0.1727, 0.1272, 0.2911, 0.1729]],\n",
      "\n",
      "         [[0.0414, 0.0542, 0.0263, 0.1895, 0.3071, 0.3816],\n",
      "          [0.0299, 0.0301, 0.0727, 0.1868, 0.2666, 0.4140],\n",
      "          [0.0978, 0.0702, 0.0621, 0.2410, 0.1738, 0.3550],\n",
      "          [0.0318, 0.0417, 0.2167, 0.1455, 0.1914, 0.3728]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "predicted trg = ['wir', 'konnen', 'essen', '<eos>']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_count 1    self.capacity  20\n",
      "0  ------------------------------------------------\n",
      "DecoderLayer@trg4\n",
      "[1, 1, 64]\n",
      "src = ['we', 'can', 'drink', 'water']\n",
      "old attention torch.Size([1, 2, 6, 6])\n",
      "old attention tensor([[[[2.9730e-03, 3.2731e-03, 9.1814e-01, 6.5980e-02, 1.3579e-03,\n",
      "           8.2762e-03],\n",
      "          [6.3200e-03, 9.8678e-03, 3.4169e-03, 1.0191e-02, 2.0954e-02,\n",
      "           9.4925e-01],\n",
      "          [4.8009e-02, 5.7026e-01, 5.9298e-02, 1.7198e-01, 5.8882e-02,\n",
      "           9.1568e-02],\n",
      "          [2.0484e-03, 9.0948e-02, 1.6443e-02, 4.7243e-03, 8.2608e-02,\n",
      "           8.0323e-01],\n",
      "          [8.1347e-02, 6.5904e-02, 9.0925e-02, 7.2938e-01, 2.6272e-02,\n",
      "           6.1697e-03],\n",
      "          [1.1852e-02, 2.6098e-03, 5.4843e-01, 4.2616e-01, 3.4951e-03,\n",
      "           7.4578e-03]],\n",
      "\n",
      "         [[3.6806e-02, 5.9090e-01, 1.9584e-01, 1.1881e-01, 2.0919e-02,\n",
      "           3.6727e-02],\n",
      "          [8.9260e-03, 1.3522e-03, 4.7151e-01, 4.8889e-01, 2.0471e-02,\n",
      "           8.8512e-03],\n",
      "          [6.7391e-03, 4.1539e-03, 9.4188e-01, 4.5676e-02, 1.2813e-03,\n",
      "           2.6617e-04],\n",
      "          [4.8008e-01, 6.8402e-02, 2.6950e-01, 4.0243e-02, 4.7552e-02,\n",
      "           9.4228e-02],\n",
      "          [2.0617e-02, 8.0514e-01, 5.3066e-02, 4.4627e-02, 3.1982e-02,\n",
      "           4.4568e-02],\n",
      "          [8.4488e-02, 7.7745e-02, 8.5223e-02, 5.5772e-02, 3.0041e-01,\n",
      "           3.9637e-01]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 6, 6])\n",
      "old attention tensor([[[[0.0732, 0.0382, 0.3733, 0.1515, 0.2721, 0.0917],\n",
      "          [0.0274, 0.0630, 0.0287, 0.0400, 0.6764, 0.1645],\n",
      "          [0.2068, 0.1731, 0.0261, 0.0934, 0.3718, 0.1288],\n",
      "          [0.2138, 0.1099, 0.0297, 0.0195, 0.5690, 0.0581],\n",
      "          [0.0273, 0.0599, 0.0637, 0.0282, 0.7776, 0.0432],\n",
      "          [0.0357, 0.0327, 0.3032, 0.0497, 0.5531, 0.0256]],\n",
      "\n",
      "         [[0.1339, 0.2101, 0.2779, 0.2221, 0.0760, 0.0800],\n",
      "          [0.0588, 0.6697, 0.1173, 0.0672, 0.0483, 0.0388],\n",
      "          [0.2984, 0.0762, 0.1408, 0.1376, 0.2703, 0.0767],\n",
      "          [0.0653, 0.2019, 0.1560, 0.1765, 0.0648, 0.3356],\n",
      "          [0.3018, 0.0610, 0.0622, 0.0864, 0.0197, 0.4689],\n",
      "          [0.0740, 0.0771, 0.1607, 0.0980, 0.0337, 0.5566]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 6, 6])\n",
      "old attention tensor([[[[0.0430, 0.2372, 0.0865, 0.5007, 0.1071, 0.0255],\n",
      "          [0.0382, 0.0328, 0.0635, 0.6804, 0.1185, 0.0666],\n",
      "          [0.1389, 0.0285, 0.0305, 0.1190, 0.0719, 0.6112],\n",
      "          [0.1197, 0.0707, 0.0242, 0.0955, 0.0968, 0.5930],\n",
      "          [0.0275, 0.0235, 0.0099, 0.0167, 0.0975, 0.8249],\n",
      "          [0.2192, 0.4206, 0.0488, 0.0368, 0.0963, 0.1784]],\n",
      "\n",
      "         [[0.0087, 0.0041, 0.1076, 0.8636, 0.0145, 0.0016],\n",
      "          [0.0407, 0.0604, 0.0720, 0.5687, 0.1841, 0.0741],\n",
      "          [0.0260, 0.0090, 0.6285, 0.3039, 0.0238, 0.0088],\n",
      "          [0.0772, 0.0725, 0.4109, 0.3534, 0.0607, 0.0253],\n",
      "          [0.0530, 0.0153, 0.2586, 0.6524, 0.0101, 0.0106],\n",
      "          [0.2004, 0.1202, 0.0344, 0.0754, 0.3915, 0.1781]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 6])\n",
      "old attention tensor([[[[0.2093, 0.5069, 0.0245, 0.0279, 0.2019, 0.0295]],\n",
      "\n",
      "         [[0.0929, 0.5894, 0.0411, 0.0511, 0.2040, 0.0214]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 6])\n",
      "old attention tensor([[[[0.1628, 0.6906, 0.0916, 0.0387, 0.0141, 0.0022]],\n",
      "\n",
      "         [[0.0216, 0.9516, 0.0049, 0.0040, 0.0126, 0.0052]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 6])\n",
      "old attention tensor([[[[0.0392, 0.6205, 0.1124, 0.0992, 0.1109, 0.0178]],\n",
      "\n",
      "         [[0.0429, 0.0736, 0.0622, 0.0692, 0.1044, 0.6477]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0548, 0.9452]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0098, 0.9902]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0548, 0.9452]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0098, 0.9902]]]])\n",
      "old attention torch.Size([1, 2, 2, 6])\n",
      "old attention tensor([[[[0.2093, 0.5069, 0.0245, 0.0279, 0.2019, 0.0295],\n",
      "          [0.0776, 0.0324, 0.2442, 0.0385, 0.1461, 0.4612]],\n",
      "\n",
      "         [[0.0929, 0.5894, 0.0411, 0.0511, 0.2040, 0.0214],\n",
      "          [0.1061, 0.0075, 0.6653, 0.0984, 0.0849, 0.0378]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0373, 0.9627]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.6240, 0.3760]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0373, 0.9627]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.6240, 0.3760]]]])\n",
      "old attention torch.Size([1, 2, 2, 6])\n",
      "old attention tensor([[[[0.1628, 0.6906, 0.0916, 0.0387, 0.0141, 0.0022],\n",
      "          [0.1852, 0.2582, 0.2113, 0.1570, 0.1125, 0.0758]],\n",
      "\n",
      "         [[0.0216, 0.9516, 0.0049, 0.0040, 0.0126, 0.0052],\n",
      "          [0.1028, 0.0998, 0.5694, 0.1513, 0.0583, 0.0185]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.5867, 0.4133]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.1382, 0.8618]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.5867, 0.4133]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.1382, 0.8618]]]])\n",
      "old attention torch.Size([1, 2, 2, 6])\n",
      "old attention tensor([[[[0.0392, 0.6205, 0.1124, 0.0992, 0.1109, 0.0178],\n",
      "          [0.0091, 0.3064, 0.1511, 0.4567, 0.0504, 0.0264]],\n",
      "\n",
      "         [[0.0429, 0.0736, 0.0622, 0.0692, 0.1044, 0.6477],\n",
      "          [0.0052, 0.0082, 0.0726, 0.0891, 0.3719, 0.4530]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.0548, 0.9452, 0.0000],\n",
      "          [0.0140, 0.1149, 0.8711]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.0098, 0.9902, 0.0000],\n",
      "          [0.0047, 0.0052, 0.9901]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 6])\n",
      "old attention tensor([[[[0.2441, 0.4305, 0.0296, 0.0571, 0.2115, 0.0272],\n",
      "          [0.0689, 0.0694, 0.0966, 0.0256, 0.3818, 0.3578],\n",
      "          [0.0243, 0.0651, 0.0611, 0.1558, 0.5727, 0.1210]],\n",
      "\n",
      "         [[0.0592, 0.4022, 0.0432, 0.0369, 0.3621, 0.0964],\n",
      "          [0.1200, 0.0555, 0.5551, 0.1530, 0.0876, 0.0287],\n",
      "          [0.1198, 0.2742, 0.0495, 0.2558, 0.1646, 0.1360]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.0480, 0.9520, 0.0000],\n",
      "          [0.0545, 0.2686, 0.6769]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.8717, 0.1283, 0.0000],\n",
      "          [0.5780, 0.0278, 0.3942]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 6])\n",
      "old attention tensor([[[[0.1573, 0.5812, 0.1311, 0.0999, 0.0237, 0.0068],\n",
      "          [0.1769, 0.3870, 0.1991, 0.1560, 0.0744, 0.0067],\n",
      "          [0.0440, 0.2261, 0.3689, 0.2515, 0.0662, 0.0433]],\n",
      "\n",
      "         [[0.0717, 0.8720, 0.0092, 0.0148, 0.0295, 0.0028],\n",
      "          [0.1978, 0.4714, 0.1451, 0.0849, 0.0726, 0.0282],\n",
      "          [0.2022, 0.3542, 0.0336, 0.0801, 0.2769, 0.0530]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.2619, 0.7381, 0.0000],\n",
      "          [0.2919, 0.5754, 0.1328]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.0909, 0.9091, 0.0000],\n",
      "          [0.0479, 0.2961, 0.6560]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 6])\n",
      "old attention tensor([[[[0.0144, 0.4255, 0.0713, 0.1177, 0.3547, 0.0163],\n",
      "          [0.0207, 0.1814, 0.0899, 0.2819, 0.3917, 0.0344],\n",
      "          [0.0224, 0.0783, 0.0841, 0.2382, 0.5517, 0.0252]],\n",
      "\n",
      "         [[0.0368, 0.0660, 0.1079, 0.1232, 0.1424, 0.5236],\n",
      "          [0.0164, 0.0148, 0.1253, 0.1667, 0.3199, 0.3569],\n",
      "          [0.0449, 0.0377, 0.1362, 0.2429, 0.1704, 0.3678]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0548, 0.9452, 0.0000, 0.0000],\n",
      "          [0.0140, 0.1149, 0.8711, 0.0000],\n",
      "          [0.0091, 0.0658, 0.5195, 0.4056]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0098, 0.9902, 0.0000, 0.0000],\n",
      "          [0.0047, 0.0052, 0.9901, 0.0000],\n",
      "          [0.0031, 0.0045, 0.5639, 0.4285]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 6])\n",
      "old attention tensor([[[[0.2161, 0.4382, 0.0239, 0.0639, 0.2338, 0.0241],\n",
      "          [0.0620, 0.0720, 0.0773, 0.0277, 0.4400, 0.3209],\n",
      "          [0.0227, 0.0692, 0.0472, 0.1697, 0.5904, 0.1008],\n",
      "          [0.0270, 0.0653, 0.0556, 0.1829, 0.5640, 0.1052]],\n",
      "\n",
      "         [[0.0446, 0.4669, 0.0325, 0.0335, 0.3056, 0.1170],\n",
      "          [0.1088, 0.0784, 0.5145, 0.1666, 0.0911, 0.0407],\n",
      "          [0.0891, 0.3324, 0.0381, 0.2233, 0.1414, 0.1757],\n",
      "          [0.1104, 0.2749, 0.0414, 0.2426, 0.1688, 0.1619]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0599, 0.9401, 0.0000, 0.0000],\n",
      "          [0.0877, 0.2282, 0.6841, 0.0000],\n",
      "          [0.0469, 0.1572, 0.3774, 0.4185]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.8816, 0.1184, 0.0000, 0.0000],\n",
      "          [0.5677, 0.0269, 0.4054, 0.0000],\n",
      "          [0.3850, 0.0193, 0.2986, 0.2970]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 6])\n",
      "old attention tensor([[[[0.1855, 0.4387, 0.1630, 0.1473, 0.0489, 0.0166],\n",
      "          [0.1690, 0.2868, 0.2147, 0.1979, 0.1221, 0.0095],\n",
      "          [0.0354, 0.1414, 0.3269, 0.3097, 0.1033, 0.0832],\n",
      "          [0.0375, 0.1046, 0.3283, 0.3587, 0.0886, 0.0822]],\n",
      "\n",
      "         [[0.1131, 0.7809, 0.0096, 0.0257, 0.0641, 0.0066],\n",
      "          [0.2532, 0.4053, 0.0999, 0.0875, 0.1117, 0.0425],\n",
      "          [0.2253, 0.1876, 0.0209, 0.0974, 0.3928, 0.0761],\n",
      "          [0.2097, 0.2127, 0.0196, 0.0709, 0.3917, 0.0953]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.2255, 0.7745, 0.0000, 0.0000],\n",
      "          [0.2768, 0.6555, 0.0677, 0.0000],\n",
      "          [0.3005, 0.5356, 0.0775, 0.0864]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0631, 0.9369, 0.0000, 0.0000],\n",
      "          [0.0689, 0.4321, 0.4990, 0.0000],\n",
      "          [0.0438, 0.2547, 0.3608, 0.3407]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 6])\n",
      "old attention tensor([[[[0.0267, 0.1234, 0.0428, 0.0573, 0.7004, 0.0493],\n",
      "          [0.0283, 0.0466, 0.0415, 0.1016, 0.7020, 0.0800],\n",
      "          [0.0354, 0.0289, 0.0442, 0.1000, 0.7400, 0.0514],\n",
      "          [0.0322, 0.0289, 0.0415, 0.0977, 0.7409, 0.0588]],\n",
      "\n",
      "         [[0.1514, 0.1568, 0.1433, 0.1992, 0.1267, 0.2226],\n",
      "          [0.0729, 0.0310, 0.1695, 0.2899, 0.2790, 0.1577],\n",
      "          [0.1592, 0.0880, 0.1686, 0.3214, 0.1265, 0.1363],\n",
      "          [0.1568, 0.0843, 0.1800, 0.3090, 0.1262, 0.1436]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0548, 0.9452, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0140, 0.1149, 0.8711, 0.0000, 0.0000],\n",
      "          [0.0091, 0.0658, 0.5195, 0.4056, 0.0000],\n",
      "          [0.7733, 0.0450, 0.0675, 0.0526, 0.0615]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0098, 0.9902, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0047, 0.0052, 0.9901, 0.0000, 0.0000],\n",
      "          [0.0031, 0.0045, 0.5639, 0.4285, 0.0000],\n",
      "          [0.0130, 0.0259, 0.0200, 0.0160, 0.9252]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 6])\n",
      "old attention tensor([[[[0.2307, 0.4889, 0.0229, 0.0706, 0.1686, 0.0183],\n",
      "          [0.0714, 0.0841, 0.0909, 0.0330, 0.3911, 0.3295],\n",
      "          [0.0241, 0.0809, 0.0535, 0.2373, 0.5122, 0.0919],\n",
      "          [0.0290, 0.0757, 0.0635, 0.2556, 0.4808, 0.0955],\n",
      "          [0.3577, 0.1924, 0.0522, 0.0545, 0.1759, 0.1673]],\n",
      "\n",
      "         [[0.0486, 0.4609, 0.0230, 0.0295, 0.3352, 0.1028],\n",
      "          [0.1354, 0.0764, 0.4741, 0.1758, 0.1023, 0.0360],\n",
      "          [0.1040, 0.3345, 0.0255, 0.2233, 0.1543, 0.1585],\n",
      "          [0.1304, 0.2700, 0.0278, 0.2421, 0.1857, 0.1440],\n",
      "          [0.0689, 0.2348, 0.2037, 0.2848, 0.0918, 0.1161]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0221, 0.9779, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0436, 0.2614, 0.6951, 0.0000, 0.0000],\n",
      "          [0.0222, 0.1817, 0.3670, 0.4292, 0.0000],\n",
      "          [0.0192, 0.1794, 0.3050, 0.2891, 0.2074]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.9357, 0.0643, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5717, 0.0127, 0.4156, 0.0000, 0.0000],\n",
      "          [0.3837, 0.0090, 0.3028, 0.3045, 0.0000],\n",
      "          [0.0364, 0.2896, 0.2801, 0.2871, 0.1068]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 6])\n",
      "old attention tensor([[[[0.1753, 0.5606, 0.1158, 0.0949, 0.0424, 0.0109],\n",
      "          [0.1810, 0.3603, 0.1737, 0.1494, 0.1281, 0.0075],\n",
      "          [0.0395, 0.1813, 0.3363, 0.2631, 0.1103, 0.0695],\n",
      "          [0.0432, 0.1320, 0.3380, 0.3199, 0.0953, 0.0715],\n",
      "          [0.2865, 0.1684, 0.2264, 0.2784, 0.0340, 0.0062]],\n",
      "\n",
      "         [[0.1082, 0.7999, 0.0130, 0.0310, 0.0441, 0.0038],\n",
      "          [0.2682, 0.3173, 0.1583, 0.1280, 0.0966, 0.0315],\n",
      "          [0.2304, 0.1851, 0.0265, 0.1150, 0.3845, 0.0584],\n",
      "          [0.2172, 0.2136, 0.0260, 0.0823, 0.3834, 0.0775],\n",
      "          [0.3372, 0.3154, 0.0745, 0.1976, 0.0554, 0.0199]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.1646, 0.8354, 0.0000, 0.0000, 0.0000],\n",
      "          [0.2131, 0.7151, 0.0718, 0.0000, 0.0000],\n",
      "          [0.2346, 0.5876, 0.0840, 0.0938, 0.0000],\n",
      "          [0.0598, 0.3233, 0.1593, 0.1881, 0.2695]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0566, 0.9434, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0462, 0.3222, 0.6316, 0.0000, 0.0000],\n",
      "          [0.0255, 0.1691, 0.4170, 0.3884, 0.0000],\n",
      "          [0.0298, 0.0412, 0.4858, 0.4137, 0.0295]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 6])\n",
      "old attention tensor([[[[0.0430, 0.2492, 0.0709, 0.0776, 0.4640, 0.0953],\n",
      "          [0.0363, 0.0540, 0.0621, 0.1379, 0.5530, 0.1567],\n",
      "          [0.0531, 0.0303, 0.0706, 0.1460, 0.6209, 0.0791],\n",
      "          [0.0459, 0.0284, 0.0648, 0.1371, 0.6243, 0.0994],\n",
      "          [0.0256, 0.1037, 0.0346, 0.0444, 0.4402, 0.3514]],\n",
      "\n",
      "         [[0.1628, 0.2978, 0.1140, 0.1293, 0.1111, 0.1851],\n",
      "          [0.0827, 0.0484, 0.1837, 0.2301, 0.3303, 0.1248],\n",
      "          [0.1949, 0.1565, 0.1392, 0.2703, 0.1184, 0.1208],\n",
      "          [0.1942, 0.1495, 0.1516, 0.2570, 0.1190, 0.1287],\n",
      "          [0.0457, 0.0187, 0.6325, 0.1739, 0.0877, 0.0414]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 6, 6])\n",
      "old attention tensor([[[[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [5.4816e-02, 9.4518e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [1.4026e-02, 1.1485e-01, 8.7112e-01, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [9.1211e-03, 6.5821e-02, 5.1947e-01, 4.0559e-01, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [7.7334e-01, 4.5028e-02, 6.7516e-02, 5.2642e-02, 6.1479e-02,\n",
      "           0.0000e+00],\n",
      "          [1.5154e-02, 2.6624e-02, 1.4953e-02, 1.2274e-02, 9.3022e-03,\n",
      "           9.2169e-01]],\n",
      "\n",
      "         [[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [9.8231e-03, 9.9018e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [4.7095e-03, 5.2001e-03, 9.9009e-01, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [3.1396e-03, 4.4834e-03, 5.6387e-01, 4.2851e-01, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [1.2956e-02, 2.5899e-02, 1.9980e-02, 1.5986e-02, 9.2518e-01,\n",
      "           0.0000e+00],\n",
      "          [9.2492e-03, 7.7113e-04, 2.9420e-03, 3.0521e-03, 9.8164e-01,\n",
      "           2.3438e-03]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 6, 6])\n",
      "old attention tensor([[[[0.2194, 0.5294, 0.0188, 0.0717, 0.1477, 0.0130],\n",
      "          [0.0770, 0.1028, 0.0877, 0.0379, 0.4082, 0.2863],\n",
      "          [0.0255, 0.0976, 0.0492, 0.2717, 0.4839, 0.0720],\n",
      "          [0.0303, 0.0908, 0.0577, 0.2922, 0.4549, 0.0741],\n",
      "          [0.3666, 0.2201, 0.0482, 0.0604, 0.1682, 0.1365],\n",
      "          [0.0572, 0.1015, 0.2542, 0.3972, 0.1225, 0.0674]],\n",
      "\n",
      "         [[0.0369, 0.5093, 0.0182, 0.0245, 0.2932, 0.1178],\n",
      "          [0.1207, 0.0952, 0.4615, 0.1743, 0.1016, 0.0465],\n",
      "          [0.0803, 0.3791, 0.0211, 0.1905, 0.1350, 0.1940],\n",
      "          [0.1026, 0.3154, 0.0233, 0.2118, 0.1660, 0.1809],\n",
      "          [0.0583, 0.2711, 0.1805, 0.2624, 0.0860, 0.1417],\n",
      "          [0.0688, 0.5581, 0.0225, 0.1076, 0.0982, 0.1448]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 6, 6])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0253, 0.9747, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0589, 0.2156, 0.7254, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0300, 0.1497, 0.3832, 0.4370, 0.0000, 0.0000],\n",
      "          [0.0220, 0.1559, 0.3178, 0.2919, 0.2124, 0.0000],\n",
      "          [0.1492, 0.0930, 0.1368, 0.1672, 0.1211, 0.3327]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.9565, 0.0435, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5997, 0.0098, 0.3905, 0.0000, 0.0000, 0.0000],\n",
      "          [0.3998, 0.0071, 0.3017, 0.2915, 0.0000, 0.0000],\n",
      "          [0.0375, 0.2838, 0.2838, 0.2973, 0.0976, 0.0000],\n",
      "          [0.0685, 0.0131, 0.1162, 0.1181, 0.2220, 0.4621]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 6, 6])\n",
      "old attention tensor([[[[0.1831, 0.4664, 0.1218, 0.1377, 0.0658, 0.0252],\n",
      "          [0.1769, 0.2663, 0.1728, 0.2039, 0.1690, 0.0111],\n",
      "          [0.0335, 0.1191, 0.2840, 0.3299, 0.1247, 0.1088],\n",
      "          [0.0349, 0.0834, 0.2791, 0.3869, 0.1056, 0.1102],\n",
      "          [0.2548, 0.1247, 0.2115, 0.3637, 0.0367, 0.0085],\n",
      "          [0.0450, 0.0440, 0.2284, 0.4526, 0.0818, 0.1483]],\n",
      "\n",
      "         [[0.1721, 0.6345, 0.0216, 0.0735, 0.0913, 0.0071],\n",
      "          [0.3100, 0.1630, 0.1569, 0.1976, 0.1381, 0.0345],\n",
      "          [0.2187, 0.0828, 0.0247, 0.1542, 0.4556, 0.0640],\n",
      "          [0.2075, 0.0951, 0.0245, 0.1128, 0.4734, 0.0867],\n",
      "          [0.3681, 0.1996, 0.0640, 0.2724, 0.0732, 0.0227],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          [0.2806, 0.0575, 0.0537, 0.2926, 0.2239, 0.0917]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 6, 6])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.1923, 0.8077, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.2930, 0.6224, 0.0846, 0.0000, 0.0000, 0.0000],\n",
      "          [0.3030, 0.5005, 0.0960, 0.1005, 0.0000, 0.0000],\n",
      "          [0.0706, 0.3752, 0.1433, 0.1679, 0.2430, 0.0000],\n",
      "          [0.1428, 0.1740, 0.0894, 0.0903, 0.1166, 0.3868]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0372, 0.9628, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0631, 0.4856, 0.4513, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0402, 0.2918, 0.3431, 0.3249, 0.0000, 0.0000],\n",
      "          [0.0366, 0.0671, 0.4551, 0.4026, 0.0385, 0.0000],\n",
      "          [0.0169, 0.1749, 0.3256, 0.2906, 0.0234, 0.1686]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 6, 6])\n",
      "old attention tensor([[[[0.0918, 0.0840, 0.0608, 0.0445, 0.4571, 0.2618],\n",
      "          [0.0690, 0.0149, 0.0426, 0.0565, 0.4403, 0.3768],\n",
      "          [0.1092, 0.0149, 0.0617, 0.0769, 0.5164, 0.2209],\n",
      "          [0.0961, 0.0138, 0.0560, 0.0705, 0.4946, 0.2691],\n",
      "          [0.0410, 0.0245, 0.0215, 0.0172, 0.2953, 0.6005],\n",
      "          [0.0820, 0.0147, 0.0286, 0.0370, 0.1914, 0.6463]],\n",
      "\n",
      "         [[0.3562, 0.4003, 0.0669, 0.0793, 0.0484, 0.0490],\n",
      "          [0.3008, 0.0824, 0.1721, 0.2305, 0.1693, 0.0448],\n",
      "          [0.4377, 0.2262, 0.0948, 0.1588, 0.0494, 0.0332],\n",
      "          [0.4385, 0.2273, 0.1002, 0.1510, 0.0489, 0.0341],\n",
      "          [0.1880, 0.0456, 0.5289, 0.1677, 0.0509, 0.0190],\n",
      "          [0.3075, 0.4155, 0.1163, 0.0957, 0.0389, 0.0262]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "predicted trg = ['wir', 'konnen', 'konnen', 'wasser', 'trinken', '<eos>']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_count 1    self.capacity  20\n",
      "0  ------------------------------------------------\n",
      "DecoderLayer@trg4\n",
      "[1, 1, 64]\n",
      "src = ['we', 'can', 'drink', 'beer']\n",
      "old attention torch.Size([1, 2, 6, 6])\n",
      "old attention tensor([[[[2.4068e-03, 2.6498e-03, 7.4328e-01, 5.3415e-02, 1.9155e-01,\n",
      "           6.7000e-03],\n",
      "          [5.7912e-03, 9.0421e-03, 3.1310e-03, 9.3384e-03, 1.0287e-01,\n",
      "           8.6983e-01],\n",
      "          [4.3055e-02, 5.1143e-01, 5.3180e-02, 1.5424e-01, 1.5598e-01,\n",
      "           8.2120e-02],\n",
      "          [2.2220e-03, 9.8654e-02, 1.7837e-02, 5.1246e-03, 4.8795e-03,\n",
      "           8.7128e-01],\n",
      "          [2.1004e-01, 2.6172e-02, 3.3520e-01, 9.3615e-02, 1.7190e-01,\n",
      "           1.6307e-01],\n",
      "          [9.9832e-03, 2.1982e-03, 4.6194e-01, 3.5895e-01, 1.6065e-01,\n",
      "           6.2816e-03]],\n",
      "\n",
      "         [[3.7307e-02, 5.9895e-01, 1.9851e-01, 1.2043e-01, 7.5795e-03,\n",
      "           3.7227e-02],\n",
      "          [8.9374e-03, 1.3540e-03, 4.7211e-01, 4.8952e-01, 1.9217e-02,\n",
      "           8.8625e-03],\n",
      "          [6.7040e-03, 4.1323e-03, 9.3698e-01, 4.5438e-02, 6.4828e-03,\n",
      "           2.6478e-04],\n",
      "          [4.9195e-01, 7.0094e-02, 2.7616e-01, 4.1238e-02, 2.4002e-02,\n",
      "           9.6557e-02],\n",
      "          [6.6602e-01, 1.0528e-01, 3.1539e-02, 1.5862e-01, 3.7184e-02,\n",
      "           1.3560e-03],\n",
      "          [4.7247e-02, 4.3476e-02, 4.7658e-02, 3.1188e-02, 6.0878e-01,\n",
      "           2.2165e-01]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 6, 6])\n",
      "old attention tensor([[[[0.0955, 0.0501, 0.4487, 0.1723, 0.1236, 0.1099],\n",
      "          [0.0891, 0.1712, 0.0759, 0.1264, 0.0395, 0.4979],\n",
      "          [0.2205, 0.1607, 0.0258, 0.0948, 0.3773, 0.1208],\n",
      "          [0.4948, 0.2187, 0.0673, 0.0420, 0.0542, 0.1230],\n",
      "          [0.2737, 0.1459, 0.0632, 0.2452, 0.1260, 0.1460],\n",
      "          [0.0752, 0.0562, 0.6538, 0.1109, 0.0524, 0.0515]],\n",
      "\n",
      "         [[0.1187, 0.2266, 0.2818, 0.2032, 0.0952, 0.0746],\n",
      "          [0.0536, 0.6403, 0.1177, 0.0672, 0.0833, 0.0379],\n",
      "          [0.3281, 0.0879, 0.1696, 0.1483, 0.1710, 0.0953],\n",
      "          [0.0512, 0.1880, 0.1233, 0.1503, 0.2196, 0.2676],\n",
      "          [0.1187, 0.0848, 0.2839, 0.2299, 0.1177, 0.1650],\n",
      "          [0.0481, 0.0727, 0.1205, 0.0867, 0.2567, 0.4153]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 6, 6])\n",
      "old attention tensor([[[[0.0512, 0.2983, 0.0908, 0.5046, 0.0168, 0.0384],\n",
      "          [0.0394, 0.0313, 0.0659, 0.7626, 0.0268, 0.0740],\n",
      "          [0.1482, 0.0295, 0.0286, 0.1504, 0.0817, 0.5617],\n",
      "          [0.1135, 0.0608, 0.0222, 0.1059, 0.0663, 0.6313],\n",
      "          [0.3832, 0.0737, 0.0187, 0.0789, 0.0146, 0.4308],\n",
      "          [0.1905, 0.3880, 0.0431, 0.0385, 0.1451, 0.1947]],\n",
      "\n",
      "         [[0.0088, 0.0037, 0.1125, 0.7715, 0.1021, 0.0014],\n",
      "          [0.0443, 0.0511, 0.0736, 0.5339, 0.2347, 0.0624],\n",
      "          [0.0258, 0.0074, 0.5566, 0.2967, 0.1074, 0.0061],\n",
      "          [0.0915, 0.0767, 0.4015, 0.3216, 0.0808, 0.0279],\n",
      "          [0.0620, 0.0282, 0.3560, 0.3902, 0.1565, 0.0071],\n",
      "          [0.3294, 0.1851, 0.0539, 0.1100, 0.0713, 0.2503]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 6])\n",
      "old attention tensor([[[[0.2618, 0.5827, 0.0271, 0.0323, 0.0639, 0.0322]],\n",
      "\n",
      "         [[0.1171, 0.7139, 0.0533, 0.0633, 0.0211, 0.0313]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 6])\n",
      "old attention tensor([[[[0.1540, 0.6886, 0.0966, 0.0408, 0.0178, 0.0022]],\n",
      "\n",
      "         [[0.0325, 0.9415, 0.0089, 0.0069, 0.0043, 0.0059]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 6])\n",
      "old attention tensor([[[[0.0560, 0.5844, 0.1546, 0.1201, 0.0592, 0.0258]],\n",
      "\n",
      "         [[0.0588, 0.1048, 0.0590, 0.0517, 0.1143, 0.6115]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0548, 0.9452]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0098, 0.9902]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0548, 0.9452]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0098, 0.9902]]]])\n",
      "old attention torch.Size([1, 2, 2, 6])\n",
      "old attention tensor([[[[0.2618, 0.5827, 0.0271, 0.0323, 0.0639, 0.0322],\n",
      "          [0.0729, 0.0330, 0.2299, 0.0457, 0.1452, 0.4733]],\n",
      "\n",
      "         [[0.1171, 0.7139, 0.0533, 0.0633, 0.0211, 0.0313],\n",
      "          [0.1205, 0.0088, 0.6474, 0.1005, 0.0685, 0.0543]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0333, 0.9667]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.5906, 0.4094]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0333, 0.9667]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.5906, 0.4094]]]])\n",
      "old attention torch.Size([1, 2, 2, 6])\n",
      "old attention tensor([[[[0.1540, 0.6886, 0.0966, 0.0408, 0.0178, 0.0022],\n",
      "          [0.1706, 0.2161, 0.1976, 0.1762, 0.1692, 0.0702]],\n",
      "\n",
      "         [[0.0325, 0.9415, 0.0089, 0.0069, 0.0043, 0.0059],\n",
      "          [0.0979, 0.0591, 0.5515, 0.1580, 0.1206, 0.0129]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.5705, 0.4295]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.1157, 0.8843]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.5705, 0.4295]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.1157, 0.8843]]]])\n",
      "old attention torch.Size([1, 2, 2, 6])\n",
      "old attention tensor([[[[0.0560, 0.5844, 0.1546, 0.1201, 0.0592, 0.0258],\n",
      "          [0.0102, 0.2340, 0.1545, 0.3807, 0.1867, 0.0340]],\n",
      "\n",
      "         [[0.0588, 0.1048, 0.0590, 0.0517, 0.1143, 0.6115],\n",
      "          [0.0085, 0.0192, 0.0908, 0.1107, 0.1486, 0.6222]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.0548, 0.9452, 0.0000],\n",
      "          [0.0140, 0.1149, 0.8711]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.0098, 0.9902, 0.0000],\n",
      "          [0.0047, 0.0052, 0.9901]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 6])\n",
      "old attention tensor([[[[0.3047, 0.4791, 0.0338, 0.0669, 0.0868, 0.0288],\n",
      "          [0.0874, 0.0897, 0.1308, 0.0434, 0.1371, 0.5115],\n",
      "          [0.0482, 0.1177, 0.1179, 0.3176, 0.1648, 0.2337]],\n",
      "\n",
      "         [[0.0855, 0.5843, 0.0681, 0.0567, 0.0377, 0.1676],\n",
      "          [0.1380, 0.0613, 0.5591, 0.1558, 0.0411, 0.0446],\n",
      "          [0.1220, 0.3092, 0.0551, 0.2746, 0.0882, 0.1508]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.0478, 0.9522, 0.0000],\n",
      "          [0.0447, 0.2940, 0.6613]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.8375, 0.1625, 0.0000],\n",
      "          [0.5042, 0.0391, 0.4566]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 6])\n",
      "old attention tensor([[[[0.1513, 0.5327, 0.1454, 0.1053, 0.0591, 0.0062],\n",
      "          [0.1916, 0.3583, 0.2096, 0.1843, 0.0492, 0.0071],\n",
      "          [0.0476, 0.2128, 0.3688, 0.2716, 0.0564, 0.0428]],\n",
      "\n",
      "         [[0.1378, 0.7674, 0.0187, 0.0321, 0.0407, 0.0033],\n",
      "          [0.2086, 0.2739, 0.1876, 0.0925, 0.2173, 0.0201],\n",
      "          [0.2570, 0.2524, 0.0501, 0.1105, 0.2899, 0.0399]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.2645, 0.7355, 0.0000],\n",
      "          [0.2622, 0.5462, 0.1916]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.0676, 0.9324, 0.0000],\n",
      "          [0.0389, 0.3003, 0.6608]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 6])\n",
      "old attention tensor([[[[0.0334, 0.4544, 0.1347, 0.1783, 0.1562, 0.0431],\n",
      "          [0.0283, 0.1411, 0.1082, 0.2803, 0.3918, 0.0502],\n",
      "          [0.0257, 0.0478, 0.0779, 0.1842, 0.6344, 0.0301]],\n",
      "\n",
      "         [[0.0569, 0.1374, 0.1000, 0.0996, 0.0954, 0.5107],\n",
      "          [0.0285, 0.0368, 0.1377, 0.1635, 0.2286, 0.4049],\n",
      "          [0.0624, 0.0760, 0.1231, 0.2038, 0.1736, 0.3611]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0548, 0.9452, 0.0000, 0.0000],\n",
      "          [0.0140, 0.1149, 0.8711, 0.0000],\n",
      "          [0.0148, 0.0168, 0.0132, 0.9553]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0098, 0.9902, 0.0000, 0.0000],\n",
      "          [0.0047, 0.0052, 0.9901, 0.0000],\n",
      "          [0.6756, 0.0585, 0.1188, 0.1471]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 6])\n",
      "old attention tensor([[[[0.2840, 0.5426, 0.0236, 0.0660, 0.0682, 0.0155],\n",
      "          [0.1014, 0.1231, 0.1310, 0.0541, 0.1477, 0.4427],\n",
      "          [0.0493, 0.1512, 0.0995, 0.3965, 0.1529, 0.1506],\n",
      "          [0.0667, 0.1100, 0.2996, 0.3529, 0.0880, 0.0830]],\n",
      "\n",
      "         [[0.0506, 0.6520, 0.0401, 0.0377, 0.0354, 0.1843],\n",
      "          [0.1173, 0.0836, 0.5319, 0.1532, 0.0521, 0.0618],\n",
      "          [0.0783, 0.3827, 0.0349, 0.2101, 0.1003, 0.1936],\n",
      "          [0.0836, 0.4385, 0.0530, 0.1398, 0.1283, 0.1568]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0500, 0.9500, 0.0000, 0.0000],\n",
      "          [0.0547, 0.2106, 0.7347, 0.0000],\n",
      "          [0.1526, 0.1084, 0.1915, 0.5475]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.9148, 0.0852, 0.0000, 0.0000],\n",
      "          [0.5401, 0.0211, 0.4388, 0.0000],\n",
      "          [0.1104, 0.0354, 0.1978, 0.6564]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 6])\n",
      "old attention tensor([[[[0.1664, 0.4382, 0.1474, 0.1548, 0.0748, 0.0183],\n",
      "          [0.1982, 0.2609, 0.2100, 0.2659, 0.0542, 0.0108],\n",
      "          [0.0356, 0.1218, 0.3173, 0.3774, 0.0595, 0.0884],\n",
      "          [0.0206, 0.0176, 0.1334, 0.2926, 0.4840, 0.0517]],\n",
      "\n",
      "         [[0.2381, 0.5540, 0.0235, 0.0847, 0.0944, 0.0053],\n",
      "          [0.2526, 0.1156, 0.1502, 0.1345, 0.3286, 0.0185],\n",
      "          [0.2579, 0.0849, 0.0333, 0.1478, 0.4281, 0.0481],\n",
      "          [0.1907, 0.0307, 0.0314, 0.1720, 0.5287, 0.0464]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.2534, 0.7466, 0.0000, 0.0000],\n",
      "          [0.3469, 0.5317, 0.1214, 0.0000],\n",
      "          [0.2228, 0.1775, 0.1466, 0.4531]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0214, 0.9786, 0.0000, 0.0000],\n",
      "          [0.0385, 0.4790, 0.4825, 0.0000],\n",
      "          [0.0112, 0.2588, 0.4902, 0.2397]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 6])\n",
      "old attention tensor([[[[0.1362, 0.1444, 0.1179, 0.0839, 0.1687, 0.3488],\n",
      "          [0.0832, 0.0271, 0.0714, 0.0995, 0.3759, 0.3428],\n",
      "          [0.0845, 0.0167, 0.0590, 0.0797, 0.5974, 0.1626],\n",
      "          [0.0842, 0.0222, 0.0366, 0.0512, 0.2762, 0.5297]],\n",
      "\n",
      "         [[0.3339, 0.3892, 0.0713, 0.0657, 0.0525, 0.0874],\n",
      "          [0.2221, 0.0922, 0.1567, 0.1884, 0.2477, 0.0929],\n",
      "          [0.3458, 0.2137, 0.1116, 0.1586, 0.1065, 0.0638],\n",
      "          [0.2836, 0.3927, 0.1150, 0.0939, 0.0582, 0.0566]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "predicted trg = ['wir', 'konnen', 'trinken', '<eos>']\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4EAAAExCAYAAADC/6eQAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAAmbUlEQVR4nO3deVTU9f7H8deAAyqYCIoSLpGlpmi53J9ldrXUSlu82aZtmldLq9viycqKvJm55JZl7qZIKEYqhoaZS5q45OB1wUzTSM0Nl1yA2L+/PzrMzavmBnyH+Twf53QO4DDf99vg+/I1q8OyLEsAAAAAACP42D0AAAAAAKD0UAIBAAAAwCCUQAAAAAAwCCUQAAAAAAxCCQQAAAAAg1ACAQAAAMAglEAAAAAAMAglEAAAAAAMQgkEAJSYwsLCMz63LMumSQAA8Cx2ZiQlsBQV/Y/Oz8+3eRIAKB0+Pj7KyMjQ1q1bJUkOh8PmieCpyEgAprEzI8uV2pGg7OxsnThxQp9++qk6deqkZs2a2T0SAJQYl8ulEydOaPr06fLx8VFUVJTq1atn91jwUGQkAJPYnZGUwFISHx+vXbt26eDBg1qyZIlCQkIIOABeacOGDVq3bp1Wr16tjh07qqCgQKGhoRRAnBcZCcAUnpKRlMAStm7dOq1cuVLff/+9Xn31VR0+fFhXXXWVunfvbvdoAFAidu7cqZMnT2rEiBGqXbu28vPz1ahRI0l/POTPx4dnIuAPZCQA03hKRlICS1i9evXk5+enXr16KSQkRImJibrqqqtUrlw5/jEEr1T0pOaix7Xn5+erXDmzTjWWZRn93LfHH3/c/fGGDRuUlJSktm3bShLnPJyBjIRJyMc/kJGekZGcXUtQWlqasrOz1axZM4WEhCgtLU1TpkxRq1at5OfnR7jBK2VlZblP7rGxsZo4caJRrwj553A7fPiwzdOUrrlz52rcuHFatmyZJCkzM1MJCQnq2rWrrrvuOpung6chI2Ea0/NRIiM9KSM5w5aQmJgYvfPOOxo3bpz7h/zIkSO644471Lp1a+N+6WGGtLQ09evXz/0qV0ePHlVERIQcDocKCgoknf1yyN6mKNzi4uL06quvKjc31+aJSseMGTOUkJCg6tWrKzw8XL///rsqVqyom2++WaGhoXaPBw9DRsI05OMfyEjPyUjz7oMuBXPnzlVSUpLGjRun9PR07d+/X6tWrVK7du30+++/S+Jl0uGdcnNzVbNmTU2cOFGvvPKKypcvr7S0NGVlZalixYqSzHg44IIFCzRnzhyNGDFCfn5+Xv/Ql4MHD2rlypWKiYnRxo0btWLFCi1dulRBQUGaOnWqV++OS0dGwkTk43+RkZ6RkZTAEnD06FF17dpVS5Ys0ebNm3XkyBGtXr1aeXl5euyxx+weDyh2RSfw+vXrq1u3boqPj9eHH36o3bt3KyQkRHPnzlWzZs0UEBCgv//972rfvr3dIxer/w2w3Nxcbd++Xdu2bdN1113n9QFnWZa2bdumZ555RsePH1fbtm3Vr18/ff755zp06JDCwsK8/u8AF4+MhElMz0eJjPTUjKQEloCQkBDFxcUpJydHzz33nNq1a6cvvvhCx48f9/ofdJjnzz/Tp06dUkREhHr27Kno6Ght2LBBzz77rCIiIpSWlqZvv/1W9evXt3ni4vXn/ffv369KlSqpc+fO8vX1VVRUlIKCgtSmTRuvfJGLH374Qf7+/qpWrZpmzpypLVu26JZbblGtWrW0dOlS7du3T+XLl5fEPTv4LzISpjA9HyUy0pMz0mHxwPtiMX/+fKWlpSk9PV0vvPCCgoODVaFCBR09elSrVq1STEyMRo0apbp169o9KkrB4sWLdeTIETVs2FCNGzeWn5+f3SOViD+f3D/99FOtWLFCp06d0tixY1WhQgV98sknOnDggPr37++V4fZn06dP1/r16yVJoaGhev7557V06VJ99NFHev/9973u1t3o6GglJSWpcuXKOnDggJ5++ml16dJFAwYMkK+vrzZu3KixY8fq+uuvt3tUeAAyEkXIR/PyUSIjPTEjKYHFYMaMGUpKStLjjz+uNWvWaPXq1Ro9erROnDihmTNnqqCgQIMGDTLqH0Mm35obGxur2bNnKzQ0VE6nU/fcc4/uvvturw06SUpJSdGYMWP05ptvKi4uTl9//bVmzZqlwMBAffLJJ8rIyNCQIUO89hX/4uPjtWjRIs2YMUO9e/dWaGioBgwYID8/P82ePVvTp0/XV199pQoVKnjF78XSpUs1fvx4xcTEKCcnR6mpqXr77bc1dOhQ+fj46Pjx42rcuLFq165t96jwAGTk2UzNSPLRvHyUyEiPzUgLV+Tw4cNWjx49rN9++839tbFjx1odOnSwLMuyMjIyrMzMTJumQ2nbvHmz9dJLL1kFBQWWZVnWxx9/bPXr189KTEy0cnJybJ6u+OzevdtKS0uzLMuyPv/8c6tbt27WmjVr3H8+ZMgQq1WrVtaOHTusQ4cOWUeOHLFp0tLx4YcfWtu3b7emT59u9ejRw8rIyLDeeusta9GiRZZlWWecH7zBjBkzrKFDh1qWZVm5ublWYWGhFRUVZU2ZMsXmyeBpyEgUIR//YFo+WhYZ6akZ6Z03OZQiy7KUnp6utLQ099e6d++uOnXqKCMjQwEBAe5XfTLB/PnzNWrUKI0ZM0Zr1661e5xStWfPHo0dO1Z79+7Vzz//LEl65plnFBERoYULF7rfF6asO3HihBISEhQUFKT8/Hw1btxYmzZtUlJSkvsyAwYM0B133KG+ffuqSpUqqlq1qo0TFy/rfx48YVmWDh06pP79+2v79u2aNGmSAgICdPToUfdlKleuXNpjlqjAwEAdPXpUp06dktPplMPhkJ+fn3JyciSd/XcEc5GRZzI1I8lHM/JRIiOlspORlMDLtGXLFu3fv19BQUG69dZb9f3332v37t2SpOXLl+vUqVNGvN/Ln0VHR2vu3Llq3ry5vv76ay1ZssSY93/Jzc1VnTp11KdPHwUHB2vp0qXau3ev/Pz89Mwzz6hp06Zq1qyZ3WNeMcuyFBQUpH79+unAgQMaOnSoqlevrnnz5mnevHmaPHmy+7Lvvfee5syZ41UP87H+9BAul8ul7du3a8+ePXruuee0Z88eNWrUSJZlKSEhQWlpaWrSpIkk73hRlMTERMXHxys2NlY33nijfv75Z02bNk2LFy/WggULtHr1anXq1EmSd+yLK0NGns3UjCQfzchHiYwsaxnJcwIvw4wZM7R48WKFh4fr3Xff1YYNG7R8+XJt27ZNkZGR2rBhgz766COjnt+wbds2TZs2TSNGjNCcOXOUnJysYcOGadasWbrnnnsUHh7uMT/0xS06OlopKSmqWrWqXnnlFaWmpio2NlaNGzfWnXfeqYiICLtHLDYFBQXy9fXV119/rU2bNmn//v2qWbOm+vTpo3379umJJ57Q008/rRdffFGS9z7vZcaMGVq2bJkaNmyoxYsXa9KkSTpy5IgGDhyo6667TpmZmfr3v//tNeeAGTNmaMmSJerbt6969+6t8ePHKzw8XDExMcrMzFRBQYFeeOEF1atXz+5R4QHIyLOZmpHko3n5KJGRZSUjKYGXoKCgQN98841iY2MVExOjTZs2KTs7W4cPH5bT6VSVKlV08uRJRUZGqmbNmnaPW2pcLpc2bdqkU6dO6ZdfflFGRoamTJmigwcPql+/foqOjlaFChXsHrNEfPbZZ0pMTFS3bt0UHR2tOnXq6N1339X27ds1ceJE/f3vf9eTTz6pcuXKlemT/fbt21W9enUFBwfrq6++0rRp0zR37lxt2rRJM2fOdL/SV1pamvr06aNFixapSpUqdo9dIpYuXaqYmBhFR0fr/fff17Fjx/Tmm28qPz9fV111lfLz81VYWKigoCC7R71iOTk52r9/vwYPHqwpU6bos88+07p16/TOO+9o06ZN6tixoySd8WbHMBcZeW6mZiT5aF4+SmRkWcpI3ifwIqWkpKh8+fI6fPiwrr/+es2dO1fJyck6cuSICgsL1aFDB/fdvKYouhVr27ZtiouL04033qjjx49r+PDh8vX11ZYtW1SuXDnl5uZ6ZcDt3LlTS5cu1Zw5c+RyuVSnTh1VqFBBgwYN0ttvv60XX3xRV199tZxOp92jXpHTp09r5syZOnbsmB555BElJia6b7276aablJOTo/j4eI0YMUKvvfaavv32W696iMv/vndRTk6O2rVrp2nTpmnXrl2aMGGCZs+erb1792rgwIE2Tlq8Nm7cKMuyFBAQoEqVKmn8+PHasmWLxo8fr/379+ujjz7SHXfcIX9/f48MN5QuMvJsJmck+WhGPkpkZFnOSErgRUpKSlJERISuvfZarVq1Sjt37lSvXr3Utm1bTZs2TXv27HE/0bMs36J1Kb7//nu1bNlS3bt316FDh7Rp0ybl5ORo+PDhkqS0tDSNHDnS657wK0m//PKLsrKylJeXpx9++EHfffedunXrpn379mn06NHq27evYmNj5evra/eoV6xSpUrq1auXpk6dqpiYGNWoUUM5OTlatGiR7rnnHrVs2VJ5eXlKSkpSTk6OAgMD7R65WBWF2/bt21WxYkUdP35cy5Ytk9Pp1OTJk+V0OrV//373G756i6+++koRERHq3Lmzjh07pl27dikhIUFOp1PJycm6+uqrvfblzHHpyMizmZqR5KM5+SiRkWU5IymBF2HlypVau3at+vbtq5CQELVs2VJ+fn5KTk7Wl19+qYULF2rkyJHGBJsk7du3T927d1fbtm3VuXNntWjRQnXr1lXt2rV1+vRpnT59Wi1atPDKh/zExsYqLi5ODRo00OOPP66srCz9+uuvatmypQ4cOKDOnTvrqaee8oqAK7Jx40adPn1aJ0+elMPhUEhIiFJTU+V0OnXnnXeqdevWat68uVfdmp2SkqL09HR17NjR/f+8Xr16+uabb1SlShU9/PDDWrRokbKzs5WcnKxPPvnE7pGLTdE575///KcCAwN17733av369erTp4+aNm2qb775RiNHjizzt+KjeJCRZzM1I8lHM/JRIiO9ISMpgX+h6C7uo0ePqmfPngoJCdHmzZuVkpKicuXKKSUlRRkZGRo+fLjq1q1r97ilqlq1anrwwQe1d+9eHT58WF988YWys7P17LPP6uGHH7Z7vBJT9PCW8ePHKyAgQMHBwfrkk090+vRpTZo0SQsXLtSoUaMUFhZm96jFZsGCBZo5c6Y+/vhjbdu2Tbt379a6devkdDq1evVq+fr6ql27dl51K59lWdqxY4emTJmiH3/8UXv37tXEiRNVo0YNffbZZxo6dKi2b9+u9PR0ZWZm6qOPPtK1115r99hX7H/PeWFhYdqxY4eOHj2qTp06KTU1VZUrV9bo0aONO+fhbGTk+ZmYkeSjGfkokZHekpGUwL/g4+OjEydOKDExUVWrVtXvv/+umJgYPfTQQ7rhhhv01FNPeeyTPUvKwoULVVBQoJtvvlm9e/dWr1691KhRIwUHB+u9997TvHnz1LFjRwUEBHjlrb4HDx7Ubbfdplq1aikvL0/SHyfDWrVqadOmTRo1apTHvfrTldq5c6fuv/9+XXPNNQoPD9fu3buVmpqqXbt26YYbbtBNN90kybse4uVwOPTQQw/Jz89PEyZMUPPmzRUeHq78/Hx1795du3fvVkREhJ5++mllZ2d7TcCf65wXHR2tLl26uF/dDyhCRp7N5IwkH83IR4mM9JaMpAT+BcuytHXrVu3YsUMhISEKDg7WyJEj1bhxY/dlvO3u/QupUaOGPv/8c82fP189evTQs88+q+TkZL388su65pprVKNGDa98zHuRsLAwxcfHq2PHjoqMjJQkHTt2TA0bNtQbb7zh8Xf9X47atWtrxYoVat++vSIiItSgQQNVrlxZoaGh6tOnj0JCQuwesUT4+fnp/vvvV3Z2tiZOnKiVK1eqTZs2kiRfX1/3k/v9/f3tHLNYneucN3r06DPOeUARMvJsJmck+WhOPkpkpDdkJG8RcQF5eXnasmWLmjVr5nW35FyurKwsff/99xoxYoTCwsL0448/Ki4uzuue23AuGRkZ+vjjj3X06FG1bdtWvr6+mjp1qkaPHq1rrrnG7vFKxOHDh/XBBx+oRo0auvnmm5WVlaXo6GiNGTNG1atXt3u8EpeXl6f58+drzpw5uu+++xQeHq4JEyZo1KhRXvUeV0U45+FS8PNyNlMzknw0Lx8lMrIsowRegqI3AsUfDh8+LJfLpdjYWA0bNky1a9e2e6RSceTIESUlJWnFihUKCQlR7969Vb9+fbvHKlG//PKL4uPjtXnzZvn7+6t///5q0KCB3WOVmtzcXMXHx2vw4MFq3bq13n77bdWpU8fusUoc5zxcCn5ezmRiRpKP5uWjREaWVZRAXLGy/ktwuYqe8+CND3E5F8uylJ2dLcuyjHqOT5Hc3FwtWbJETZs2VXh4uN3jACgjTMxI8tE8ZGTZQwkEgItU9ObPAADgTGRk2UIJBAAAAACDePZb2QMAAAAAihUlEAAAAAAMQgkEAAAAAINQAgEAAADAIJRAAAAAADBIObsHKG6FhYXKzMyU0+nkZWoBwMtZlqW8vDwFBATIx4fbNS+EjAQAM1woH72uBGZmZmrnzp12jwEAKEX16tVTpUqV7B7D45GRAGCW8+Wj15VAp9Mp6Y+F/fz8bJkhNTVVkZGRthzbE5i8v527R0RE2HLcIomJibrvvvtsncFOJu9v5+6hoaGaNm2a+9yPv0ZG2svk3SUykowwk137Xygfva4EFj28xc/PT/7+/rbNYeexPYHJ+9u1+8GDB205rqfNYCeT97d7dx7aeHHISPuZvLtERprK5N0le/c/Xz7yBAoAAAAAMAglEAAAAAAMQgkEAAAAAINQAgEAAADAIJRAAAAAADAIJRAAAAAADEIJBAAAAACDUAIBAAAAwCCUQAAAAAAwCCUQAAAAAAxCCQQAAAAAg1ACAQAAAMAglEAAAAAAMAglEAAAAAAMQgkEAAAAAINQAgEAAADAIJRAAAAAADAIJRAAAAAADEIJBAAAAACDUAIBAAAAwCCUQAAAAAAwCCUQAAAAAAxCCQQAAAAAg1ACAQAAAMAglEAAAAAAMAglEAAAAAAM4tElcOzYsUpISLB7DAAAPA4ZCQC4XOXsHuCvvPTSS3aPAACARyIjAQCXy9Z7Ajt37qy1a9dKkhYuXKjGjRsrOztbkvTWW2+pVatWmjZtmiQpMjJSL730ku666y5t3brVtpkBACgNZCQAoKTYek9ghw4dtGrVKt1yyy367rvvVLlyZblcLt16661auXKlbrjhBvdl8/LydPvtt2vs2LEXdd2pqaklNfZFSUlJsfX4djN5f7t2d7lcthzX02awk8n7m7x7SSEjvZPJu0tkpKlM3l3yzP1tL4H9+vXTa6+9JpfLpR49eig5OVkBAQGqXbu2qlWrdsblW7RocdHXHRkZKX9//+Ie+aKkpKSoefPmthzbE5i8v527OxwOW45bxOVyXdLvqLcxeX87dw8LC1NiYqItxy5pZKT3MXl3iYwkI8xk1/4XykdbHw5av3595eXladmyZbrmmmt0++23Kzk5WcuXL9ddd9111uUrVqxow5QAAJQ+MhIAUFJsf3XQ9u3ba9SoUbr11ltVt25dZWRkKDExUXfeeafdowEAYCsyEgBQEmwvgR06dNDPP/+sVq1aSZJatWqlatWqKSwszObJAACwFxkJACgJtr9FRNOmTbVjxw7354MHD3Z/PGzYMPfHf74MAAAmICMBACXB9nsCAQAAAAClhxIIAAAAAAahBAIAAACAQSiBAAAAAGAQSiAAAAAAGIQSCAAAAAAGoQQCAAAAgEEogQAAAABgEEogAAAAABiEEggAAAAABqEEAgAAAIBBKIEAAAAAYBBKIAAAAAAYhBIIAAAAAAahBAIAAACAQSiBAAAAAGAQSiAAAAAAGIQSCAAAAAAGoQQCAAAAgEEogQAAAABgEEogAAAAABiEEggAAAAABqEEAgAAAIBBKIEAAAAAYBBKIAAAAAAYhBIIAAAAAAahBAIAAACAQSiBAAAAAGAQSiAAAAAAGIQSCAAAAAAGoQQCAAAAgEEogQAAAABgEEogAAAAABiEEggAAAAABqEEAgAAAIBBKIEAAAAAYBBKIAAAAAAYhBIIAAAAAAahBAIAAACAQSiBAAAAAGAQSiAAAAAAGIQSCAAAAAAGoQQCAAAAgEEogQAAAABgEEogAAAAABiEEggAAAAABqEEAgAAAIBBKIEAAAAAYBBKIAAAAAAYhBIIAAAAAAahBAIAAACAQSiBAAAAAGAQSiAAAAAAGIQSCAAAAAAGuWAJXL9+ve69997SmAUAgDKDfAQAlFXcEwgAAAAABil3KRd2uVx69dVXNXr0aP3000+KiYmRj4+PqlatqqioKEVEROiNN95QYGCgduzYoUOHDql+/foaPny4AgIC1LhxYz3zzDNKTk5Wenq6evXqpccee0ySFB8fr9mzZ6uwsFBBQUGKiopS3bp1//L6AADwBOQjAKAsuegSuG7dOkVFRWnixIn67bffNHXqVM2ZM0fBwcGaN2+enn/+eS1atEiSlJqaqpkzZ8rhcOiRRx7R4sWL9eCDDyo3N1dVqlRRXFycUlNT1a1bNz344IPavHmzEhISFBsbqwoVKmj16tV64YUXlJSU9JfX91dSU1Ov4K/lyqWkpNh6fLuZvL9du7tcLluO62kz2Mnk/U3evazlY9H32YmMMBcZaSaTd5c8c/+LKoGHDh1Snz591K1bNzVo0EAffPCBOnXqpODgYElSly5d9P777+vXX3+VJN12223y8/OTJNWrV08nT550X1e7du0kSY0aNVJubq6ysrL07bffas+ePeratav7cqdOndKJEycueH3nExkZKX9//4tZr9ilpKSoefPmthzbE5i8v527OxwOW45bxOVyqUWLFrbOYCeT97dz97CwMCUmJtpybKls5qNERtrF5N0lMpKMMJNd+18oHy+qBPr6+mry5Ml67rnndPfdd6uwsPCsy1iWpfz8fElS+fLl3V93OByyLMv9eVHoFP0yWpalwsJCde7cWf3795ckFRYWKj09XZUrV77g9QEAYBfyEQBQFl3UC8NUq1ZNzZo10+uvv67XXntNLVq00FdffaXjx49LkubOnaugoCDVqVPnsoZo3bq1Fi1apPT0dEnS7Nmz1b1798u6LgAASgv5CAAoiy7phWEeeOABff311/ruu+/Uo0cPde/eXYWFhQoODtakSZPk43N5LzbaunVr9e7dWz179pTD4VBgYKDGjRtn+133AABcDPIRAFCmWF4mOzvbcrlcVnZ2tm0zuFwu247tCUze387dJdn6n8vlsn0G9jdv97CwMNvP+WUJGWkvk3e3LDLS7hnY3az9L5SPvE8gAAAAABiEEggAAAAABqEEAgAAAIBBKIEAAAAAYBBKIAAAAAAYhBIIAAAAAAahBAIAAACAQSiBAAAAAGAQSiAAAAAAGIQSCAAAAAAGoQQCAAAAgEEogQAAAABgEEogAAAAABiEEggAAAAABqEEAgAAAIBBKIEAAAAAYBBKIAAAAAAYhBIIAAAAAAahBAIAAACAQSiBAAAAAGAQSiAAAAAAGIQSCAAAAAAGoQQCAAAAgEEogQAAAABgEEogAAAAABiEEggAAAAABqEEAgAAAIBBKIEAAAAAYBBKIAAAAAAYhBIIAAAAAAahBAIAAACAQSiBAAAAAGAQSiAAAAAAGIQSCAAAAAAGoQQCAAAAgEEogQAAAABgEEogAAAAABiEEggAAAAABqEEAgAAAIBBKIEAAAAAYBBKIAAAAAAYhBIIAAAAAAahBAIAAACAQSiBAAAAAGAQSiAAAAAAGIQSCAAAAAAGoQQCAAAAgEEogQAAAABgEEogAAAAABiEEggAAAAABqEEAgAAAIBBKIEAAAAAYBBKIAAAAAAYhBIIAAAAAAa55BLYs2dPHT9+/Kyv9+7dW7t27frL733jjTc0bdq0Sz0kAAAej3wEAJQV5S71G5KTk8/59SlTplzxMAAAlFXkIwCgrLikEjhgwABJUvfu3bVr1y7ddddd2rFjh/r166ehQ4dq7NixysrK0pgxY1SrVi399NNPys/P17vvvqvmzZufcV1DhgzRjh07NH78eDmdTo0cOVIbNmxQQUGBGjZsqLfffluBgYG644479MADD2jt2rU6ePCgOnfurJdffrnY/gIAALhS5CMAoCy5pIeDDh06VJIUHR2tsLAwXX/99UpKSlKHDh3OuNyWLVvUs2dPJSQkqEuXLhozZoz7zyzL0qBBg3TgwAFNmTJFAQEBmjx5snx9fTVv3jx9+eWXCg0N1ciRI93fk5WVpVmzZikuLk6ffvqp9u3bdyU7AwBQrMhHAEBZcskPB/2zFi1anPPrV199tW644QZJUsOGDTV//nz3n82YMUPHjh1TQkKC/Pz8JEnffvutTp8+rTVr1kiS8vLyFBIS4v6edu3aSZKqV6+ukJAQnTx5UrVq1frL2VJTUy9/sWKQkpJi6/HtZvL+du3ucrlsOa6nzWAnk/c3efdz8eR8lMhIO5m8u0RGmsrk3SXP3P+KSmDFihXP+fXy5cu7P3Y4HLIsy/353/72NzVr1kwDBgzQnDlz5HQ6VVhYqDfffFNt2rSRJGVmZionJ8f9Pf7+/ue9vvOJjIw84/tKU0pKylkP7zGJyfvbubvD4bDluEVcLtd5/+FrApP3t3P3sLAwJSYm2nLsv+LJ+SiRkXYxeXeJjCQjzGTX/hfKx0t+dVBfX1/l5+df9kCRkZF64oknVKlSJY0bN06S1Lp1a8XGxio3N1eFhYWKiorS6NGjL/sYAACUNvIRAFBWXHIJvPvuu/Xkk08qMzPzsg/qcDg0ZMgQzZo1Sxs3btRzzz2n8PBwPfDAA+rUqZMsy9Ibb7xx2dcPAEBpIx8BAGXFJT8c9Hy3QC5fvtz98cKFC90ft2zZ0v35sGHD3F8PDw/Xhg0b3J8PHDjwgtd7rs8BAPAE5CMAoKy45HsCAQAAAABlFyUQAAAAAAxCCQQAAAAAg1ACAQAAAMAglEAAAAAAMAglEAAAAAAMQgkEAAAAAINQAgEAAADAIJRAAAAAADAIJRAAAAAADEIJBAAAAACDUAIBAAAAwCCUQAAAAAAwCCUQAAAAAAxCCQQAAAAAg1ACAQAAAMAglEAAAAAAMAglEAAAAAAMQgkEAAAAAINQAgEAAADAIJRAAAAAADAIJRAAAAAADEIJBAAAAACDUAIBAAAAwCCUQAAAAAAwCCUQAAAAAAxCCQQAAAAAg1ACAQAAAMAglEAAAAAAMAglEAAAAAAMQgkEAAAAAINQAgEAAADAIJRAAAAAADAIJRAAAAAADEIJBAAAAACDUAIBAAAAwCCUQAAAAAAwCCUQAAAAAAxCCQQAAAAAg1ACAQAAAMAglEAAAAAAMAglEAAAAAAMQgkEAAAAAINQAgEAAADAIJRAAAAAADAIJRAAAAAADEIJBAAAAACDUAIBAAAAwCCUQAAAAAAwCCUQAAAAAAxCCQQAAAAAg1ACAQAAAMAglEAAAAAAMAglEAAAAAAMQgkEAAAAAINQAgEAAADAIMVWAjMyMjRr1ixt2bKluK5SkjRixAjt2bOnWK8TAIDSQj4CADxNuSu9gs2bN2vOnDlau3at2rVrp/bt22v58uWaMGGC8vLyVL58eb3++utq2rSp8vLyNGzYMK1du1a+vr5q0qSJBgwYoMDAQM2aNUtxcXFyOp3y9/fXoEGDdN1116lq1ap6/vnnFRISokcffVTt27eXn59fcewOAECJIR8BAJ7KYVmWdTnfuHXrVkVFRSk4OFgPPfSQO3x++eUX/etf/9LMmTNVpUoV/fTTT3r66ae1ZMkSTZ06VT/99JNGjx4tX19fvfXWW3I6nRo4cKBuvPFGLV++XKGhoUpISFBOTo4effRR9/H+85//KD4+XuvXr1fPnj31+OOPn3OunJwcpaamXt7fBgCgTIqMjJS/v7/dY0jy3HyUyEgAMM358vGy7wn08fGRj4+PHA6HHA6H++vJyclKT09Xjx493F9zOBzau3evVq1apVdeeUVOp1OS9OSTT+r555+Xr6+v7r77bnXt2lVt27ZV69at1aZNmzOO5+vr6z6mj8+FH8Vq5z8IUlJS1Lx5c1uO7QlM3t/O3f/8e2gHl8ulFi1a2DqDnUze387dw8LClJiYaMuxz8fT81EiI+1i8u4SGUlGmMmu/S+Uj5ddAhs1aqR58+Zpy5YtiouL04gRI3TnnXcqMDBQt9xyiz788EP3ZQ8ePKjQ0FAVFhae8UtYWFiovLw8SdLIkSO1c+dOrVmzRpMnT9aCBQs0duxYzZw5U1988YWCgoLUtWtXDRw40B2SAAB4GvIRAODprviFYZo0aaIhQ4ZowYIFqlmzpv7v//5PycnJ2r17tyRp5cqVuv/++5Wdna3bbrtNs2fPVl5engoLCxUbG6tbb71Vx48fV5s2bRQUFKQePXro5Zdf1tatWyX9EZBFYdepUycCDgBQJpCPAABPdcUvDFOkUqVKeuKJJyRJgwYNUr9+/WRZlsqVK6cJEyYoICBAffv21fDhw/WPf/xD+fn5atKkiaKionTVVVepb9++6tGjh8qXLy9fX18NHjxYkvT6668X14gAAJQ68hEA4GmKrQT+WceOHdWxY8ezvl6+fHkNHDjwnN/TtWtXde3atSTGAQDAI5CPAABPwJvFAwAAAIBBKIEAAAAAYBBKIAAAAAAYhBIIAAAAAAahBAIAAACAQSiBAAAAAGAQSiAAAAAAGIQSCAAAAAAGoQQCAAAAgEEogQAAAABgEEogAAAAABiEEggAAAAABqEEAgAAAIBBKIEAAAAAYBBKIAAAAAAYhBIIAAAAAAahBAIAAACAQSiBAAAAAGAQSiAAAAAAGIQSCAAAAAAGoQQCAAAAgEEogQAAAABgEEogAAAAABiEEggAAAAABqEEAgAAAIBBytk9QHGzLEuSlJuba+scOTk5th7fbibvb9fuYWFhthzX02awk8n727V7aGiopP+e+/HXyEj7mby7REaayuTdJXv2v1A+OiwvS87Tp09r586ddo8BAChF9erVU6VKlewew+ORkQBglvPlo9eVwMLCQmVmZsrpdMrhcNg9DgCgBFmWpby8PAUEBMjHh2c4XAgZCQBmuFA+el0JBAAAAACcHzebAgAAAIBBKIEAAAAAYBBKIAAAAAAYhBIIAAAAAAb5f1cKt8+x3JerAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1080x1800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_count 1    self.capacity  20\n",
      "0  ------------------------------------------------\n",
      "DecoderLayer@trg4\n",
      "[1, 1, 64]\n",
      "src = ['we', 'can', 'read', 'book']\n",
      "old attention torch.Size([1, 2, 6, 6])\n",
      "old attention tensor([[[[3.1085e-03, 3.4223e-03, 9.5998e-01, 1.4135e-02, 1.0706e-02,\n",
      "           8.6533e-03],\n",
      "          [5.1197e-03, 7.9937e-03, 2.7680e-03, 1.3851e-01, 7.6641e-02,\n",
      "           7.6897e-01],\n",
      "          [2.3330e-02, 2.7712e-01, 2.8816e-02, 1.5600e-01, 4.7023e-01,\n",
      "           4.4497e-02],\n",
      "          [9.2522e-03, 2.2223e-04, 4.7026e-02, 2.7458e-03, 9.3793e-01,\n",
      "           2.8288e-03],\n",
      "          [3.7723e-02, 6.5816e-01, 1.8756e-01, 2.2487e-02, 5.3529e-02,\n",
      "           4.0537e-02],\n",
      "          [1.6098e-02, 3.5446e-03, 7.4486e-01, 6.3907e-02, 1.6147e-01,\n",
      "           1.0129e-02]],\n",
      "\n",
      "         [[4.2100e-02, 6.7590e-01, 2.2401e-01, 1.3396e-02, 2.5889e-03,\n",
      "           4.2010e-02],\n",
      "          [1.7340e-02, 2.6269e-03, 9.1597e-01, 3.2644e-02, 1.4224e-02,\n",
      "           1.7195e-02],\n",
      "          [7.0271e-03, 4.3314e-03, 9.8213e-01, 4.1824e-04, 5.8144e-03,\n",
      "           2.7754e-04],\n",
      "          [2.1859e-01, 9.4650e-02, 9.5583e-02, 9.3886e-03, 1.7180e-02,\n",
      "           5.6461e-01],\n",
      "          [5.3912e-02, 2.6538e-02, 6.6371e-01, 5.3897e-02, 1.2909e-01,\n",
      "           7.2849e-02],\n",
      "          [1.3353e-02, 1.2287e-02, 1.3469e-02, 8.5802e-01, 4.0226e-02,\n",
      "           6.2643e-02]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 6, 6])\n",
      "old attention tensor([[[[0.0775, 0.0271, 0.3096, 0.3606, 0.1641, 0.0610],\n",
      "          [0.0646, 0.1429, 0.0439, 0.2391, 0.2031, 0.3064],\n",
      "          [0.3159, 0.1812, 0.0362, 0.1321, 0.1871, 0.1474],\n",
      "          [0.1269, 0.2270, 0.0530, 0.4035, 0.0722, 0.1175],\n",
      "          [0.1853, 0.1685, 0.1393, 0.3036, 0.1152, 0.0882],\n",
      "          [0.0326, 0.0222, 0.2528, 0.0796, 0.5928, 0.0200]],\n",
      "\n",
      "         [[0.1525, 0.2166, 0.3287, 0.1067, 0.0779, 0.1177],\n",
      "          [0.0731, 0.6062, 0.1231, 0.0284, 0.1023, 0.0668],\n",
      "          [0.3918, 0.1230, 0.2298, 0.0578, 0.0932, 0.1043],\n",
      "          [0.2338, 0.2265, 0.1171, 0.1664, 0.1597, 0.0965],\n",
      "          [0.0874, 0.1566, 0.1299, 0.1639, 0.1177, 0.3444],\n",
      "          [0.0364, 0.0366, 0.0935, 0.3409, 0.1310, 0.3616]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 6, 6])\n",
      "old attention tensor([[[[0.1129, 0.5143, 0.1491, 0.0388, 0.1180, 0.0669],\n",
      "          [0.1286, 0.1117, 0.1381, 0.1493, 0.2709, 0.2014],\n",
      "          [0.1664, 0.0378, 0.0275, 0.1084, 0.0723, 0.5876],\n",
      "          [0.1170, 0.1930, 0.0389, 0.0648, 0.1129, 0.4734],\n",
      "          [0.2897, 0.1926, 0.0134, 0.2566, 0.0479, 0.1999],\n",
      "          [0.2446, 0.4590, 0.0375, 0.0813, 0.0906, 0.0869]],\n",
      "\n",
      "         [[0.0612, 0.0288, 0.6554, 0.2344, 0.0110, 0.0092],\n",
      "          [0.1171, 0.1664, 0.2227, 0.2504, 0.0470, 0.1963],\n",
      "          [0.0287, 0.0114, 0.8323, 0.1003, 0.0213, 0.0059],\n",
      "          [0.1038, 0.1103, 0.4158, 0.3272, 0.0143, 0.0286],\n",
      "          [0.1165, 0.2281, 0.3746, 0.1255, 0.0114, 0.1440],\n",
      "          [0.2487, 0.1708, 0.0477, 0.2608, 0.0614, 0.2105]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 6])\n",
      "old attention tensor([[[[0.3156, 0.4805, 0.0383, 0.0721, 0.0566, 0.0369]],\n",
      "\n",
      "         [[0.1268, 0.6691, 0.0619, 0.0742, 0.0397, 0.0283]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 6])\n",
      "old attention tensor([[[[0.2357, 0.6186, 0.1233, 0.0128, 0.0074, 0.0022]],\n",
      "\n",
      "         [[0.0266, 0.9164, 0.0065, 0.0249, 0.0151, 0.0105]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 6])\n",
      "old attention tensor([[[[0.0716, 0.7552, 0.0963, 0.0333, 0.0312, 0.0125]],\n",
      "\n",
      "         [[0.0248, 0.0231, 0.0468, 0.0633, 0.2473, 0.5947]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0548, 0.9452]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0098, 0.9902]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0548, 0.9452]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0098, 0.9902]]]])\n",
      "old attention torch.Size([1, 2, 2, 6])\n",
      "old attention tensor([[[[0.3156, 0.4805, 0.0383, 0.0721, 0.0566, 0.0369],\n",
      "          [0.0500, 0.0238, 0.1440, 0.1162, 0.4163, 0.2497]],\n",
      "\n",
      "         [[0.1268, 0.6691, 0.0619, 0.0742, 0.0397, 0.0283],\n",
      "          [0.0715, 0.0058, 0.4748, 0.0567, 0.3741, 0.0170]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0520, 0.9480]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.4427, 0.5573]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0520, 0.9480]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.4427, 0.5573]]]])\n",
      "old attention torch.Size([1, 2, 2, 6])\n",
      "old attention tensor([[[[0.2357, 0.6186, 0.1233, 0.0128, 0.0074, 0.0022],\n",
      "          [0.1524, 0.1321, 0.1551, 0.2162, 0.2701, 0.0740]],\n",
      "\n",
      "         [[0.0266, 0.9164, 0.0065, 0.0249, 0.0151, 0.0105],\n",
      "          [0.1114, 0.0717, 0.5263, 0.0222, 0.2448, 0.0236]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.4253, 0.5747]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0875, 0.9125]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.4253, 0.5747]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0875, 0.9125]]]])\n",
      "old attention torch.Size([1, 2, 2, 6])\n",
      "old attention tensor([[[[0.0716, 0.7552, 0.0963, 0.0333, 0.0312, 0.0125],\n",
      "          [0.0215, 0.4720, 0.1948, 0.0478, 0.2396, 0.0243]],\n",
      "\n",
      "         [[0.0248, 0.0231, 0.0468, 0.0633, 0.2473, 0.5947],\n",
      "          [0.0036, 0.0053, 0.0780, 0.0300, 0.5946, 0.2885]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.0548, 0.9452, 0.0000],\n",
      "          [0.0140, 0.1149, 0.8711]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.0098, 0.9902, 0.0000],\n",
      "          [0.0047, 0.0052, 0.9901]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 6])\n",
      "old attention tensor([[[[0.3700, 0.3896, 0.0421, 0.0951, 0.0712, 0.0319],\n",
      "          [0.0602, 0.0489, 0.0676, 0.0997, 0.4712, 0.2525],\n",
      "          [0.0507, 0.1343, 0.1087, 0.2254, 0.1378, 0.3431]],\n",
      "\n",
      "         [[0.0807, 0.4638, 0.0665, 0.1892, 0.1055, 0.0944],\n",
      "          [0.0869, 0.0407, 0.4713, 0.0480, 0.3379, 0.0151],\n",
      "          [0.1475, 0.4093, 0.0824, 0.0826, 0.1184, 0.1597]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.0826, 0.9174, 0.0000],\n",
      "          [0.0601, 0.1507, 0.7892]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.6514, 0.3486, 0.0000],\n",
      "          [0.4028, 0.0459, 0.5513]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 6])\n",
      "old attention tensor([[[[0.2603, 0.4752, 0.1794, 0.0505, 0.0268, 0.0078],\n",
      "          [0.2758, 0.2669, 0.2417, 0.1527, 0.0529, 0.0100],\n",
      "          [0.0465, 0.1337, 0.3013, 0.1963, 0.2664, 0.0558]],\n",
      "\n",
      "         [[0.0786, 0.8265, 0.0103, 0.0490, 0.0301, 0.0055],\n",
      "          [0.1615, 0.3130, 0.0925, 0.0924, 0.3004, 0.0401],\n",
      "          [0.1474, 0.1793, 0.0241, 0.4997, 0.0760, 0.0735]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.3027, 0.6973, 0.0000],\n",
      "          [0.3850, 0.5067, 0.1082]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.0734, 0.9266, 0.0000],\n",
      "          [0.0578, 0.5271, 0.4151]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 6])\n",
      "old attention tensor([[[[0.0711, 0.7370, 0.0978, 0.0545, 0.0238, 0.0159],\n",
      "          [0.0941, 0.5034, 0.1466, 0.1479, 0.0665, 0.0415],\n",
      "          [0.1311, 0.3958, 0.2036, 0.1790, 0.0584, 0.0321]],\n",
      "\n",
      "         [[0.0299, 0.0166, 0.0746, 0.1256, 0.2632, 0.4902],\n",
      "          [0.0157, 0.0069, 0.1176, 0.0979, 0.4253, 0.3366],\n",
      "          [0.0280, 0.0111, 0.1255, 0.1883, 0.3142, 0.3330]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0548, 0.9452, 0.0000, 0.0000],\n",
      "          [0.0140, 0.1149, 0.8711, 0.0000],\n",
      "          [0.0652, 0.0268, 0.0704, 0.8375]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0098, 0.9902, 0.0000, 0.0000],\n",
      "          [0.0047, 0.0052, 0.9901, 0.0000],\n",
      "          [0.2494, 0.2607, 0.0249, 0.4651]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 6])\n",
      "old attention tensor([[[[0.3540, 0.4627, 0.0325, 0.0664, 0.0569, 0.0275],\n",
      "          [0.0636, 0.0633, 0.0648, 0.0839, 0.4527, 0.2717],\n",
      "          [0.0505, 0.1778, 0.0982, 0.1762, 0.1262, 0.3711],\n",
      "          [0.3628, 0.1907, 0.1289, 0.1244, 0.1638, 0.0295]],\n",
      "\n",
      "         [[0.0939, 0.4810, 0.0490, 0.2231, 0.0751, 0.0778],\n",
      "          [0.1232, 0.0480, 0.4433, 0.0663, 0.3037, 0.0157],\n",
      "          [0.1892, 0.4276, 0.0617, 0.1006, 0.0841, 0.1367],\n",
      "          [0.3457, 0.0342, 0.3332, 0.0384, 0.2226, 0.0258]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0681, 0.9319, 0.0000, 0.0000],\n",
      "          [0.0403, 0.1337, 0.8259, 0.0000],\n",
      "          [0.0196, 0.1702, 0.7052, 0.1050]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.6777, 0.3223, 0.0000, 0.0000],\n",
      "          [0.4514, 0.0506, 0.4980, 0.0000],\n",
      "          [0.0870, 0.3961, 0.2827, 0.2343]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 6])\n",
      "old attention tensor([[[[0.2670, 0.4504, 0.2038, 0.0414, 0.0284, 0.0091],\n",
      "          [0.2734, 0.2222, 0.2689, 0.1538, 0.0690, 0.0127],\n",
      "          [0.0457, 0.0889, 0.3332, 0.1713, 0.3056, 0.0553],\n",
      "          [0.1915, 0.0714, 0.2569, 0.3123, 0.1357, 0.0323]],\n",
      "\n",
      "         [[0.0410, 0.9043, 0.0106, 0.0272, 0.0133, 0.0036],\n",
      "          [0.1269, 0.3546, 0.1610, 0.0907, 0.2262, 0.0407],\n",
      "          [0.1145, 0.2337, 0.0375, 0.4773, 0.0503, 0.0868],\n",
      "          [0.2774, 0.3852, 0.0404, 0.0922, 0.1604, 0.0444]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.2816, 0.7184, 0.0000, 0.0000],\n",
      "          [0.4171, 0.4279, 0.1550, 0.0000],\n",
      "          [0.2531, 0.1655, 0.2269, 0.3545]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0553, 0.9447, 0.0000, 0.0000],\n",
      "          [0.0376, 0.4008, 0.5616, 0.0000],\n",
      "          [0.0288, 0.3948, 0.2435, 0.3329]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 6])\n",
      "old attention tensor([[[[0.0641, 0.7834, 0.0723, 0.0491, 0.0178, 0.0133],\n",
      "          [0.1007, 0.4933, 0.1368, 0.1647, 0.0635, 0.0409],\n",
      "          [0.1318, 0.3829, 0.1852, 0.2047, 0.0618, 0.0336],\n",
      "          [0.1105, 0.6346, 0.0795, 0.1088, 0.0493, 0.0172]],\n",
      "\n",
      "         [[0.0249, 0.0177, 0.0529, 0.0965, 0.2189, 0.5892],\n",
      "          [0.0134, 0.0071, 0.1018, 0.0798, 0.4056, 0.3922],\n",
      "          [0.0221, 0.0110, 0.1048, 0.1505, 0.3068, 0.4048],\n",
      "          [0.0126, 0.0106, 0.1011, 0.1152, 0.3961, 0.3645]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0548, 0.9452, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0140, 0.1149, 0.8711, 0.0000, 0.0000],\n",
      "          [0.0652, 0.0268, 0.0704, 0.8375, 0.0000],\n",
      "          [0.0032, 0.0020, 0.0053, 0.0071, 0.9826]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0098, 0.9902, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0047, 0.0052, 0.9901, 0.0000, 0.0000],\n",
      "          [0.2494, 0.2607, 0.0249, 0.4651, 0.0000],\n",
      "          [0.0019, 0.0135, 0.0338, 0.0278, 0.9229]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 6])\n",
      "old attention tensor([[[[0.3634, 0.5142, 0.0257, 0.0465, 0.0323, 0.0179],\n",
      "          [0.0890, 0.0948, 0.0730, 0.0847, 0.3930, 0.2654],\n",
      "          [0.0670, 0.2690, 0.1006, 0.1587, 0.0877, 0.3170],\n",
      "          [0.4258, 0.2315, 0.1152, 0.0987, 0.1084, 0.0204],\n",
      "          [0.2040, 0.2139, 0.2035, 0.0834, 0.1424, 0.1527]],\n",
      "\n",
      "         [[0.0834, 0.4538, 0.0255, 0.3088, 0.0502, 0.0784],\n",
      "          [0.1527, 0.0604, 0.3487, 0.1207, 0.2967, 0.0208],\n",
      "          [0.1778, 0.4349, 0.0297, 0.1551, 0.0548, 0.1476],\n",
      "          [0.4193, 0.0385, 0.2460, 0.0630, 0.2022, 0.0310],\n",
      "          [0.0981, 0.0981, 0.0231, 0.7138, 0.0385, 0.0284]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0814, 0.9186, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0659, 0.1180, 0.8160, 0.0000, 0.0000],\n",
      "          [0.0198, 0.1710, 0.7207, 0.0885, 0.0000],\n",
      "          [0.0019, 0.0121, 0.0514, 0.0252, 0.9093]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.7101, 0.2899, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4073, 0.0299, 0.5629, 0.0000, 0.0000],\n",
      "          [0.0687, 0.3682, 0.2839, 0.2793, 0.0000],\n",
      "          [0.0397, 0.0694, 0.2688, 0.3295, 0.2926]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 6])\n",
      "old attention tensor([[[[0.2189, 0.4995, 0.1973, 0.0362, 0.0324, 0.0157],\n",
      "          [0.2157, 0.2221, 0.2843, 0.1596, 0.0934, 0.0248],\n",
      "          [0.0262, 0.0663, 0.2933, 0.1473, 0.3662, 0.1006],\n",
      "          [0.1515, 0.0586, 0.2526, 0.3224, 0.1641, 0.0508],\n",
      "          [0.1883, 0.1779, 0.2018, 0.2155, 0.1884, 0.0281]],\n",
      "\n",
      "         [[0.0870, 0.8385, 0.0417, 0.0144, 0.0153, 0.0031],\n",
      "          [0.1627, 0.1617, 0.4253, 0.0403, 0.1804, 0.0295],\n",
      "          [0.2012, 0.1489, 0.1388, 0.3459, 0.0457, 0.1195],\n",
      "          [0.4515, 0.2183, 0.1002, 0.0450, 0.1500, 0.0351],\n",
      "          [0.1623, 0.2485, 0.3917, 0.0550, 0.1107, 0.0319]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.2799, 0.7201, 0.0000, 0.0000, 0.0000],\n",
      "          [0.3478, 0.4746, 0.1776, 0.0000, 0.0000],\n",
      "          [0.1832, 0.1236, 0.2861, 0.4071, 0.0000],\n",
      "          [0.1448, 0.0824, 0.1948, 0.3555, 0.2225]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0351, 0.9649, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0194, 0.2710, 0.7096, 0.0000, 0.0000],\n",
      "          [0.0113, 0.2895, 0.4147, 0.2845, 0.0000],\n",
      "          [0.0169, 0.1221, 0.5628, 0.0875, 0.2106]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 6])\n",
      "old attention tensor([[[[0.0761, 0.7621, 0.0781, 0.0309, 0.0247, 0.0281],\n",
      "          [0.0778, 0.3692, 0.1694, 0.1345, 0.1391, 0.1100],\n",
      "          [0.1352, 0.2266, 0.2327, 0.1927, 0.1194, 0.0934],\n",
      "          [0.0939, 0.5733, 0.0928, 0.0898, 0.1114, 0.0388],\n",
      "          [0.0127, 0.1111, 0.2680, 0.1070, 0.3305, 0.1707]],\n",
      "\n",
      "         [[0.0850, 0.0733, 0.0823, 0.1155, 0.1848, 0.4589],\n",
      "          [0.0352, 0.0204, 0.1609, 0.0834, 0.4194, 0.2806],\n",
      "          [0.0698, 0.0466, 0.1419, 0.1817, 0.2683, 0.2917],\n",
      "          [0.0289, 0.0284, 0.1489, 0.1273, 0.3945, 0.2720],\n",
      "          [0.0415, 0.0355, 0.2170, 0.0428, 0.4600, 0.2031]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 6, 6])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0548, 0.9452, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0140, 0.1149, 0.8711, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0652, 0.0268, 0.0704, 0.8375, 0.0000, 0.0000],\n",
      "          [0.0032, 0.0020, 0.0053, 0.0071, 0.9826, 0.0000],\n",
      "          [0.0071, 0.0790, 0.4460, 0.0065, 0.0844, 0.3770]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0098, 0.9902, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0047, 0.0052, 0.9901, 0.0000, 0.0000, 0.0000],\n",
      "          [0.2494, 0.2607, 0.0249, 0.4651, 0.0000, 0.0000],\n",
      "          [0.0019, 0.0135, 0.0338, 0.0278, 0.9229, 0.0000],\n",
      "          [0.0016, 0.0022, 0.5239, 0.0102, 0.0127, 0.4494]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 6, 6])\n",
      "old attention tensor([[[[0.3546, 0.5168, 0.0238, 0.0509, 0.0352, 0.0187],\n",
      "          [0.0825, 0.0902, 0.0633, 0.0865, 0.4137, 0.2637],\n",
      "          [0.0660, 0.2636, 0.0905, 0.1708, 0.0952, 0.3140],\n",
      "          [0.4136, 0.2337, 0.1069, 0.1073, 0.1169, 0.0215],\n",
      "          [0.2000, 0.2157, 0.1871, 0.0890, 0.1524, 0.1558],\n",
      "          [0.0740, 0.2245, 0.1079, 0.1680, 0.0912, 0.3345]],\n",
      "\n",
      "         [[0.0657, 0.5001, 0.0237, 0.2681, 0.0529, 0.0894],\n",
      "          [0.1267, 0.0682, 0.3440, 0.1102, 0.3277, 0.0232],\n",
      "          [0.1335, 0.4741, 0.0285, 0.1322, 0.0599, 0.1718],\n",
      "          [0.3661, 0.0479, 0.2511, 0.0621, 0.2333, 0.0395],\n",
      "          [0.0836, 0.1176, 0.0224, 0.6997, 0.0427, 0.0340],\n",
      "          [0.1546, 0.4781, 0.0251, 0.1261, 0.0539, 0.1623]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 6, 6])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0889, 0.9111, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0825, 0.1011, 0.8164, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0255, 0.1605, 0.7395, 0.0745, 0.0000, 0.0000],\n",
      "          [0.0025, 0.0114, 0.0841, 0.0313, 0.8707, 0.0000],\n",
      "          [0.0152, 0.0205, 0.1407, 0.0359, 0.6212, 0.1664]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.7066, 0.2934, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4016, 0.0334, 0.5650, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0654, 0.3700, 0.2284, 0.3363, 0.0000, 0.0000],\n",
      "          [0.0365, 0.0669, 0.2447, 0.3641, 0.2879, 0.0000],\n",
      "          [0.1467, 0.0127, 0.2363, 0.0657, 0.2997, 0.2389]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 6, 6])\n",
      "old attention tensor([[[[0.2296, 0.3947, 0.2337, 0.0714, 0.0433, 0.0272],\n",
      "          [0.2019, 0.1621, 0.2934, 0.2249, 0.0886, 0.0291],\n",
      "          [0.0193, 0.0443, 0.2308, 0.1984, 0.3745, 0.1327],\n",
      "          [0.1127, 0.0358, 0.2111, 0.4261, 0.1555, 0.0588],\n",
      "          [0.1680, 0.1244, 0.1903, 0.2978, 0.1876, 0.0319],\n",
      "          [0.0216, 0.0371, 0.2296, 0.1931, 0.4046, 0.1140]],\n",
      "\n",
      "         [[0.1302, 0.7561, 0.0356, 0.0457, 0.0257, 0.0067],\n",
      "          [0.2003, 0.1556, 0.3139, 0.0716, 0.2160, 0.0426],\n",
      "          [0.1692, 0.0772, 0.0589, 0.5357, 0.0420, 0.1170],\n",
      "          [0.4900, 0.1788, 0.0542, 0.0781, 0.1536, 0.0452],\n",
      "          [0.1957, 0.2518, 0.2758, 0.1083, 0.1196, 0.0488],\n",
      "          [0.1413, 0.0949, 0.0506, 0.5275, 0.0376, 0.1481]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "old attention torch.Size([1, 2, 6, 6])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.2644, 0.7356, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.3919, 0.5020, 0.1061, 0.0000, 0.0000, 0.0000],\n",
      "          [0.2556, 0.1564, 0.1854, 0.4026, 0.0000, 0.0000],\n",
      "          [0.1453, 0.0770, 0.1450, 0.4053, 0.2274, 0.0000],\n",
      "          [0.2161, 0.2325, 0.0707, 0.2616, 0.1389, 0.0802]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0325, 0.9675, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0423, 0.4368, 0.5209, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0169, 0.3480, 0.3368, 0.2983, 0.0000, 0.0000],\n",
      "          [0.0231, 0.1422, 0.5051, 0.0878, 0.2419, 0.0000],\n",
      "          [0.0205, 0.2113, 0.3147, 0.0707, 0.1144, 0.2684]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 6, 6])\n",
      "old attention tensor([[[[0.1862, 0.4549, 0.1002, 0.1071, 0.0383, 0.1133],\n",
      "          [0.1245, 0.1756, 0.1229, 0.2216, 0.1051, 0.2502],\n",
      "          [0.2050, 0.1143, 0.1567, 0.2893, 0.0771, 0.1575],\n",
      "          [0.1806, 0.3135, 0.0900, 0.1924, 0.1037, 0.1198],\n",
      "          [0.0241, 0.0517, 0.1729, 0.1844, 0.2172, 0.3497],\n",
      "          [0.1983, 0.1096, 0.1438, 0.2779, 0.0836, 0.1868]],\n",
      "\n",
      "         [[0.2283, 0.1200, 0.0995, 0.2149, 0.1149, 0.2224],\n",
      "          [0.1061, 0.0325, 0.2047, 0.1765, 0.3114, 0.1689],\n",
      "          [0.1868, 0.0718, 0.1534, 0.3175, 0.1423, 0.1281],\n",
      "          [0.0950, 0.0564, 0.1720, 0.2667, 0.2534, 0.1564],\n",
      "          [0.1195, 0.0600, 0.2953, 0.0916, 0.3125, 0.1211],\n",
      "          [0.1890, 0.0711, 0.1552, 0.2990, 0.1546, 0.1311]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 7, 7])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0548, 0.9452, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0140, 0.1149, 0.8711, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0652, 0.0268, 0.0704, 0.8375, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0032, 0.0020, 0.0053, 0.0071, 0.9826, 0.0000, 0.0000],\n",
      "          [0.0071, 0.0790, 0.4460, 0.0065, 0.0844, 0.3770, 0.0000],\n",
      "          [0.0203, 0.0132, 0.0249, 0.2573, 0.4490, 0.0216, 0.2138]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0098, 0.9902, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0047, 0.0052, 0.9901, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.2494, 0.2607, 0.0249, 0.4651, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0019, 0.0135, 0.0338, 0.0278, 0.9229, 0.0000, 0.0000],\n",
      "          [0.0016, 0.0022, 0.5239, 0.0102, 0.0127, 0.4494, 0.0000],\n",
      "          [0.1530, 0.2138, 0.0218, 0.2928, 0.0046, 0.0246, 0.2894]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 7, 6])\n",
      "old attention tensor([[[[0.3401, 0.5434, 0.0218, 0.0437, 0.0330, 0.0181],\n",
      "          [0.0824, 0.0980, 0.0628, 0.0797, 0.4057, 0.2715],\n",
      "          [0.0641, 0.2833, 0.0867, 0.1502, 0.0932, 0.3227],\n",
      "          [0.4126, 0.2505, 0.1033, 0.0968, 0.1153, 0.0215],\n",
      "          [0.1964, 0.2309, 0.1816, 0.0800, 0.1506, 0.1604],\n",
      "          [0.0723, 0.2417, 0.1038, 0.1485, 0.0897, 0.3441],\n",
      "          [0.3981, 0.2644, 0.0853, 0.1078, 0.1230, 0.0213]],\n",
      "\n",
      "         [[0.0754, 0.4947, 0.0224, 0.2800, 0.0471, 0.0804],\n",
      "          [0.1496, 0.0690, 0.3384, 0.1174, 0.3031, 0.0225],\n",
      "          [0.1599, 0.4639, 0.0278, 0.1391, 0.0539, 0.1554],\n",
      "          [0.4142, 0.0445, 0.2385, 0.0616, 0.2069, 0.0342],\n",
      "          [0.0933, 0.1108, 0.0208, 0.7083, 0.0371, 0.0297],\n",
      "          [0.1839, 0.4646, 0.0245, 0.1322, 0.0485, 0.1464],\n",
      "          [0.3932, 0.0554, 0.2333, 0.0607, 0.2172, 0.0404]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 7, 7])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0778, 0.9222, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0589, 0.1000, 0.8411, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0188, 0.1541, 0.7499, 0.0772, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0015, 0.0098, 0.0641, 0.0240, 0.9005, 0.0000, 0.0000],\n",
      "          [0.0091, 0.0174, 0.1244, 0.0250, 0.6739, 0.1502, 0.0000],\n",
      "          [0.0112, 0.0819, 0.4092, 0.0474, 0.1186, 0.2831, 0.0486]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.7274, 0.2726, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4437, 0.0339, 0.5224, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0699, 0.4026, 0.2450, 0.2825, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0432, 0.0792, 0.2719, 0.3230, 0.2828, 0.0000, 0.0000],\n",
      "          [0.1821, 0.0149, 0.2497, 0.0510, 0.2523, 0.2500, 0.0000],\n",
      "          [0.0341, 0.1873, 0.1040, 0.1294, 0.3076, 0.1092, 0.1285]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 7, 6])\n",
      "old attention tensor([[[[0.2345, 0.3913, 0.2461, 0.0595, 0.0422, 0.0263],\n",
      "          [0.1994, 0.1526, 0.3031, 0.2163, 0.0991, 0.0296],\n",
      "          [0.0206, 0.0375, 0.2469, 0.1812, 0.3944, 0.1193],\n",
      "          [0.1182, 0.0346, 0.2255, 0.4034, 0.1605, 0.0579],\n",
      "          [0.1729, 0.1153, 0.1980, 0.2834, 0.1994, 0.0310],\n",
      "          [0.0231, 0.0315, 0.2448, 0.1753, 0.4228, 0.1024],\n",
      "          [0.1223, 0.0374, 0.2268, 0.4172, 0.1472, 0.0491]],\n",
      "\n",
      "         [[0.0749, 0.8473, 0.0297, 0.0293, 0.0140, 0.0048],\n",
      "          [0.1570, 0.1928, 0.3570, 0.0731, 0.1768, 0.0432],\n",
      "          [0.1465, 0.1061, 0.0767, 0.5119, 0.0366, 0.1223],\n",
      "          [0.4044, 0.2628, 0.0678, 0.0818, 0.1372, 0.0460],\n",
      "          [0.1481, 0.3089, 0.3033, 0.0993, 0.0952, 0.0452],\n",
      "          [0.1210, 0.1308, 0.0669, 0.4941, 0.0327, 0.1545],\n",
      "          [0.4530, 0.2145, 0.0598, 0.0834, 0.1486, 0.0407]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 7, 7])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.2633, 0.7367, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4234, 0.4517, 0.1248, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.2520, 0.1510, 0.2238, 0.3732, 0.0000, 0.0000, 0.0000],\n",
      "          [0.1756, 0.0877, 0.1657, 0.3647, 0.2064, 0.0000, 0.0000],\n",
      "          [0.2335, 0.2154, 0.0884, 0.2280, 0.1324, 0.1022, 0.0000],\n",
      "          [0.1391, 0.0903, 0.1139, 0.2073, 0.1313, 0.1165, 0.2016]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0282, 0.9718, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0311, 0.3465, 0.6225, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0131, 0.3351, 0.3652, 0.2865, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0161, 0.1331, 0.5279, 0.0760, 0.2468, 0.0000, 0.0000],\n",
      "          [0.0136, 0.1625, 0.3644, 0.0519, 0.1111, 0.2965, 0.0000],\n",
      "          [0.0066, 0.1762, 0.1947, 0.1530, 0.1446, 0.1669, 0.1580]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 7, 6])\n",
      "old attention tensor([[[[0.1741, 0.5378, 0.0814, 0.1010, 0.0279, 0.0779],\n",
      "          [0.1256, 0.2137, 0.1216, 0.2504, 0.0991, 0.1896],\n",
      "          [0.1879, 0.1308, 0.1543, 0.3149, 0.0792, 0.1329],\n",
      "          [0.1721, 0.3724, 0.0792, 0.2004, 0.0915, 0.0843],\n",
      "          [0.0220, 0.0626, 0.1877, 0.2150, 0.2238, 0.2890],\n",
      "          [0.1860, 0.1298, 0.1402, 0.3014, 0.0861, 0.1565],\n",
      "          [0.1860, 0.3763, 0.0753, 0.1931, 0.0825, 0.0869]],\n",
      "\n",
      "         [[0.1687, 0.1135, 0.0813, 0.1904, 0.1223, 0.3237],\n",
      "          [0.0752, 0.0306, 0.1752, 0.1540, 0.3388, 0.2262],\n",
      "          [0.1350, 0.0665, 0.1498, 0.2848, 0.1757, 0.1883],\n",
      "          [0.0667, 0.0457, 0.1487, 0.2325, 0.2867, 0.2196],\n",
      "          [0.0859, 0.0523, 0.2548, 0.0780, 0.3651, 0.1639],\n",
      "          [0.1342, 0.0656, 0.1508, 0.2636, 0.1897, 0.1960],\n",
      "          [0.0721, 0.0466, 0.1531, 0.2349, 0.2843, 0.2091]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 8, 8])\n",
      "old attention tensor([[[[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [5.4816e-02, 9.4518e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [1.4026e-02, 1.1485e-01, 8.7112e-01, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [6.5203e-02, 2.6850e-02, 7.0398e-02, 8.3755e-01, 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [3.1531e-03, 1.9565e-03, 5.2809e-03, 7.0545e-03, 9.8255e-01,\n",
      "           0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [7.0856e-03, 7.9000e-02, 4.4596e-01, 6.4885e-03, 8.4437e-02,\n",
      "           3.7703e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [2.0255e-02, 1.3158e-02, 2.4901e-02, 2.5729e-01, 4.4903e-01,\n",
      "           2.1563e-02, 2.1380e-01, 0.0000e+00],\n",
      "          [1.8542e-03, 1.0354e-03, 3.0358e-03, 4.4816e-03, 5.3923e-01,\n",
      "           5.6043e-03, 4.0254e-03, 4.4074e-01]],\n",
      "\n",
      "         [[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [9.8231e-03, 9.9018e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [4.7095e-03, 5.2001e-03, 9.9009e-01, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [2.4937e-01, 2.6068e-01, 2.4883e-02, 4.6506e-01, 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [1.8761e-03, 1.3533e-02, 3.3832e-02, 2.7844e-02, 9.2292e-01,\n",
      "           0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [1.6118e-03, 2.2176e-03, 5.2386e-01, 1.0188e-02, 1.2726e-02,\n",
      "           4.4939e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [1.5301e-01, 2.1375e-01, 2.1792e-02, 2.9283e-01, 4.5941e-03,\n",
      "           2.4633e-02, 2.8939e-01, 0.0000e+00],\n",
      "          [8.6569e-04, 6.0883e-03, 1.9998e-02, 1.1520e-02, 4.8528e-01,\n",
      "           2.1744e-02, 1.0328e-02, 4.4418e-01]]]])\n",
      "new attention tensor([[[[0.1402, 0.1402, 0.1402, 0.1159, 0.1159, 0.1159, 0.1159, 0.1159],\n",
      "          [0.1402, 0.1402, 0.1402, 0.1159, 0.1159, 0.1159, 0.1159, 0.1159],\n",
      "          [0.1402, 0.1402, 0.1402, 0.1159, 0.1159, 0.1159, 0.1159, 0.1159],\n",
      "          [0.1402, 0.1402, 0.1402, 0.1159, 0.1159, 0.1159, 0.1159, 0.1159],\n",
      "          [0.1402, 0.1402, 0.1402, 0.1159, 0.1159, 0.1159, 0.1159, 0.1159],\n",
      "          [0.1402, 0.1402, 0.1402, 0.1159, 0.1159, 0.1159, 0.1159, 0.1159],\n",
      "          [0.1402, 0.1402, 0.1402, 0.1159, 0.1159, 0.1159, 0.1159, 0.1159],\n",
      "          [0.1402, 0.1402, 0.1402, 0.1159, 0.1159, 0.1159, 0.1159, 0.1159]],\n",
      "\n",
      "         [[0.1402, 0.1402, 0.1402, 0.1159, 0.1159, 0.1159, 0.1159, 0.1159],\n",
      "          [0.1402, 0.1402, 0.1402, 0.1159, 0.1159, 0.1159, 0.1159, 0.1159],\n",
      "          [0.1402, 0.1402, 0.1402, 0.1159, 0.1159, 0.1159, 0.1159, 0.1159],\n",
      "          [0.1402, 0.1402, 0.1402, 0.1159, 0.1159, 0.1159, 0.1159, 0.1159],\n",
      "          [0.1402, 0.1402, 0.1402, 0.1159, 0.1159, 0.1159, 0.1159, 0.1159],\n",
      "          [0.1402, 0.1402, 0.1402, 0.1159, 0.1159, 0.1159, 0.1159, 0.1159],\n",
      "          [0.1402, 0.1402, 0.1402, 0.1159, 0.1159, 0.1159, 0.1159, 0.1159],\n",
      "          [0.1402, 0.1402, 0.1402, 0.1159, 0.1159, 0.1159, 0.1159, 0.1159]]]])\n",
      "old attention torch.Size([1, 2, 8, 6])\n",
      "old attention tensor([[[[0.3444, 0.5584, 0.0203, 0.0369, 0.0250, 0.0150],\n",
      "          [0.1003, 0.1213, 0.0682, 0.0799, 0.3666, 0.2637],\n",
      "          [0.0746, 0.3388, 0.0878, 0.1380, 0.0752, 0.2857],\n",
      "          [0.4412, 0.2708, 0.0969, 0.0836, 0.0898, 0.0177],\n",
      "          [0.2183, 0.2613, 0.1799, 0.0744, 0.1238, 0.1423],\n",
      "          [0.0848, 0.2902, 0.1062, 0.1378, 0.0734, 0.3076],\n",
      "          [0.4272, 0.2866, 0.0798, 0.0931, 0.0958, 0.0174],\n",
      "          [0.2323, 0.3237, 0.1552, 0.0629, 0.1086, 0.1172]],\n",
      "\n",
      "         [[0.0729, 0.4601, 0.0164, 0.3312, 0.0389, 0.0804],\n",
      "          [0.1659, 0.0755, 0.2848, 0.1597, 0.2883, 0.0257],\n",
      "          [0.1565, 0.4479, 0.0192, 0.1754, 0.0434, 0.1577],\n",
      "          [0.4502, 0.0466, 0.1944, 0.0808, 0.1905, 0.0373],\n",
      "          [0.0836, 0.0975, 0.0146, 0.7470, 0.0291, 0.0283],\n",
      "          [0.1802, 0.4484, 0.0171, 0.1661, 0.0394, 0.1488],\n",
      "          [0.4284, 0.0579, 0.1902, 0.0795, 0.2001, 0.0439],\n",
      "          [0.0796, 0.0922, 0.0127, 0.7504, 0.0327, 0.0324]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 8, 8])\n",
      "old attention tensor([[[[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [9.2976e-02, 9.0702e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [8.6512e-02, 9.7637e-02, 8.1585e-01, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [2.0364e-02, 1.5478e-01, 7.5400e-01, 7.0854e-02, 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [2.1481e-03, 1.0714e-02, 7.3887e-02, 2.2023e-02, 8.9123e-01,\n",
      "           0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [1.3076e-02, 1.6941e-02, 1.1982e-01, 2.2826e-02, 6.7468e-01,\n",
      "           1.5265e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [1.1799e-02, 8.0195e-02, 4.0176e-01, 4.2686e-02, 1.3657e-01,\n",
      "           2.8408e-01, 4.2901e-02, 0.0000e+00],\n",
      "          [9.4841e-04, 5.6036e-03, 3.7297e-02, 1.0856e-02, 4.7019e-01,\n",
      "           4.4676e-02, 9.9409e-03, 4.2049e-01]],\n",
      "\n",
      "         [[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [7.2407e-01, 2.7593e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [4.1194e-01, 3.0986e-02, 5.5707e-01, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [6.1662e-02, 3.6940e-01, 2.6014e-01, 3.0880e-01, 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [3.9411e-02, 7.2529e-02, 2.8882e-01, 3.0558e-01, 2.9366e-01,\n",
      "           0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [1.6674e-01, 1.4115e-02, 2.6964e-01, 4.6476e-02, 2.3590e-01,\n",
      "           2.6712e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [2.8943e-02, 1.6396e-01, 1.0437e-01, 1.3585e-01, 3.2197e-01,\n",
      "           1.1050e-01, 1.3440e-01, 0.0000e+00],\n",
      "          [2.0382e-02, 4.3156e-02, 1.6651e-01, 1.5765e-01, 1.4852e-01,\n",
      "           1.6712e-01, 1.6581e-01, 1.3085e-01]]]])\n",
      "new attention tensor([[[[0.1402, 0.1402, 0.1402, 0.1159, 0.1159, 0.1159, 0.1159, 0.1159],\n",
      "          [0.1402, 0.1402, 0.1402, 0.1159, 0.1159, 0.1159, 0.1159, 0.1159],\n",
      "          [0.1402, 0.1402, 0.1402, 0.1159, 0.1159, 0.1159, 0.1159, 0.1159],\n",
      "          [0.1402, 0.1402, 0.1402, 0.1159, 0.1159, 0.1159, 0.1159, 0.1159],\n",
      "          [0.1402, 0.1402, 0.1402, 0.1159, 0.1159, 0.1159, 0.1159, 0.1159],\n",
      "          [0.1402, 0.1402, 0.1402, 0.1159, 0.1159, 0.1159, 0.1159, 0.1159],\n",
      "          [0.1402, 0.1402, 0.1402, 0.1159, 0.1159, 0.1159, 0.1159, 0.1159],\n",
      "          [0.1402, 0.1402, 0.1402, 0.1159, 0.1159, 0.1159, 0.1159, 0.1159]],\n",
      "\n",
      "         [[0.1402, 0.1402, 0.1402, 0.1159, 0.1159, 0.1159, 0.1159, 0.1159],\n",
      "          [0.1402, 0.1402, 0.1402, 0.1159, 0.1159, 0.1159, 0.1159, 0.1159],\n",
      "          [0.1402, 0.1402, 0.1402, 0.1159, 0.1159, 0.1159, 0.1159, 0.1159],\n",
      "          [0.1402, 0.1402, 0.1402, 0.1159, 0.1159, 0.1159, 0.1159, 0.1159],\n",
      "          [0.1402, 0.1402, 0.1402, 0.1159, 0.1159, 0.1159, 0.1159, 0.1159],\n",
      "          [0.1402, 0.1402, 0.1402, 0.1159, 0.1159, 0.1159, 0.1159, 0.1159],\n",
      "          [0.1402, 0.1402, 0.1402, 0.1159, 0.1159, 0.1159, 0.1159, 0.1159],\n",
      "          [0.1402, 0.1402, 0.1402, 0.1159, 0.1159, 0.1159, 0.1159, 0.1159]]]])\n",
      "old attention torch.Size([1, 2, 8, 6])\n",
      "old attention tensor([[[[0.1998, 0.4100, 0.2369, 0.0609, 0.0515, 0.0410],\n",
      "          [0.1746, 0.1629, 0.2959, 0.2050, 0.1173, 0.0445],\n",
      "          [0.0172, 0.0362, 0.2232, 0.1675, 0.3963, 0.1596],\n",
      "          [0.1044, 0.0347, 0.2178, 0.3868, 0.1783, 0.0780],\n",
      "          [0.1512, 0.1259, 0.1897, 0.2671, 0.2199, 0.0462],\n",
      "          [0.0192, 0.0301, 0.2182, 0.1632, 0.4305, 0.1388],\n",
      "          [0.1093, 0.0375, 0.2217, 0.4019, 0.1641, 0.0656],\n",
      "          [0.1716, 0.1355, 0.1894, 0.2565, 0.2088, 0.0382]],\n",
      "\n",
      "         [[0.1324, 0.7322, 0.0843, 0.0241, 0.0209, 0.0061],\n",
      "          [0.1542, 0.1034, 0.5374, 0.0377, 0.1350, 0.0322],\n",
      "          [0.1944, 0.0877, 0.1655, 0.3706, 0.0374, 0.1444],\n",
      "          [0.4878, 0.1749, 0.1213, 0.0492, 0.1271, 0.0397],\n",
      "          [0.1543, 0.1664, 0.5019, 0.0560, 0.0834, 0.0381],\n",
      "          [0.1636, 0.1070, 0.1451, 0.3655, 0.0347, 0.1841],\n",
      "          [0.5394, 0.1390, 0.1030, 0.0490, 0.1357, 0.0339],\n",
      "          [0.1596, 0.1869, 0.4839, 0.0524, 0.0796, 0.0376]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 8, 8])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.2916, 0.7084, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.3526, 0.4830, 0.1643, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.2118, 0.1241, 0.2496, 0.4144, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.1546, 0.0824, 0.1899, 0.3532, 0.2199, 0.0000, 0.0000, 0.0000],\n",
      "          [0.1778, 0.2087, 0.1069, 0.2358, 0.1548, 0.1159, 0.0000, 0.0000],\n",
      "          [0.1132, 0.0731, 0.1229, 0.2243, 0.1245, 0.1170, 0.2250, 0.0000],\n",
      "          [0.0886, 0.0531, 0.1049, 0.2011, 0.1252, 0.1033, 0.1957, 0.1281]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0326, 0.9674, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0313, 0.3158, 0.6529, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0103, 0.2699, 0.4631, 0.2566, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0170, 0.1171, 0.5929, 0.0698, 0.2032, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0141, 0.1539, 0.3878, 0.0516, 0.1055, 0.2871, 0.0000, 0.0000],\n",
      "          [0.0054, 0.1423, 0.2523, 0.1397, 0.1152, 0.2007, 0.1443, 0.0000],\n",
      "          [0.0097, 0.0712, 0.3510, 0.0421, 0.1137, 0.2565, 0.0438, 0.1119]]]])\n",
      "new attention tensor([[[[0.1402, 0.1402, 0.1402, 0.1159, 0.1159, 0.1159, 0.1159, 0.1159],\n",
      "          [0.1402, 0.1402, 0.1402, 0.1159, 0.1159, 0.1159, 0.1159, 0.1159],\n",
      "          [0.1402, 0.1402, 0.1402, 0.1159, 0.1159, 0.1159, 0.1159, 0.1159],\n",
      "          [0.1402, 0.1402, 0.1402, 0.1159, 0.1159, 0.1159, 0.1159, 0.1159],\n",
      "          [0.1402, 0.1402, 0.1402, 0.1159, 0.1159, 0.1159, 0.1159, 0.1159],\n",
      "          [0.1402, 0.1402, 0.1402, 0.1159, 0.1159, 0.1159, 0.1159, 0.1159],\n",
      "          [0.1402, 0.1402, 0.1402, 0.1159, 0.1159, 0.1159, 0.1159, 0.1159],\n",
      "          [0.1402, 0.1402, 0.1402, 0.1159, 0.1159, 0.1159, 0.1159, 0.1159]],\n",
      "\n",
      "         [[0.1402, 0.1402, 0.1402, 0.1159, 0.1159, 0.1159, 0.1159, 0.1159],\n",
      "          [0.1402, 0.1402, 0.1402, 0.1159, 0.1159, 0.1159, 0.1159, 0.1159],\n",
      "          [0.1402, 0.1402, 0.1402, 0.1159, 0.1159, 0.1159, 0.1159, 0.1159],\n",
      "          [0.1402, 0.1402, 0.1402, 0.1159, 0.1159, 0.1159, 0.1159, 0.1159],\n",
      "          [0.1402, 0.1402, 0.1402, 0.1159, 0.1159, 0.1159, 0.1159, 0.1159],\n",
      "          [0.1402, 0.1402, 0.1402, 0.1159, 0.1159, 0.1159, 0.1159, 0.1159],\n",
      "          [0.1402, 0.1402, 0.1402, 0.1159, 0.1159, 0.1159, 0.1159, 0.1159],\n",
      "          [0.1402, 0.1402, 0.1402, 0.1159, 0.1159, 0.1159, 0.1159, 0.1159]]]])\n",
      "old attention torch.Size([1, 2, 8, 6])\n",
      "old attention tensor([[[[0.1733, 0.4444, 0.0984, 0.0801, 0.0473, 0.1566],\n",
      "          [0.0898, 0.1517, 0.1224, 0.1727, 0.1443, 0.3191],\n",
      "          [0.1568, 0.0986, 0.1634, 0.2421, 0.1155, 0.2235],\n",
      "          [0.1394, 0.2931, 0.0907, 0.1620, 0.1570, 0.1577],\n",
      "          [0.0159, 0.0389, 0.1519, 0.1368, 0.2644, 0.3921],\n",
      "          [0.1493, 0.0958, 0.1444, 0.2264, 0.1244, 0.2596],\n",
      "          [0.1505, 0.2998, 0.0863, 0.1552, 0.1425, 0.1657],\n",
      "          [0.0151, 0.0361, 0.1619, 0.1352, 0.2627, 0.3889]],\n",
      "\n",
      "         [[0.2721, 0.2159, 0.0914, 0.1574, 0.0877, 0.1755],\n",
      "          [0.1396, 0.0682, 0.2056, 0.1410, 0.2860, 0.1596],\n",
      "          [0.2158, 0.1392, 0.1433, 0.2426, 0.1325, 0.1266],\n",
      "          [0.1182, 0.0977, 0.1719, 0.2111, 0.2436, 0.1575],\n",
      "          [0.1648, 0.1304, 0.2501, 0.0778, 0.2630, 0.1139],\n",
      "          [0.2155, 0.1409, 0.1441, 0.2285, 0.1416, 0.1295],\n",
      "          [0.1280, 0.0977, 0.1754, 0.2118, 0.2400, 0.1470],\n",
      "          [0.1760, 0.1377, 0.2419, 0.0809, 0.2513, 0.1122]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "predicted trg = ['wir', 'konnen', 'buch', 'lesen', 'konnen', 'buch', 'lesen', '<eos>']\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA4EAAAIvCAYAAADKy97mAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAA3RUlEQVR4nO3deZTe89038Pdk18SaRQcVGqUIdyU5tUWTWlohKHeXpIrUE4pqq27r/dDWVqJJeqiSqNjSEFWE2FqqtiBMaklagluqaCTITUSazCQzzx9O8mgJyiS/yXxfr3Mc5srl9/t8mLne877WmqampqYAAABQhDZVDwAAAMCqowQCAAAURAkEAAAoiBIIAABQECUQAACgIEogAABAQZRAAACAgiiBAAAABVECAVhpGhsb/+nrpqamiiYBgJalyoxUAlehZf+jlyxZUvEkAKtGmzZtsmDBgkyfPj1JUlNTU/FEtFQyEihNlRnZbpWdiSxatCivv/56Lr300uy1117p06dP1SMBrDR1dXV5/fXXc9lll6VNmzY59dRTs/nmm1c9Fi2UjARKUnVGKoGryLXXXptnn302s2fPzu9///t07dpVwAGt0iOPPJKHHnoo999/fwYNGpSlS5emR48eCiArJCOBUrSUjFQCV7KHHnoo99xzTx5++OEcd9xxmTNnTtZaa60ccsghVY8GsFI8/fTTeeONN/Kzn/0sG2+8cZYsWZKtt946ydtP+WvTxisReJuMBErTUjJSCVzJNt9883To0CHDhw9P165dM3ny5Ky11lpp166dX4Zo1Ur9/l72ou5lz+tfsmRJ2rUr66b2wAMPXP7PjzzySG677bYMHDgwSYr8nmDFZCQlKvV7Wz6+raVkZHnfgavQrFmzsmjRovTp0yddu3bNrFmz8qtf/So77bRTOnToUOQNAGV49NFHM3z48CxcuLDqUVa5hQsXLg+4CRMmZMyYMcW8I+Z1112XCy64IH/4wx+SJG+99VYmTZqUIUOGZLPNNqt4OloaGUmJ5GOZ+Zi0vIx0C7uSjB8/Pj/60Y9ywQUXZM6cOUmSV155Jbvuumv69+9f1Dc95dluu+3yyiuv5MQTT8xbb71V9TirzKxZs3Lssccuf5evV199NZtuumlqamqydOnSJO9+O+jW4vLLL8+kSZOy/vrrZ8MNN8w//vGPfOITn8gOO+yQHj16VD0eLYyMpFTysbx8TFpmRiqBK8F1112X2267Leedd14OPvjgvPTSS7n22muz2WabZbvttkvibdJpnZqampbfmJ900km5//7781//9V/5xz/+UfFkq0Z9fX022mijjBkzJs8++2w6deqUWbNmZeHChWnbtm2S1vl0yNmzZ+eee+7J+PHj06tXr/zxj3/Mt771rQwfPjyDBw/OgAEDqh6RFkRGUiL5WGY+Ji03I2ua3N3W7MaOHZva2tosXLgwjz/+eF555ZXcf//9+dGPfpRvfvObVY8HK90ll1ySRx99NDvuuGPGjx+fjTfeOOedd14+8YlPVD3aStHU1LT8l9Znnnkm1113XV588cU8++yz6datW1566aX06dMnnTt3zhe+8IXsvvvuFU/cvP7+97/nK1/5Sj73uc9l3rx5GThwYLbbbrv85je/yUknnZTa2tp/+m9E2WQkJZOPZeVj0nIzsrxXY64CXbt2zcSJE7N48eIcddRR2W233fLb3/428+bN84sQrd5rr72WO+64I+eee2569uyZb33rW/nmN7+ZH/7whxk1alS6dOlS9YjN6p0/001NTenVq1eGDh2aG264IY888ki+853v5NOf/nRmzZqVu+++O1tssUXFEzefv/zlL+nYsWO6d++eK6+8Mk888UR23HHHfOpTn8qdd96ZF154IZ06dUrikR3+PxlJqeRjOfmYtPyM9EhgM7nhhhsya9aszJ07N0cffXTWW2+9rLHGGnn11Vdz7733Zvz48Rk1alR69epV9aisArfffnteeeWVbLXVVtlmm23SoUOHqkdaaf71l7a5c+fm4IMPzi9/+cvl3+9PP/109t133wwdOjQ/+tGPWs0vee/cfcKECXn88cfz3HPP5dBDD80aa6yRhx9+OM8880yOP/74VhduV1xxRW677basvfba+fvf/55vf/vbOeCAA3LyySenbdu2+dOf/pTzzjsvn/nMZ6oelRZARrKMfJSPrT0fk9UjI5XAZnD55Zfntttuy4EHHpgHHngg999/f0aPHp3XX389V155ZZYuXZrTTz+9qF+GSr43d8KECbn66qvTo0ePtG/fPnvvvXf23HPPVhl07/z/PGPGjKy//vrp3r17zj777Dz66KMZM2ZM1ltvvdx+++158MEH8+1vfzubbLJJtUOvBBMmTMiNN96Ys846K3fffXf+8pe/ZNttt82OO+6Yq666KgsWLMjZZ5+d9u3bt4rXPNx555258MILM378+CxevDgzZszIKaeckrPPPjtt2rTJvHnzss0222TjjTeuelRaABn5bqVmpHyUj609H5PVJyM9HfRjmjt3bu65556MHTs266yzTvbdd9+cf/75OeWUU/L73/8+O++8c2pqalrtc71XpMRwS5InnngijzzySG666aa0adMmF1xwQe655560adMmX/rSl1pV0L0z4C699NJMmDAhm2yySXbYYYfsv//+WbJkSQYNGpQvfelLmTp1ai6++OJWGXANDQ3505/+lDPOOCOf+cxn8pnPfCa33HJLRowYkT333DOHHnpo1lxzzXTs2LHqUZvNSy+9lM9//vPp3LlzOnTokF122SUDBw7Mk08+meHDh1c9Hi2IjHxvJWakfJSPJeRjsvpkZOuo3BVqamrK3LlzM2vWrOWXHXLIIenZs2cWLFiQzp07FxVuN9xwQ0aNGpWf//znefDBB6seZ5V6/vnnc9555+Vvf/tbnnvuuSTJ4Ycfnk033TQ333zz8s+FaS2WBdz111+f++67LzfeeGM6d+6cP/7xj7n33ntz4okn5he/+EX22muvjBs3rtUE3L8+eaKhoSFPP/10nnjiieWX7b333tlqq62yYMGCbLLJJunateuqHnOl6tKlS1599dXMnz8/7du3T01NTTp06JDFixcnefd/I8olI/9ZqRkpH+XjMq09H5PVJyM9EvgRPfHEE+natWu6deuWnXfeOQ8//HDWWmut9OrVK3fddVfmz5/fqj/v5L1cccUVueOOOzJ8+PCcc845mT9/fvr27duq7t1bkfr6+vTs2TNHHHFExo4dmzvvvDMdOnTIxhtvnMMPPzyXXXZZ+vTpU/WYzW7JkiV58MEH861vfSuvvvpqevTokd69e+fWW2/N3Llzc+ihh2aDDTaoesxm86/vctaxY8estdZa+d73vpdrrrkmPXr0yIABA3LTTTflhRdeyNprr13xxM1n8uTJWbRoUerr67P99ttnwoQJGTduXLbccsssXrw4999/fy666KIkZT7KwT+Tke9WakbKR/nY2vMxWT0z0msCP4LLL788t99+ezbccMOcdtppeeSRR3LXXXflz3/+c3r37p1HHnkk559/flGvb/jzn/+ccePG5Wc/+1muueaaTJkyJeecc06uuuqq7L333tlwww1bzDd9c7viiisybdq0dOvWLT/84Q8zY8aMTJgwIdtss02+9KUvZdNNN616xGbzXq9jGTNmTPr27ZtHH300n/3sZ/OFL3whBx10UDbaaKMcc8wxWX/99SuaduW5/PLLc8cdd6SmpiadO3fO5ptvnk033TQjRoxI//7988wzz2TUqFGt5jbg8ssvz+9///sceeSROeyww3LhhRdmww03zPjx4/PWW29l6dKlOfroo7P55ptXPSotgIx8t1IzUj7Kx9aej8nqm5FK4L9h6dKlueOOOzJhwoSMHz8+jz32WBYtWpQ5c+akffv2WXfddfPGG2+kd+/e2Wijjaoed5Wpq6vLY489lvnz5+evf/1rFixYkF/96leZPXt2jj322FxxxRVZY401qh5zpfj1r3+dyZMnZ+jQobniiivSs2fPnHbaaXnyySczZsyY5Tf47dq1W+0D/p0Bd/fdd2fJkiVZZ5110rt37yxatCjf+973cuaZZ+Z//ud/MmbMmJx//vn55Cc/WfHUze/222/PJZdckl//+td55ZVXMnPmzFx22WU5+uij88lPfjINDQ1Ze+21W0W4L168OC+99FLOPPPM/OpXv8qvf/3rPPTQQ/nRj36Uxx57LIMGDUqSLFy4sKin9PHeZOR7KzUj5aN8bM35mKz+GenpoB/StGnT0qlTp8yZMyef+cxnct1112XKlCl55ZVX0tjYmD322CN77bVX1WOuUstu9P785z9n4sSJ+Y//+I/MmzcvI0aMSNu2bfPEE0+kXbt2qa+vb5UB9/TTT+fOO+/MNddck7q6uvTs2TNrrLFGTj/99Jxyyin5/ve/nw022CDt27evetRmsSzgrrzyytx2223Ze++9c/TRR+fCCy/MxhtvnFdffTWXX3557r///lx44YWtJuAaGxv/6R3L5syZk/79+6dTp07ZYIMN0qVLl0yePDmzZs3KjjvuWOGkzetPf/pTmpqa0rlz56y55pq58MIL88QTT+TCCy/MSy+9lPPPPz+77rprOnbs2CLDjVVLRr5byRkpH+Vja87HpHVkpBL4Id12223ZdNNN8+lPfzr33ntvnn766QwfPjwDBw7MuHHj8vzzzy9/oefqfo/Wh/Xwww9n++23zyGHHJKXX345jz32WBYvXpwRI0YkSWbNmpWRI0e2uud9J8lf//rXLFy4MA0NDfnLX/6S++67L0OHDs0LL7yQ0aNH58gjj8yECRPStm3bqkf92N55D+eTTz6Z22+/PZdffnmuvvrqDBw4MFtvvXUWLFiQc889Ny+++GIOOeSQVvMi9yTLA+7JJ5/MGmuskZdffnn5z3rbtm2z7rrrplu3blm4cGGS1vPW77feems23XTT7Lfffnnttdfy7LPPZtKkSWnfvn2mTJmSDTbYoNW8nTcfn4x8t1IzUj7Kx6R152PSOjJSCfwQ7rnnnjz44IM58sgj07Vr12y//fbp0KFDpkyZkptuuik333xzRo4c2Wq+sT+MF154IYccckgGDhyY/fbbL/369UuvXr2y8cYb580338ybb76Zfv36tcqn/EyYMCETJ07MZz/72Rx44IFZuHBhXnzxxWy//fb5+9//nv322y8HH3xwqwu43/zmN1m4cGG22267XH311bnvvvsyduzY3HfffTn//PNzww03ZJtttql44uYzbdq0zJ07N4MGDVr+2VZbbrllJk+enCTp0aNHttxyy8yZMyf3339/xo4dm6R1/IK77Dbv//yf/5MuXbpk8ODBmTp1ao444ohst912ueOOOzJy5MhWcy8+H4+MfLdSM1I+ysekdedj0noyUgl8H8se5n711Vdz6KGHpmvXrnn88cczbdq0tGvXLtOmTcuCBQsyYsSI9OrVq+pxV6nu3bvnP//zP/O3v/0tc+bMyW9/+9ssWrQo3/nOd/K1r32t6vFWmmVPb7nwwgvTuXPnrLfeevnlL3+ZN998M2PHjs3NN9+cUaNGpba2tupRm8WyG+xJkybl+uuvz7HHHptTTz01n/jEJ3LDDTckSZ577rkW92Lnj6upqSkzZ87Mr371qzz11FP529/+lrFjx2b99ddPnz59ctppp2XSpEn561//mjlz5uSCCy5oFffu/uttXm1tbWbOnJlXX301e+21V2bMmJG11147o0ePLu42j3eTkStWYkbKR/nYmvMxaX0ZqQS+jzZt2uT111/P5MmT061bt/zjH//I+PHj89WvfjVbbrllDj744Bb7Ys+V5eabb87SpUuzww475LDDDsvw4cOz9dZbZ7311ssZZ5yR66+/PoMGDUrnzp1bzT0+7zR79uzssssu+dSnPpWGhoYkb98gfupTn8pjjz2WUaNGtbob/L/+9a/55S9/mYEDB+bzn/989t1330yfPj0jRozI+uuvv/yDX1uTmpqafPWrX02HDh1y0UUXpW/fvtlwww2zZMmSDB06NM8++2zWX3/9HH744VmwYEG6dOlS9cjN4r1u86644ooccMABy9/dD5aRke9WckbKR/nYmvMxaX0ZqQS+j6ampkyfPj0zZ85M165ds95662XkyJH/9JB+a3sx9wf55Cc/md/85je54YYbMmzYsHznO9/JlClTcswxx2STTTbJJz/5yVb1A/+vamtrc+2112bQoEHp3bt3kuS1117LVlttlZNOOqnFP/T/UdTW1ubAAw/MhRdemJ122ilHHXVU7rvvvtxwww1p165dRowY0are6nmZDh06ZN99982iRYsyZsyY3HPPPRkwYECSt+8N7Ny5c5Is/3tr8F63eaNHj25VT2Oi+cjIdys5I+WjfExabz4mrS8jfUTEB2hoaMgTTzyRPn36tLp77T6qhQsX5uGHH87Pfvaz1NbW5qmnnsrEiRNb3Wsb3suCBQvyi1/8Iq+++moGDhyYtm3b5pJLLsno0aNbzdMd3suSJUtyzTXX5KqrrsoPf/jD7L777kla14u8V6ShoSE33HBDrrnmmuyzzz7ZcMMNc9FFF2XUqFGt6jOulnGbx7/D98u7lZqR8lE+tvZ8TFrXbZ4S+G9YunRpq3gxc3OZM2dO6urqMmHChJxzzjnZeOONqx5plXjllVdy22235Y9//GO6du2aww47LFtssUXVY6109fX1ueGGG/KLX/wiP/nJT5YHXQnq6+tz7bXX5swzz0z//v1zyimnpGfPnlWPtdK5zePf4fvln5WYkfJRPpaSj8nqf5unBPKxre4/BB/Vstc8tManuKxIfX19Jk+enM9//vP51Kc+VfU4q1R9fX1+//vfZ7vttsuGG25Y9TjAaqLEjJSP8pGWTwkE/i0lPMVlRUreHYD3V3JGlLz76koJBAAAKEjL/ih7AAAAmpUSCAAAUBAlEAAAoCBKIAAAQEGUQAAAgIIogQAAAAVpV/UAza2xsTFvvfVW2rdv7/NKAFq5pqamNDQ0pHPnzmnTxv2aH0RGApThg/Kx1ZXAt956K08//XTVYwCwCm2++eZZc801qx6jxZORAGVZUT62uhLYvn37JG8v3KFDh0pmmDFjRnr37l3JuVuCkvevcvdNN920kvMuM3ny5Oyzzz6VzlClkvevcvcePXpk3Lhxy2/7eX8yslol757ISBlRpqr2/6B8bHUlcNnTWzp06JCOHTtWNkeV524JSt6/qt1nz55dyXlb2gxVKnn/qnf31MYPR0ZWr+TdExlZqpJ3T6rdf0X56AUUAAAABVECAQAACqIEAgAAFEQJBAAAKIgSCAAAUBAlEAAAoCBKIAAAQEGUQAAAgIIogQAAAAVRAgEAAAqiBAIAABRECQQAACiIEggAAFAQJRAAAKAgSiAAAEBBlEAAAICCKIEAAAAFUQIBAAAKogQCAAAURAkEAAAoiBIIAABQECUQAACgIEogAABAQZRAAACAgiiBAAAABWnRJfC8887LpEmTqh4DAFocGQnAR9Wu6gHezw9+8IOqRwCAFklGAvBRVfpI4H777ZcHH3wwSXLzzTdnm222yaJFi5Ik//f//t/stNNOGTduXJKkd+/e+cEPfpAvf/nLmT59emUzA8CqICMBWFkqfSRwjz32yL333psdd9wx9913X9Zee+3U1dVl5513zj333JMtt9xy+XUbGhryxS9+Meedd96HOvaMGTNW1tgfyrRp0yo9f9VK3r+q3evq6io5b0uboUol71/y7iuLjGydSt49kZGlKnn3pGXuX3kJPPbYY3PCCSekrq4uw4YNy5QpU9K5c+dsvPHG6d69+z9dv1+/fh/62L17907Hjh2be+QPZdq0aenbt28l524JSt6/yt1ramoqOe8ydXV1/9bPaGtT8v5V7l5bW5vJkydXcu6VTUa2PiXvnshIGVGmqvb/oHys9OmgW2yxRRoaGvKHP/whm2yySb74xS9mypQpueuuu/LlL3/5Xdf/xCc+UcGUALDqyUgAVpbK3x109913z6hRo7LzzjunV69eWbBgQSZPnpwvfelLVY8GAJWSkQCsDJWXwD322CPPPfdcdtpppyTJTjvtlO7du6e2trbiyQCgWjISgJWh8o+I2G677TJz5szlX5955pnL//mcc85Z/s/vvA4AlEBGArAyVP5IIAAAAKuOEggAAFAQJRAAAKAgSiAAAEBBlEAAAICCKIEAAAAFUQIBAAAKogQCAAAURAkEAAAoiBIIAABQECUQAACgIEogAABAQZRAAACAgiiBAAAABVECAQAACqIEAgAAFEQJBAAAKIgSCAAAUBAlEAAAoCBKIAAAQEGUQAAAgIIogQAAAAVRAgEAAAqiBAIAABRECQQAACiIEggAAFAQJRAAAKAgSiAAAEBBlEAAAICCKIEAAAAFUQIBAAAKogQCAAAURAkEAAAoiBIIAABQECUQAACgIEogAABAQZRAAACAgiiBAAAABVECAQAACqIEAgAAFEQJBAAAKIgSCAAAUBAlEAAAoCBKIAAAQEGUQAAAgIIogQAAAAVRAgEAAAqiBAIAABRECQQAACiIEggAAFAQJRAAAKAgSiAAAEBBlEAAAICCKIEAAAAF+cASOHXq1AwePHhVzAIAqw35CMDqyiOBAAAABWn371y5rq4uxx13XEaPHp1nnnkm48ePT5s2bdKtW7eceuqp2XTTTXPSSSelS5cumTlzZl5++eVsscUWGTFiRDp37pxtttkmhx9+eKZMmZK5c+dm+PDh+eY3v5kkufbaa3P11VensbEx66yzTk499dT06tXrfY8HAC2BfARgdfKhHwl86KGHcvLJJ2fMmDFZvHhxLrnkklx55ZW56aabMnjw4Hz3u99NU1NTkmTGjBkZN25cbr311rz00ku5/fbbkyT19fVZd911M3HixJx//vk5++yzs3jx4jz88MOZNGlSJkyYkEmTJmX48OE5+uijl597RccDgKrJRwBWNx/qkcCXX345RxxxRIYOHZrPfvazOffcc7PXXntlvfXWS5IccMABOeuss/Liiy8mSXbZZZd06NAhSbL55pvnjTfeWH6s3XbbLUmy9dZbp76+PgsXLszdd9+d559/PkOGDFl+vfnz5+f111//wOOtyIwZMz7MaivNtGnTKj1/1Urev6rd6+rqKjlvS5uhSiXvX+ruq2M+JjKySiXvnsjIUpW8e9Iy9/9QJbBt27a5+OKLc9RRR2XPPfdMY2Pju67T1NSUJUuWJEk6deq0/PKamprl94AmSceOHZdfvuzfa2xszH777Zfjjz8+SdLY2Ji5c+dm7bXX/sDjrUjv3r2Xn2tVmzZtWvr27VvJuVuCkvevcvdlP1NVqaurS79+/SqdoUol71/l7rW1tZk8eXIl505Wz3xMZGRVSt49kZEyokxV7f9B+fihng7avXv39OnTJyeeeGJOOOGE9OvXL7feemvmzZuXJLnuuuuyzjrrpGfPnh9pyP79++eWW27J3LlzkyRXX311DjnkkI90LABYVeQjAKujf+uNYfbff//87ne/y3333Zdhw4blkEMOSWNjY9Zbb72MHTs2bdp8tDcb7d+/fw477LAceuihqampSZcuXXLBBRdUfq8NAHwY8hGA1UpTK7No0aKmurq6pkWLFlU2Q11dXWXnbglK3r/K3ZNU+lddXV3lM9i/vN1ra2srv81fncjIapW8e1OTjKx6BruXtf8H5aPPCQQAACiIEggAAFAQJRAAAKAgSiAAAEBBlEAAAICCKIEAAAAFUQIBAAAKogQCAAAURAkEAAAoiBIIAABQECUQAACgIEogAABAQZRAAACAgiiBAAAABVECAQAACqIEAgAAFEQJBAAAKIgSCAAAUBAlEAAAoCBKIAAAQEGUQAAAgIIogQAAAAVRAgEAAAqiBAIAABRECQQAACiIEggAAFAQJRAAAKAgSiAAAEBBlEAAAICCKIEAAAAFUQIBAAAKogQCAAAURAkEAAAoiBIIAABQECUQAACgIEogAABAQZRAAACAgiiBAAAABVECAQAACqIEAgAAFEQJBAAAKIgSCAAAUBAlEAAAoCBKIAAAQEGUQAAAgIIogQAAAAVRAgEAAAqiBAIAABRECQQAACiIEggAAFAQJRAAAKAgSiAAAEBBlEAAAICCKIEAAAAFWSklcOrUqRk8eHCzHGvXXXfN9OnTm+VYAFA1GQlA1TwSCAAAUJCVVgIXLlyY73//+9lvv/1y0EEHZdasWTnppJMybty45dd559ezZs3KQQcdlL333jv77LNPbr311uXXu+aaa3LAAQdk4MCB+fnPf76yRgaAVUJGAlCllVYCZ8+enWHDhuXGG2/M4MGDc8IJJ7zv9Y899tjsueeeueWWW3LxxRdn9OjRWbBgQZKkY8eOuf7663Pttdfm0ksvzezZs1fW2ACw0slIAKrUbmUdeIsttkifPn2SJPvvv39+8pOfpEePHu953ddffz1PPfVUvva1ryVJamtrc+eddy7/82WvnejevXu6deuW1157LbW1te97/hkzZjTHGh/ZtGnTKj1/1Urev6rd6+rqKjlvS5uhSiXvX/LuH4WMlBGlkpFlKnn3pGXuv9JKYJs2//wgY01NTdZaa600NTUtv6yhoeHtIdq1W36dZZ577rlssMEG//Tny67zzmOsSO/evdOxY8ePvsDHMG3atPTt27eSc7cEJe9f5e7v/PmpQl1dXfr161fpDFUqef8qd6+trc3kyZMrOffHISNlRIlkpIwoUVX7f1A+rrSng86cOTNPPvlkkrdfr9C3b9+su+66y+99nDNnTh5++OEkSZcuXbL11ltn0qRJSd5+mszQoUPz5ptvrqzxAKAyMhKAKq20RwI//elP54ILLsgLL7yQrl275pxzzkmbNm1y3HHH5ctf/nI22mij7LDDDsuvP2rUqJx22mkZP358ampqctZZZ6V79+4razwAqIyMBKBKK6UEbr/99it8+HHChAnveXnPnj1z6aWXvuvyu+66632/BoDViYwEoGo+JxAAAKAgSiAAAEBBlEAAAICCKIEAAAAFUQIBAAAKogQCAAAURAkEAAAoiBIIAABQECUQAACgIEogAABAQZRAAACAgiiBAAAABVECAQAACqIEAgAAFEQJBAAAKIgSCAAAUBAlEAAAoCBKIAAAQEGUQAAAgIIogQAAAAVRAgEAAAqiBAIAABRECQQAACiIEggAAFAQJRAAAKAgSiAAAEBBlEAAAICCKIEAAAAFUQIBAAAKogQCAAAURAkEAAAoiBIIAABQECUQAACgIEogAABAQZRAAACAgiiBAAAABVECAQAACqIEAgAAFEQJBAAAKIgSCAAAUBAlEAAAoCBKIAAAQEGUQAAAgIIogQAAAAVRAgEAAAqiBAIAABRECQQAACiIEggAAFAQJRAAAKAgSiAAAEBBlEAAAICCKIEAAAAFUQIBAAAKogQCAAAURAkEAAAoSLOVwKlTp2bw4MHNdTgAaDVkJAAtiUcCAQAACtKuuQ9YX1+fkSNH5pFHHsnSpUuz1VZb5ZRTTkmXLl1y1VVXZeLEiWnfvn06duyY008/PZtttlnmzJmT008/PbNnz05DQ0P23nvvHHHEEXnxxRczbNiwDBgwII8//njmz5+f448/PnvssUdzjw0AK52MBKAlqGlqampqjgNNnTo1Z5xxRvbcc8+89dZbOeGEE1JTU5PRo0dn/vz5OfXUU/Mf//Efueuuu9KjR49MmjQpixcvzje+8Y0cfPDBGTZsWHbdddcsXrw4hx12WIYMGZJtt902u+22W8aMGZMvfvGL+d3vfpdzzjknf/zjH1c4x+LFizNjxozmWAmA1UTv3r3TsWPHqsdYIRkJQBVWlI/N/kjg3XffnTfffDMPPPBAkqShoSFdu3ZN27Zts+eee2bIkCEZOHBg+vfvnwEDBmThwoV55JFH8sYbb+S8885LkixcuDBPPfVUtt1227Rv3z4DBgxIkmy11VZ5/fXXP9QcVf5CMG3atPTt27eSc7cEJe9f5e41NTWVnHeZurq69OvXr9IZqlTy/lXuXltbm8mTJ1dy7o9CRsqIUndPZKSMKFNV+39QPjZ7CWxsbMx///d/Lw+lt956K4sXL06SjBw5Mk8//XQeeOCBXHzxxbnxxhtz1llnpampKRMnTswaa6yRJJk3b146duyY//3f/0379u3Tps3bL12s+gcYAD4OGQlAS9DsbwzTv3//TJgwIfX19WlsbMypp56a0aNHZ968eRkwYEDWWWedDBs2LMccc0ymT5+eLl265HOf+1wuu+yyJMn8+fMzdOjQ/OEPf2ju0QCgUjISgJag2R8JPOqoozJixIjsv//+Wbp0abbccsucdNJJ6dKlS4488sgMGzYsnTp1Stu2bXPmmWcmefvezzPOOCP77LNP6uvrM3jw4Oy777558cUXm3s8AKiMjASgJWi2Erj99tvn5ptvTpL8+Mc/fs/rDBkyJEOGDHnX5RtttFHGjh37npc/+uijK/waAFYHMhKAlsTnBAIAABRECQQAACiIEggAAFAQJRAAAKAgSiAAAEBBlEAAAICCKIEAAAAFUQIBAAAKogQCAAAURAkEAAAoiBIIAABQECUQAACgIEogAABAQZRAAACAgiiBAAAABVECAQAACqIEAgAAFEQJBAAAKIgSCAAAUBAlEAAAoCBKIAAAQEGUQAAAgIIogQAAAAVRAgEAAAqiBAIAABRECQQAACiIEggAAFAQJRAAAKAgSiAAAEBBlEAAAICCKIEAAAAFUQIBAAAKogQCAAAURAkEAAAoiBIIAABQECUQAACgIEogAABAQZRAAACAgiiBAAAABVECAQAACqIEAgAAFEQJBAAAKIgSCAAAUBAlEAAAoCBKIAAAQEGUQAAAgIIogQAAAAVRAgEAAAqiBAIAABRECQQAACiIEggAAFAQJRAAAKAgSiAAAEBBlEAAAICCfGAJnDp1agYPHrwqZgGA1YZ8BGB15ZFAAACAgrT7d65cV1eX4447LqNHj84zzzyT8ePHp02bNunWrVtOPfXUbLrppjnppJPSpUuXzJw5My+//HK22GKLjBgxIp07d84222yTww8/PFOmTMncuXMzfPjwfPOb30ySXHvttbn66qvT2NiYddZZJ6eeemp69er1vscDgJZAPgKwOvnQjwQ+9NBDOfnkkzNmzJgsXrw4l1xySa688srcdNNNGTx4cL773e+mqakpSTJjxoyMGzcut956a1566aXcfvvtSZL6+vqsu+66mThxYs4///ycffbZWbx4cR5++OFMmjQpEyZMyKRJkzJ8+PAcffTRy8+9ouMBQNXkIwCrmw/1SODLL7+cI444IkOHDs1nP/vZnHvuudlrr72y3nrrJUkOOOCAnHXWWXnxxReTJLvssks6dOiQJNl8883zxhtvLD/WbrvtliTZeuutU19fn4ULF+buu+/O888/nyFDhiy/3vz58/P6669/4PFWZMaMGR9mtZVm2rRplZ6/aiXvX9XudXV1lZy3pc1QpZL3L3X31TEfExlZpZJ3T2RkqUrePWmZ+3+oEti2bdtcfPHFOeqoo7LnnnumsbHxXddpamrKkiVLkiSdOnVafnlNTc3ye0CTpGPHjssvX/bvNTY2Zr/99svxxx+fJGlsbMzcuXOz9tprf+DxVqR3797Lz7WqTZs2LX379q3k3C1ByftXufuyn6mq1NXVpV+/fpXOUKWS969y99ra2kyePLmScyerZz4mMrIqJe+eyEgZUaaq9v+gfPxQTwft3r17+vTpkxNPPDEnnHBC+vXrl1tvvTXz5s1Lklx33XVZZ5110rNnz480ZP/+/XPLLbdk7ty5SZKrr746hxxyyEc6FgCsKvIRgNXRv/XGMPvvv39+97vf5b777suwYcNyyCGHpLGxMeutt17Gjh2bNm0+2puN9u/fP4cddlgOPfTQ1NTUpEuXLrngggsqv9cGAD4M+QjAaqWplVm0aFFTXV1d06JFiyqboa6urrJztwQl71/l7kkq/auurq7yGexf3u61tbWV3+avTmRktUrevalJRlY9g93L2v+D8tHnBAIAABRECQQAACiIEggAAFAQJRAAAKAgSiAAAEBBlEAAAICCKIEAAAAFUQIBAAAKogQCAAAURAkEAAAoiBIIAABQECUQAACgIEogAABAQZRAAACAgiiBAAAABVECAQAACqIEAgAAFEQJBAAAKIgSCAAAUBAlEAAAoCBKIAAAQEGUQAAAgIIogQAAAAVRAgEAAAqiBAIAABRECQQAACiIEggAAFAQJRAAAKAgSiAAAEBBlEAAAICCKIEAAAAFUQIBAAAKogQCAAAURAkEAAAoiBIIAABQECUQAACgIEogAABAQZRAAACAgiiBAAAABVECAQAACqIEAgAAFEQJBAAAKIgSCAAAUBAlEAAAoCBKIAAAQEGUQAAAgIIogQAAAAVRAgEAAAqiBAIAABRECQQAACiIEggAAFAQJRAAAKAgSiAAAEBBlEAAAICCKIEAAAAFWSklcOrUqRk8eHCzHGvXXXfN9OnTm+VYAFA1GQlA1TwSCAAAUJCVVgIXLlyY73//+9lvv/1y0EEHZdasWTnppJMybty45dd559ezZs3KQQcdlL333jv77LNPbr311uXXu+aaa3LAAQdk4MCB+fnPf76yRgaAVUJGAlCldivrwLNnz87IkSPTp0+fXHPNNTnhhBPSq1evFV7/2GOPzVe/+tUceOCBmT17dg466KB84QtfSJJ07Ngx119/fV555ZXsuuuuGTJkSGpra9/3/DNmzGjWff5d06ZNq/T8VSt5/6p2r6urq+S8LW2GKpW8f8m7fxQyUkaUSkaWqeTdk5a5/0orgVtssUX69OmTJNl///3zk5/8JD169HjP677++ut56qmn8rWvfS1JUltbmzvvvHP5ny977UT37t3TrVu3vPbaax8YcL17907Hjh2bY5V/27Rp09K3b99Kzt0SlLx/lbvX1NRUct5l6urq0q9fv0pnqFLJ+1e5e21tbSZPnlzJuT8OGSkjSiQjZUSJqtr/g/JxpT0dtE2bfz50TU1N1lprrTQ1NS2/rKGhIUnSrl275ddZ5rnnnsuiRYv+6c+XXeedxwCA1Y2MBKBKK60Ezpw5M08++WSSt1+v0Ldv36y77rrLn4IyZ86cPPzww0mSLl26ZOutt86kSZOSvP00maFDh+bNN99cWeMBQGVkJABVWmlPB/30pz+dCy64IC+88EK6du2ac845J23atMlxxx2XL3/5y9loo42yww47LL/+qFGjctppp2X8+PGpqanJWWedle7du6+s8QCgMjISgCqtlBK4/fbbr/A5qBMmTHjPy3v27JlLL730XZffdddd7/s1AKxOZCQAVfM5gQAAAAVRAgEAAAqiBAIAABRECQQAACiIEggAAFAQJRAAAKAgSiAAAEBBlEAAAICCKIEAAAAFUQIBAAAKogQCAAAURAkEAAAoiBIIAABQECUQAACgIEogAABAQZRAAACAgiiBAAAABVECAQAACqIEAgAAFEQJBAAAKIgSCAAAUBAlEAAAoCBKIAAAQEGUQAAAgIIogQAAAAVRAgEAAAqiBAIAABRECQQAACiIEggAAFAQJRAAAKAgSiAAAEBBlEAAAICCKIEAAAAFUQIBAAAKogQCAAAURAkEAAAoiBIIAABQECUQAACgIEogAABAQZRAAACAgiiBAAAABVECAQAACqIEAgAAFEQJBAAAKIgSCAAAUBAlEAAAoCBKIAAAQEGUQAAAgIIogQAAAAVRAgEAAAqiBAIAABRECQQAACiIEggAAFAQJRAAAKAgzVYCp06dmsGDBzfX4QCg1ZCRALQkHgkEAAAoSLvmPmB9fX1GjhyZRx55JEuXLs1WW22VU045JV26dMlVV12ViRMnpn379unYsWNOP/30bLbZZpkzZ05OP/30zJ49Ow0NDdl7771zxBFH5MUXX8ywYcMyYMCAPP7445k/f36OP/747LHHHs09NgCsdDISgJag2R8JvPjii9O2bdtcf/31uemmm9KjR4+MHDkyS5cuzU9/+tNccsklue666/L1r38906ZNS5Icf/zx+c///M9cf/31+e1vf5sHHnggt956a5LkhRdeSP/+/fPb3/42//Vf/5Wf/vSnzT0yAKwSMhKAlqCmqampqTkONHXq1Jxxxhnp1KlT3nzzzXTq1ClJ0tDQkK5du2b8+PE57rjj8qc//SkDBw5M//79M2DAgCxevDh9+/bN5ptvvvxYCxcuzKBBg/L1r389e+65Z5544om0adMmL7zwQvbdd988+uijK5xj8eLFmTFjRnOsBMBqonfv3unYsWPVY6yQjASgCivKx2Z/OmhjY2P++7//OwMGDEiSvPXWW1m8eHGSZOTIkXn66afzwAMP5OKLL86NN96Ys846K01NTZk4cWLWWGONJMm8efPSsWPH/O///m/at2+fNm3efsCypqbmQ89R5S8E06ZNS9++fSs5d0tQ8v5V7v7v/HysDHV1denXr1+lM1Sp5P2r3L22tjaTJ0+u5NwfhYyUEaXunshIGVGmqvb/oHxs9qeD9u/fPxMmTEh9fX0aGxtz6qmnZvTo0Zk3b14GDBiQddZZJ8OGDcsxxxyT6dOnp0uXLvnc5z6Xyy67LEkyf/78DB06NH/4wx+aezQAqJSMBKAlaPZHAo866qiMGDEi+++/f5YuXZott9wyJ510Urp06ZIjjzwyw4YNS6dOndK2bduceeaZSd6+9/OMM87IPvvsk/r6+gwePDj77rtvXnzxxeYeDwAqIyMBaAmarQRuv/32ufnmm5MkP/7xj9/zOkOGDMmQIUPedflGG22UsWPHvufl73xtw79+DQCrAxkJQEvicwIBAAAKogQCAAAURAkEAAAoiBIIAABQECUQAACgIEogAABAQZRAAACAgiiBAAAABVECAQAACqIEAgAAFEQJBAAAKIgSCAAAUBAlEAAAoCBKIAAAQEGUQAAAgIIogQAAAAVRAgEAAAqiBAIAABRECQQAACiIEggAAFAQJRAAAKAgSiAAAEBBlEAAAICCKIEAAAAFUQIBAAAKogQCAAAURAkEAAAoiBIIAABQECUQAACgIEogAABAQZRAAACAgiiBAAAABVECAQAACqIEAgAAFEQJBAAAKIgSCAAAUBAlEAAAoCBKIAAAQEGUQAAAgIIogQAAAAVRAgEAAAqiBAIAABRECQQAACiIEggAAFAQJRAAAKAgSiAAAEBBlEAAAICCKIEAAAAFUQIBAAAKogQCAAAURAkEAAAoiBIIAABQECUQAACgIEogAABAQZRAAACAgjRbCVywYEGuuuqqPPHEE811yCTJz372szz//PPNekwAWFXkIwAtTbuPe4DHH38811xzTR588MHstttu2X333XPXXXfloosuSkNDQzp16pQTTzwx2223XRoaGnLOOefkwQcfTNu2bbPtttvm5JNPTpcuXXLVVVdl4sSJad++fTp27JjTTz89m222Wbp165bvfve76dq1a77xjW9k9913T4cOHZpjdwBYaeQjAC3VR34kcPr06fnKV76S8847L/3798/vfve7nHLKKVm4cGF+/vOf5+KLL86kSZNyxhln5Hvf+14WLlyYiy66KHPnzs2NN96YG2+8MY2NjTn33HOzdOnS/PSnP80ll1yS6667Ll//+tczbdq0JMm3v/3t3HzzzTnmmGNy//33Z9CgQZkwYUKz/QcAgOYkHwFo6T7yI4Ft2rRJmzZtUlNTk5qamuWXT5kyJXPnzs2wYcOWX1ZTU5O//e1vuffee/PDH/4w7du3T5IcdNBB+e53v5u2bdtmzz33zJAhQzJw4MD0798/AwYM+KfztW3bdvk527T54O46Y8aMj7pas1gW0qUqef+qdq+rq6vkvC1thiqVvH/Ju/+rlp6PiYysUsm7JzKyVCXvnrTQ/Zs+pscff7zp5JNPbvriF7/YdPbZZzf94he/aPrBD37wT9f5+9//3rRkyZKm/fffv2nKlCnLL58+fXrTzjvvvPzrmTNnNl122WVN3/jGN5q+//3vNzU1NTVdccUVTfvss0/TQQcd1HTLLbc01dfXv+88ixYtaqqrq2tatGjRx13tI6urq6vs3C1ByftXuXuSSv+qq6urfAb7l7d7bW1t5bf5K9LS8rGpSUZWreTdm5pkZNUz2L2s/T8oHz/2G8Nsu+22+elPf5obb7wxG220UT7/+c9nypQp+Z//+Z8kyT333JN99903ixYtyi677JKrr746DQ0NaWxszIQJE7Lzzjtn3rx5GTBgQNZZZ50MGzYsxxxzTKZPn54kmT17ds4777xceeWV2WuvvZbfSwoALZl8BKCl+thvDLPMmmuumW9961tJktNPPz3HHntsmpqa0q5du1x00UXp3LlzjjzyyIwYMSJf+cpXsmTJkmy77bY59dRTs9Zaa+XII4/MsGHD0qlTp7Rt2zZnnnlmkuTEE09srhEBYJWTjwC0NM1WAt9p0KBBGTRo0Lsu79SpU3784x+/578zZMiQDBkyZGWMAwAtgnwEoCXwYfEAAAAFUQIBAAAKogQCAAAURAkEAAAoiBIIAABQECUQAACgIEogAABAQZRAAACAgiiBAAAABVECAQAACqIEAgAAFEQJBAAAKIgSCAAAUBAlEAAAoCBKIAAAQEGUQAAAgIIogQAAAAVRAgEAAAqiBAIAABRECQQAACiIEggAAFAQJRAAAKAgSiAAAEBBlEAAAICCKIEAAAAFUQIBAAAK0q7qAZpbU1NTkqS+vr7SORYvXlzp+atW8v5V7V5bW1vJeVvaDFUqef+qdu/Ro0eS/3/bz/uTkdUrefdERpaq5N2Tavb/oHysaWplyfnmm2/m6aefrnoMAFahzTffPGuuuWbVY7R4MhKgLCvKx1ZXAhsbG/PWW2+lffv2qampqXocAFaipqamNDQ0pHPnzmnTxiscPoiMBCjDB+VjqyuBAAAArJi7TQEAAAqiBAIAABRECQQAACiIEggAAFCQ/weVwNm9JagAJwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1080x1800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_count 1    self.capacity  20\n",
      "0  ------------------------------------------------\n",
      "DecoderLayer@trg4\n",
      "[1, 1, 64]\n",
      "src = ['we', 'can', 'read', 'newspaper']\n",
      "old attention torch.Size([1, 2, 6, 6])\n",
      "old attention tensor([[[[2.8662e-03, 3.1555e-03, 8.8513e-01, 1.3033e-02, 8.7834e-02,\n",
      "           7.9787e-03],\n",
      "          [3.1984e-04, 4.9939e-04, 1.7292e-04, 8.6531e-03, 9.4232e-01,\n",
      "           4.8040e-02],\n",
      "          [2.2352e-02, 2.6550e-01, 2.7607e-02, 1.4946e-01, 4.9245e-01,\n",
      "           4.2631e-02],\n",
      "          [3.4184e-02, 8.2106e-04, 1.7374e-01, 1.0145e-02, 7.7066e-01,\n",
      "           1.0451e-02],\n",
      "          [4.0888e-01, 2.9409e-01, 6.8118e-02, 1.7671e-01, 2.9018e-02,\n",
      "           2.3189e-02],\n",
      "          [1.1868e-02, 2.6133e-03, 5.4917e-01, 4.7117e-02, 3.8177e-01,\n",
      "           7.4678e-03]],\n",
      "\n",
      "         [[3.6924e-02, 5.9279e-01, 1.9647e-01, 1.1749e-02, 1.2523e-01,\n",
      "           3.6844e-02],\n",
      "          [2.5634e-03, 3.8834e-04, 1.3541e-01, 4.8259e-03, 8.5427e-01,\n",
      "           2.5419e-03],\n",
      "          [7.0258e-03, 4.3306e-03, 9.8195e-01, 4.1817e-04, 5.9990e-03,\n",
      "           2.7749e-04],\n",
      "          [2.0626e-01, 8.9311e-02, 9.0191e-02, 8.8590e-03, 7.2621e-02,\n",
      "           5.3276e-01],\n",
      "          [5.1982e-03, 4.2806e-01, 1.6015e-02, 3.1868e-01, 1.3328e-01,\n",
      "           9.8768e-02],\n",
      "          [1.3509e-02, 1.2431e-02, 1.3626e-02, 8.6805e-01, 2.9006e-02,\n",
      "           6.3375e-02]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 6, 6])\n",
      "old attention tensor([[[[0.0525, 0.0207, 0.2514, 0.2725, 0.3431, 0.0597],\n",
      "          [0.0465, 0.1068, 0.0398, 0.1822, 0.3665, 0.2581],\n",
      "          [0.2484, 0.1634, 0.0373, 0.1073, 0.2661, 0.1774],\n",
      "          [0.1317, 0.2413, 0.0674, 0.3429, 0.0830, 0.1337],\n",
      "          [0.0755, 0.1981, 0.1845, 0.0287, 0.4011, 0.1121],\n",
      "          [0.0509, 0.0390, 0.4558, 0.1249, 0.2858, 0.0436]],\n",
      "\n",
      "         [[0.1615, 0.2541, 0.3401, 0.0832, 0.0493, 0.1118],\n",
      "          [0.0599, 0.5461, 0.1069, 0.0196, 0.2267, 0.0407],\n",
      "          [0.4315, 0.1338, 0.2521, 0.0455, 0.0504, 0.0866],\n",
      "          [0.1531, 0.1554, 0.0876, 0.0975, 0.4532, 0.0532],\n",
      "          [0.8220, 0.0685, 0.0185, 0.0247, 0.0337, 0.0326],\n",
      "          [0.0362, 0.0433, 0.1028, 0.2864, 0.2445, 0.2869]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 6, 6])\n",
      "old attention tensor([[[[0.1095, 0.5032, 0.2055, 0.0492, 0.0714, 0.0613],\n",
      "          [0.1457, 0.1405, 0.1508, 0.1882, 0.1189, 0.2558],\n",
      "          [0.1752, 0.0443, 0.0293, 0.0998, 0.1414, 0.5100],\n",
      "          [0.1141, 0.1839, 0.0409, 0.0537, 0.2797, 0.3276],\n",
      "          [0.0589, 0.1122, 0.1284, 0.0140, 0.4312, 0.2553],\n",
      "          [0.2412, 0.4300, 0.0418, 0.0730, 0.1356, 0.0785]],\n",
      "\n",
      "         [[0.0742, 0.0281, 0.5755, 0.2785, 0.0343, 0.0094],\n",
      "          [0.1042, 0.1690, 0.1719, 0.2633, 0.1080, 0.1836],\n",
      "          [0.0245, 0.0076, 0.8076, 0.1287, 0.0269, 0.0048],\n",
      "          [0.1069, 0.0902, 0.3977, 0.3163, 0.0596, 0.0292],\n",
      "          [0.1398, 0.0258, 0.2838, 0.2891, 0.1568, 0.1047],\n",
      "          [0.1911, 0.1312, 0.0347, 0.2190, 0.2392, 0.1848]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 6])\n",
      "old attention tensor([[[[0.2855, 0.5263, 0.0433, 0.0781, 0.0283, 0.0385]],\n",
      "\n",
      "         [[0.1361, 0.6017, 0.0773, 0.0733, 0.0857, 0.0259]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 6])\n",
      "old attention tensor([[[[0.2687, 0.5193, 0.1649, 0.0188, 0.0248, 0.0035]],\n",
      "\n",
      "         [[0.0210, 0.9208, 0.0056, 0.0222, 0.0193, 0.0110]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 6])\n",
      "old attention tensor([[[[0.1071, 0.6825, 0.1110, 0.0364, 0.0375, 0.0254]],\n",
      "\n",
      "         [[0.0205, 0.0284, 0.0443, 0.0636, 0.1755, 0.6678]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0548, 0.9452]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0098, 0.9902]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0548, 0.9452]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0098, 0.9902]]]])\n",
      "old attention torch.Size([1, 2, 2, 6])\n",
      "old attention tensor([[[[0.2855, 0.5263, 0.0433, 0.0781, 0.0283, 0.0385],\n",
      "          [0.0710, 0.0317, 0.1855, 0.1371, 0.2489, 0.3258]],\n",
      "\n",
      "         [[0.1361, 0.6017, 0.0773, 0.0733, 0.0857, 0.0259],\n",
      "          [0.0845, 0.0070, 0.6432, 0.0666, 0.1824, 0.0163]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0506, 0.9494]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.4561, 0.5439]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0506, 0.9494]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.4561, 0.5439]]]])\n",
      "old attention torch.Size([1, 2, 2, 6])\n",
      "old attention tensor([[[[0.2687, 0.5193, 0.1649, 0.0188, 0.0248, 0.0035],\n",
      "          [0.2176, 0.1373, 0.1551, 0.2337, 0.1714, 0.0849]],\n",
      "\n",
      "         [[0.0210, 0.9208, 0.0056, 0.0222, 0.0193, 0.0110],\n",
      "          [0.1509, 0.0966, 0.6470, 0.0381, 0.0365, 0.0310]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.4691, 0.5309]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0822, 0.9178]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.4691, 0.5309]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0822, 0.9178]]]])\n",
      "old attention torch.Size([1, 2, 2, 6])\n",
      "old attention tensor([[[[0.1071, 0.6825, 0.1110, 0.0364, 0.0375, 0.0254],\n",
      "          [0.0281, 0.5835, 0.2230, 0.0633, 0.0644, 0.0377]],\n",
      "\n",
      "         [[0.0205, 0.0284, 0.0443, 0.0636, 0.1755, 0.6678],\n",
      "          [0.0064, 0.0096, 0.1087, 0.0495, 0.3566, 0.4693]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.0548, 0.9452, 0.0000],\n",
      "          [0.0140, 0.1149, 0.8711]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.0098, 0.9902, 0.0000],\n",
      "          [0.0047, 0.0052, 0.9901]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 6])\n",
      "old attention tensor([[[[0.3358, 0.4333, 0.0529, 0.1137, 0.0267, 0.0377],\n",
      "          [0.1033, 0.0886, 0.1095, 0.1369, 0.1742, 0.3875],\n",
      "          [0.0522, 0.1617, 0.1267, 0.2330, 0.0659, 0.3604]],\n",
      "\n",
      "         [[0.0830, 0.4042, 0.0705, 0.1583, 0.2046, 0.0793],\n",
      "          [0.0927, 0.0405, 0.6579, 0.0556, 0.1416, 0.0117],\n",
      "          [0.1735, 0.3815, 0.0696, 0.0771, 0.1292, 0.1691]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.0668, 0.9332, 0.0000],\n",
      "          [0.0612, 0.1668, 0.7719]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.6681, 0.3319, 0.0000],\n",
      "          [0.4616, 0.0428, 0.4956]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 6])\n",
      "old attention tensor([[[[0.2622, 0.3906, 0.2066, 0.0661, 0.0640, 0.0106],\n",
      "          [0.2804, 0.1973, 0.2476, 0.1423, 0.1213, 0.0111],\n",
      "          [0.0384, 0.0991, 0.2479, 0.1516, 0.4176, 0.0454]],\n",
      "\n",
      "         [[0.0390, 0.8966, 0.0061, 0.0392, 0.0134, 0.0057],\n",
      "          [0.1892, 0.4641, 0.0881, 0.1639, 0.0222, 0.0726],\n",
      "          [0.0893, 0.1805, 0.0160, 0.5730, 0.0352, 0.1060]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.2587, 0.7413, 0.0000],\n",
      "          [0.3651, 0.5356, 0.0993]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.0646, 0.9354, 0.0000],\n",
      "          [0.0448, 0.4705, 0.4847]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 6])\n",
      "old attention tensor([[[[0.1202, 0.6328, 0.1008, 0.0591, 0.0515, 0.0355],\n",
      "          [0.1378, 0.4237, 0.1250, 0.1588, 0.0767, 0.0781],\n",
      "          [0.1815, 0.2714, 0.1628, 0.2338, 0.0814, 0.0691]],\n",
      "\n",
      "         [[0.0281, 0.0183, 0.0535, 0.1081, 0.3300, 0.4619],\n",
      "          [0.0192, 0.0106, 0.1133, 0.1277, 0.2978, 0.4314],\n",
      "          [0.0291, 0.0136, 0.0896, 0.1705, 0.4252, 0.2719]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0548, 0.9452, 0.0000, 0.0000],\n",
      "          [0.0140, 0.1149, 0.8711, 0.0000],\n",
      "          [0.3395, 0.2290, 0.2557, 0.1758]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0098, 0.9902, 0.0000, 0.0000],\n",
      "          [0.0047, 0.0052, 0.9901, 0.0000],\n",
      "          [0.0355, 0.6121, 0.2033, 0.1491]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 6])\n",
      "old attention tensor([[[[0.3183, 0.4821, 0.0464, 0.0933, 0.0260, 0.0338],\n",
      "          [0.0994, 0.0982, 0.1044, 0.1198, 0.1890, 0.3893],\n",
      "          [0.0490, 0.1880, 0.1206, 0.2020, 0.0720, 0.3685],\n",
      "          [0.2804, 0.1074, 0.1988, 0.1610, 0.1456, 0.1068]],\n",
      "\n",
      "         [[0.0667, 0.3461, 0.0524, 0.1862, 0.2454, 0.1032],\n",
      "          [0.0873, 0.0380, 0.5956, 0.0727, 0.1896, 0.0168],\n",
      "          [0.1398, 0.3166, 0.0502, 0.0926, 0.1594, 0.2413],\n",
      "          [0.0472, 0.0048, 0.3571, 0.1123, 0.4538, 0.0248]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0589, 0.9411, 0.0000, 0.0000],\n",
      "          [0.0424, 0.1430, 0.8146, 0.0000],\n",
      "          [0.0037, 0.0225, 0.4681, 0.5057]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.6852, 0.3148, 0.0000, 0.0000],\n",
      "          [0.4111, 0.0361, 0.5528, 0.0000],\n",
      "          [0.1177, 0.0952, 0.3701, 0.4170]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 6])\n",
      "old attention tensor([[[[0.2982, 0.3714, 0.1682, 0.0746, 0.0704, 0.0171],\n",
      "          [0.2901, 0.1555, 0.2050, 0.1910, 0.1406, 0.0178],\n",
      "          [0.0317, 0.0650, 0.1833, 0.1915, 0.4639, 0.0647],\n",
      "          [0.2066, 0.1097, 0.3913, 0.1740, 0.0947, 0.0236]],\n",
      "\n",
      "         [[0.0405, 0.9117, 0.0120, 0.0200, 0.0126, 0.0032],\n",
      "          [0.2276, 0.3356, 0.2168, 0.1264, 0.0267, 0.0669],\n",
      "          [0.1263, 0.1736, 0.0456, 0.4831, 0.0470, 0.1245],\n",
      "          [0.2582, 0.3655, 0.0513, 0.1988, 0.0471, 0.0792]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.3068, 0.6932, 0.0000, 0.0000],\n",
      "          [0.4431, 0.4327, 0.1243, 0.0000],\n",
      "          [0.1545, 0.1539, 0.3642, 0.3274]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0485, 0.9515, 0.0000, 0.0000],\n",
      "          [0.0303, 0.3651, 0.6046, 0.0000],\n",
      "          [0.0155, 0.1005, 0.4775, 0.4065]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 6])\n",
      "old attention tensor([[[[0.0834, 0.6615, 0.1149, 0.0508, 0.0566, 0.0328],\n",
      "          [0.0915, 0.3310, 0.1605, 0.1973, 0.1088, 0.1109],\n",
      "          [0.1298, 0.1905, 0.1926, 0.2938, 0.1068, 0.0864],\n",
      "          [0.0981, 0.2887, 0.1539, 0.2429, 0.1072, 0.1093]],\n",
      "\n",
      "         [[0.0262, 0.0191, 0.0534, 0.0734, 0.3872, 0.4407],\n",
      "          [0.0198, 0.0126, 0.1537, 0.0897, 0.3476, 0.3767],\n",
      "          [0.0311, 0.0177, 0.1076, 0.1300, 0.4829, 0.2307],\n",
      "          [0.0141, 0.0134, 0.2210, 0.0658, 0.3852, 0.3004]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0548, 0.9452, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0140, 0.1149, 0.8711, 0.0000, 0.0000],\n",
      "          [0.3395, 0.2290, 0.2557, 0.1758, 0.0000],\n",
      "          [0.0032, 0.0020, 0.0053, 0.0019, 0.9876]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0098, 0.9902, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0047, 0.0052, 0.9901, 0.0000, 0.0000],\n",
      "          [0.0355, 0.6121, 0.2033, 0.1491, 0.0000],\n",
      "          [0.0017, 0.0124, 0.0310, 0.1080, 0.8468]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 6])\n",
      "old attention tensor([[[[0.3301, 0.5258, 0.0351, 0.0656, 0.0205, 0.0228],\n",
      "          [0.1235, 0.1268, 0.1002, 0.1062, 0.1937, 0.3495],\n",
      "          [0.0615, 0.2627, 0.1131, 0.1743, 0.0702, 0.3182],\n",
      "          [0.3370, 0.1312, 0.1789, 0.1316, 0.1368, 0.0846],\n",
      "          [0.1952, 0.2018, 0.2118, 0.1023, 0.1068, 0.1821]],\n",
      "\n",
      "         [[0.0631, 0.3514, 0.0275, 0.2580, 0.1997, 0.1003],\n",
      "          [0.1135, 0.0500, 0.4697, 0.1323, 0.2131, 0.0213],\n",
      "          [0.1357, 0.3340, 0.0230, 0.1366, 0.1258, 0.2449],\n",
      "          [0.0553, 0.0055, 0.2434, 0.1946, 0.4721, 0.0290],\n",
      "          [0.0935, 0.0879, 0.0245, 0.5925, 0.1575, 0.0442]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0602, 0.9398, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0822, 0.1480, 0.7697, 0.0000, 0.0000],\n",
      "          [0.0049, 0.0222, 0.4454, 0.5275, 0.0000],\n",
      "          [0.0029, 0.0188, 0.0685, 0.2783, 0.6315]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.7103, 0.2897, 0.0000, 0.0000, 0.0000],\n",
      "          [0.3793, 0.0223, 0.5983, 0.0000, 0.0000],\n",
      "          [0.0947, 0.0676, 0.3451, 0.4926, 0.0000],\n",
      "          [0.0367, 0.0502, 0.2574, 0.3822, 0.2735]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 6])\n",
      "old attention tensor([[[[0.2390, 0.4376, 0.1595, 0.0717, 0.0577, 0.0346],\n",
      "          [0.2497, 0.1738, 0.2129, 0.1900, 0.1392, 0.0343],\n",
      "          [0.0225, 0.0569, 0.1671, 0.1696, 0.4634, 0.1204],\n",
      "          [0.1742, 0.1231, 0.4069, 0.1606, 0.0943, 0.0410],\n",
      "          [0.2585, 0.1611, 0.1545, 0.2606, 0.1279, 0.0375]],\n",
      "\n",
      "         [[0.1054, 0.7676, 0.0721, 0.0165, 0.0339, 0.0046],\n",
      "          [0.2417, 0.1332, 0.5006, 0.0533, 0.0273, 0.0440],\n",
      "          [0.1899, 0.0995, 0.1715, 0.3041, 0.0787, 0.1562],\n",
      "          [0.3877, 0.2065, 0.1606, 0.1128, 0.0653, 0.0671],\n",
      "          [0.1935, 0.1539, 0.4347, 0.0522, 0.1256, 0.0400]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.3529, 0.6471, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4060, 0.4328, 0.1612, 0.0000, 0.0000],\n",
      "          [0.1394, 0.1050, 0.4719, 0.2837, 0.0000],\n",
      "          [0.2005, 0.0961, 0.2257, 0.2180, 0.2596]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0560, 0.9440, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0336, 0.2357, 0.7307, 0.0000, 0.0000],\n",
      "          [0.0105, 0.0702, 0.7826, 0.1368, 0.0000],\n",
      "          [0.0261, 0.0963, 0.6232, 0.0753, 0.1791]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 6])\n",
      "old attention tensor([[[[0.1167, 0.4553, 0.1197, 0.0463, 0.1244, 0.1376],\n",
      "          [0.0710, 0.1702, 0.1459, 0.1566, 0.1535, 0.3028],\n",
      "          [0.1097, 0.0807, 0.1542, 0.2322, 0.1662, 0.2569],\n",
      "          [0.0685, 0.1304, 0.1239, 0.1919, 0.1628, 0.3225],\n",
      "          [0.0167, 0.0570, 0.1881, 0.1451, 0.1548, 0.4383]],\n",
      "\n",
      "         [[0.1583, 0.1175, 0.0943, 0.0752, 0.3179, 0.2368],\n",
      "          [0.0929, 0.0553, 0.2616, 0.0944, 0.2781, 0.2176],\n",
      "          [0.1550, 0.1118, 0.1419, 0.1297, 0.3305, 0.1311],\n",
      "          [0.0769, 0.0762, 0.3098, 0.0618, 0.2989, 0.1765],\n",
      "          [0.1379, 0.1072, 0.2999, 0.0434, 0.2600, 0.1517]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "predicted trg = ['wir', 'konnen', 'zeitung', 'lesen', '<eos>']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_count 1    self.capacity  20\n",
      "0  ------------------------------------------------\n",
      "DecoderLayer@trg4\n",
      "[1, 1, 64]\n",
      "src = ['i', 'eat', 'bread']\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[0.0497, 0.4402, 0.2871, 0.1224, 0.1006],\n",
      "          [0.4070, 0.1963, 0.0380, 0.3546, 0.0040],\n",
      "          [0.1299, 0.0870, 0.0316, 0.0861, 0.6654],\n",
      "          [0.2226, 0.3791, 0.2816, 0.1044, 0.0122],\n",
      "          [0.0470, 0.1480, 0.2425, 0.5482, 0.0143]],\n",
      "\n",
      "         [[0.1798, 0.1168, 0.0701, 0.4999, 0.1333],\n",
      "          [0.0514, 0.2092, 0.0615, 0.5580, 0.1198],\n",
      "          [0.0427, 0.0573, 0.0451, 0.0460, 0.8089],\n",
      "          [0.0497, 0.0123, 0.8383, 0.0817, 0.0181],\n",
      "          [0.0797, 0.0374, 0.0844, 0.0832, 0.7153]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[0.2072, 0.1296, 0.1944, 0.2388, 0.2300],\n",
      "          [0.1183, 0.2363, 0.2817, 0.1212, 0.2425],\n",
      "          [0.0318, 0.1512, 0.5703, 0.0909, 0.1558],\n",
      "          [0.1595, 0.4139, 0.1240, 0.0802, 0.2224],\n",
      "          [0.2450, 0.2381, 0.2746, 0.1113, 0.1310]],\n",
      "\n",
      "         [[0.3305, 0.2989, 0.1403, 0.0509, 0.1793],\n",
      "          [0.0155, 0.0523, 0.4662, 0.3558, 0.1102],\n",
      "          [0.1431, 0.2083, 0.1710, 0.2316, 0.2461],\n",
      "          [0.0419, 0.2085, 0.0504, 0.5882, 0.1110],\n",
      "          [0.0425, 0.0666, 0.3962, 0.1454, 0.3494]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[0.1244, 0.2006, 0.3816, 0.2254, 0.0680],\n",
      "          [0.1717, 0.1093, 0.5307, 0.0715, 0.1168],\n",
      "          [0.1392, 0.0933, 0.6396, 0.0869, 0.0410],\n",
      "          [0.5499, 0.0188, 0.3973, 0.0225, 0.0115],\n",
      "          [0.1864, 0.0388, 0.6942, 0.0274, 0.0531]],\n",
      "\n",
      "         [[0.1457, 0.2802, 0.4448, 0.1099, 0.0193],\n",
      "          [0.0232, 0.0912, 0.2662, 0.3150, 0.3043],\n",
      "          [0.0571, 0.0769, 0.3962, 0.3273, 0.1425],\n",
      "          [0.0566, 0.2496, 0.5228, 0.1365, 0.0345],\n",
      "          [0.2045, 0.2862, 0.1168, 0.2052, 0.1874]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 5])\n",
      "old attention tensor([[[[0.2514, 0.1781, 0.2122, 0.3004, 0.0580]],\n",
      "\n",
      "         [[0.2436, 0.2808, 0.3235, 0.0867, 0.0655]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 5])\n",
      "old attention tensor([[[[0.7443, 0.0796, 0.0722, 0.0857, 0.0183]],\n",
      "\n",
      "         [[0.2001, 0.1755, 0.1103, 0.2568, 0.2572]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 5])\n",
      "old attention tensor([[[[0.0113, 0.9283, 0.0267, 0.0178, 0.0160]],\n",
      "\n",
      "         [[0.0421, 0.4167, 0.1148, 0.1099, 0.3166]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.5428, 0.4572]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0282, 0.9718]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.5428, 0.4572]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0282, 0.9718]]]])\n",
      "old attention torch.Size([1, 2, 2, 5])\n",
      "old attention tensor([[[[0.2514, 0.1781, 0.2122, 0.3004, 0.0580],\n",
      "          [0.0829, 0.1240, 0.1740, 0.0432, 0.5758]],\n",
      "\n",
      "         [[0.2436, 0.2808, 0.3235, 0.0867, 0.0655],\n",
      "          [0.5173, 0.0273, 0.3394, 0.0826, 0.0334]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0200, 0.9800]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.1896, 0.8104]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0200, 0.9800]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.1896, 0.8104]]]])\n",
      "old attention torch.Size([1, 2, 2, 5])\n",
      "old attention tensor([[[[0.7443, 0.0796, 0.0722, 0.0857, 0.0183],\n",
      "          [0.1044, 0.1767, 0.5459, 0.0873, 0.0857]],\n",
      "\n",
      "         [[0.2001, 0.1755, 0.1103, 0.2568, 0.2572],\n",
      "          [0.1603, 0.2049, 0.0256, 0.4568, 0.1524]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.3968, 0.6032]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.1148, 0.8852]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.3968, 0.6032]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.1148, 0.8852]]]])\n",
      "old attention torch.Size([1, 2, 2, 5])\n",
      "old attention tensor([[[[0.0113, 0.9283, 0.0267, 0.0178, 0.0160],\n",
      "          [0.0489, 0.1216, 0.3339, 0.2561, 0.2395]],\n",
      "\n",
      "         [[0.0421, 0.4167, 0.1148, 0.1099, 0.3166],\n",
      "          [0.0298, 0.0939, 0.2544, 0.3713, 0.2505]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.5428, 0.4572, 0.0000],\n",
      "          [0.1344, 0.8069, 0.0588]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.0282, 0.9718, 0.0000],\n",
      "          [0.0023, 0.0049, 0.9928]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 5])\n",
      "old attention tensor([[[[0.2959, 0.1119, 0.1671, 0.4074, 0.0176],\n",
      "          [0.1477, 0.1250, 0.1382, 0.0722, 0.5170],\n",
      "          [0.3469, 0.0467, 0.3513, 0.0674, 0.1877]],\n",
      "\n",
      "         [[0.0417, 0.2006, 0.5570, 0.0784, 0.1222],\n",
      "          [0.4255, 0.0305, 0.4412, 0.0836, 0.0192],\n",
      "          [0.0391, 0.4536, 0.2784, 0.0926, 0.1362]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.0551, 0.9449, 0.0000],\n",
      "          [0.0860, 0.3311, 0.5829]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.0355, 0.9645, 0.0000],\n",
      "          [0.0155, 0.9100, 0.0745]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 5])\n",
      "old attention tensor([[[[0.7882, 0.0268, 0.0572, 0.1016, 0.0263],\n",
      "          [0.2680, 0.1228, 0.4487, 0.1127, 0.0479],\n",
      "          [0.6000, 0.1332, 0.1109, 0.0897, 0.0662]],\n",
      "\n",
      "         [[0.2703, 0.0918, 0.1262, 0.4132, 0.0985],\n",
      "          [0.2086, 0.1633, 0.0282, 0.5038, 0.0961],\n",
      "          [0.0628, 0.1950, 0.0305, 0.3983, 0.3134]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.4806, 0.5194, 0.0000],\n",
      "          [0.1942, 0.5200, 0.2858]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.1469, 0.8531, 0.0000],\n",
      "          [0.1771, 0.3817, 0.4412]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 5])\n",
      "old attention tensor([[[[0.0789, 0.4375, 0.2266, 0.1105, 0.1465],\n",
      "          [0.0365, 0.3448, 0.2793, 0.1707, 0.1687],\n",
      "          [0.0615, 0.3029, 0.1846, 0.1458, 0.3051]],\n",
      "\n",
      "         [[0.1617, 0.2657, 0.2919, 0.1477, 0.1330],\n",
      "          [0.0824, 0.1709, 0.2930, 0.1879, 0.2659],\n",
      "          [0.1481, 0.1678, 0.2696, 0.3062, 0.1084]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5428, 0.4572, 0.0000, 0.0000],\n",
      "          [0.1344, 0.8069, 0.0588, 0.0000],\n",
      "          [0.0398, 0.0027, 0.9489, 0.0086]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0282, 0.9718, 0.0000, 0.0000],\n",
      "          [0.0023, 0.0049, 0.9928, 0.0000],\n",
      "          [0.0459, 0.3619, 0.5813, 0.0109]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 5])\n",
      "old attention tensor([[[[0.2868, 0.1354, 0.1872, 0.3718, 0.0189],\n",
      "          [0.1376, 0.1417, 0.1463, 0.0643, 0.5101],\n",
      "          [0.3287, 0.0501, 0.3772, 0.0576, 0.1865],\n",
      "          [0.3874, 0.0589, 0.3484, 0.1087, 0.0966]],\n",
      "\n",
      "         [[0.0528, 0.2120, 0.5328, 0.0891, 0.1132],\n",
      "          [0.4765, 0.0301, 0.3897, 0.0868, 0.0168],\n",
      "          [0.0438, 0.4744, 0.2635, 0.0975, 0.1208],\n",
      "          [0.1681, 0.1302, 0.1896, 0.2488, 0.2633]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0563, 0.9437, 0.0000, 0.0000],\n",
      "          [0.0829, 0.3287, 0.5884, 0.0000],\n",
      "          [0.0151, 0.2679, 0.3257, 0.3913]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0342, 0.9658, 0.0000, 0.0000],\n",
      "          [0.0161, 0.8943, 0.0896, 0.0000],\n",
      "          [0.0486, 0.1459, 0.1303, 0.6751]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 5])\n",
      "old attention tensor([[[[0.8118, 0.0252, 0.0383, 0.0958, 0.0289],\n",
      "          [0.3045, 0.1434, 0.3657, 0.1248, 0.0616],\n",
      "          [0.6500, 0.1247, 0.0742, 0.0818, 0.0694],\n",
      "          [0.6443, 0.1149, 0.1071, 0.0744, 0.0593]],\n",
      "\n",
      "         [[0.2882, 0.0960, 0.1601, 0.3814, 0.0743],\n",
      "          [0.2110, 0.1750, 0.0349, 0.5060, 0.0731],\n",
      "          [0.0686, 0.2089, 0.0411, 0.4181, 0.2633],\n",
      "          [0.1526, 0.2272, 0.0598, 0.2739, 0.2864]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5292, 0.4708, 0.0000, 0.0000],\n",
      "          [0.2633, 0.4475, 0.2892, 0.0000],\n",
      "          [0.0675, 0.0948, 0.1583, 0.6794]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.1475, 0.8525, 0.0000, 0.0000],\n",
      "          [0.1689, 0.3529, 0.4782, 0.0000],\n",
      "          [0.0592, 0.1664, 0.2681, 0.5063]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 5])\n",
      "old attention tensor([[[[0.0859, 0.3212, 0.2229, 0.1110, 0.2590],\n",
      "          [0.0349, 0.2377, 0.2601, 0.1594, 0.3079],\n",
      "          [0.0567, 0.1881, 0.1531, 0.1228, 0.4794],\n",
      "          [0.1131, 0.1606, 0.1400, 0.1000, 0.4864]],\n",
      "\n",
      "         [[0.2741, 0.1944, 0.3621, 0.0878, 0.0815],\n",
      "          [0.1523, 0.1347, 0.4250, 0.1243, 0.1637],\n",
      "          [0.2754, 0.1271, 0.3471, 0.1871, 0.0634],\n",
      "          [0.4403, 0.1265, 0.2650, 0.1062, 0.0621]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [5.4283e-01, 4.5717e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [1.3437e-01, 8.0686e-01, 5.8769e-02, 0.0000e+00, 0.0000e+00],\n",
      "          [3.9787e-02, 2.6973e-03, 9.4888e-01, 8.6344e-03, 0.0000e+00],\n",
      "          [3.7154e-02, 2.5894e-01, 1.2810e-02, 6.7727e-01, 1.3824e-02]],\n",
      "\n",
      "         [[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [2.8229e-02, 9.7177e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [2.3448e-03, 4.8957e-03, 9.9276e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [4.5875e-02, 3.6194e-01, 5.8129e-01, 1.0895e-02, 0.0000e+00],\n",
      "          [9.7131e-04, 2.0336e-03, 4.8963e-01, 1.2635e-02, 4.9473e-01]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[0.3123, 0.1290, 0.1553, 0.3864, 0.0171],\n",
      "          [0.1599, 0.1440, 0.1316, 0.0711, 0.4934],\n",
      "          [0.3736, 0.0516, 0.3340, 0.0646, 0.1763],\n",
      "          [0.4345, 0.0584, 0.3002, 0.1180, 0.0889],\n",
      "          [0.4067, 0.0439, 0.3000, 0.0565, 0.1928]],\n",
      "\n",
      "         [[0.0345, 0.2025, 0.5531, 0.0868, 0.1230],\n",
      "          [0.3726, 0.0327, 0.4779, 0.0965, 0.0203],\n",
      "          [0.0309, 0.4587, 0.2797, 0.0975, 0.1332],\n",
      "          [0.1154, 0.1306, 0.2076, 0.2509, 0.2955],\n",
      "          [0.0328, 0.4606, 0.2612, 0.1130, 0.1324]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0726, 0.9274, 0.0000, 0.0000, 0.0000],\n",
      "          [0.1009, 0.3247, 0.5745, 0.0000, 0.0000],\n",
      "          [0.0204, 0.2603, 0.3291, 0.3902, 0.0000],\n",
      "          [0.0468, 0.1553, 0.2700, 0.2330, 0.2950]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0255, 0.9745, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0121, 0.9005, 0.0874, 0.0000, 0.0000],\n",
      "          [0.0331, 0.1333, 0.1055, 0.7280, 0.0000],\n",
      "          [0.0043, 0.2711, 0.0306, 0.6564, 0.0377]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[0.8056, 0.0191, 0.0401, 0.1012, 0.0341],\n",
      "          [0.2890, 0.1087, 0.3957, 0.1341, 0.0725],\n",
      "          [0.6230, 0.1072, 0.0850, 0.0924, 0.0924],\n",
      "          [0.6263, 0.0953, 0.1218, 0.0825, 0.0741],\n",
      "          [0.6200, 0.1071, 0.0874, 0.0903, 0.0952]],\n",
      "\n",
      "         [[0.3546, 0.0645, 0.1978, 0.3324, 0.0507],\n",
      "          [0.2812, 0.1257, 0.0427, 0.5020, 0.0483],\n",
      "          [0.1001, 0.1787, 0.0623, 0.4382, 0.2206],\n",
      "          [0.2169, 0.1864, 0.0890, 0.2816, 0.2261],\n",
      "          [0.1026, 0.1790, 0.0712, 0.4220, 0.2252]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5493, 0.4507, 0.0000, 0.0000, 0.0000],\n",
      "          [0.2738, 0.4261, 0.3001, 0.0000, 0.0000],\n",
      "          [0.0755, 0.1126, 0.1428, 0.6692, 0.0000],\n",
      "          [0.0811, 0.1106, 0.0884, 0.6245, 0.0954]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.1927, 0.8073, 0.0000, 0.0000, 0.0000],\n",
      "          [0.2066, 0.3000, 0.4935, 0.0000, 0.0000],\n",
      "          [0.0675, 0.1288, 0.3114, 0.4924, 0.0000],\n",
      "          [0.0828, 0.1258, 0.2241, 0.3468, 0.2206]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[0.1372, 0.1316, 0.2474, 0.1301, 0.3537],\n",
      "          [0.0498, 0.0818, 0.2811, 0.1754, 0.4119],\n",
      "          [0.0882, 0.0718, 0.1490, 0.1375, 0.5536],\n",
      "          [0.1518, 0.0567, 0.1317, 0.1018, 0.5581],\n",
      "          [0.0890, 0.0683, 0.1459, 0.1347, 0.5621]],\n",
      "\n",
      "         [[0.4591, 0.1561, 0.2688, 0.0675, 0.0485],\n",
      "          [0.3223, 0.1123, 0.3692, 0.0954, 0.1008],\n",
      "          [0.4846, 0.1051, 0.2510, 0.1220, 0.0373],\n",
      "          [0.6467, 0.0897, 0.1759, 0.0560, 0.0317],\n",
      "          [0.4925, 0.1042, 0.2506, 0.1158, 0.0369]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "predicted trg = ['ich', 'essen', 'apfel', 'essen', '<eos>']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_count 1    self.capacity  20\n",
      "0  ------------------------------------------------\n",
      "DecoderLayer@trg4\n",
      "[1, 1, 64]\n",
      "src = ['i', 'eat', 'apple']\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[0.0503, 0.4456, 0.2906, 0.1116, 0.1019],\n",
      "          [0.6123, 0.2953, 0.0572, 0.0292, 0.0060],\n",
      "          [0.1291, 0.0864, 0.0314, 0.0921, 0.6610],\n",
      "          [0.0494, 0.3889, 0.1324, 0.1657, 0.2637],\n",
      "          [0.0818, 0.2577, 0.4224, 0.2132, 0.0249]],\n",
      "\n",
      "         [[0.3071, 0.1996, 0.1198, 0.1458, 0.2277],\n",
      "          [0.0960, 0.3904, 0.1147, 0.1754, 0.2236],\n",
      "          [0.0446, 0.0598, 0.0471, 0.0046, 0.8439],\n",
      "          [0.0012, 0.1646, 0.0188, 0.0141, 0.8012],\n",
      "          [0.0733, 0.0344, 0.0775, 0.1573, 0.6575]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[0.1989, 0.1175, 0.1995, 0.2740, 0.2101],\n",
      "          [0.1048, 0.2368, 0.2770, 0.1226, 0.2588],\n",
      "          [0.0351, 0.1367, 0.5792, 0.0653, 0.1837],\n",
      "          [0.1143, 0.2532, 0.2505, 0.0330, 0.3490],\n",
      "          [0.1846, 0.1865, 0.2178, 0.2914, 0.1196]],\n",
      "\n",
      "         [[0.3185, 0.2517, 0.1349, 0.1530, 0.1419],\n",
      "          [0.0210, 0.0562, 0.7042, 0.0739, 0.1448],\n",
      "          [0.1196, 0.1633, 0.1708, 0.3235, 0.2228],\n",
      "          [0.0851, 0.0833, 0.0073, 0.7596, 0.0648],\n",
      "          [0.0431, 0.0557, 0.3613, 0.2024, 0.3375]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[0.0989, 0.1967, 0.2573, 0.4054, 0.0418],\n",
      "          [0.1161, 0.0653, 0.3425, 0.4315, 0.0446],\n",
      "          [0.0676, 0.0614, 0.5464, 0.3075, 0.0171],\n",
      "          [0.0742, 0.0342, 0.4284, 0.4472, 0.0160],\n",
      "          [0.1280, 0.0225, 0.4479, 0.3860, 0.0155]],\n",
      "\n",
      "         [[0.0877, 0.1638, 0.2822, 0.4541, 0.0121],\n",
      "          [0.0236, 0.1256, 0.3710, 0.1319, 0.3479],\n",
      "          [0.0458, 0.0828, 0.3999, 0.3649, 0.1066],\n",
      "          [0.0505, 0.0601, 0.1766, 0.5517, 0.1611],\n",
      "          [0.1796, 0.3299, 0.1649, 0.1534, 0.1722]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 5])\n",
      "old attention tensor([[[[0.2943, 0.2703, 0.2551, 0.0994, 0.0809]],\n",
      "\n",
      "         [[0.1495, 0.1724, 0.1968, 0.4368, 0.0446]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 5])\n",
      "old attention tensor([[[[0.7582, 0.0750, 0.0763, 0.0763, 0.0142]],\n",
      "\n",
      "         [[0.2347, 0.2535, 0.1276, 0.1454, 0.2388]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 5])\n",
      "old attention tensor([[[[0.0097, 0.9460, 0.0209, 0.0124, 0.0111]],\n",
      "\n",
      "         [[0.0207, 0.3300, 0.0796, 0.3220, 0.2477]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.5428, 0.4572]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0282, 0.9718]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.5428, 0.4572]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0282, 0.9718]]]])\n",
      "old attention torch.Size([1, 2, 2, 5])\n",
      "old attention tensor([[[[0.2943, 0.2703, 0.2551, 0.0994, 0.0809],\n",
      "          [0.0517, 0.0723, 0.0969, 0.4752, 0.3038]],\n",
      "\n",
      "         [[0.1495, 0.1724, 0.1968, 0.4368, 0.0446],\n",
      "          [0.4995, 0.0216, 0.2731, 0.1723, 0.0335]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0141, 0.9859]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.2041, 0.7959]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0141, 0.9859]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.2041, 0.7959]]]])\n",
      "old attention torch.Size([1, 2, 2, 5])\n",
      "old attention tensor([[[[0.7582, 0.0750, 0.0763, 0.0763, 0.0142],\n",
      "          [0.1070, 0.1189, 0.5001, 0.2166, 0.0574]],\n",
      "\n",
      "         [[0.2347, 0.2535, 0.1276, 0.1454, 0.2388],\n",
      "          [0.2754, 0.3299, 0.0456, 0.1584, 0.1906]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.3889, 0.6111]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.2327, 0.7673]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.3889, 0.6111]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.2327, 0.7673]]]])\n",
      "old attention torch.Size([1, 2, 2, 5])\n",
      "old attention tensor([[[[0.0097, 0.9460, 0.0209, 0.0124, 0.0111],\n",
      "          [0.0328, 0.1995, 0.2029, 0.4393, 0.1254]],\n",
      "\n",
      "         [[0.0207, 0.3300, 0.0796, 0.3220, 0.2477],\n",
      "          [0.0248, 0.1813, 0.2267, 0.1657, 0.4015]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.5428, 0.4572, 0.0000],\n",
      "          [0.1344, 0.8069, 0.0588]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.0282, 0.9718, 0.0000],\n",
      "          [0.0023, 0.0049, 0.9928]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 5])\n",
      "old attention tensor([[[[0.4709, 0.2112, 0.2571, 0.0327, 0.0281],\n",
      "          [0.0976, 0.0776, 0.0848, 0.4582, 0.2818],\n",
      "          [0.2941, 0.0366, 0.2903, 0.2304, 0.1486]],\n",
      "\n",
      "         [[0.0237, 0.1132, 0.2787, 0.5052, 0.0791],\n",
      "          [0.3892, 0.0234, 0.3486, 0.2194, 0.0194],\n",
      "          [0.0301, 0.3046, 0.1420, 0.4253, 0.0979]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.0384, 0.9616, 0.0000],\n",
      "          [0.0646, 0.4465, 0.4889]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.0395, 0.9605, 0.0000],\n",
      "          [0.0163, 0.9194, 0.0643]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 5])\n",
      "old attention tensor([[[[0.8251, 0.0237, 0.0709, 0.0630, 0.0173],\n",
      "          [0.2341, 0.0808, 0.4586, 0.1994, 0.0272],\n",
      "          [0.6223, 0.1140, 0.1383, 0.0840, 0.0414]],\n",
      "\n",
      "         [[0.2818, 0.1074, 0.1604, 0.3724, 0.0781],\n",
      "          [0.3491, 0.3038, 0.0587, 0.1653, 0.1230],\n",
      "          [0.1240, 0.3302, 0.0702, 0.0840, 0.3917]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.5027, 0.4973, 0.0000],\n",
      "          [0.1912, 0.4986, 0.3102]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.2063, 0.7937, 0.0000],\n",
      "          [0.2135, 0.3405, 0.4460]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 5])\n",
      "old attention tensor([[[[0.0433, 0.5581, 0.1643, 0.1396, 0.0947],\n",
      "          [0.0273, 0.4984, 0.2064, 0.1687, 0.0992],\n",
      "          [0.0378, 0.4068, 0.1565, 0.2104, 0.1885]],\n",
      "\n",
      "         [[0.0758, 0.3156, 0.2212, 0.2236, 0.1638],\n",
      "          [0.0423, 0.2275, 0.2032, 0.2053, 0.3218],\n",
      "          [0.0911, 0.2505, 0.2609, 0.2119, 0.1857]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5428, 0.4572, 0.0000, 0.0000],\n",
      "          [0.1344, 0.8069, 0.0588, 0.0000],\n",
      "          [0.0398, 0.0027, 0.9489, 0.0086]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0282, 0.9718, 0.0000, 0.0000],\n",
      "          [0.0023, 0.0049, 0.9928, 0.0000],\n",
      "          [0.0459, 0.3619, 0.5813, 0.0109]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 5])\n",
      "old attention tensor([[[[0.4238, 0.2414, 0.2666, 0.0395, 0.0287],\n",
      "          [0.0830, 0.0817, 0.0818, 0.4927, 0.2608],\n",
      "          [0.2638, 0.0377, 0.2938, 0.2618, 0.1430],\n",
      "          [0.3522, 0.0536, 0.3127, 0.2080, 0.0735]],\n",
      "\n",
      "         [[0.0314, 0.1286, 0.3026, 0.4588, 0.0785],\n",
      "          [0.4411, 0.0241, 0.3358, 0.1815, 0.0176],\n",
      "          [0.0349, 0.3357, 0.1473, 0.3906, 0.0915],\n",
      "          [0.2313, 0.1505, 0.2326, 0.1212, 0.2644]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0397, 0.9603, 0.0000, 0.0000],\n",
      "          [0.0629, 0.4514, 0.4857, 0.0000],\n",
      "          [0.0102, 0.3184, 0.2496, 0.4218]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0381, 0.9619, 0.0000, 0.0000],\n",
      "          [0.0169, 0.9024, 0.0807, 0.0000],\n",
      "          [0.0551, 0.1679, 0.1254, 0.6516]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 5])\n",
      "old attention tensor([[[[0.8618, 0.0229, 0.0480, 0.0478, 0.0195],\n",
      "          [0.2667, 0.0978, 0.4060, 0.1920, 0.0375],\n",
      "          [0.6823, 0.1119, 0.0968, 0.0649, 0.0441],\n",
      "          [0.6632, 0.0839, 0.1373, 0.0804, 0.0352]],\n",
      "\n",
      "         [[0.2572, 0.0989, 0.1700, 0.4198, 0.0540],\n",
      "          [0.3331, 0.3131, 0.0650, 0.1930, 0.0957],\n",
      "          [0.1265, 0.3415, 0.0854, 0.1084, 0.3381],\n",
      "          [0.1801, 0.2702, 0.0946, 0.1909, 0.2642]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5367, 0.4633, 0.0000, 0.0000],\n",
      "          [0.2521, 0.4510, 0.2969, 0.0000],\n",
      "          [0.0578, 0.0807, 0.1538, 0.7077]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.2029, 0.7971, 0.0000, 0.0000],\n",
      "          [0.2038, 0.3196, 0.4765, 0.0000],\n",
      "          [0.0537, 0.1472, 0.2553, 0.5437]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 5])\n",
      "old attention tensor([[[[0.0489, 0.4591, 0.1689, 0.1427, 0.1805],\n",
      "          [0.0263, 0.4122, 0.2064, 0.1694, 0.1858],\n",
      "          [0.0378, 0.2895, 0.1392, 0.1968, 0.3368],\n",
      "          [0.0757, 0.2593, 0.1312, 0.1520, 0.3817]],\n",
      "\n",
      "         [[0.1394, 0.2578, 0.2974, 0.2029, 0.1025],\n",
      "          [0.0784, 0.1945, 0.3144, 0.2009, 0.2118],\n",
      "          [0.1754, 0.1917, 0.3430, 0.1882, 0.1017],\n",
      "          [0.2866, 0.1979, 0.2426, 0.1826, 0.0903]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [5.4283e-01, 4.5717e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [1.3437e-01, 8.0686e-01, 5.8769e-02, 0.0000e+00, 0.0000e+00],\n",
      "          [3.9787e-02, 2.6973e-03, 9.4888e-01, 8.6344e-03, 0.0000e+00],\n",
      "          [3.7154e-02, 2.5894e-01, 1.2810e-02, 6.7727e-01, 1.3824e-02]],\n",
      "\n",
      "         [[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [2.8229e-02, 9.7177e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [2.3448e-03, 4.8957e-03, 9.9276e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [4.5875e-02, 3.6194e-01, 5.8129e-01, 1.0895e-02, 0.0000e+00],\n",
      "          [9.7131e-04, 2.0336e-03, 4.8963e-01, 1.2635e-02, 4.9473e-01]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[0.4805, 0.2301, 0.2307, 0.0327, 0.0260],\n",
      "          [0.1049, 0.0872, 0.0800, 0.4634, 0.2645],\n",
      "          [0.3163, 0.0396, 0.2749, 0.2312, 0.1380],\n",
      "          [0.4157, 0.0539, 0.2839, 0.1776, 0.0688],\n",
      "          [0.3446, 0.0332, 0.2482, 0.2260, 0.1480]],\n",
      "\n",
      "         [[0.0204, 0.1239, 0.3096, 0.4596, 0.0865],\n",
      "          [0.3396, 0.0260, 0.4012, 0.2118, 0.0213],\n",
      "          [0.0243, 0.3248, 0.1537, 0.3957, 0.1015],\n",
      "          [0.1593, 0.1536, 0.2529, 0.1304, 0.3039],\n",
      "          [0.0267, 0.3355, 0.1461, 0.3877, 0.1041]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0495, 0.9505, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0767, 0.4478, 0.4755, 0.0000, 0.0000],\n",
      "          [0.0133, 0.3224, 0.2518, 0.4125, 0.0000],\n",
      "          [0.0367, 0.2176, 0.2311, 0.2588, 0.2559]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0300, 0.9700, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0122, 0.9087, 0.0791, 0.0000, 0.0000],\n",
      "          [0.0384, 0.1543, 0.1041, 0.7032, 0.0000],\n",
      "          [0.0047, 0.2952, 0.0300, 0.6341, 0.0360]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[0.8604, 0.0173, 0.0514, 0.0481, 0.0228],\n",
      "          [0.2477, 0.0739, 0.4439, 0.1927, 0.0418],\n",
      "          [0.6496, 0.1017, 0.1133, 0.0731, 0.0624],\n",
      "          [0.6367, 0.0717, 0.1584, 0.0891, 0.0441],\n",
      "          [0.6442, 0.1013, 0.1175, 0.0730, 0.0641]],\n",
      "\n",
      "         [[0.2611, 0.0527, 0.1868, 0.4674, 0.0320],\n",
      "          [0.4102, 0.2113, 0.0806, 0.2354, 0.0625],\n",
      "          [0.1709, 0.2678, 0.1263, 0.1525, 0.2826],\n",
      "          [0.2232, 0.1900, 0.1301, 0.2579, 0.1988],\n",
      "          [0.1677, 0.2493, 0.1377, 0.1722, 0.2731]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5839, 0.4161, 0.0000, 0.0000, 0.0000],\n",
      "          [0.2739, 0.4285, 0.2975, 0.0000, 0.0000],\n",
      "          [0.0633, 0.0831, 0.1267, 0.7269, 0.0000],\n",
      "          [0.0764, 0.1074, 0.0828, 0.6466, 0.0868]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.2526, 0.7474, 0.0000, 0.0000, 0.0000],\n",
      "          [0.2566, 0.2876, 0.4558, 0.0000, 0.0000],\n",
      "          [0.0633, 0.1169, 0.2859, 0.5339, 0.0000],\n",
      "          [0.0986, 0.1176, 0.2029, 0.3795, 0.2013]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[0.0863, 0.2023, 0.2241, 0.1719, 0.3154],\n",
      "          [0.0412, 0.1766, 0.2760, 0.1927, 0.3136],\n",
      "          [0.0631, 0.1214, 0.1570, 0.1951, 0.4634],\n",
      "          [0.1059, 0.0922, 0.1339, 0.1547, 0.5133],\n",
      "          [0.0654, 0.1180, 0.1559, 0.1843, 0.4764]],\n",
      "\n",
      "         [[0.3046, 0.2323, 0.2615, 0.1316, 0.0701],\n",
      "          [0.1938, 0.1888, 0.3175, 0.1394, 0.1605],\n",
      "          [0.3672, 0.1689, 0.2831, 0.1154, 0.0654],\n",
      "          [0.5258, 0.1469, 0.1809, 0.0970, 0.0494],\n",
      "          [0.3763, 0.1653, 0.2773, 0.1165, 0.0647]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "predicted trg = ['ich', 'essen', 'apfel', 'essen', '<eos>']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_count 1    self.capacity  20\n",
      "0  ------------------------------------------------\n",
      "DecoderLayer@trg4\n",
      "[1, 1, 64]\n",
      "src = ['i', 'drink', 'water']\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[3.4847e-02, 3.0875e-01, 5.6457e-01, 2.1263e-02, 7.0576e-02],\n",
      "          [7.5075e-02, 3.6209e-02, 8.8710e-01, 8.7417e-04, 7.4119e-04],\n",
      "          [2.3980e-03, 9.2839e-02, 5.1645e-03, 1.1613e-01, 7.8347e-01],\n",
      "          [8.2360e-02, 4.0281e-02, 8.1625e-01, 5.0125e-02, 1.0986e-02],\n",
      "          [2.6703e-02, 8.4149e-02, 8.7335e-01, 7.6729e-03, 8.1252e-03]],\n",
      "\n",
      "         [[1.4115e-01, 9.1739e-02, 5.6858e-01, 9.3863e-02, 1.0466e-01],\n",
      "          [1.0188e-01, 4.1435e-01, 2.3109e-01, 1.5352e-02, 2.3732e-01],\n",
      "          [3.0065e-01, 5.7268e-01, 4.2356e-02, 1.7621e-02, 6.6692e-02],\n",
      "          [5.2102e-02, 5.9935e-01, 1.2794e-01, 1.3587e-01, 8.4738e-02],\n",
      "          [7.6078e-02, 3.5697e-02, 6.7406e-02, 1.3793e-01, 6.8289e-01]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[0.1261, 0.0763, 0.3292, 0.3377, 0.1307],\n",
      "          [0.0732, 0.1502, 0.1834, 0.4478, 0.1453],\n",
      "          [0.3702, 0.0672, 0.0383, 0.4441, 0.0802],\n",
      "          [0.0332, 0.0531, 0.0309, 0.8454, 0.0374],\n",
      "          [0.0524, 0.0439, 0.1041, 0.7759, 0.0236]],\n",
      "\n",
      "         [[0.2266, 0.2143, 0.2999, 0.1595, 0.0997],\n",
      "          [0.0672, 0.2094, 0.2832, 0.0300, 0.4103],\n",
      "          [0.0608, 0.4552, 0.1295, 0.0734, 0.2811],\n",
      "          [0.3199, 0.2415, 0.0607, 0.0192, 0.3588],\n",
      "          [0.0903, 0.1434, 0.0756, 0.0618, 0.6289]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[0.0515, 0.1302, 0.5774, 0.1919, 0.0490],\n",
      "          [0.1057, 0.0740, 0.1233, 0.5448, 0.1522],\n",
      "          [0.1502, 0.0616, 0.1235, 0.1877, 0.4769],\n",
      "          [0.0254, 0.0715, 0.0179, 0.1333, 0.7519],\n",
      "          [0.3057, 0.1275, 0.0857, 0.2206, 0.2605]],\n",
      "\n",
      "         [[0.0143, 0.0490, 0.8935, 0.0413, 0.0019],\n",
      "          [0.0444, 0.2014, 0.1395, 0.2142, 0.4005],\n",
      "          [0.0957, 0.3819, 0.3828, 0.1073, 0.0323],\n",
      "          [0.1421, 0.0485, 0.7453, 0.0292, 0.0349],\n",
      "          [0.1922, 0.2510, 0.1016, 0.3056, 0.1496]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 5])\n",
      "old attention tensor([[[[0.4091, 0.1548, 0.0563, 0.3056, 0.0742]],\n",
      "\n",
      "         [[0.1574, 0.2151, 0.1104, 0.4570, 0.0602]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 5])\n",
      "old attention tensor([[[[0.7003, 0.0947, 0.1365, 0.0592, 0.0093]],\n",
      "\n",
      "         [[0.3703, 0.1185, 0.0724, 0.2073, 0.2315]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 5])\n",
      "old attention tensor([[[[0.0133, 0.9010, 0.0296, 0.0503, 0.0059]],\n",
      "\n",
      "         [[0.0310, 0.6091, 0.0264, 0.0335, 0.3000]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.5428, 0.4572]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0282, 0.9718]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.5428, 0.4572]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0282, 0.9718]]]])\n",
      "old attention torch.Size([1, 2, 2, 5])\n",
      "old attention tensor([[[[0.4091, 0.1548, 0.0563, 0.3056, 0.0742],\n",
      "          [0.0688, 0.1325, 0.0584, 0.1046, 0.6357]],\n",
      "\n",
      "         [[0.1574, 0.2151, 0.1104, 0.4570, 0.0602],\n",
      "          [0.2803, 0.0093, 0.5637, 0.1360, 0.0107]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0157, 0.9843]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.1363, 0.8637]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0157, 0.9843]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.1363, 0.8637]]]])\n",
      "old attention torch.Size([1, 2, 2, 5])\n",
      "old attention tensor([[[[0.7003, 0.0947, 0.1365, 0.0592, 0.0093],\n",
      "          [0.1468, 0.3563, 0.1722, 0.1792, 0.1455]],\n",
      "\n",
      "         [[0.3703, 0.1185, 0.0724, 0.2073, 0.2315],\n",
      "          [0.2156, 0.1435, 0.4514, 0.0984, 0.0911]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.3355, 0.6645]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.2964, 0.7036]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.3355, 0.6645]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.2964, 0.7036]]]])\n",
      "old attention torch.Size([1, 2, 2, 5])\n",
      "old attention tensor([[[[0.0133, 0.9010, 0.0296, 0.0503, 0.0059],\n",
      "          [0.0330, 0.0386, 0.5746, 0.2157, 0.1381]],\n",
      "\n",
      "         [[0.0310, 0.6091, 0.0264, 0.0335, 0.3000],\n",
      "          [0.0152, 0.0681, 0.1284, 0.5828, 0.2054]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.5428, 0.4572, 0.0000],\n",
      "          [0.0142, 0.0098, 0.9760]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.0282, 0.9718, 0.0000],\n",
      "          [0.7082, 0.0803, 0.2115]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 5])\n",
      "old attention tensor([[[[0.5143, 0.1897, 0.1075, 0.1649, 0.0236],\n",
      "          [0.0884, 0.1653, 0.1216, 0.1358, 0.4889],\n",
      "          [0.0949, 0.0938, 0.4958, 0.2433, 0.0722]],\n",
      "\n",
      "         [[0.0563, 0.1870, 0.0519, 0.4368, 0.2680],\n",
      "          [0.2954, 0.0092, 0.5033, 0.1847, 0.0075],\n",
      "          [0.0784, 0.4415, 0.1601, 0.0707, 0.2492]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.0814, 0.9186, 0.0000],\n",
      "          [0.2517, 0.1992, 0.5491]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.0379, 0.9621, 0.0000],\n",
      "          [0.0787, 0.3687, 0.5526]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 5])\n",
      "old attention tensor([[[[0.5272, 0.0611, 0.2582, 0.1079, 0.0455],\n",
      "          [0.1262, 0.2898, 0.2704, 0.2346, 0.0790],\n",
      "          [0.0736, 0.1606, 0.4307, 0.1239, 0.2113]],\n",
      "\n",
      "         [[0.3105, 0.0942, 0.2022, 0.2892, 0.1039],\n",
      "          [0.2516, 0.2688, 0.1582, 0.1856, 0.1359],\n",
      "          [0.1239, 0.1730, 0.2171, 0.1977, 0.2882]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.3041, 0.6959, 0.0000],\n",
      "          [0.1599, 0.5398, 0.3003]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.0288, 0.9712, 0.0000],\n",
      "          [0.0679, 0.3710, 0.5611]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 5])\n",
      "old attention tensor([[[[0.2420, 0.1407, 0.0296, 0.3078, 0.2799],\n",
      "          [0.0793, 0.0411, 0.0384, 0.5697, 0.2715],\n",
      "          [0.3042, 0.0429, 0.0288, 0.1885, 0.4356]],\n",
      "\n",
      "         [[0.5204, 0.2721, 0.0531, 0.0348, 0.1196],\n",
      "          [0.2981, 0.0661, 0.1529, 0.2320, 0.2509],\n",
      "          [0.6220, 0.1629, 0.0922, 0.0288, 0.0941]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5428, 0.4572, 0.0000, 0.0000],\n",
      "          [0.0142, 0.0098, 0.9760, 0.0000],\n",
      "          [0.0145, 0.0243, 0.9095, 0.0516]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0282, 0.9718, 0.0000, 0.0000],\n",
      "          [0.7082, 0.0803, 0.2115, 0.0000],\n",
      "          [0.0433, 0.8921, 0.0327, 0.0319]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 5])\n",
      "old attention tensor([[[[0.5965, 0.1565, 0.0929, 0.1261, 0.0281],\n",
      "          [0.1047, 0.1350, 0.1013, 0.1022, 0.5568],\n",
      "          [0.1253, 0.0819, 0.4992, 0.2093, 0.0844],\n",
      "          [0.0392, 0.4617, 0.0847, 0.3009, 0.1135]],\n",
      "\n",
      "         [[0.0522, 0.1858, 0.0477, 0.4555, 0.2589],\n",
      "          [0.2826, 0.0088, 0.4884, 0.2133, 0.0070],\n",
      "          [0.0658, 0.4711, 0.1408, 0.0731, 0.2492],\n",
      "          [0.4015, 0.0379, 0.1234, 0.2667, 0.1705]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0681, 0.9319, 0.0000, 0.0000],\n",
      "          [0.2317, 0.2014, 0.5669, 0.0000],\n",
      "          [0.0054, 0.0160, 0.2787, 0.6999]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0468, 0.9532, 0.0000, 0.0000],\n",
      "          [0.0748, 0.3512, 0.5740, 0.0000],\n",
      "          [0.0189, 0.1098, 0.6899, 0.1815]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 5])\n",
      "old attention tensor([[[[0.6980, 0.0365, 0.1649, 0.0765, 0.0241],\n",
      "          [0.1856, 0.2768, 0.2137, 0.2565, 0.0675],\n",
      "          [0.1120, 0.1493, 0.3895, 0.1344, 0.2148],\n",
      "          [0.5427, 0.0959, 0.2691, 0.0653, 0.0270]],\n",
      "\n",
      "         [[0.3836, 0.0502, 0.2774, 0.2336, 0.0553],\n",
      "          [0.3525, 0.1674, 0.2429, 0.1552, 0.0820],\n",
      "          [0.1683, 0.1156, 0.3404, 0.1774, 0.1983],\n",
      "          [0.3503, 0.0753, 0.3109, 0.1884, 0.0751]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.2352, 0.7648, 0.0000, 0.0000],\n",
      "          [0.1040, 0.5068, 0.3892, 0.0000],\n",
      "          [0.0649, 0.1500, 0.4665, 0.3186]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0684, 0.9316, 0.0000, 0.0000],\n",
      "          [0.0557, 0.2127, 0.7316, 0.0000],\n",
      "          [0.0761, 0.0929, 0.7507, 0.0802]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 5])\n",
      "old attention tensor([[[[0.2207, 0.1252, 0.0502, 0.2563, 0.3477],\n",
      "          [0.0414, 0.0342, 0.0702, 0.5151, 0.3390],\n",
      "          [0.1824, 0.0325, 0.0473, 0.1454, 0.5924],\n",
      "          [0.0599, 0.0275, 0.0702, 0.1989, 0.6436]],\n",
      "\n",
      "         [[0.4924, 0.3056, 0.0487, 0.0410, 0.1122],\n",
      "          [0.2240, 0.0611, 0.1176, 0.3664, 0.2310],\n",
      "          [0.6082, 0.1830, 0.0799, 0.0417, 0.0873],\n",
      "          [0.6161, 0.1165, 0.1301, 0.0623, 0.0749]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "predicted trg = ['ich', 'trinken', 'bier', '<eos>']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_count 1    self.capacity  20\n",
      "0  ------------------------------------------------\n",
      "DecoderLayer@trg4\n",
      "[1, 1, 64]\n",
      "src = ['i', 'drink', 'beer']\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[7.4400e-03, 6.5919e-02, 1.2054e-01, 7.9104e-01, 1.5068e-02],\n",
      "          [5.7965e-02, 2.7957e-02, 6.8493e-01, 2.2857e-01, 5.7227e-04],\n",
      "          [2.6985e-03, 1.0447e-01, 5.8117e-03, 5.3728e-03, 8.8164e-01],\n",
      "          [2.1775e-01, 8.2136e-02, 6.7909e-02, 4.6512e-01, 1.6708e-01],\n",
      "          [1.6182e-02, 5.0995e-02, 5.2926e-01, 3.9864e-01, 4.9240e-03]],\n",
      "\n",
      "         [[1.5021e-01, 9.7627e-02, 6.0508e-01, 3.5705e-02, 1.1138e-01],\n",
      "          [7.7385e-02, 3.1472e-01, 1.7553e-01, 2.5210e-01, 1.8026e-01],\n",
      "          [3.0247e-01, 5.7615e-01, 4.2613e-02, 1.1670e-02, 6.7096e-02],\n",
      "          [7.6649e-01, 1.2536e-02, 1.6558e-01, 5.3840e-02, 1.5607e-03],\n",
      "          [5.7259e-02, 2.6867e-02, 5.0732e-02, 3.5118e-01, 5.1397e-01]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[0.1853, 0.1186, 0.3853, 0.1466, 0.1642],\n",
      "          [0.1281, 0.2344, 0.2537, 0.1636, 0.2202],\n",
      "          [0.6566, 0.1185, 0.0609, 0.0382, 0.1259],\n",
      "          [0.2462, 0.3575, 0.2148, 0.0666, 0.1148],\n",
      "          [0.2115, 0.1492, 0.4158, 0.1335, 0.0900]],\n",
      "\n",
      "         [[0.2232, 0.2397, 0.3048, 0.1290, 0.1033],\n",
      "          [0.0405, 0.1946, 0.2342, 0.1933, 0.3375],\n",
      "          [0.0493, 0.4069, 0.1234, 0.1702, 0.2501],\n",
      "          [0.1294, 0.3512, 0.2652, 0.1461, 0.1081],\n",
      "          [0.0551, 0.1330, 0.0774, 0.2468, 0.4878]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[0.0721, 0.1780, 0.6504, 0.0295, 0.0701],\n",
      "          [0.1880, 0.1319, 0.2636, 0.1872, 0.2293],\n",
      "          [0.1558, 0.0602, 0.1459, 0.1227, 0.5154],\n",
      "          [0.4165, 0.2329, 0.0927, 0.0329, 0.2250],\n",
      "          [0.2861, 0.1166, 0.1007, 0.2409, 0.2557]],\n",
      "\n",
      "         [[0.0165, 0.0524, 0.8205, 0.1087, 0.0019],\n",
      "          [0.0624, 0.2495, 0.1806, 0.0488, 0.4587],\n",
      "          [0.1296, 0.3848, 0.3786, 0.0711, 0.0360],\n",
      "          [0.1387, 0.0650, 0.5712, 0.2097, 0.0154],\n",
      "          [0.2704, 0.3180, 0.1307, 0.0653, 0.2155]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 5])\n",
      "old attention tensor([[[[0.5344, 0.1834, 0.0739, 0.1158, 0.0925]],\n",
      "\n",
      "         [[0.2768, 0.4165, 0.1611, 0.0534, 0.0922]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 5])\n",
      "old attention tensor([[[[0.7144, 0.0818, 0.1404, 0.0530, 0.0105]],\n",
      "\n",
      "         [[0.4355, 0.1275, 0.0897, 0.1048, 0.2424]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 5])\n",
      "old attention tensor([[[[0.0186, 0.9143, 0.0338, 0.0234, 0.0098]],\n",
      "\n",
      "         [[0.0463, 0.5966, 0.0203, 0.0578, 0.2790]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.5428, 0.4572]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0282, 0.9718]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.5428, 0.4572]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0282, 0.9718]]]])\n",
      "old attention torch.Size([1, 2, 2, 5])\n",
      "old attention tensor([[[[0.5344, 0.1834, 0.0739, 0.1158, 0.0925],\n",
      "          [0.0574, 0.1166, 0.0518, 0.2418, 0.5324]],\n",
      "\n",
      "         [[0.2768, 0.4165, 0.1611, 0.0534, 0.0922],\n",
      "          [0.2816, 0.0096, 0.5983, 0.0990, 0.0115]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0177, 0.9823]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.1218, 0.8782]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0177, 0.9823]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.1218, 0.8782]]]])\n",
      "old attention torch.Size([1, 2, 2, 5])\n",
      "old attention tensor([[[[0.7144, 0.0818, 0.1404, 0.0530, 0.0105],\n",
      "          [0.1206, 0.2928, 0.1705, 0.2908, 0.1252]],\n",
      "\n",
      "         [[0.4355, 0.1275, 0.0897, 0.1048, 0.2424],\n",
      "          [0.1319, 0.0738, 0.2935, 0.4517, 0.0492]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.3501, 0.6499]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.1915, 0.8085]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.3501, 0.6499]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.1915, 0.8085]]]])\n",
      "old attention torch.Size([1, 2, 2, 5])\n",
      "old attention tensor([[[[0.0186, 0.9143, 0.0338, 0.0234, 0.0098],\n",
      "          [0.0314, 0.0189, 0.3525, 0.4820, 0.1152]],\n",
      "\n",
      "         [[0.0463, 0.5966, 0.0203, 0.0578, 0.2790],\n",
      "          [0.0465, 0.1562, 0.2572, 0.1689, 0.3712]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.5428, 0.4572, 0.0000],\n",
      "          [0.0142, 0.0098, 0.9760]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.0282, 0.9718, 0.0000],\n",
      "          [0.7082, 0.0803, 0.2115]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 5])\n",
      "old attention tensor([[[[0.5885, 0.1924, 0.1156, 0.0775, 0.0260],\n",
      "          [0.0712, 0.1367, 0.1020, 0.2740, 0.4161],\n",
      "          [0.1080, 0.1118, 0.5678, 0.1244, 0.0880]],\n",
      "\n",
      "         [[0.0864, 0.3643, 0.0800, 0.0838, 0.3855],\n",
      "          [0.3163, 0.0105, 0.5314, 0.1336, 0.0082],\n",
      "          [0.0742, 0.3579, 0.1605, 0.1533, 0.2541]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.0858, 0.9142, 0.0000],\n",
      "          [0.2363, 0.2314, 0.5323]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.0338, 0.9662, 0.0000],\n",
      "          [0.0711, 0.4310, 0.4979]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 5])\n",
      "old attention tensor([[[[0.5483, 0.0555, 0.2513, 0.0928, 0.0521],\n",
      "          [0.1598, 0.3199, 0.3109, 0.1142, 0.0953],\n",
      "          [0.0583, 0.1043, 0.2823, 0.4006, 0.1545]],\n",
      "\n",
      "         [[0.3297, 0.0906, 0.2190, 0.2748, 0.0860],\n",
      "          [0.1857, 0.1654, 0.1225, 0.4446, 0.0818],\n",
      "          [0.0999, 0.1227, 0.1684, 0.4446, 0.1644]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.3806, 0.6194, 0.0000],\n",
      "          [0.1816, 0.4160, 0.4024]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.0599, 0.9401, 0.0000],\n",
      "          [0.0673, 0.3088, 0.6239]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 5])\n",
      "old attention tensor([[[[0.2785, 0.1209, 0.0345, 0.1730, 0.3931],\n",
      "          [0.1146, 0.0562, 0.0547, 0.3140, 0.4606],\n",
      "          [0.2629, 0.0328, 0.0252, 0.2081, 0.4709]],\n",
      "\n",
      "         [[0.5657, 0.2327, 0.0346, 0.0706, 0.0964],\n",
      "          [0.4457, 0.0898, 0.0958, 0.1522, 0.2165],\n",
      "          [0.6437, 0.1519, 0.0497, 0.0775, 0.0772]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5428, 0.4572, 0.0000, 0.0000],\n",
      "          [0.0142, 0.0098, 0.9760, 0.0000],\n",
      "          [0.0145, 0.0243, 0.9095, 0.0516]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0282, 0.9718, 0.0000, 0.0000],\n",
      "          [0.7082, 0.0803, 0.2115, 0.0000],\n",
      "          [0.0433, 0.8921, 0.0327, 0.0319]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 5])\n",
      "old attention tensor([[[[0.6540, 0.1511, 0.0949, 0.0711, 0.0289],\n",
      "          [0.0843, 0.1107, 0.0843, 0.2592, 0.4615],\n",
      "          [0.1382, 0.0939, 0.5494, 0.1212, 0.0972],\n",
      "          [0.0487, 0.6113, 0.1142, 0.0933, 0.1325]],\n",
      "\n",
      "         [[0.0835, 0.3784, 0.0748, 0.0773, 0.3859],\n",
      "          [0.3211, 0.0109, 0.5342, 0.1259, 0.0080],\n",
      "          [0.0646, 0.3967, 0.1432, 0.1336, 0.2619],\n",
      "          [0.3418, 0.0320, 0.1038, 0.3769, 0.1455]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0733, 0.9267, 0.0000, 0.0000],\n",
      "          [0.2131, 0.2367, 0.5502, 0.0000],\n",
      "          [0.0074, 0.0244, 0.2876, 0.6806]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0426, 0.9574, 0.0000, 0.0000],\n",
      "          [0.0724, 0.4041, 0.5235, 0.0000],\n",
      "          [0.0230, 0.1576, 0.5925, 0.2268]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 5])\n",
      "old attention tensor([[[[0.6947, 0.0346, 0.1599, 0.0819, 0.0290],\n",
      "          [0.2148, 0.3128, 0.2519, 0.1366, 0.0839],\n",
      "          [0.0713, 0.0833, 0.2140, 0.4977, 0.1338],\n",
      "          [0.4662, 0.1002, 0.2712, 0.1321, 0.0303]],\n",
      "\n",
      "         [[0.3545, 0.0439, 0.2812, 0.2775, 0.0429],\n",
      "          [0.2063, 0.0884, 0.1614, 0.4987, 0.0452],\n",
      "          [0.1075, 0.0652, 0.2179, 0.5137, 0.0957],\n",
      "          [0.2132, 0.0423, 0.2113, 0.4951, 0.0381]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.3088, 0.6912, 0.0000, 0.0000],\n",
      "          [0.1289, 0.3955, 0.4756, 0.0000],\n",
      "          [0.0803, 0.1292, 0.5114, 0.2790]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.1042, 0.8958, 0.0000, 0.0000],\n",
      "          [0.0574, 0.2012, 0.7413, 0.0000],\n",
      "          [0.0698, 0.0999, 0.7260, 0.1043]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 5])\n",
      "old attention tensor([[[[0.2326, 0.0896, 0.0460, 0.1774, 0.4545],\n",
      "          [0.0632, 0.0399, 0.0797, 0.3266, 0.4906],\n",
      "          [0.1605, 0.0232, 0.0341, 0.1913, 0.5910],\n",
      "          [0.0703, 0.0232, 0.0564, 0.2344, 0.6156]],\n",
      "\n",
      "         [[0.5411, 0.2588, 0.0360, 0.0674, 0.0968],\n",
      "          [0.3916, 0.1045, 0.1142, 0.1533, 0.2364],\n",
      "          [0.6286, 0.1723, 0.0518, 0.0708, 0.0765],\n",
      "          [0.5858, 0.1042, 0.0849, 0.1639, 0.0612]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5428, 0.4572, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0142, 0.0098, 0.9760, 0.0000, 0.0000],\n",
      "          [0.0145, 0.0243, 0.9095, 0.0516, 0.0000],\n",
      "          [0.0058, 0.0047, 0.5558, 0.0186, 0.4150]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0282, 0.9718, 0.0000, 0.0000, 0.0000],\n",
      "          [0.7082, 0.0803, 0.2115, 0.0000, 0.0000],\n",
      "          [0.0433, 0.8921, 0.0327, 0.0319, 0.0000],\n",
      "          [0.0322, 0.0037, 0.0073, 0.9506, 0.0063]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[0.6214, 0.1722, 0.1112, 0.0709, 0.0243],\n",
      "          [0.0827, 0.1308, 0.1019, 0.2724, 0.4123],\n",
      "          [0.1242, 0.1028, 0.5813, 0.1140, 0.0778],\n",
      "          [0.0447, 0.6364, 0.1271, 0.0879, 0.1039],\n",
      "          [0.1402, 0.0914, 0.5475, 0.1263, 0.0945]],\n",
      "\n",
      "         [[0.0591, 0.3482, 0.0644, 0.0855, 0.4428],\n",
      "          [0.2666, 0.0110, 0.5504, 0.1620, 0.0100],\n",
      "          [0.0483, 0.3653, 0.1266, 0.1530, 0.3069],\n",
      "          [0.2507, 0.0329, 0.0960, 0.4389, 0.1816],\n",
      "          [0.0512, 0.3646, 0.1348, 0.1634, 0.2860]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.1382, 0.8618, 0.0000, 0.0000, 0.0000],\n",
      "          [0.3066, 0.1992, 0.4942, 0.0000, 0.0000],\n",
      "          [0.0132, 0.0220, 0.2880, 0.6769, 0.0000],\n",
      "          [0.1532, 0.1034, 0.2479, 0.2240, 0.2715]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0390, 0.9610, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0726, 0.4136, 0.5138, 0.0000, 0.0000],\n",
      "          [0.0265, 0.1719, 0.6135, 0.1880, 0.0000],\n",
      "          [0.0414, 0.2133, 0.3354, 0.0680, 0.3420]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[0.5724, 0.0424, 0.2242, 0.0963, 0.0647],\n",
      "          [0.1532, 0.2715, 0.3070, 0.1309, 0.1375],\n",
      "          [0.0605, 0.0789, 0.2452, 0.4151, 0.2002],\n",
      "          [0.3660, 0.0960, 0.3384, 0.1455, 0.0541],\n",
      "          [0.0608, 0.0807, 0.2443, 0.4165, 0.1976]],\n",
      "\n",
      "         [[0.3150, 0.0505, 0.2959, 0.2958, 0.0428],\n",
      "          [0.1789, 0.0776, 0.1613, 0.5471, 0.0351],\n",
      "          [0.1040, 0.0784, 0.2324, 0.4920, 0.0933],\n",
      "          [0.1966, 0.0474, 0.2183, 0.5011, 0.0366],\n",
      "          [0.0972, 0.0761, 0.2214, 0.5059, 0.0994]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.3707, 0.6293, 0.0000, 0.0000, 0.0000],\n",
      "          [0.1811, 0.4361, 0.3828, 0.0000, 0.0000],\n",
      "          [0.1320, 0.1760, 0.4275, 0.2645, 0.0000],\n",
      "          [0.1175, 0.2360, 0.2570, 0.1198, 0.2698]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.1361, 0.8639, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0974, 0.2298, 0.6728, 0.0000, 0.0000],\n",
      "          [0.0947, 0.1214, 0.6580, 0.1259, 0.0000],\n",
      "          [0.0481, 0.1075, 0.3751, 0.1192, 0.3500]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[0.2255, 0.0465, 0.0271, 0.1183, 0.5825],\n",
      "          [0.0859, 0.0204, 0.0291, 0.1616, 0.7030],\n",
      "          [0.1826, 0.0147, 0.0204, 0.1249, 0.6574],\n",
      "          [0.0910, 0.0137, 0.0279, 0.1399, 0.7275],\n",
      "          [0.1644, 0.0140, 0.0175, 0.1054, 0.6988]],\n",
      "\n",
      "         [[0.7169, 0.1412, 0.0345, 0.0571, 0.0503],\n",
      "          [0.6260, 0.0603, 0.0821, 0.1268, 0.1049],\n",
      "          [0.7767, 0.0901, 0.0418, 0.0524, 0.0391],\n",
      "          [0.7453, 0.0576, 0.0601, 0.1042, 0.0329],\n",
      "          [0.7853, 0.0869, 0.0393, 0.0500, 0.0384]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "predicted trg = ['ich', 'trinken', 'bier', 'trinken', '<eos>']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_count 1    self.capacity  20\n",
      "0  ------------------------------------------------\n",
      "DecoderLayer@trg4\n",
      "[1, 1, 64]\n",
      "src = ['i', 'read', 'book']\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[5.0490e-02, 4.4734e-01, 1.6760e-01, 2.3232e-01, 1.0226e-01],\n",
      "          [2.4178e-02, 1.1661e-02, 2.8757e-02, 9.3516e-01, 2.3871e-04],\n",
      "          [8.5350e-03, 3.2141e-04, 3.5886e-03, 9.8575e-01, 1.8062e-03],\n",
      "          [1.6974e-01, 4.3503e-02, 2.9075e-01, 1.8941e-01, 3.0660e-01],\n",
      "          [3.9132e-02, 1.2332e-01, 1.0132e-01, 7.2432e-01, 1.1907e-02]],\n",
      "\n",
      "         [[3.4960e-01, 2.2722e-01, 1.3881e-01, 2.5153e-02, 2.5922e-01],\n",
      "          [1.1173e-01, 4.5442e-01, 2.5594e-02, 1.4798e-01, 2.6027e-01],\n",
      "          [3.9267e-01, 1.6759e-02, 1.1992e-02, 3.8590e-02, 5.3999e-01],\n",
      "          [1.4584e-01, 1.1631e-01, 1.3748e-01, 3.8338e-01, 2.1699e-01],\n",
      "          [1.4834e-02, 6.9605e-03, 8.1823e-01, 2.6821e-02, 1.3316e-01]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[0.1070, 0.0587, 0.5823, 0.1729, 0.0790],\n",
      "          [0.0952, 0.2062, 0.1817, 0.3564, 0.1605],\n",
      "          [0.1493, 0.0673, 0.6153, 0.0813, 0.0868],\n",
      "          [0.3070, 0.0739, 0.3763, 0.1433, 0.0995],\n",
      "          [0.0582, 0.0490, 0.1809, 0.6902, 0.0216]],\n",
      "\n",
      "         [[0.2534, 0.2680, 0.1556, 0.1452, 0.1778],\n",
      "          [0.0485, 0.1458, 0.2364, 0.2062, 0.3632],\n",
      "          [0.2574, 0.3388, 0.1382, 0.1602, 0.1055],\n",
      "          [0.1286, 0.2884, 0.1344, 0.1614, 0.2872],\n",
      "          [0.0456, 0.0769, 0.2710, 0.1675, 0.4389]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[0.1679, 0.4321, 0.0736, 0.1819, 0.1445],\n",
      "          [0.1576, 0.1051, 0.4411, 0.0905, 0.2058],\n",
      "          [0.1340, 0.2044, 0.0944, 0.0930, 0.4743],\n",
      "          [0.1754, 0.4234, 0.2488, 0.0293, 0.1231],\n",
      "          [0.3979, 0.0841, 0.2347, 0.1396, 0.1437]],\n",
      "\n",
      "         [[0.1821, 0.2832, 0.4897, 0.0255, 0.0196],\n",
      "          [0.0499, 0.1652, 0.2415, 0.0328, 0.5106],\n",
      "          [0.2446, 0.0117, 0.6872, 0.0218, 0.0347],\n",
      "          [0.2994, 0.1160, 0.2457, 0.0286, 0.3104],\n",
      "          [0.2716, 0.1301, 0.3773, 0.0565, 0.1645]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 5])\n",
      "old attention tensor([[[[0.5150, 0.1780, 0.1159, 0.1140, 0.0771]],\n",
      "\n",
      "         [[0.2776, 0.3738, 0.1677, 0.0874, 0.0935]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 5])\n",
      "old attention tensor([[[[0.7851, 0.1156, 0.0518, 0.0359, 0.0118]],\n",
      "\n",
      "         [[0.1668, 0.0786, 0.4900, 0.1212, 0.1434]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 5])\n",
      "old attention tensor([[[[0.0184, 0.9673, 0.0058, 0.0051, 0.0036]],\n",
      "\n",
      "         [[0.0231, 0.4527, 0.0670, 0.1146, 0.3427]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.5428, 0.4572]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0282, 0.9718]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.5428, 0.4572]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0282, 0.9718]]]])\n",
      "old attention torch.Size([1, 2, 2, 5])\n",
      "old attention tensor([[[[0.5150, 0.1780, 0.1159, 0.1140, 0.0771],\n",
      "          [0.0384, 0.0668, 0.2066, 0.3988, 0.2894]],\n",
      "\n",
      "         [[0.2776, 0.3738, 0.1677, 0.0874, 0.0935],\n",
      "          [0.4338, 0.0152, 0.0808, 0.4542, 0.0160]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0178, 0.9822]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0904, 0.9096]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0178, 0.9822]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0904, 0.9096]]]])\n",
      "old attention torch.Size([1, 2, 2, 5])\n",
      "old attention tensor([[[[0.7851, 0.1156, 0.0518, 0.0359, 0.0118],\n",
      "          [0.0573, 0.1797, 0.3688, 0.2837, 0.1105]],\n",
      "\n",
      "         [[0.1668, 0.0786, 0.4900, 0.1212, 0.1434],\n",
      "          [0.1843, 0.1659, 0.1282, 0.3693, 0.1522]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.4093, 0.5907]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0946, 0.9054]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.4093, 0.5907]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0946, 0.9054]]]])\n",
      "old attention torch.Size([1, 2, 2, 5])\n",
      "old attention tensor([[[[0.0184, 0.9673, 0.0058, 0.0051, 0.0036],\n",
      "          [0.0512, 0.0490, 0.1186, 0.7188, 0.0624]],\n",
      "\n",
      "         [[0.0231, 0.4527, 0.0670, 0.1146, 0.3427],\n",
      "          [0.0080, 0.0549, 0.0725, 0.6153, 0.2492]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [5.4283e-01, 4.5717e-01, 0.0000e+00],\n",
      "          [5.7928e-03, 9.5962e-04, 9.9325e-01]],\n",
      "\n",
      "         [[1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [2.8229e-02, 9.7177e-01, 0.0000e+00],\n",
      "          [2.5488e-03, 1.1255e-01, 8.8490e-01]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 5])\n",
      "old attention tensor([[[[0.6745, 0.2157, 0.0487, 0.0369, 0.0243],\n",
      "          [0.0678, 0.1273, 0.1814, 0.3356, 0.2878],\n",
      "          [0.4407, 0.1077, 0.1374, 0.1546, 0.1595]],\n",
      "\n",
      "         [[0.0931, 0.2091, 0.5268, 0.0482, 0.1228],\n",
      "          [0.7789, 0.0182, 0.0847, 0.1087, 0.0095],\n",
      "          [0.0914, 0.1230, 0.6858, 0.0445, 0.0553]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.0658, 0.9342, 0.0000],\n",
      "          [0.0042, 0.0484, 0.9474]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.0138, 0.9862, 0.0000],\n",
      "          [0.0183, 0.4935, 0.4883]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 5])\n",
      "old attention tensor([[[[0.5411, 0.0849, 0.1485, 0.1380, 0.0875],\n",
      "          [0.0911, 0.3484, 0.2415, 0.1719, 0.1471],\n",
      "          [0.2053, 0.2316, 0.2270, 0.2361, 0.1000]],\n",
      "\n",
      "         [[0.4281, 0.1219, 0.1964, 0.1105, 0.1431],\n",
      "          [0.2576, 0.2144, 0.1049, 0.2971, 0.1261],\n",
      "          [0.1388, 0.3819, 0.1510, 0.0956, 0.2328]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.4345, 0.5655, 0.0000],\n",
      "          [0.2094, 0.3470, 0.4436]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.1623, 0.8377, 0.0000],\n",
      "          [0.0669, 0.0898, 0.8434]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 5])\n",
      "old attention tensor([[[[0.3826, 0.2786, 0.1097, 0.0858, 0.1432],\n",
      "          [0.0594, 0.1742, 0.1028, 0.5258, 0.1377],\n",
      "          [0.0832, 0.1035, 0.1985, 0.3226, 0.2922]],\n",
      "\n",
      "         [[0.1795, 0.5616, 0.0676, 0.0629, 0.1283],\n",
      "          [0.0358, 0.1776, 0.1253, 0.3810, 0.2803],\n",
      "          [0.1946, 0.3646, 0.0737, 0.2333, 0.1339]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "predicted trg = ['ich', 'lesen', '<eos>']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_count 1    self.capacity  20\n",
      "0  ------------------------------------------------\n",
      "DecoderLayer@trg4\n",
      "[1, 1, 64]\n",
      "src = ['i', 'read', 'newspaper']\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[0.0178, 0.1578, 0.0591, 0.7292, 0.0361],\n",
      "          [0.1153, 0.0556, 0.1371, 0.6909, 0.0011],\n",
      "          [0.0335, 0.0013, 0.0141, 0.9440, 0.0071],\n",
      "          [0.4514, 0.0616, 0.4078, 0.0345, 0.0448],\n",
      "          [0.0141, 0.0443, 0.0364, 0.9009, 0.0043]],\n",
      "\n",
      "         [[0.1480, 0.0962, 0.0588, 0.5873, 0.1097],\n",
      "          [0.0946, 0.3848, 0.0217, 0.2785, 0.2204],\n",
      "          [0.3334, 0.0142, 0.0102, 0.1838, 0.4584],\n",
      "          [0.0065, 0.1109, 0.5827, 0.1462, 0.1537],\n",
      "          [0.0149, 0.0070, 0.8192, 0.0256, 0.1333]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[0.0726, 0.0469, 0.4315, 0.3710, 0.0779],\n",
      "          [0.0915, 0.2014, 0.2028, 0.3096, 0.1947],\n",
      "          [0.1569, 0.0813, 0.5218, 0.1368, 0.1032],\n",
      "          [0.1264, 0.1840, 0.0392, 0.5438, 0.1067],\n",
      "          [0.0712, 0.0695, 0.2694, 0.5506, 0.0393]],\n",
      "\n",
      "         [[0.2784, 0.3160, 0.1229, 0.1073, 0.1754],\n",
      "          [0.0357, 0.1130, 0.1627, 0.4607, 0.2279],\n",
      "          [0.2037, 0.2249, 0.0889, 0.4265, 0.0560],\n",
      "          [0.8978, 0.0450, 0.0165, 0.0143, 0.0264],\n",
      "          [0.0452, 0.0741, 0.2221, 0.3192, 0.3394]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[0.1692, 0.5060, 0.1029, 0.1173, 0.1045],\n",
      "          [0.1129, 0.0789, 0.2836, 0.4234, 0.1012],\n",
      "          [0.1461, 0.1567, 0.0893, 0.2435, 0.3644],\n",
      "          [0.0808, 0.0490, 0.0292, 0.4810, 0.3600],\n",
      "          [0.3817, 0.1022, 0.1941, 0.1918, 0.1303]],\n",
      "\n",
      "         [[0.1981, 0.2055, 0.4932, 0.0803, 0.0229],\n",
      "          [0.0397, 0.0997, 0.2626, 0.2031, 0.3949],\n",
      "          [0.2469, 0.0115, 0.5588, 0.1433, 0.0395],\n",
      "          [0.2119, 0.0864, 0.3865, 0.1211, 0.1941],\n",
      "          [0.2323, 0.1161, 0.3225, 0.1661, 0.1630]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 5])\n",
      "old attention tensor([[[[0.5020, 0.2309, 0.1330, 0.0589, 0.0752]],\n",
      "\n",
      "         [[0.2585, 0.2630, 0.1467, 0.2546, 0.0772]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 5])\n",
      "old attention tensor([[[[0.7331, 0.1150, 0.0599, 0.0762, 0.0158]],\n",
      "\n",
      "         [[0.1172, 0.0954, 0.3374, 0.3094, 0.1405]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 5])\n",
      "old attention tensor([[[[0.0169, 0.9671, 0.0042, 0.0064, 0.0054]],\n",
      "\n",
      "         [[0.0164, 0.4570, 0.0520, 0.1136, 0.3610]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.5428, 0.4572]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0282, 0.9718]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.5428, 0.4572]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0282, 0.9718]]]])\n",
      "old attention torch.Size([1, 2, 2, 5])\n",
      "old attention tensor([[[[0.5020, 0.2309, 0.1330, 0.0589, 0.0752],\n",
      "          [0.0589, 0.0856, 0.2206, 0.2462, 0.3886]],\n",
      "\n",
      "         [[0.2585, 0.2630, 0.1467, 0.2546, 0.0772],\n",
      "          [0.3068, 0.0096, 0.0860, 0.5842, 0.0134]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0158, 0.9842]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.1339, 0.8661]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0158, 0.9842]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.1339, 0.8661]]]])\n",
      "old attention torch.Size([1, 2, 2, 5])\n",
      "old attention tensor([[[[0.7331, 0.1150, 0.0599, 0.0762, 0.0158],\n",
      "          [0.0868, 0.2130, 0.3962, 0.1542, 0.1498]],\n",
      "\n",
      "         [[0.1172, 0.0954, 0.3374, 0.3094, 0.1405],\n",
      "          [0.2661, 0.2105, 0.1589, 0.1865, 0.1779]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.4235, 0.5765]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.1209, 0.8791]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.4235, 0.5765]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.1209, 0.8791]]]])\n",
      "old attention torch.Size([1, 2, 2, 5])\n",
      "old attention tensor([[[[0.0169, 0.9671, 0.0042, 0.0064, 0.0054],\n",
      "          [0.0999, 0.1812, 0.2733, 0.2786, 0.1670]],\n",
      "\n",
      "         [[0.0164, 0.4570, 0.0520, 0.1136, 0.3610],\n",
      "          [0.0092, 0.0639, 0.0768, 0.5625, 0.2877]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [5.4283e-01, 4.5717e-01, 0.0000e+00],\n",
      "          [5.7928e-03, 9.5962e-04, 9.9325e-01]],\n",
      "\n",
      "         [[1.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [2.8229e-02, 9.7177e-01, 0.0000e+00],\n",
      "          [2.5488e-03, 1.1255e-01, 8.8490e-01]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 5])\n",
      "old attention tensor([[[[0.6018, 0.2848, 0.0604, 0.0266, 0.0263],\n",
      "          [0.0921, 0.1459, 0.1718, 0.2319, 0.3584],\n",
      "          [0.4093, 0.1094, 0.1489, 0.1468, 0.1856]],\n",
      "\n",
      "         [[0.0657, 0.1188, 0.3929, 0.3357, 0.0870],\n",
      "          [0.6805, 0.0137, 0.1084, 0.1884, 0.0089],\n",
      "          [0.0781, 0.0955, 0.5737, 0.2066, 0.0461]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.0452, 0.9548, 0.0000],\n",
      "          [0.0069, 0.0839, 0.9093]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.0243, 0.9757, 0.0000],\n",
      "          [0.0330, 0.4514, 0.5156]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 5])\n",
      "old attention tensor([[[[0.4808, 0.1331, 0.1514, 0.1190, 0.1157],\n",
      "          [0.1258, 0.3237, 0.2170, 0.1813, 0.1521],\n",
      "          [0.2836, 0.2642, 0.2262, 0.1080, 0.1180]],\n",
      "\n",
      "         [[0.1887, 0.0943, 0.1307, 0.4855, 0.1009],\n",
      "          [0.3031, 0.2492, 0.1290, 0.1691, 0.1496],\n",
      "          [0.0922, 0.2626, 0.0986, 0.3644, 0.1822]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.3971, 0.6029, 0.0000],\n",
      "          [0.2135, 0.4160, 0.3705]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.2237, 0.7763, 0.0000],\n",
      "          [0.0735, 0.0634, 0.8631]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 5])\n",
      "old attention tensor([[[[0.2261, 0.2718, 0.0668, 0.2291, 0.2062],\n",
      "          [0.0878, 0.3580, 0.1381, 0.1695, 0.2466],\n",
      "          [0.0572, 0.1194, 0.1673, 0.2943, 0.3618]],\n",
      "\n",
      "         [[0.1903, 0.3835, 0.0477, 0.2068, 0.1718],\n",
      "          [0.0464, 0.1559, 0.0888, 0.3597, 0.3492],\n",
      "          [0.2534, 0.3034, 0.0495, 0.2249, 0.1688]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [5.4283e-01, 4.5717e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [5.7928e-03, 9.5962e-04, 9.9325e-01, 0.0000e+00],\n",
      "          [3.2158e-02, 5.3844e-02, 8.9735e-01, 1.6650e-02]],\n",
      "\n",
      "         [[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [2.8229e-02, 9.7177e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [2.5488e-03, 1.1255e-01, 8.8490e-01, 0.0000e+00],\n",
      "          [5.3481e-03, 7.5643e-01, 2.1576e-01, 2.2460e-02]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 5])\n",
      "old attention tensor([[[[0.6485, 0.2151, 0.0718, 0.0347, 0.0299],\n",
      "          [0.0818, 0.0939, 0.1798, 0.2728, 0.3717],\n",
      "          [0.3859, 0.0775, 0.1620, 0.1766, 0.1980],\n",
      "          [0.4937, 0.1264, 0.1333, 0.1552, 0.0914]],\n",
      "\n",
      "         [[0.0486, 0.1225, 0.3613, 0.3650, 0.1026],\n",
      "          [0.6225, 0.0159, 0.1135, 0.2363, 0.0118],\n",
      "          [0.0643, 0.1042, 0.5440, 0.2300, 0.0575],\n",
      "          [0.0725, 0.0113, 0.3106, 0.5781, 0.0275]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0340, 0.9660, 0.0000, 0.0000],\n",
      "          [0.0058, 0.0749, 0.9193, 0.0000],\n",
      "          [0.0065, 0.0642, 0.4947, 0.4346]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0284, 0.9716, 0.0000, 0.0000],\n",
      "          [0.0361, 0.4423, 0.5215, 0.0000],\n",
      "          [0.0403, 0.1917, 0.3369, 0.4312]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 5])\n",
      "old attention tensor([[[[0.4576, 0.1164, 0.1701, 0.1129, 0.1432],\n",
      "          [0.1003, 0.2892, 0.2464, 0.1734, 0.1907],\n",
      "          [0.2518, 0.2343, 0.2651, 0.1069, 0.1419],\n",
      "          [0.2435, 0.2195, 0.2390, 0.1014, 0.1966]],\n",
      "\n",
      "         [[0.2058, 0.0899, 0.1209, 0.4909, 0.0925],\n",
      "          [0.3258, 0.2612, 0.1169, 0.1485, 0.1475],\n",
      "          [0.1028, 0.2701, 0.0997, 0.3379, 0.1895],\n",
      "          [0.1863, 0.2051, 0.1620, 0.1908, 0.2558]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4187, 0.5813, 0.0000, 0.0000],\n",
      "          [0.2478, 0.3645, 0.3876, 0.0000],\n",
      "          [0.1184, 0.2020, 0.4571, 0.2225]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.2343, 0.7657, 0.0000, 0.0000],\n",
      "          [0.1164, 0.0876, 0.7960, 0.0000],\n",
      "          [0.0393, 0.0867, 0.6383, 0.2358]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 5])\n",
      "old attention tensor([[[[0.2212, 0.1574, 0.0829, 0.3058, 0.2327],\n",
      "          [0.0796, 0.2212, 0.1793, 0.2211, 0.2988],\n",
      "          [0.0513, 0.0686, 0.1857, 0.3342, 0.3602],\n",
      "          [0.1246, 0.0630, 0.1899, 0.3081, 0.3144]],\n",
      "\n",
      "         [[0.2157, 0.3637, 0.0467, 0.2283, 0.1455],\n",
      "          [0.0579, 0.1500, 0.0961, 0.4027, 0.2933],\n",
      "          [0.2810, 0.2795, 0.0515, 0.2483, 0.1397],\n",
      "          [0.2345, 0.2046, 0.0821, 0.2779, 0.2008]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [5.4283e-01, 4.5717e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [5.7928e-03, 9.5962e-04, 9.9325e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [3.2158e-02, 5.3844e-02, 8.9735e-01, 1.6650e-02, 0.0000e+00],\n",
      "          [1.8754e-03, 3.6060e-04, 4.1220e-01, 1.1487e-03, 5.8442e-01]],\n",
      "\n",
      "         [[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [2.8229e-02, 9.7177e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [2.5488e-03, 1.1255e-01, 8.8490e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [5.3481e-03, 7.5643e-01, 2.1576e-01, 2.2460e-02, 0.0000e+00],\n",
      "          [9.4989e-04, 4.2061e-02, 4.3012e-01, 5.9595e-02, 4.6727e-01]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[0.6224, 0.2594, 0.0602, 0.0309, 0.0270],\n",
      "          [0.0911, 0.1266, 0.1639, 0.2605, 0.3579],\n",
      "          [0.4075, 0.1013, 0.1450, 0.1630, 0.1832],\n",
      "          [0.5084, 0.1583, 0.1141, 0.1374, 0.0818],\n",
      "          [0.4100, 0.0832, 0.1474, 0.1637, 0.1956]],\n",
      "\n",
      "         [[0.0486, 0.1309, 0.4314, 0.2777, 0.1114],\n",
      "          [0.6360, 0.0166, 0.1445, 0.1906, 0.0123],\n",
      "          [0.0604, 0.1054, 0.6011, 0.1735, 0.0596],\n",
      "          [0.0751, 0.0131, 0.4000, 0.4798, 0.0320],\n",
      "          [0.0634, 0.1081, 0.6098, 0.1600, 0.0588]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0499, 0.9501, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0100, 0.0823, 0.9077, 0.0000, 0.0000],\n",
      "          [0.0107, 0.0636, 0.5146, 0.4112, 0.0000],\n",
      "          [0.0045, 0.0401, 0.3904, 0.1350, 0.4300]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0226, 0.9774, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0382, 0.4021, 0.5596, 0.0000, 0.0000],\n",
      "          [0.0374, 0.1947, 0.3410, 0.4269, 0.0000],\n",
      "          [0.0148, 0.1427, 0.2273, 0.3288, 0.2864]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[0.3578, 0.1172, 0.1808, 0.1286, 0.2156],\n",
      "          [0.0825, 0.2646, 0.2293, 0.1792, 0.2444],\n",
      "          [0.2117, 0.2217, 0.2487, 0.1211, 0.1967],\n",
      "          [0.1966, 0.2075, 0.2299, 0.1117, 0.2543],\n",
      "          [0.1989, 0.2231, 0.2510, 0.1164, 0.2106]],\n",
      "\n",
      "         [[0.2623, 0.0851, 0.0949, 0.4712, 0.0865],\n",
      "          [0.3902, 0.2450, 0.0895, 0.1505, 0.1248],\n",
      "          [0.1315, 0.2544, 0.0858, 0.3508, 0.1775],\n",
      "          [0.2357, 0.2034, 0.1316, 0.1951, 0.2343],\n",
      "          [0.1296, 0.2377, 0.0827, 0.3710, 0.1792]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4274, 0.5726, 0.0000, 0.0000, 0.0000],\n",
      "          [0.2765, 0.3935, 0.3300, 0.0000, 0.0000],\n",
      "          [0.1528, 0.2221, 0.3902, 0.2348, 0.0000],\n",
      "          [0.1790, 0.2123, 0.2224, 0.1805, 0.2058]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.3832, 0.6168, 0.0000, 0.0000, 0.0000],\n",
      "          [0.1991, 0.1047, 0.6962, 0.0000, 0.0000],\n",
      "          [0.0915, 0.0880, 0.6358, 0.1847, 0.0000],\n",
      "          [0.1070, 0.0600, 0.4084, 0.0897, 0.3348]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[0.1739, 0.0589, 0.0836, 0.3454, 0.3383],\n",
      "          [0.0698, 0.0823, 0.1629, 0.2495, 0.4354],\n",
      "          [0.0507, 0.0368, 0.1523, 0.3359, 0.4243],\n",
      "          [0.0979, 0.0263, 0.1518, 0.3128, 0.4112],\n",
      "          [0.0493, 0.0361, 0.1453, 0.3313, 0.4379]],\n",
      "\n",
      "         [[0.4162, 0.2992, 0.0539, 0.1450, 0.0858],\n",
      "          [0.1878, 0.1755, 0.1268, 0.2965, 0.2134],\n",
      "          [0.4729, 0.2348, 0.0521, 0.1519, 0.0882],\n",
      "          [0.4781, 0.1791, 0.0750, 0.1608, 0.1069],\n",
      "          [0.4700, 0.2291, 0.0519, 0.1583, 0.0906]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "predicted trg = ['ich', 'lesen', 'zeitung', 'lesen', '<eos>']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_count 1    self.capacity  20\n",
      "0  ------------------------------------------------\n",
      "DecoderLayer@trg4\n",
      "[1, 1, 64]\n",
      "src = ['we', 'eat', 'bread']\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[0.0809, 0.0890, 0.4671, 0.1993, 0.1637],\n",
      "          [0.0044, 0.0069, 0.0200, 0.1197, 0.8490],\n",
      "          [0.1354, 0.0490, 0.0329, 0.0897, 0.6930],\n",
      "          [0.3540, 0.0129, 0.4478, 0.1659, 0.0194],\n",
      "          [0.0547, 0.0069, 0.2827, 0.6390, 0.0167]],\n",
      "\n",
      "         [[0.0477, 0.7657, 0.0186, 0.1326, 0.0354],\n",
      "          [0.1699, 0.0257, 0.1166, 0.5331, 0.1546],\n",
      "          [0.0427, 0.0585, 0.0450, 0.0459, 0.8079],\n",
      "          [0.0499, 0.0086, 0.8415, 0.0820, 0.0181],\n",
      "          [0.0753, 0.0903, 0.0797, 0.0786, 0.6760]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[0.1958, 0.0682, 0.2578, 0.2371, 0.2411],\n",
      "          [0.0896, 0.1482, 0.0679, 0.1424, 0.5519],\n",
      "          [0.0349, 0.0935, 0.5274, 0.0929, 0.2513],\n",
      "          [0.2137, 0.1492, 0.2124, 0.1145, 0.3102],\n",
      "          [0.2241, 0.1748, 0.3109, 0.1080, 0.1822]],\n",
      "\n",
      "         [[0.2913, 0.3164, 0.1613, 0.0642, 0.1668],\n",
      "          [0.0553, 0.4330, 0.2254, 0.2633, 0.0229],\n",
      "          [0.1142, 0.1131, 0.1828, 0.3308, 0.2591],\n",
      "          [0.0321, 0.1738, 0.0499, 0.6364, 0.1078],\n",
      "          [0.0374, 0.0368, 0.3941, 0.1540, 0.3778]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[0.0863, 0.4027, 0.3038, 0.1581, 0.0491],\n",
      "          [0.1319, 0.1071, 0.2950, 0.3117, 0.1543],\n",
      "          [0.1032, 0.0688, 0.7086, 0.0872, 0.0322],\n",
      "          [0.3535, 0.1634, 0.4621, 0.0137, 0.0073],\n",
      "          [0.1141, 0.2466, 0.5795, 0.0191, 0.0407]],\n",
      "\n",
      "         [[0.1586, 0.0339, 0.6587, 0.1309, 0.0178],\n",
      "          [0.0677, 0.0773, 0.6073, 0.1432, 0.1046],\n",
      "          [0.0591, 0.1045, 0.4082, 0.2699, 0.1583],\n",
      "          [0.0950, 0.0392, 0.6930, 0.1416, 0.0312],\n",
      "          [0.2386, 0.1067, 0.2458, 0.2214, 0.1875]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 5])\n",
      "old attention tensor([[[[0.1607, 0.4514, 0.1332, 0.2135, 0.0412]],\n",
      "\n",
      "         [[0.1594, 0.5797, 0.1819, 0.0449, 0.0342]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 5])\n",
      "old attention tensor([[[[0.3753, 0.5416, 0.0410, 0.0359, 0.0062]],\n",
      "\n",
      "         [[0.0177, 0.9395, 0.0086, 0.0158, 0.0185]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 5])\n",
      "old attention tensor([[[[0.1384, 0.2940, 0.1720, 0.1461, 0.2495]],\n",
      "\n",
      "         [[0.0712, 0.0495, 0.2265, 0.2124, 0.4403]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0548, 0.9452]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0098, 0.9902]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0548, 0.9452]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0098, 0.9902]]]])\n",
      "old attention torch.Size([1, 2, 2, 5])\n",
      "old attention tensor([[[[0.1607, 0.4514, 0.1332, 0.2135, 0.0412],\n",
      "          [0.1487, 0.0688, 0.2478, 0.0128, 0.5219]],\n",
      "\n",
      "         [[0.1594, 0.5797, 0.1819, 0.0449, 0.0342],\n",
      "          [0.6456, 0.0485, 0.2071, 0.0487, 0.0501]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0215, 0.9785]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.5502, 0.4498]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0215, 0.9785]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.5502, 0.4498]]]])\n",
      "old attention torch.Size([1, 2, 2, 5])\n",
      "old attention tensor([[[[0.3753, 0.5416, 0.0410, 0.0359, 0.0062],\n",
      "          [0.2757, 0.1131, 0.4840, 0.0459, 0.0812]],\n",
      "\n",
      "         [[0.0177, 0.9395, 0.0086, 0.0158, 0.0185],\n",
      "          [0.1949, 0.1557, 0.0610, 0.4511, 0.1373]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.5122, 0.4878]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0843, 0.9157]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.5122, 0.4878]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0843, 0.9157]]]])\n",
      "old attention torch.Size([1, 2, 2, 5])\n",
      "old attention tensor([[[[0.1384, 0.2940, 0.1720, 0.1461, 0.2495],\n",
      "          [0.0603, 0.2421, 0.2491, 0.1924, 0.2561]],\n",
      "\n",
      "         [[0.0712, 0.0495, 0.2265, 0.2124, 0.4403],\n",
      "          [0.0438, 0.0361, 0.2673, 0.3569, 0.2959]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.0548, 0.9452, 0.0000],\n",
      "          [0.1599, 0.7701, 0.0700]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.0098, 0.9902, 0.0000],\n",
      "          [0.0023, 0.0117, 0.9859]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 5])\n",
      "old attention tensor([[[[0.2795, 0.2935, 0.1936, 0.2059, 0.0276],\n",
      "          [0.1959, 0.1432, 0.1941, 0.0329, 0.4339],\n",
      "          [0.3120, 0.0390, 0.3895, 0.0336, 0.2260]],\n",
      "\n",
      "         [[0.0804, 0.4477, 0.3535, 0.0423, 0.0761],\n",
      "          [0.4723, 0.1643, 0.2569, 0.0649, 0.0417],\n",
      "          [0.0832, 0.5996, 0.2055, 0.0452, 0.0664]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.0398, 0.9602, 0.0000],\n",
      "          [0.0672, 0.2985, 0.6343]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.4101, 0.5899, 0.0000],\n",
      "          [0.0262, 0.8537, 0.1202]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 5])\n",
      "old attention tensor([[[[0.3025, 0.6520, 0.0277, 0.0149, 0.0030],\n",
      "          [0.4190, 0.3286, 0.2271, 0.0193, 0.0060],\n",
      "          [0.2636, 0.6697, 0.0451, 0.0148, 0.0068]],\n",
      "\n",
      "         [[0.0740, 0.8406, 0.0412, 0.0370, 0.0073],\n",
      "          [0.2559, 0.3639, 0.0507, 0.2284, 0.1011],\n",
      "          [0.1483, 0.1983, 0.0851, 0.3804, 0.1879]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.1257, 0.8743, 0.0000],\n",
      "          [0.1654, 0.5626, 0.2720]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.0846, 0.9154, 0.0000],\n",
      "          [0.1363, 0.4729, 0.3908]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 5])\n",
      "old attention tensor([[[[0.1144, 0.1473, 0.3144, 0.1351, 0.2888],\n",
      "          [0.1059, 0.0990, 0.1872, 0.1722, 0.4358],\n",
      "          [0.0538, 0.1328, 0.1679, 0.1330, 0.5126]],\n",
      "\n",
      "         [[0.1696, 0.0628, 0.4174, 0.1757, 0.1745],\n",
      "          [0.1414, 0.0423, 0.4230, 0.1674, 0.2259],\n",
      "          [0.1147, 0.0482, 0.3505, 0.3215, 0.1651]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0548, 0.9452, 0.0000, 0.0000],\n",
      "          [0.1599, 0.7701, 0.0700, 0.0000],\n",
      "          [0.0398, 0.0032, 0.9484, 0.0086]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0098, 0.9902, 0.0000, 0.0000],\n",
      "          [0.0023, 0.0117, 0.9859, 0.0000],\n",
      "          [0.0608, 0.1544, 0.7703, 0.0144]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 5])\n",
      "old attention tensor([[[[0.2529, 0.3258, 0.1900, 0.2067, 0.0247],\n",
      "          [0.1818, 0.1603, 0.1964, 0.0332, 0.4283],\n",
      "          [0.2965, 0.0408, 0.4080, 0.0320, 0.2226],\n",
      "          [0.3354, 0.1762, 0.3469, 0.0538, 0.0876]],\n",
      "\n",
      "         [[0.0810, 0.4816, 0.3219, 0.0467, 0.0689],\n",
      "          [0.4878, 0.1707, 0.2309, 0.0726, 0.0380],\n",
      "          [0.0794, 0.6386, 0.1787, 0.0466, 0.0567],\n",
      "          [0.1868, 0.3259, 0.1387, 0.1704, 0.1782]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0319, 0.9681, 0.0000, 0.0000],\n",
      "          [0.0734, 0.3380, 0.5887, 0.0000],\n",
      "          [0.0116, 0.0612, 0.3657, 0.5615]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4087, 0.5913, 0.0000, 0.0000],\n",
      "          [0.0225, 0.8390, 0.1384, 0.0000],\n",
      "          [0.0320, 0.1877, 0.0905, 0.6899]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 5])\n",
      "old attention tensor([[[[0.3472, 0.6107, 0.0191, 0.0184, 0.0045],\n",
      "          [0.5049, 0.2922, 0.1735, 0.0216, 0.0078],\n",
      "          [0.3039, 0.6392, 0.0314, 0.0164, 0.0090],\n",
      "          [0.5667, 0.2978, 0.0903, 0.0269, 0.0182]],\n",
      "\n",
      "         [[0.0870, 0.8058, 0.0636, 0.0360, 0.0075],\n",
      "          [0.2825, 0.3104, 0.0673, 0.2335, 0.1063],\n",
      "          [0.1542, 0.1574, 0.1158, 0.3788, 0.1938],\n",
      "          [0.2746, 0.3476, 0.1079, 0.1563, 0.1136]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.1577, 0.8423, 0.0000, 0.0000],\n",
      "          [0.2169, 0.5415, 0.2416, 0.0000],\n",
      "          [0.0663, 0.2345, 0.1243, 0.5749]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0662, 0.9338, 0.0000, 0.0000],\n",
      "          [0.1074, 0.5558, 0.3367, 0.0000],\n",
      "          [0.0416, 0.4639, 0.1853, 0.3092]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 5])\n",
      "old attention tensor([[[[0.0993, 0.0615, 0.2420, 0.1037, 0.4934],\n",
      "          [0.0725, 0.0348, 0.1243, 0.1223, 0.6461],\n",
      "          [0.0382, 0.0415, 0.1133, 0.0822, 0.7248],\n",
      "          [0.0632, 0.0194, 0.1072, 0.0566, 0.7536]],\n",
      "\n",
      "         [[0.3010, 0.0824, 0.4479, 0.0908, 0.0779],\n",
      "          [0.2776, 0.0609, 0.4617, 0.0976, 0.1022],\n",
      "          [0.2338, 0.0735, 0.4473, 0.1773, 0.0681],\n",
      "          [0.4578, 0.0951, 0.2991, 0.0880, 0.0599]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [5.4816e-02, 9.4518e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [1.5994e-01, 7.7011e-01, 6.9952e-02, 0.0000e+00, 0.0000e+00],\n",
      "          [3.9768e-02, 3.1554e-03, 9.4845e-01, 8.6304e-03, 0.0000e+00],\n",
      "          [4.0245e-02, 1.9729e-01, 1.3876e-02, 7.3361e-01, 1.4974e-02]],\n",
      "\n",
      "         [[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [9.8231e-03, 9.9018e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [2.3287e-03, 1.1725e-02, 9.8595e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [6.0794e-02, 1.5444e-01, 7.7033e-01, 1.4438e-02, 0.0000e+00],\n",
      "          [9.6738e-04, 6.0686e-03, 4.8765e-01, 1.2584e-02, 4.9273e-01]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[0.2669, 0.3052, 0.1668, 0.2405, 0.0206],\n",
      "          [0.2086, 0.1631, 0.1890, 0.0401, 0.3992],\n",
      "          [0.3330, 0.0423, 0.3832, 0.0409, 0.2006],\n",
      "          [0.3683, 0.1728, 0.3155, 0.0667, 0.0766],\n",
      "          [0.3594, 0.0368, 0.3508, 0.0362, 0.2168]],\n",
      "\n",
      "         [[0.0537, 0.4837, 0.3352, 0.0474, 0.0800],\n",
      "          [0.3908, 0.1978, 0.2797, 0.0831, 0.0486],\n",
      "          [0.0554, 0.6393, 0.1887, 0.0491, 0.0676],\n",
      "          [0.1259, 0.3342, 0.1489, 0.1778, 0.2132],\n",
      "          [0.0596, 0.6262, 0.1828, 0.0596, 0.0719]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0416, 0.9584, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0951, 0.2863, 0.6186, 0.0000, 0.0000],\n",
      "          [0.0173, 0.0621, 0.3882, 0.5324, 0.0000],\n",
      "          [0.0358, 0.1146, 0.2451, 0.3168, 0.2876]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.3979, 0.6021, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0214, 0.8000, 0.1786, 0.0000, 0.0000],\n",
      "          [0.0235, 0.1346, 0.0864, 0.7555, 0.0000],\n",
      "          [0.0041, 0.1278, 0.0341, 0.7914, 0.0427]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[0.3123, 0.6465, 0.0172, 0.0190, 0.0051],\n",
      "          [0.4668, 0.3187, 0.1797, 0.0245, 0.0102],\n",
      "          [0.2764, 0.6560, 0.0331, 0.0205, 0.0140],\n",
      "          [0.5233, 0.3249, 0.0959, 0.0319, 0.0239],\n",
      "          [0.2940, 0.6320, 0.0367, 0.0218, 0.0156]],\n",
      "\n",
      "         [[0.1618, 0.6404, 0.1361, 0.0529, 0.0087],\n",
      "          [0.3676, 0.1829, 0.1002, 0.2552, 0.0940],\n",
      "          [0.2007, 0.0839, 0.1649, 0.3841, 0.1665],\n",
      "          [0.3629, 0.1992, 0.1657, 0.1737, 0.0985],\n",
      "          [0.2020, 0.0860, 0.1846, 0.3664, 0.1609]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.1695, 0.8305, 0.0000, 0.0000, 0.0000],\n",
      "          [0.2037, 0.4983, 0.2979, 0.0000, 0.0000],\n",
      "          [0.0643, 0.2085, 0.1296, 0.5975, 0.0000],\n",
      "          [0.0657, 0.1535, 0.0957, 0.5783, 0.1069]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0969, 0.9031, 0.0000, 0.0000, 0.0000],\n",
      "          [0.1460, 0.4716, 0.3824, 0.0000, 0.0000],\n",
      "          [0.0564, 0.3690, 0.2504, 0.3242, 0.0000],\n",
      "          [0.0680, 0.2394, 0.2021, 0.2931, 0.1974]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[0.1035, 0.0305, 0.2075, 0.0847, 0.5739],\n",
      "          [0.0646, 0.0137, 0.0925, 0.0898, 0.7395],\n",
      "          [0.0509, 0.0223, 0.1107, 0.0786, 0.7375],\n",
      "          [0.0682, 0.0089, 0.0949, 0.0488, 0.7792],\n",
      "          [0.0527, 0.0216, 0.1114, 0.0784, 0.7358]],\n",
      "\n",
      "         [[0.5257, 0.1007, 0.2751, 0.0621, 0.0364],\n",
      "          [0.5435, 0.0778, 0.2846, 0.0486, 0.0456],\n",
      "          [0.4500, 0.1092, 0.2903, 0.1132, 0.0373],\n",
      "          [0.6663, 0.1074, 0.1601, 0.0416, 0.0246],\n",
      "          [0.4535, 0.1171, 0.2891, 0.1025, 0.0378]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "predicted trg = ['wir', 'essen', 'apfel', 'essen', '<eos>']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_count 1    self.capacity  20\n",
      "0  ------------------------------------------------\n",
      "DecoderLayer@trg4\n",
      "[1, 1, 64]\n",
      "src = ['we', 'eat', 'apple']\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[0.0825, 0.0908, 0.4766, 0.1830, 0.1671],\n",
      "          [0.0049, 0.0077, 0.0224, 0.0146, 0.9503],\n",
      "          [0.1344, 0.0487, 0.0327, 0.0959, 0.6883],\n",
      "          [0.0703, 0.1299, 0.1885, 0.2359, 0.3754],\n",
      "          [0.1087, 0.0137, 0.5613, 0.2833, 0.0331]],\n",
      "\n",
      "         [[0.0536, 0.8603, 0.0209, 0.0254, 0.0397],\n",
      "          [0.3113, 0.0472, 0.2137, 0.1446, 0.2832],\n",
      "          [0.0445, 0.0611, 0.0470, 0.0046, 0.8428],\n",
      "          [0.0014, 0.0026, 0.0225, 0.0169, 0.9566],\n",
      "          [0.0695, 0.0834, 0.0736, 0.1493, 0.6241]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[0.1792, 0.0517, 0.2320, 0.3430, 0.1941],\n",
      "          [0.0820, 0.1444, 0.0672, 0.1722, 0.5342],\n",
      "          [0.0429, 0.0902, 0.5126, 0.0801, 0.2742],\n",
      "          [0.1298, 0.1094, 0.2744, 0.0379, 0.4484],\n",
      "          [0.1662, 0.1475, 0.2434, 0.2785, 0.1644]],\n",
      "\n",
      "         [[0.2908, 0.2902, 0.1596, 0.1172, 0.1422],\n",
      "          [0.0648, 0.5383, 0.2550, 0.1145, 0.0274],\n",
      "          [0.1115, 0.1325, 0.2161, 0.2867, 0.2533],\n",
      "          [0.0748, 0.0203, 0.0102, 0.8125, 0.0822],\n",
      "          [0.0415, 0.0382, 0.3801, 0.1771, 0.3632]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[0.0780, 0.3274, 0.2518, 0.3075, 0.0354],\n",
      "          [0.1183, 0.0842, 0.2501, 0.4720, 0.0754],\n",
      "          [0.0601, 0.0519, 0.5449, 0.3291, 0.0140],\n",
      "          [0.0584, 0.1080, 0.4450, 0.3793, 0.0092],\n",
      "          [0.0911, 0.1660, 0.4880, 0.2401, 0.0149]],\n",
      "\n",
      "         [[0.1053, 0.0381, 0.4425, 0.4023, 0.0117],\n",
      "          [0.0510, 0.0916, 0.5335, 0.2451, 0.0788],\n",
      "          [0.0484, 0.1199, 0.3651, 0.3698, 0.0968],\n",
      "          [0.0479, 0.1099, 0.2476, 0.4713, 0.1233],\n",
      "          [0.2122, 0.1344, 0.2864, 0.2115, 0.1556]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 5])\n",
      "old attention tensor([[[[0.1633, 0.5874, 0.1385, 0.0625, 0.0483]],\n",
      "\n",
      "         [[0.1357, 0.4121, 0.1360, 0.2874, 0.0288]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 5])\n",
      "old attention tensor([[[[0.3915, 0.5075, 0.0468, 0.0490, 0.0054]],\n",
      "\n",
      "         [[0.0185, 0.9417, 0.0101, 0.0129, 0.0169]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 5])\n",
      "old attention tensor([[[[0.1395, 0.3481, 0.1672, 0.1549, 0.1903]],\n",
      "\n",
      "         [[0.0365, 0.0258, 0.1365, 0.4853, 0.3158]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0548, 0.9452]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0098, 0.9902]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0548, 0.9452]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0098, 0.9902]]]])\n",
      "old attention torch.Size([1, 2, 2, 5])\n",
      "old attention tensor([[[[0.1633, 0.5874, 0.1385, 0.0625, 0.0483],\n",
      "          [0.1204, 0.0378, 0.1422, 0.4001, 0.2996]],\n",
      "\n",
      "         [[0.1357, 0.4121, 0.1360, 0.2874, 0.0288],\n",
      "          [0.6398, 0.0518, 0.1886, 0.0643, 0.0556]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0149, 0.9851]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.5716, 0.4284]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0149, 0.9851]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.5716, 0.4284]]]])\n",
      "old attention torch.Size([1, 2, 2, 5])\n",
      "old attention tensor([[[[0.3915, 0.5075, 0.0468, 0.0490, 0.0054],\n",
      "          [0.2208, 0.0866, 0.4353, 0.2124, 0.0450]],\n",
      "\n",
      "         [[0.0185, 0.9417, 0.0101, 0.0129, 0.0169],\n",
      "          [0.3269, 0.2528, 0.0971, 0.1392, 0.1840]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.4754, 0.5246]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.1643, 0.8357]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.4754, 0.5246]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.1643, 0.8357]]]])\n",
      "old attention torch.Size([1, 2, 2, 5])\n",
      "old attention tensor([[[[0.1395, 0.3481, 0.1672, 0.1549, 0.1903],\n",
      "          [0.0513, 0.2359, 0.1823, 0.3652, 0.1653]],\n",
      "\n",
      "         [[0.0365, 0.0258, 0.1365, 0.4853, 0.3158],\n",
      "          [0.0393, 0.0406, 0.2478, 0.2227, 0.4496]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.0548, 0.9452, 0.0000],\n",
      "          [0.1599, 0.7701, 0.0700]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.0098, 0.9902, 0.0000],\n",
      "          [0.0023, 0.0117, 0.9859]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 5])\n",
      "old attention tensor([[[[0.3269, 0.3793, 0.2117, 0.0488, 0.0333],\n",
      "          [0.1721, 0.0937, 0.1247, 0.3203, 0.2893],\n",
      "          [0.2635, 0.0261, 0.2986, 0.2359, 0.1759]],\n",
      "\n",
      "         [[0.0619, 0.3248, 0.2326, 0.3207, 0.0599],\n",
      "          [0.4487, 0.1601, 0.2233, 0.1260, 0.0419],\n",
      "          [0.0645, 0.4583, 0.1219, 0.3030, 0.0523]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.0372, 0.9628, 0.0000],\n",
      "          [0.0575, 0.3261, 0.6165]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.4087, 0.5913, 0.0000],\n",
      "          [0.0286, 0.8822, 0.0892]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 5])\n",
      "old attention tensor([[[[0.3315, 0.5909, 0.0459, 0.0286, 0.0030],\n",
      "          [0.3696, 0.2468, 0.2524, 0.1266, 0.0046],\n",
      "          [0.2839, 0.6065, 0.0696, 0.0336, 0.0065]],\n",
      "\n",
      "         [[0.0705, 0.7964, 0.0433, 0.0825, 0.0073],\n",
      "          [0.2939, 0.4262, 0.0689, 0.1056, 0.1054],\n",
      "          [0.2151, 0.2873, 0.1294, 0.1565, 0.2117]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.1341, 0.8659, 0.0000],\n",
      "          [0.1631, 0.5253, 0.3117]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.1406, 0.8594, 0.0000],\n",
      "          [0.1452, 0.4304, 0.4244]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 5])\n",
      "old attention tensor([[[[0.0876, 0.2011, 0.2753, 0.2323, 0.2037],\n",
      "          [0.1029, 0.1309, 0.2006, 0.2487, 0.3169],\n",
      "          [0.0551, 0.2003, 0.1801, 0.2239, 0.3404]],\n",
      "\n",
      "         [[0.0910, 0.0397, 0.3000, 0.3550, 0.2142],\n",
      "          [0.0804, 0.0313, 0.2841, 0.3282, 0.2761],\n",
      "          [0.0865, 0.0439, 0.2791, 0.3421, 0.2484]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0548, 0.9452, 0.0000, 0.0000],\n",
      "          [0.1599, 0.7701, 0.0700, 0.0000],\n",
      "          [0.0398, 0.0032, 0.9484, 0.0086]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0098, 0.9902, 0.0000, 0.0000],\n",
      "          [0.0023, 0.0117, 0.9859, 0.0000],\n",
      "          [0.0608, 0.1544, 0.7703, 0.0144]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 5])\n",
      "old attention tensor([[[[0.2908, 0.4243, 0.2057, 0.0493, 0.0299],\n",
      "          [0.1539, 0.1028, 0.1221, 0.3419, 0.2793],\n",
      "          [0.2426, 0.0267, 0.3042, 0.2562, 0.1704],\n",
      "          [0.2998, 0.1414, 0.2782, 0.2110, 0.0695]],\n",
      "\n",
      "         [[0.0626, 0.3654, 0.2259, 0.2909, 0.0551],\n",
      "          [0.4639, 0.1732, 0.2131, 0.1112, 0.0386],\n",
      "          [0.0619, 0.5109, 0.1121, 0.2697, 0.0454],\n",
      "          [0.2227, 0.3553, 0.1744, 0.0632, 0.1844]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0302, 0.9698, 0.0000, 0.0000],\n",
      "          [0.0608, 0.3696, 0.5696, 0.0000],\n",
      "          [0.0099, 0.0577, 0.3023, 0.6301]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4037, 0.5963, 0.0000, 0.0000],\n",
      "          [0.0239, 0.8724, 0.1037, 0.0000],\n",
      "          [0.0398, 0.2622, 0.0827, 0.6153]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 5])\n",
      "old attention tensor([[[[0.3759, 0.5640, 0.0306, 0.0253, 0.0041],\n",
      "          [0.4414, 0.2236, 0.2014, 0.1281, 0.0055],\n",
      "          [0.3226, 0.5895, 0.0499, 0.0299, 0.0081],\n",
      "          [0.5641, 0.2310, 0.1243, 0.0680, 0.0126]],\n",
      "\n",
      "         [[0.0757, 0.7286, 0.0581, 0.1305, 0.0071],\n",
      "          [0.3043, 0.3584, 0.0809, 0.1445, 0.1119],\n",
      "          [0.2088, 0.2170, 0.1533, 0.2066, 0.2143],\n",
      "          [0.2568, 0.3268, 0.1146, 0.2020, 0.0998]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.1443, 0.8557, 0.0000, 0.0000],\n",
      "          [0.1965, 0.5274, 0.2761, 0.0000],\n",
      "          [0.0674, 0.2609, 0.1546, 0.5172]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.1048, 0.8952, 0.0000, 0.0000],\n",
      "          [0.1237, 0.4949, 0.3814, 0.0000],\n",
      "          [0.0494, 0.4950, 0.1816, 0.2740]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 5])\n",
      "old attention tensor([[[[0.0811, 0.0866, 0.2399, 0.2119, 0.3805],\n",
      "          [0.0810, 0.0520, 0.1541, 0.1971, 0.5158],\n",
      "          [0.0428, 0.0777, 0.1368, 0.1797, 0.5631],\n",
      "          [0.0601, 0.0327, 0.1255, 0.1519, 0.6297]],\n",
      "\n",
      "         [[0.1679, 0.0555, 0.3740, 0.3013, 0.1013],\n",
      "          [0.1559, 0.0464, 0.3581, 0.3022, 0.1374],\n",
      "          [0.1614, 0.0620, 0.3813, 0.2833, 0.1120],\n",
      "          [0.2881, 0.0741, 0.2705, 0.2845, 0.0828]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [5.4816e-02, 9.4518e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [1.5994e-01, 7.7011e-01, 6.9952e-02, 0.0000e+00, 0.0000e+00],\n",
      "          [3.9768e-02, 3.1554e-03, 9.4845e-01, 8.6304e-03, 0.0000e+00],\n",
      "          [4.0245e-02, 1.9729e-01, 1.3876e-02, 7.3361e-01, 1.4974e-02]],\n",
      "\n",
      "         [[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [9.8231e-03, 9.9018e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [2.3287e-03, 1.1725e-02, 9.8595e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [6.0794e-02, 1.5444e-01, 7.7033e-01, 1.4438e-02, 0.0000e+00],\n",
      "          [9.6738e-04, 6.0686e-03, 4.8765e-01, 1.2584e-02, 4.9273e-01]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[0.3240, 0.4168, 0.1916, 0.0413, 0.0263],\n",
      "          [0.1842, 0.1075, 0.1221, 0.3166, 0.2695],\n",
      "          [0.2835, 0.0287, 0.2992, 0.2287, 0.1599],\n",
      "          [0.3442, 0.1441, 0.2662, 0.1818, 0.0636],\n",
      "          [0.3053, 0.0244, 0.2760, 0.2230, 0.1712]],\n",
      "\n",
      "         [[0.0404, 0.3633, 0.2278, 0.3066, 0.0618],\n",
      "          [0.3646, 0.2006, 0.2518, 0.1348, 0.0482],\n",
      "          [0.0420, 0.5059, 0.1150, 0.2848, 0.0523],\n",
      "          [0.1503, 0.3718, 0.1864, 0.0716, 0.2198],\n",
      "          [0.0454, 0.4972, 0.1116, 0.2901, 0.0557]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0389, 0.9611, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0780, 0.3195, 0.6025, 0.0000, 0.0000],\n",
      "          [0.0144, 0.0595, 0.3312, 0.5949, 0.0000],\n",
      "          [0.0279, 0.1204, 0.2256, 0.3574, 0.2687]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.3916, 0.6084, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0223, 0.8431, 0.1345, 0.0000, 0.0000],\n",
      "          [0.0301, 0.1984, 0.0816, 0.6898, 0.0000],\n",
      "          [0.0051, 0.1625, 0.0308, 0.7637, 0.0379]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[0.3405, 0.6028, 0.0284, 0.0234, 0.0049],\n",
      "          [0.4060, 0.2395, 0.2135, 0.1339, 0.0072],\n",
      "          [0.2903, 0.6119, 0.0525, 0.0327, 0.0126],\n",
      "          [0.5190, 0.2556, 0.1342, 0.0740, 0.0171],\n",
      "          [0.3075, 0.5861, 0.0577, 0.0346, 0.0141]],\n",
      "\n",
      "         [[0.1212, 0.5297, 0.1082, 0.2334, 0.0076],\n",
      "          [0.3756, 0.2141, 0.1138, 0.1970, 0.0995],\n",
      "          [0.2458, 0.1102, 0.2004, 0.2553, 0.1884],\n",
      "          [0.3086, 0.1802, 0.1595, 0.2637, 0.0880],\n",
      "          [0.2368, 0.1062, 0.2101, 0.2732, 0.1735]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.1669, 0.8331, 0.0000, 0.0000, 0.0000],\n",
      "          [0.2055, 0.4736, 0.3209, 0.0000, 0.0000],\n",
      "          [0.0689, 0.2138, 0.1466, 0.5708, 0.0000],\n",
      "          [0.0733, 0.1621, 0.1144, 0.5285, 0.1217]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.1219, 0.8781, 0.0000, 0.0000, 0.0000],\n",
      "          [0.1526, 0.4367, 0.4108, 0.0000, 0.0000],\n",
      "          [0.0594, 0.3881, 0.2518, 0.3008, 0.0000],\n",
      "          [0.0684, 0.2169, 0.2100, 0.2920, 0.2127]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[0.0772, 0.0392, 0.2093, 0.1669, 0.5074],\n",
      "          [0.0657, 0.0190, 0.1135, 0.1440, 0.6578],\n",
      "          [0.0515, 0.0357, 0.1237, 0.1539, 0.6351],\n",
      "          [0.0541, 0.0120, 0.0965, 0.1180, 0.7195],\n",
      "          [0.0534, 0.0356, 0.1251, 0.1474, 0.6385]],\n",
      "\n",
      "         [[0.3998, 0.0870, 0.2999, 0.1580, 0.0553],\n",
      "          [0.3961, 0.0720, 0.2952, 0.1575, 0.0791],\n",
      "          [0.3837, 0.1026, 0.3001, 0.1497, 0.0639],\n",
      "          [0.5680, 0.1019, 0.1729, 0.1196, 0.0375],\n",
      "          [0.3817, 0.1072, 0.2918, 0.1552, 0.0641]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "predicted trg = ['wir', 'essen', 'apfel', 'essen', '<eos>']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_count 1    self.capacity  20\n",
      "0  ------------------------------------------------\n",
      "DecoderLayer@trg4\n",
      "[1, 1, 64]\n",
      "src = ['we', 'drink', 'water']\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[0.0478, 0.0526, 0.7738, 0.0291, 0.0967],\n",
      "          [0.0050, 0.0078, 0.0082, 0.0140, 0.9650],\n",
      "          [0.0024, 0.1096, 0.0051, 0.1140, 0.7690],\n",
      "          [0.0784, 0.0868, 0.7767, 0.0477, 0.0105],\n",
      "          [0.0291, 0.0037, 0.9501, 0.0083, 0.0088]],\n",
      "\n",
      "         [[0.0445, 0.7139, 0.1791, 0.0296, 0.0330],\n",
      "          [0.0172, 0.0026, 0.9237, 0.0409, 0.0156],\n",
      "          [0.6507, 0.0752, 0.0917, 0.0381, 0.1443],\n",
      "          [0.0222, 0.8291, 0.0546, 0.0580, 0.0362],\n",
      "          [0.0721, 0.0865, 0.0639, 0.1307, 0.6469]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[0.1186, 0.0477, 0.3028, 0.3845, 0.1464],\n",
      "          [0.0252, 0.0528, 0.0404, 0.7155, 0.1661],\n",
      "          [0.2808, 0.1296, 0.0302, 0.4753, 0.0842],\n",
      "          [0.0293, 0.0534, 0.0299, 0.8390, 0.0484],\n",
      "          [0.0393, 0.0325, 0.0759, 0.8231, 0.0292]],\n",
      "\n",
      "         [[0.2066, 0.2696, 0.3077, 0.1162, 0.0999],\n",
      "          [0.0774, 0.7543, 0.0762, 0.0571, 0.0350],\n",
      "          [0.0773, 0.1789, 0.1890, 0.0852, 0.4696],\n",
      "          [0.3882, 0.0870, 0.0773, 0.0182, 0.4292],\n",
      "          [0.0818, 0.0748, 0.0716, 0.0460, 0.7258]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[0.0452, 0.2290, 0.5449, 0.1500, 0.0309],\n",
      "          [0.0459, 0.0288, 0.6544, 0.2077, 0.0632],\n",
      "          [0.1263, 0.0630, 0.1025, 0.1457, 0.5625],\n",
      "          [0.0251, 0.0167, 0.0167, 0.1214, 0.8202],\n",
      "          [0.1858, 0.4126, 0.0483, 0.1312, 0.2221]],\n",
      "\n",
      "         [[0.0093, 0.0040, 0.9657, 0.0198, 0.0012],\n",
      "          [0.0461, 0.0695, 0.6260, 0.1767, 0.0817],\n",
      "          [0.1260, 0.1052, 0.6208, 0.1079, 0.0400],\n",
      "          [0.0960, 0.0319, 0.8234, 0.0233, 0.0255],\n",
      "          [0.2126, 0.1077, 0.1294, 0.3643, 0.1860]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 5])\n",
      "old attention tensor([[[[0.2119, 0.5428, 0.0248, 0.1788, 0.0416]],\n",
      "\n",
      "         [[0.0928, 0.5701, 0.0607, 0.2480, 0.0284]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 5])\n",
      "old attention tensor([[[[0.2199, 0.7038, 0.0548, 0.0191, 0.0023]],\n",
      "\n",
      "         [[0.0153, 0.9633, 0.0029, 0.0105, 0.0081]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 5])\n",
      "old attention tensor([[[[0.0832, 0.4972, 0.1106, 0.2453, 0.0637]],\n",
      "\n",
      "         [[0.0901, 0.1128, 0.0894, 0.0863, 0.6214]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0548, 0.9452]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0098, 0.9902]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0548, 0.9452]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0098, 0.9902]]]])\n",
      "old attention torch.Size([1, 2, 2, 5])\n",
      "old attention tensor([[[[0.2119, 0.5428, 0.0248, 0.1788, 0.0416],\n",
      "          [0.1088, 0.0467, 0.0581, 0.2409, 0.5456]],\n",
      "\n",
      "         [[0.0928, 0.5701, 0.0607, 0.2480, 0.0284],\n",
      "          [0.3905, 0.0246, 0.2602, 0.2680, 0.0567]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0463, 0.9537]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.5959, 0.4041]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0463, 0.9537]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.5959, 0.4041]]]])\n",
      "old attention torch.Size([1, 2, 2, 5])\n",
      "old attention tensor([[[[0.2199, 0.7038, 0.0548, 0.0191, 0.0023],\n",
      "          [0.3065, 0.2506, 0.2195, 0.1471, 0.0762]],\n",
      "\n",
      "         [[0.0153, 0.9633, 0.0029, 0.0105, 0.0081],\n",
      "          [0.2061, 0.2524, 0.3451, 0.1348, 0.0615]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.4848, 0.5152]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.1089, 0.8911]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.4848, 0.5152]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.1089, 0.8911]]]])\n",
      "old attention torch.Size([1, 2, 2, 5])\n",
      "old attention tensor([[[[0.0832, 0.4972, 0.1106, 0.2453, 0.0637],\n",
      "          [0.0174, 0.1874, 0.6197, 0.1115, 0.0640]],\n",
      "\n",
      "         [[0.0901, 0.1128, 0.0894, 0.0863, 0.6214],\n",
      "          [0.0160, 0.0167, 0.1593, 0.5077, 0.3004]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.0548, 0.9452, 0.0000],\n",
      "          [0.0140, 0.1149, 0.8711]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.0098, 0.9902, 0.0000],\n",
      "          [0.0047, 0.0052, 0.9901]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 5])\n",
      "old attention tensor([[[[0.2430, 0.4618, 0.0535, 0.2033, 0.0383],\n",
      "          [0.0636, 0.0747, 0.0280, 0.4972, 0.3365],\n",
      "          [0.0199, 0.0569, 0.1462, 0.6492, 0.1279]],\n",
      "\n",
      "         [[0.0561, 0.3939, 0.0387, 0.4240, 0.0873],\n",
      "          [0.3010, 0.1282, 0.3289, 0.2057, 0.0363],\n",
      "          [0.1299, 0.2449, 0.2771, 0.2065, 0.1415]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.0338, 0.9662, 0.0000],\n",
      "          [0.0687, 0.3639, 0.5675]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.8197, 0.1803, 0.0000],\n",
      "          [0.4306, 0.0348, 0.5346]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 5])\n",
      "old attention tensor([[[[0.2783, 0.5289, 0.1511, 0.0348, 0.0069],\n",
      "          [0.2996, 0.3433, 0.2540, 0.0964, 0.0068],\n",
      "          [0.0812, 0.2834, 0.4492, 0.1246, 0.0617]],\n",
      "\n",
      "         [[0.0375, 0.9189, 0.0105, 0.0246, 0.0086],\n",
      "          [0.1101, 0.6898, 0.0349, 0.0766, 0.0886],\n",
      "          [0.1140, 0.3203, 0.0489, 0.2552, 0.2616]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.0981, 0.9019, 0.0000],\n",
      "          [0.1606, 0.7348, 0.1046]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.0308, 0.9692, 0.0000],\n",
      "          [0.0363, 0.4530, 0.5108]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 5])\n",
      "old attention tensor([[[[0.0520, 0.0973, 0.0593, 0.6656, 0.1258],\n",
      "          [0.0443, 0.0366, 0.0892, 0.6678, 0.1621],\n",
      "          [0.0488, 0.0239, 0.0882, 0.7190, 0.1201]],\n",
      "\n",
      "         [[0.2222, 0.2043, 0.1712, 0.0881, 0.3143],\n",
      "          [0.1721, 0.0696, 0.2470, 0.2055, 0.3058],\n",
      "          [0.2844, 0.1449, 0.2630, 0.0860, 0.2217]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0548, 0.9452, 0.0000, 0.0000],\n",
      "          [0.0140, 0.1149, 0.8711, 0.0000],\n",
      "          [0.1815, 0.0954, 0.0794, 0.6436]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0098, 0.9902, 0.0000, 0.0000],\n",
      "          [0.0047, 0.0052, 0.9901, 0.0000],\n",
      "          [0.0536, 0.8880, 0.0188, 0.0395]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 5])\n",
      "old attention tensor([[[[0.2858, 0.4840, 0.0501, 0.1431, 0.0369],\n",
      "          [0.0869, 0.0924, 0.0285, 0.4212, 0.3709],\n",
      "          [0.0295, 0.0773, 0.1671, 0.5769, 0.1493],\n",
      "          [0.0458, 0.0774, 0.0813, 0.5625, 0.2331]],\n",
      "\n",
      "         [[0.0542, 0.3828, 0.0374, 0.4184, 0.1072],\n",
      "          [0.2931, 0.1296, 0.3193, 0.2148, 0.0432],\n",
      "          [0.1167, 0.2431, 0.2562, 0.2094, 0.1745],\n",
      "          [0.3830, 0.0678, 0.1139, 0.3542, 0.0810]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0240, 0.9760, 0.0000, 0.0000],\n",
      "          [0.0502, 0.4084, 0.5414, 0.0000],\n",
      "          [0.0084, 0.0903, 0.2374, 0.6639]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.8459, 0.1541, 0.0000, 0.0000],\n",
      "          [0.4786, 0.0302, 0.4912, 0.0000],\n",
      "          [0.0665, 0.0415, 0.3710, 0.5210]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 5])\n",
      "old attention tensor([[[[0.3625, 0.5171, 0.0952, 0.0221, 0.0031],\n",
      "          [0.4217, 0.2984, 0.1949, 0.0801, 0.0049],\n",
      "          [0.1287, 0.3007, 0.4105, 0.1120, 0.0480],\n",
      "          [0.5069, 0.2282, 0.2220, 0.0363, 0.0067]],\n",
      "\n",
      "         [[0.0464, 0.9146, 0.0148, 0.0203, 0.0040],\n",
      "          [0.1584, 0.6303, 0.0586, 0.0851, 0.0675],\n",
      "          [0.1332, 0.3144, 0.0590, 0.2828, 0.2107],\n",
      "          [0.2406, 0.4830, 0.1402, 0.1047, 0.0316]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0832, 0.9168, 0.0000, 0.0000],\n",
      "          [0.1159, 0.7636, 0.1206, 0.0000],\n",
      "          [0.0708, 0.1575, 0.1671, 0.6046]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0424, 0.9576, 0.0000, 0.0000],\n",
      "          [0.0284, 0.3146, 0.6570, 0.0000],\n",
      "          [0.0357, 0.0910, 0.8259, 0.0474]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 5])\n",
      "old attention tensor([[[[0.0433, 0.1516, 0.0921, 0.5285, 0.1846],\n",
      "          [0.0309, 0.0365, 0.1454, 0.5231, 0.2641],\n",
      "          [0.0327, 0.0210, 0.1410, 0.6393, 0.1660],\n",
      "          [0.0101, 0.0374, 0.1372, 0.2709, 0.5444]],\n",
      "\n",
      "         [[0.2268, 0.3003, 0.1221, 0.0953, 0.2554],\n",
      "          [0.2002, 0.1154, 0.1865, 0.2608, 0.2371],\n",
      "          [0.3189, 0.2267, 0.1879, 0.0932, 0.1733],\n",
      "          [0.2347, 0.1503, 0.2687, 0.2094, 0.1369]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0548, 0.9452, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0140, 0.1149, 0.8711, 0.0000, 0.0000],\n",
      "          [0.1815, 0.0954, 0.0794, 0.6436, 0.0000],\n",
      "          [0.0129, 0.0169, 0.0124, 0.0410, 0.9167]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0098, 0.9902, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0047, 0.0052, 0.9901, 0.0000, 0.0000],\n",
      "          [0.0536, 0.8880, 0.0188, 0.0395, 0.0000],\n",
      "          [0.0323, 0.0027, 0.0064, 0.9523, 0.0063]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[0.2653, 0.5397, 0.0519, 0.1194, 0.0237],\n",
      "          [0.0898, 0.1124, 0.0334, 0.4463, 0.3182],\n",
      "          [0.0293, 0.0951, 0.2171, 0.5497, 0.1088],\n",
      "          [0.0465, 0.0947, 0.1032, 0.5695, 0.1860],\n",
      "          [0.1100, 0.1567, 0.4097, 0.2087, 0.1149]],\n",
      "\n",
      "         [[0.0364, 0.4579, 0.0290, 0.3465, 0.1303],\n",
      "          [0.2492, 0.1712, 0.3215, 0.2008, 0.0573],\n",
      "          [0.0793, 0.3037, 0.2135, 0.1643, 0.2392],\n",
      "          [0.3306, 0.0931, 0.1121, 0.3428, 0.1214],\n",
      "          [0.0662, 0.5285, 0.1360, 0.1037, 0.1655]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0265, 0.9735, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0823, 0.3394, 0.5783, 0.0000, 0.0000],\n",
      "          [0.0087, 0.0642, 0.2666, 0.6605, 0.0000],\n",
      "          [0.1628, 0.1003, 0.1502, 0.2328, 0.3539]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.9020, 0.0980, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4709, 0.0215, 0.5077, 0.0000, 0.0000],\n",
      "          [0.0669, 0.0386, 0.4951, 0.3994, 0.0000],\n",
      "          [0.0821, 0.0145, 0.1284, 0.0891, 0.6859]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[0.3716, 0.4052, 0.1686, 0.0426, 0.0120],\n",
      "          [0.3874, 0.1862, 0.3086, 0.1099, 0.0080],\n",
      "          [0.0830, 0.1515, 0.5265, 0.1359, 0.1031],\n",
      "          [0.4379, 0.1558, 0.3419, 0.0500, 0.0144],\n",
      "          [0.0999, 0.0517, 0.5877, 0.1080, 0.1529]],\n",
      "\n",
      "         [[0.1020, 0.7697, 0.0531, 0.0650, 0.0103],\n",
      "          [0.2440, 0.3417, 0.1202, 0.1866, 0.1076],\n",
      "          [0.1390, 0.0931, 0.0983, 0.4153, 0.2544],\n",
      "          [0.3070, 0.2463, 0.2267, 0.1760, 0.0440],\n",
      "          [0.2087, 0.0635, 0.2949, 0.2245, 0.2084]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0902, 0.9098, 0.0000, 0.0000, 0.0000],\n",
      "          [0.1783, 0.7064, 0.1152, 0.0000, 0.0000],\n",
      "          [0.1177, 0.1677, 0.1704, 0.5442, 0.0000],\n",
      "          [0.1389, 0.3066, 0.1315, 0.0987, 0.3243]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0304, 0.9696, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0458, 0.5500, 0.4042, 0.0000, 0.0000],\n",
      "          [0.0590, 0.1233, 0.7674, 0.0502, 0.0000],\n",
      "          [0.0163, 0.2203, 0.4540, 0.0525, 0.2569]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[0.0980, 0.0283, 0.0275, 0.3593, 0.4869],\n",
      "          [0.0502, 0.0053, 0.0279, 0.3255, 0.5909],\n",
      "          [0.0871, 0.0078, 0.0465, 0.4401, 0.4184],\n",
      "          [0.0130, 0.0052, 0.0238, 0.1401, 0.8180],\n",
      "          [0.0653, 0.0059, 0.0234, 0.1501, 0.7553]],\n",
      "\n",
      "         [[0.5111, 0.3493, 0.0621, 0.0298, 0.0477],\n",
      "          [0.6047, 0.1353, 0.1239, 0.0797, 0.0563],\n",
      "          [0.6008, 0.2519, 0.0871, 0.0275, 0.0327],\n",
      "          [0.5779, 0.1923, 0.1445, 0.0559, 0.0293],\n",
      "          [0.4813, 0.3974, 0.0676, 0.0251, 0.0285]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "predicted trg = ['wir', 'konnen', 'bier', 'trinken', '<eos>']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_count 1    self.capacity  20\n",
      "0  ------------------------------------------------\n",
      "DecoderLayer@trg4\n",
      "[1, 1, 64]\n",
      "src = ['we', 'drink', 'beer']\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[0.0079, 0.0087, 0.1279, 0.8395, 0.0160],\n",
      "          [0.0047, 0.0074, 0.0077, 0.0706, 0.9096],\n",
      "          [0.0026, 0.1231, 0.0057, 0.0053, 0.8633],\n",
      "          [0.2280, 0.0388, 0.0711, 0.4871, 0.1750],\n",
      "          [0.0170, 0.0021, 0.5565, 0.4192, 0.0052]],\n",
      "\n",
      "         [[0.0453, 0.7277, 0.1826, 0.0108, 0.0336],\n",
      "          [0.0172, 0.0026, 0.9260, 0.0385, 0.0157],\n",
      "          [0.6593, 0.0762, 0.0929, 0.0254, 0.1462],\n",
      "          [0.6948, 0.1049, 0.1501, 0.0488, 0.0014],\n",
      "          [0.0550, 0.0659, 0.0487, 0.3371, 0.4933]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[0.1848, 0.0719, 0.3721, 0.1683, 0.2029],\n",
      "          [0.0949, 0.1544, 0.1436, 0.0433, 0.5638],\n",
      "          [0.5554, 0.2095, 0.0518, 0.0409, 0.1424],\n",
      "          [0.2981, 0.1305, 0.3056, 0.0973, 0.1684],\n",
      "          [0.1916, 0.1288, 0.3735, 0.1817, 0.1244]],\n",
      "\n",
      "         [[0.1870, 0.2943, 0.2800, 0.1443, 0.0943],\n",
      "          [0.0698, 0.7190, 0.0774, 0.0991, 0.0346],\n",
      "          [0.0582, 0.1666, 0.1586, 0.2341, 0.3826],\n",
      "          [0.1852, 0.1470, 0.3157, 0.1903, 0.1618],\n",
      "          [0.0500, 0.0721, 0.0663, 0.2863, 0.5253]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[0.0564, 0.2972, 0.5793, 0.0175, 0.0496],\n",
      "          [0.0521, 0.0306, 0.8058, 0.0359, 0.0756],\n",
      "          [0.1227, 0.0545, 0.1205, 0.0890, 0.6133],\n",
      "          [0.4061, 0.0558, 0.0892, 0.0181, 0.4307],\n",
      "          [0.1579, 0.3882, 0.0531, 0.1632, 0.2375]],\n",
      "\n",
      "         [[0.0096, 0.0031, 0.8834, 0.1027, 0.0011],\n",
      "          [0.0548, 0.0608, 0.6058, 0.2065, 0.0722],\n",
      "          [0.1534, 0.1056, 0.5751, 0.1232, 0.0427],\n",
      "          [0.1129, 0.0511, 0.6009, 0.2211, 0.0141],\n",
      "          [0.3247, 0.1471, 0.1703, 0.0812, 0.2766]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 5])\n",
      "old attention tensor([[[[0.2633, 0.5960, 0.0282, 0.0692, 0.0434]],\n",
      "\n",
      "         [[0.1367, 0.7296, 0.0733, 0.0202, 0.0402]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 5])\n",
      "old attention tensor([[[[0.2385, 0.6876, 0.0540, 0.0174, 0.0025]],\n",
      "\n",
      "         [[0.0244, 0.9562, 0.0052, 0.0038, 0.0104]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 5])\n",
      "old attention tensor([[[[0.1300, 0.5230, 0.1433, 0.0944, 0.1093]],\n",
      "\n",
      "         [[0.1354, 0.1639, 0.0596, 0.1428, 0.4983]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0548, 0.9452]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0098, 0.9902]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0548, 0.9452]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0098, 0.9902]]]])\n",
      "old attention torch.Size([1, 2, 2, 5])\n",
      "old attention tensor([[[[0.2633, 0.5960, 0.0282, 0.0692, 0.0434],\n",
      "          [0.1077, 0.0485, 0.0730, 0.2253, 0.5455]],\n",
      "\n",
      "         [[0.1367, 0.7296, 0.0733, 0.0202, 0.0402],\n",
      "          [0.4193, 0.0311, 0.2651, 0.2008, 0.0837]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0340, 0.9660]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.5392, 0.4608]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0340, 0.9660]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.5392, 0.4608]]]])\n",
      "old attention torch.Size([1, 2, 2, 5])\n",
      "old attention tensor([[[[0.2385, 0.6876, 0.0540, 0.0174, 0.0025],\n",
      "          [0.2907, 0.2092, 0.2456, 0.1792, 0.0752]],\n",
      "\n",
      "         [[0.0244, 0.9562, 0.0052, 0.0038, 0.0104],\n",
      "          [0.1797, 0.1146, 0.3623, 0.3049, 0.0385]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.4871, 0.5129]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0762, 0.9238]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.4871, 0.5129]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0762, 0.9238]]]])\n",
      "old attention torch.Size([1, 2, 2, 5])\n",
      "old attention tensor([[[[0.1300, 0.5230, 0.1433, 0.0944, 0.1093],\n",
      "          [0.0208, 0.1294, 0.4202, 0.3340, 0.0957]],\n",
      "\n",
      "         [[0.1354, 0.1639, 0.0596, 0.1428, 0.4983],\n",
      "          [0.0371, 0.0590, 0.2421, 0.2854, 0.3764]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.0548, 0.9452, 0.0000],\n",
      "          [0.0140, 0.0181, 0.9679]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.0098, 0.9902, 0.0000],\n",
      "          [0.7323, 0.0490, 0.2187]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 5])\n",
      "old attention tensor([[[[0.3191, 0.5389, 0.0468, 0.0751, 0.0201],\n",
      "          [0.1336, 0.1522, 0.0615, 0.2112, 0.4415],\n",
      "          [0.1036, 0.1840, 0.4420, 0.1686, 0.1019]],\n",
      "\n",
      "         [[0.0788, 0.6616, 0.0445, 0.0535, 0.1616],\n",
      "          [0.3443, 0.1629, 0.2972, 0.1268, 0.0688],\n",
      "          [0.0961, 0.4768, 0.1554, 0.1267, 0.1450]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.0385, 0.9615, 0.0000],\n",
      "          [0.1932, 0.1645, 0.6423]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.8816, 0.1184, 0.0000],\n",
      "          [0.1087, 0.0302, 0.8610]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 5])\n",
      "old attention tensor([[[[0.2664, 0.5585, 0.1354, 0.0322, 0.0074],\n",
      "          [0.3674, 0.3105, 0.2851, 0.0303, 0.0068],\n",
      "          [0.0579, 0.0485, 0.3657, 0.4798, 0.0482]],\n",
      "\n",
      "         [[0.1141, 0.7734, 0.0603, 0.0452, 0.0070],\n",
      "          [0.2154, 0.3069, 0.1483, 0.2758, 0.0536],\n",
      "          [0.1569, 0.0597, 0.2276, 0.4813, 0.0745]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.1106, 0.8894, 0.0000],\n",
      "          [0.1923, 0.3829, 0.4248]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.0121, 0.9879, 0.0000],\n",
      "          [0.0135, 0.5324, 0.4540]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 5])\n",
      "old attention tensor([[[[0.2336, 0.0707, 0.0432, 0.0981, 0.5544],\n",
      "          [0.1485, 0.0143, 0.0464, 0.2041, 0.5867],\n",
      "          [0.1418, 0.0124, 0.0321, 0.1629, 0.6508]],\n",
      "\n",
      "         [[0.4491, 0.4210, 0.0286, 0.0448, 0.0566],\n",
      "          [0.5157, 0.1647, 0.0680, 0.1834, 0.0682],\n",
      "          [0.3996, 0.4704, 0.0380, 0.0541, 0.0379]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0548, 0.9452, 0.0000, 0.0000],\n",
      "          [0.0140, 0.0181, 0.9679, 0.0000],\n",
      "          [0.0148, 0.0078, 0.9250, 0.0525]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0098, 0.9902, 0.0000, 0.0000],\n",
      "          [0.7323, 0.0490, 0.2187, 0.0000],\n",
      "          [0.0525, 0.8692, 0.0396, 0.0387]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 5])\n",
      "old attention tensor([[[[0.3503, 0.5200, 0.0427, 0.0657, 0.0214],\n",
      "          [0.1559, 0.1590, 0.0541, 0.1853, 0.4458],\n",
      "          [0.1260, 0.2013, 0.4173, 0.1515, 0.1039],\n",
      "          [0.1082, 0.1632, 0.1857, 0.2086, 0.3343]],\n",
      "\n",
      "         [[0.0797, 0.6238, 0.0463, 0.0567, 0.1935],\n",
      "          [0.3375, 0.1621, 0.2934, 0.1265, 0.0804],\n",
      "          [0.0884, 0.4757, 0.1471, 0.1217, 0.1672],\n",
      "          [0.3768, 0.0714, 0.0985, 0.3445, 0.1088]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0276, 0.9724, 0.0000, 0.0000],\n",
      "          [0.1492, 0.1907, 0.6602, 0.0000],\n",
      "          [0.0060, 0.0595, 0.2473, 0.6872]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.8930, 0.1070, 0.0000, 0.0000],\n",
      "          [0.1184, 0.0267, 0.8550, 0.0000],\n",
      "          [0.0210, 0.0148, 0.8093, 0.1549]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 5])\n",
      "old attention tensor([[[[0.3666, 0.5035, 0.0951, 0.0305, 0.0042],\n",
      "          [0.4926, 0.2475, 0.2194, 0.0347, 0.0059],\n",
      "          [0.0775, 0.0381, 0.2567, 0.5880, 0.0397],\n",
      "          [0.4615, 0.1728, 0.2827, 0.0748, 0.0082]],\n",
      "\n",
      "         [[0.1387, 0.7211, 0.0841, 0.0525, 0.0036],\n",
      "          [0.2367, 0.2421, 0.1800, 0.3034, 0.0378],\n",
      "          [0.1578, 0.0416, 0.2756, 0.4849, 0.0400],\n",
      "          [0.2447, 0.1161, 0.2819, 0.3462, 0.0111]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.1015, 0.8985, 0.0000, 0.0000],\n",
      "          [0.1204, 0.3066, 0.5730, 0.0000],\n",
      "          [0.0674, 0.1154, 0.4907, 0.3265]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0251, 0.9749, 0.0000, 0.0000],\n",
      "          [0.0127, 0.4249, 0.5623, 0.0000],\n",
      "          [0.0419, 0.1829, 0.6639, 0.1114]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 5])\n",
      "old attention tensor([[[[0.1570, 0.0675, 0.0401, 0.0768, 0.6586],\n",
      "          [0.0739, 0.0121, 0.0473, 0.1746, 0.6921],\n",
      "          [0.0584, 0.0099, 0.0285, 0.1155, 0.7877],\n",
      "          [0.0202, 0.0103, 0.0373, 0.0991, 0.8331]],\n",
      "\n",
      "         [[0.3856, 0.5151, 0.0215, 0.0368, 0.0409],\n",
      "          [0.4918, 0.2398, 0.0556, 0.1597, 0.0531],\n",
      "          [0.3208, 0.5928, 0.0231, 0.0369, 0.0264],\n",
      "          [0.4269, 0.2413, 0.0794, 0.2197, 0.0327]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0548, 0.9452, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0140, 0.0181, 0.9679, 0.0000, 0.0000],\n",
      "          [0.0148, 0.0078, 0.9250, 0.0525, 0.0000],\n",
      "          [0.0058, 0.0076, 0.5542, 0.0185, 0.4138]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0098, 0.9902, 0.0000, 0.0000, 0.0000],\n",
      "          [0.7323, 0.0490, 0.2187, 0.0000, 0.0000],\n",
      "          [0.0525, 0.8692, 0.0396, 0.0387, 0.0000],\n",
      "          [0.0323, 0.0027, 0.0073, 0.9515, 0.0063]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[0.3193, 0.5611, 0.0458, 0.0585, 0.0153],\n",
      "          [0.1582, 0.1895, 0.0651, 0.1922, 0.3949],\n",
      "          [0.1126, 0.2126, 0.4602, 0.1372, 0.0775],\n",
      "          [0.1055, 0.1892, 0.2272, 0.2068, 0.2713],\n",
      "          [0.1264, 0.1823, 0.4483, 0.1505, 0.0925]],\n",
      "\n",
      "         [[0.0508, 0.6523, 0.0349, 0.0535, 0.2085],\n",
      "          [0.2711, 0.1990, 0.2819, 0.1466, 0.1014],\n",
      "          [0.0597, 0.5047, 0.1189, 0.1249, 0.1918],\n",
      "          [0.2848, 0.0866, 0.0898, 0.3981, 0.1407],\n",
      "          [0.0632, 0.4871, 0.1292, 0.1381, 0.1824]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0385, 0.9615, 0.0000, 0.0000, 0.0000],\n",
      "          [0.2542, 0.1803, 0.5655, 0.0000, 0.0000],\n",
      "          [0.0093, 0.0574, 0.2441, 0.6893, 0.0000],\n",
      "          [0.1148, 0.0782, 0.2497, 0.2666, 0.2907]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.9167, 0.0833, 0.0000, 0.0000, 0.0000],\n",
      "          [0.1200, 0.0271, 0.8529, 0.0000, 0.0000],\n",
      "          [0.0232, 0.0166, 0.8354, 0.1248, 0.0000],\n",
      "          [0.0528, 0.0114, 0.4329, 0.0534, 0.4495]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[0.3581, 0.4312, 0.1520, 0.0433, 0.0154],\n",
      "          [0.4420, 0.1885, 0.3199, 0.0381, 0.0115],\n",
      "          [0.0605, 0.0313, 0.3069, 0.5192, 0.0821],\n",
      "          [0.3967, 0.1188, 0.3806, 0.0876, 0.0163],\n",
      "          [0.0614, 0.0288, 0.3104, 0.5192, 0.0802]],\n",
      "\n",
      "         [[0.2089, 0.4876, 0.1744, 0.1208, 0.0082],\n",
      "          [0.2408, 0.1115, 0.2021, 0.4015, 0.0441],\n",
      "          [0.1357, 0.0193, 0.2762, 0.5186, 0.0502],\n",
      "          [0.2373, 0.0604, 0.2860, 0.4029, 0.0135],\n",
      "          [0.1295, 0.0200, 0.2610, 0.5350, 0.0544]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.1572, 0.8428, 0.0000, 0.0000, 0.0000],\n",
      "          [0.1838, 0.3633, 0.4529, 0.0000, 0.0000],\n",
      "          [0.1228, 0.1648, 0.4053, 0.3071, 0.0000],\n",
      "          [0.1133, 0.1947, 0.2842, 0.0910, 0.3168]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0351, 0.9649, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0311, 0.4579, 0.5109, 0.0000, 0.0000],\n",
      "          [0.0560, 0.1988, 0.6451, 0.1001, 0.0000],\n",
      "          [0.0188, 0.2616, 0.3426, 0.0766, 0.3004]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[0.1518, 0.0200, 0.0178, 0.0501, 0.7603],\n",
      "          [0.0845, 0.0038, 0.0142, 0.0787, 0.8187],\n",
      "          [0.0897, 0.0047, 0.0131, 0.0672, 0.8252],\n",
      "          [0.0290, 0.0043, 0.0145, 0.0539, 0.8983],\n",
      "          [0.0745, 0.0042, 0.0106, 0.0541, 0.8566]],\n",
      "\n",
      "         [[0.5319, 0.4107, 0.0171, 0.0244, 0.0159],\n",
      "          [0.6727, 0.1997, 0.0320, 0.0788, 0.0169],\n",
      "          [0.4664, 0.4815, 0.0185, 0.0222, 0.0114],\n",
      "          [0.5980, 0.2496, 0.0446, 0.0950, 0.0128],\n",
      "          [0.4616, 0.4896, 0.0169, 0.0205, 0.0114]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "predicted trg = ['wir', 'trinken', 'bier', 'trinken', '<eos>']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_count 1    self.capacity  20\n",
      "0  ------------------------------------------------\n",
      "DecoderLayer@trg4\n",
      "[1, 1, 64]\n",
      "src = ['we', 'read', 'book']\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[8.3008e-02, 9.1387e-02, 2.7554e-01, 3.8194e-01, 1.6812e-01],\n",
      "          [4.2573e-03, 6.6472e-03, 1.1666e-01, 5.3538e-02, 8.1890e-01],\n",
      "          [8.5360e-03, 2.1507e-04, 3.5890e-03, 9.8585e-01, 1.8064e-03],\n",
      "          [3.3921e-02, 8.0885e-01, 5.8106e-02, 3.7853e-02, 6.1271e-02],\n",
      "          [4.4387e-02, 5.5926e-03, 1.1493e-01, 8.2159e-01, 1.3506e-02]],\n",
      "\n",
      "         [[5.4749e-02, 8.7898e-01, 2.1738e-02, 3.9391e-03, 4.0596e-02],\n",
      "          [2.1002e-01, 3.1816e-02, 3.8817e-01, 1.7896e-01, 1.9103e-01],\n",
      "          [3.5025e-01, 1.2298e-01, 1.0696e-02, 3.4421e-02, 4.8165e-01],\n",
      "          [1.5315e-01, 7.1995e-02, 1.4438e-01, 4.0261e-01, 2.2787e-01],\n",
      "          [1.4675e-02, 1.7604e-02, 8.0946e-01, 2.6533e-02, 1.3173e-01]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[0.1084, 0.0307, 0.5879, 0.1887, 0.0843],\n",
      "          [0.0718, 0.1347, 0.2646, 0.1996, 0.3293],\n",
      "          [0.1261, 0.2108, 0.4719, 0.0701, 0.1212],\n",
      "          [0.2201, 0.1795, 0.3560, 0.1465, 0.0980],\n",
      "          [0.0488, 0.0289, 0.1727, 0.7197, 0.0299]],\n",
      "\n",
      "         [[0.2473, 0.2925, 0.1607, 0.1256, 0.1739],\n",
      "          [0.0962, 0.6756, 0.0373, 0.1279, 0.0629],\n",
      "          [0.2768, 0.1820, 0.1882, 0.2149, 0.1381],\n",
      "          [0.1322, 0.2334, 0.1661, 0.1734, 0.2948],\n",
      "          [0.0395, 0.0358, 0.3218, 0.1511, 0.4517]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[0.1293, 0.5556, 0.0627, 0.1511, 0.1014],\n",
      "          [0.1496, 0.1008, 0.2110, 0.3309, 0.2078],\n",
      "          [0.1097, 0.1866, 0.0681, 0.1046, 0.5310],\n",
      "          [0.2580, 0.1550, 0.3169, 0.0332, 0.2369],\n",
      "          [0.2127, 0.3915, 0.1421, 0.1255, 0.1282]],\n",
      "\n",
      "         [[0.1586, 0.0593, 0.7407, 0.0247, 0.0168],\n",
      "          [0.1587, 0.1968, 0.3828, 0.0449, 0.2167],\n",
      "          [0.2104, 0.1327, 0.6082, 0.0213, 0.0274],\n",
      "          [0.1876, 0.3681, 0.2297, 0.0209, 0.1938],\n",
      "          [0.2427, 0.1240, 0.4220, 0.0369, 0.1743]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 5])\n",
      "old attention tensor([[[[0.3240, 0.4936, 0.0663, 0.0663, 0.0497]],\n",
      "\n",
      "         [[0.1389, 0.6935, 0.0909, 0.0381, 0.0386]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 5])\n",
      "old attention tensor([[[[0.3670, 0.5929, 0.0233, 0.0132, 0.0037]],\n",
      "\n",
      "         [[0.0204, 0.9114, 0.0369, 0.0142, 0.0172]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 5])\n",
      "old attention tensor([[[[0.1593, 0.7169, 0.0527, 0.0322, 0.0390]],\n",
      "\n",
      "         [[0.0465, 0.0223, 0.0972, 0.2536, 0.5803]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0548, 0.9452]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0098, 0.9902]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0548, 0.9452]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0098, 0.9902]]]])\n",
      "old attention torch.Size([1, 2, 2, 5])\n",
      "old attention tensor([[[[0.3240, 0.4936, 0.0663, 0.0663, 0.0497],\n",
      "          [0.0569, 0.0315, 0.1439, 0.4957, 0.2719]],\n",
      "\n",
      "         [[0.1389, 0.6935, 0.0909, 0.0381, 0.0386],\n",
      "          [0.1569, 0.0121, 0.1235, 0.6876, 0.0199]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0838, 0.9162]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.3702, 0.6298]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0838, 0.9162]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.3702, 0.6298]]]])\n",
      "old attention torch.Size([1, 2, 2, 5])\n",
      "old attention tensor([[[[0.3670, 0.5929, 0.0233, 0.0132, 0.0037],\n",
      "          [0.2053, 0.1066, 0.3025, 0.2805, 0.1050]],\n",
      "\n",
      "         [[0.0204, 0.9114, 0.0369, 0.0142, 0.0172],\n",
      "          [0.1877, 0.1446, 0.0954, 0.4830, 0.0893]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.3929, 0.6071]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0926, 0.9074]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.3929, 0.6071]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0926, 0.9074]]]])\n",
      "old attention torch.Size([1, 2, 2, 5])\n",
      "old attention tensor([[[[0.1593, 0.7169, 0.0527, 0.0322, 0.0390],\n",
      "          [0.0581, 0.5067, 0.0657, 0.3238, 0.0457]],\n",
      "\n",
      "         [[0.0465, 0.0223, 0.0972, 0.2536, 0.5803],\n",
      "          [0.0080, 0.0062, 0.0366, 0.7172, 0.2320]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.0548, 0.9452, 0.0000],\n",
      "          [0.0058, 0.0035, 0.9907]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.0098, 0.9902, 0.0000],\n",
      "          [0.0028, 0.0164, 0.9808]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 5])\n",
      "old attention tensor([[[[0.4354, 0.4450, 0.0549, 0.0369, 0.0278],\n",
      "          [0.1243, 0.1165, 0.1051, 0.3798, 0.2744],\n",
      "          [0.2726, 0.2839, 0.1238, 0.1694, 0.1503]],\n",
      "\n",
      "         [[0.1195, 0.3472, 0.3973, 0.0477, 0.0883],\n",
      "          [0.2817, 0.0759, 0.2470, 0.3704, 0.0250],\n",
      "          [0.1086, 0.0759, 0.7255, 0.0415, 0.0485]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.0924, 0.9076, 0.0000],\n",
      "          [0.0053, 0.0276, 0.9671]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.4648, 0.5352, 0.0000],\n",
      "          [0.0440, 0.1568, 0.7992]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 5])\n",
      "old attention tensor([[[[0.3282, 0.5754, 0.0341, 0.0480, 0.0144],\n",
      "          [0.3810, 0.3005, 0.1637, 0.1121, 0.0426],\n",
      "          [0.3255, 0.3169, 0.1628, 0.1585, 0.0364]],\n",
      "\n",
      "         [[0.1040, 0.8431, 0.0198, 0.0240, 0.0089],\n",
      "          [0.2820, 0.2716, 0.0773, 0.2819, 0.0872],\n",
      "          [0.2924, 0.3533, 0.1078, 0.1644, 0.0821]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.3361, 0.6639, 0.0000],\n",
      "          [0.3069, 0.2773, 0.4158]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.0861, 0.9139, 0.0000],\n",
      "          [0.0670, 0.2887, 0.6443]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 5])\n",
      "old attention tensor([[[[0.1186, 0.7342, 0.0213, 0.0656, 0.0602],\n",
      "          [0.0933, 0.4190, 0.0538, 0.2878, 0.1461],\n",
      "          [0.0280, 0.1617, 0.0617, 0.5561, 0.1925]],\n",
      "\n",
      "         [[0.1485, 0.0755, 0.0697, 0.2483, 0.4580],\n",
      "          [0.0761, 0.0360, 0.0556, 0.5358, 0.2965],\n",
      "          [0.1078, 0.0598, 0.0409, 0.5241, 0.2675]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0548, 0.9452, 0.0000, 0.0000],\n",
      "          [0.0058, 0.0035, 0.9907, 0.0000],\n",
      "          [0.0332, 0.0224, 0.9272, 0.0172]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0098, 0.9902, 0.0000, 0.0000],\n",
      "          [0.0028, 0.0164, 0.9808, 0.0000],\n",
      "          [0.0159, 0.2746, 0.6426, 0.0669]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 5])\n",
      "old attention tensor([[[[0.4094, 0.4795, 0.0498, 0.0360, 0.0254],\n",
      "          [0.1134, 0.1203, 0.0987, 0.3968, 0.2708],\n",
      "          [0.2544, 0.3011, 0.1190, 0.1763, 0.1492],\n",
      "          [0.3441, 0.1409, 0.1424, 0.2996, 0.0730]],\n",
      "\n",
      "         [[0.0943, 0.3151, 0.4131, 0.0642, 0.1132],\n",
      "          [0.2120, 0.0610, 0.2292, 0.4698, 0.0281],\n",
      "          [0.0876, 0.0671, 0.7277, 0.0560, 0.0615],\n",
      "          [0.1567, 0.0097, 0.4893, 0.2998, 0.0445]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0823, 0.9177, 0.0000, 0.0000],\n",
      "          [0.0042, 0.0274, 0.9684, 0.0000],\n",
      "          [0.0039, 0.0230, 0.4758, 0.4974]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5049, 0.4951, 0.0000, 0.0000],\n",
      "          [0.0557, 0.1942, 0.7501, 0.0000],\n",
      "          [0.0365, 0.0601, 0.3321, 0.5713]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 5])\n",
      "old attention tensor([[[[0.3962, 0.4459, 0.0525, 0.0784, 0.0269],\n",
      "          [0.3624, 0.2026, 0.2270, 0.1480, 0.0600],\n",
      "          [0.3098, 0.1967, 0.2285, 0.2131, 0.0520],\n",
      "          [0.2953, 0.1882, 0.2127, 0.2423, 0.0615]],\n",
      "\n",
      "         [[0.1096, 0.8439, 0.0185, 0.0198, 0.0082],\n",
      "          [0.3013, 0.2383, 0.0836, 0.2803, 0.0964],\n",
      "          [0.3258, 0.3028, 0.1181, 0.1570, 0.0962],\n",
      "          [0.2894, 0.2454, 0.0873, 0.3028, 0.0752]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.3935, 0.6065, 0.0000, 0.0000],\n",
      "          [0.3652, 0.2493, 0.3855, 0.0000],\n",
      "          [0.1873, 0.1471, 0.3804, 0.2852]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0830, 0.9170, 0.0000, 0.0000],\n",
      "          [0.0796, 0.2982, 0.6222, 0.0000],\n",
      "          [0.0287, 0.2023, 0.5306, 0.2383]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 5])\n",
      "old attention tensor([[[[0.1410, 0.6659, 0.0337, 0.0791, 0.0802],\n",
      "          [0.0891, 0.3062, 0.0813, 0.3232, 0.2002],\n",
      "          [0.0292, 0.1109, 0.0853, 0.5474, 0.2272],\n",
      "          [0.0787, 0.2117, 0.1028, 0.4185, 0.1883]],\n",
      "\n",
      "         [[0.1858, 0.0955, 0.0766, 0.2271, 0.4149],\n",
      "          [0.0933, 0.0452, 0.0591, 0.5444, 0.2580],\n",
      "          [0.1445, 0.0819, 0.0476, 0.5027, 0.2233],\n",
      "          [0.0729, 0.0593, 0.0435, 0.5745, 0.2498]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [5.4816e-02, 9.4518e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [5.7779e-03, 3.5214e-03, 9.9070e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [3.3226e-02, 2.2414e-02, 9.2716e-01, 1.7204e-02, 0.0000e+00],\n",
      "          [1.8739e-03, 1.1628e-03, 4.1187e-01, 1.1477e-03, 5.8395e-01]],\n",
      "\n",
      "         [[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [9.8231e-03, 9.9018e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [2.8250e-03, 1.6355e-02, 9.8082e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [1.5928e-02, 2.7463e-01, 6.4256e-01, 6.6889e-02, 0.0000e+00],\n",
      "          [9.8456e-04, 7.1017e-03, 4.4582e-01, 6.1770e-02, 4.8433e-01]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[0.4112, 0.5029, 0.0402, 0.0252, 0.0205],\n",
      "          [0.1407, 0.1553, 0.0973, 0.3419, 0.2648],\n",
      "          [0.2809, 0.3457, 0.1058, 0.1364, 0.1313],\n",
      "          [0.3991, 0.1721, 0.1294, 0.2333, 0.0662],\n",
      "          [0.2990, 0.3042, 0.1154, 0.1318, 0.1495]],\n",
      "\n",
      "         [[0.0797, 0.3027, 0.4576, 0.0435, 0.1165],\n",
      "          [0.2127, 0.0699, 0.3017, 0.3819, 0.0338],\n",
      "          [0.0725, 0.0637, 0.7645, 0.0379, 0.0613],\n",
      "          [0.1409, 0.0103, 0.5861, 0.2133, 0.0494],\n",
      "          [0.0756, 0.0631, 0.7642, 0.0365, 0.0607]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.1209, 0.8791, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0078, 0.0288, 0.9634, 0.0000, 0.0000],\n",
      "          [0.0074, 0.0243, 0.5202, 0.4481, 0.0000],\n",
      "          [0.0033, 0.0130, 0.4016, 0.1485, 0.4336]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5233, 0.4767, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0522, 0.1732, 0.7746, 0.0000, 0.0000],\n",
      "          [0.0326, 0.0514, 0.3475, 0.5685, 0.0000],\n",
      "          [0.0147, 0.0430, 0.2218, 0.4551, 0.2654]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[0.3183, 0.4334, 0.0737, 0.1153, 0.0592],\n",
      "          [0.2891, 0.1994, 0.2322, 0.1799, 0.0994],\n",
      "          [0.2477, 0.1945, 0.2342, 0.2386, 0.0850],\n",
      "          [0.2280, 0.1797, 0.2227, 0.2687, 0.1008],\n",
      "          [0.2422, 0.1697, 0.2417, 0.2532, 0.0932]],\n",
      "\n",
      "         [[0.2435, 0.6666, 0.0285, 0.0436, 0.0178],\n",
      "          [0.3933, 0.1573, 0.0748, 0.2713, 0.1032],\n",
      "          [0.4214, 0.2049, 0.1056, 0.1598, 0.1083],\n",
      "          [0.3858, 0.1592, 0.0774, 0.2946, 0.0829],\n",
      "          [0.4131, 0.2043, 0.1023, 0.1695, 0.1108]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4782, 0.5218, 0.0000, 0.0000, 0.0000],\n",
      "          [0.3941, 0.2407, 0.3652, 0.0000, 0.0000],\n",
      "          [0.2304, 0.1383, 0.3551, 0.2762, 0.0000],\n",
      "          [0.2284, 0.1319, 0.2240, 0.2123, 0.2033]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.1456, 0.8544, 0.0000, 0.0000, 0.0000],\n",
      "          [0.1302, 0.3399, 0.5299, 0.0000, 0.0000],\n",
      "          [0.0643, 0.2322, 0.5177, 0.1858, 0.0000],\n",
      "          [0.0763, 0.2111, 0.3355, 0.0961, 0.2810]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[0.1752, 0.3279, 0.0611, 0.1726, 0.2631],\n",
      "          [0.0783, 0.1446, 0.0790, 0.3466, 0.3515],\n",
      "          [0.0307, 0.0593, 0.0801, 0.5002, 0.3298],\n",
      "          [0.0657, 0.0921, 0.0921, 0.4047, 0.3454],\n",
      "          [0.0300, 0.0596, 0.0747, 0.5003, 0.3355]],\n",
      "\n",
      "         [[0.3904, 0.2345, 0.0826, 0.1199, 0.1726],\n",
      "          [0.2986, 0.1464, 0.0863, 0.3110, 0.1576],\n",
      "          [0.3288, 0.2185, 0.0630, 0.2590, 0.1307],\n",
      "          [0.2526, 0.2036, 0.0608, 0.3247, 0.1583],\n",
      "          [0.3165, 0.2170, 0.0623, 0.2712, 0.1330]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "predicted trg = ['wir', 'lesen', 'zeitung', 'lesen', '<eos>']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_count 1    self.capacity  20\n",
      "0  ------------------------------------------------\n",
      "DecoderLayer@trg4\n",
      "[1, 1, 64]\n",
      "src = ['we', 'read', 'newspaper']\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[2.0667e-02, 2.2753e-02, 6.8603e-02, 8.4612e-01, 4.1857e-02],\n",
      "          [3.7075e-04, 5.7886e-04, 1.0159e-02, 9.1758e-01, 7.1313e-02],\n",
      "          [3.3543e-02, 8.4514e-04, 1.4103e-02, 9.4441e-01, 7.0984e-03],\n",
      "          [3.2657e-01, 3.2103e-01, 2.9504e-01, 2.4961e-02, 3.2399e-02],\n",
      "          [1.4691e-02, 1.8510e-03, 3.8038e-02, 9.4095e-01, 4.4702e-03]],\n",
      "\n",
      "         [[4.5124e-02, 7.2445e-01, 1.7916e-02, 1.7905e-01, 3.3459e-02],\n",
      "          [2.8564e-03, 4.3273e-04, 5.2794e-03, 9.8883e-01, 2.5982e-03],\n",
      "          [3.0228e-01, 1.0614e-01, 9.2314e-03, 1.6666e-01, 4.1569e-01],\n",
      "          [4.6295e-03, 3.6406e-01, 4.1680e-01, 1.0454e-01, 1.0996e-01],\n",
      "          [1.4693e-02, 1.7625e-02, 8.1044e-01, 2.5358e-02, 1.3189e-01]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[0.0723, 0.0220, 0.4211, 0.4016, 0.0829],\n",
      "          [0.0476, 0.0955, 0.2065, 0.3767, 0.2737],\n",
      "          [0.1347, 0.2259, 0.3835, 0.1161, 0.1398],\n",
      "          [0.0991, 0.2330, 0.0367, 0.5015, 0.1297],\n",
      "          [0.0677, 0.0464, 0.2661, 0.5582, 0.0615]],\n",
      "\n",
      "         [[0.2597, 0.3564, 0.1227, 0.0966, 0.1645],\n",
      "          [0.0813, 0.6062, 0.0245, 0.2513, 0.0367],\n",
      "          [0.2038, 0.1327, 0.1199, 0.4757, 0.0679],\n",
      "          [0.8464, 0.0821, 0.0228, 0.0220, 0.0267],\n",
      "          [0.0392, 0.0386, 0.2658, 0.3460, 0.3104]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[0.1430, 0.5629, 0.0905, 0.1113, 0.0922],\n",
      "          [0.1737, 0.1354, 0.2744, 0.1708, 0.2458],\n",
      "          [0.1165, 0.2125, 0.0568, 0.2396, 0.3747],\n",
      "          [0.0810, 0.1201, 0.0239, 0.4511, 0.3239],\n",
      "          [0.2370, 0.3775, 0.1085, 0.1489, 0.1281]],\n",
      "\n",
      "         [[0.1670, 0.0586, 0.6758, 0.0801, 0.0184],\n",
      "          [0.1304, 0.1920, 0.3928, 0.1071, 0.1777],\n",
      "          [0.2043, 0.1182, 0.5234, 0.1214, 0.0327],\n",
      "          [0.1994, 0.0312, 0.4155, 0.1704, 0.1836],\n",
      "          [0.2042, 0.1132, 0.3356, 0.1971, 0.1499]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 5])\n",
      "old attention tensor([[[[0.2938, 0.5486, 0.0714, 0.0353, 0.0509]],\n",
      "\n",
      "         [[0.1510, 0.5963, 0.1070, 0.1098, 0.0359]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 5])\n",
      "old attention tensor([[[[0.4020, 0.5194, 0.0364, 0.0351, 0.0072]],\n",
      "\n",
      "         [[0.0167, 0.9070, 0.0292, 0.0300, 0.0171]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 5])\n",
      "old attention tensor([[[[0.2370, 0.5177, 0.0711, 0.0689, 0.1052]],\n",
      "\n",
      "         [[0.0438, 0.0351, 0.0950, 0.1811, 0.6450]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0548, 0.9452]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0098, 0.9902]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0548, 0.9452]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0098, 0.9902]]]])\n",
      "old attention torch.Size([1, 2, 2, 5])\n",
      "old attention tensor([[[[0.2938, 0.5486, 0.0714, 0.0353, 0.0509],\n",
      "          [0.0882, 0.0443, 0.1961, 0.2700, 0.4014]],\n",
      "\n",
      "         [[0.1510, 0.5963, 0.1070, 0.1098, 0.0359],\n",
      "          [0.2892, 0.0255, 0.2130, 0.4374, 0.0349]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0690, 0.9310]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.4217, 0.5783]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0690, 0.9310]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.4217, 0.5783]]]])\n",
      "old attention torch.Size([1, 2, 2, 5])\n",
      "old attention tensor([[[[0.4020, 0.5194, 0.0364, 0.0351, 0.0072],\n",
      "          [0.2689, 0.1097, 0.3033, 0.1828, 0.1354]],\n",
      "\n",
      "         [[0.0167, 0.9070, 0.0292, 0.0300, 0.0171],\n",
      "          [0.3129, 0.2230, 0.1867, 0.1167, 0.1607]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.3816, 0.6184]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0808, 0.9192]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.3816, 0.6184]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0808, 0.9192]]]])\n",
      "old attention torch.Size([1, 2, 2, 5])\n",
      "old attention tensor([[[[0.2370, 0.5177, 0.0711, 0.0689, 0.1052],\n",
      "          [0.0671, 0.5774, 0.0962, 0.1655, 0.0938]],\n",
      "\n",
      "         [[0.0438, 0.0351, 0.0950, 0.1811, 0.6450],\n",
      "          [0.0162, 0.0139, 0.0487, 0.5285, 0.3927]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.0548, 0.9452, 0.0000],\n",
      "          [0.0058, 0.0035, 0.9907]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.0098, 0.9902, 0.0000],\n",
      "          [0.0028, 0.0164, 0.9808]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 5])\n",
      "old attention tensor([[[[0.4020, 0.4590, 0.0700, 0.0321, 0.0368],\n",
      "          [0.1654, 0.1430, 0.1215, 0.2133, 0.3568],\n",
      "          [0.2554, 0.2715, 0.1407, 0.1497, 0.1827]],\n",
      "\n",
      "         [[0.1159, 0.3044, 0.3586, 0.1537, 0.0673],\n",
      "          [0.3232, 0.0958, 0.3097, 0.2452, 0.0261],\n",
      "          [0.1359, 0.0763, 0.6288, 0.1118, 0.0472]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.0833, 0.9167, 0.0000],\n",
      "          [0.0109, 0.0586, 0.9304]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.4959, 0.5041, 0.0000],\n",
      "          [0.0575, 0.1756, 0.7669]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 5])\n",
      "old attention tensor([[[[0.3493, 0.5446, 0.0468, 0.0361, 0.0232],\n",
      "          [0.4416, 0.2576, 0.1550, 0.0946, 0.0512],\n",
      "          [0.4139, 0.3097, 0.1504, 0.0827, 0.0434]],\n",
      "\n",
      "         [[0.0706, 0.7837, 0.0235, 0.1086, 0.0136],\n",
      "          [0.3342, 0.2971, 0.1184, 0.1158, 0.1346],\n",
      "          [0.2167, 0.2534, 0.1068, 0.3292, 0.0939]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.3204, 0.6796, 0.0000],\n",
      "          [0.3272, 0.3196, 0.3532]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.1029, 0.8971, 0.0000],\n",
      "          [0.0832, 0.2857, 0.6310]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 5])\n",
      "old attention tensor([[[[0.1995, 0.3933, 0.0444, 0.1536, 0.2091],\n",
      "          [0.1153, 0.2701, 0.0894, 0.1951, 0.3301],\n",
      "          [0.0454, 0.1395, 0.1213, 0.2263, 0.4676]],\n",
      "\n",
      "         [[0.2395, 0.1228, 0.0442, 0.2132, 0.3803],\n",
      "          [0.1686, 0.0885, 0.0517, 0.2801, 0.4112],\n",
      "          [0.2621, 0.1431, 0.0339, 0.2592, 0.3016]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0548, 0.9452, 0.0000, 0.0000],\n",
      "          [0.0058, 0.0035, 0.9907, 0.0000],\n",
      "          [0.0332, 0.0224, 0.9272, 0.0172]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0098, 0.9902, 0.0000, 0.0000],\n",
      "          [0.0028, 0.0164, 0.9808, 0.0000],\n",
      "          [0.0159, 0.2746, 0.6426, 0.0669]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 5])\n",
      "old attention tensor([[[[0.3647, 0.5059, 0.0636, 0.0327, 0.0331],\n",
      "          [0.1491, 0.1530, 0.1153, 0.2322, 0.3503],\n",
      "          [0.2315, 0.2936, 0.1347, 0.1626, 0.1775],\n",
      "          [0.4126, 0.1566, 0.1697, 0.1598, 0.1013]],\n",
      "\n",
      "         [[0.0870, 0.2795, 0.3576, 0.1898, 0.0861],\n",
      "          [0.2607, 0.0877, 0.3117, 0.3068, 0.0330],\n",
      "          [0.1074, 0.0701, 0.6231, 0.1378, 0.0616],\n",
      "          [0.1145, 0.0084, 0.3502, 0.4967, 0.0302]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0743, 0.9257, 0.0000, 0.0000],\n",
      "          [0.0088, 0.0581, 0.9331, 0.0000],\n",
      "          [0.0063, 0.0374, 0.4366, 0.5198]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5347, 0.4653, 0.0000, 0.0000],\n",
      "          [0.0663, 0.2013, 0.7324, 0.0000],\n",
      "          [0.0478, 0.0674, 0.3230, 0.5618]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 5])\n",
      "old attention tensor([[[[0.4055, 0.4429, 0.0649, 0.0477, 0.0390],\n",
      "          [0.4263, 0.1871, 0.2087, 0.1083, 0.0696],\n",
      "          [0.4087, 0.2118, 0.2169, 0.1004, 0.0622],\n",
      "          [0.4152, 0.1877, 0.2171, 0.1003, 0.0797]],\n",
      "\n",
      "         [[0.0687, 0.7938, 0.0213, 0.1044, 0.0118],\n",
      "          [0.3465, 0.2621, 0.1266, 0.1199, 0.1449],\n",
      "          [0.2240, 0.2194, 0.1107, 0.3434, 0.1026],\n",
      "          [0.2812, 0.3146, 0.1309, 0.1598, 0.1135]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.3691, 0.6309, 0.0000, 0.0000],\n",
      "          [0.3749, 0.2751, 0.3500, 0.0000],\n",
      "          [0.1945, 0.1831, 0.3821, 0.2403]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.1073, 0.8927, 0.0000, 0.0000],\n",
      "          [0.1011, 0.2906, 0.6083, 0.0000],\n",
      "          [0.0445, 0.2163, 0.5847, 0.1545]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 5])\n",
      "old attention tensor([[[[0.1844, 0.3152, 0.0590, 0.2092, 0.2322],\n",
      "          [0.0869, 0.1815, 0.1136, 0.2451, 0.3729],\n",
      "          [0.0381, 0.0978, 0.1437, 0.2561, 0.4644],\n",
      "          [0.0774, 0.1466, 0.1388, 0.2343, 0.4029]],\n",
      "\n",
      "         [[0.2706, 0.1411, 0.0423, 0.2290, 0.3170],\n",
      "          [0.2060, 0.1150, 0.0519, 0.3016, 0.3255],\n",
      "          [0.3015, 0.1670, 0.0351, 0.2662, 0.2302],\n",
      "          [0.1902, 0.1845, 0.0422, 0.2832, 0.2999]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0548, 0.9452, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0058, 0.0035, 0.9907, 0.0000, 0.0000],\n",
      "          [0.0332, 0.0224, 0.9272, 0.0172, 0.0000],\n",
      "          [0.0369, 0.0288, 0.8959, 0.0191, 0.0193]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0098, 0.9902, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0028, 0.0164, 0.9808, 0.0000, 0.0000],\n",
      "          [0.0159, 0.2746, 0.6426, 0.0669, 0.0000],\n",
      "          [0.0136, 0.2267, 0.6258, 0.0717, 0.0622]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[0.3368, 0.5360, 0.0615, 0.0341, 0.0315],\n",
      "          [0.1388, 0.1611, 0.1131, 0.2456, 0.3414],\n",
      "          [0.2149, 0.3077, 0.1325, 0.1718, 0.1731],\n",
      "          [0.3888, 0.1688, 0.1693, 0.1730, 0.1002],\n",
      "          [0.3532, 0.1556, 0.1900, 0.1866, 0.1145]],\n",
      "\n",
      "         [[0.0713, 0.2590, 0.3483, 0.2175, 0.1039],\n",
      "          [0.2211, 0.0825, 0.3062, 0.3504, 0.0397],\n",
      "          [0.0922, 0.0670, 0.6073, 0.1584, 0.0751],\n",
      "          [0.0901, 0.0074, 0.3242, 0.5435, 0.0349],\n",
      "          [0.0781, 0.0088, 0.3333, 0.5412, 0.0386]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0737, 0.9263, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0082, 0.0601, 0.9317, 0.0000, 0.0000],\n",
      "          [0.0061, 0.0441, 0.4494, 0.5003, 0.0000],\n",
      "          [0.0037, 0.0251, 0.2913, 0.3158, 0.3641]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5592, 0.4408, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0765, 0.2223, 0.7012, 0.0000, 0.0000],\n",
      "          [0.0518, 0.0775, 0.3124, 0.5583, 0.0000],\n",
      "          [0.0380, 0.0460, 0.1905, 0.3403, 0.3853]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[0.4253, 0.3712, 0.0862, 0.0593, 0.0581],\n",
      "          [0.3986, 0.1476, 0.2518, 0.1167, 0.0853],\n",
      "          [0.3771, 0.1596, 0.2709, 0.1126, 0.0798],\n",
      "          [0.3812, 0.1439, 0.2562, 0.1115, 0.1072],\n",
      "          [0.3636, 0.1631, 0.2636, 0.1017, 0.1080]],\n",
      "\n",
      "         [[0.0728, 0.7860, 0.0224, 0.1065, 0.0122],\n",
      "          [0.3577, 0.2338, 0.1357, 0.1187, 0.1541],\n",
      "          [0.2323, 0.1955, 0.1181, 0.3410, 0.1131],\n",
      "          [0.2905, 0.2807, 0.1371, 0.1659, 0.1260],\n",
      "          [0.3057, 0.2454, 0.1428, 0.1838, 0.1223]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4153, 0.5847, 0.0000, 0.0000, 0.0000],\n",
      "          [0.3997, 0.2449, 0.3554, 0.0000, 0.0000],\n",
      "          [0.2149, 0.1622, 0.3779, 0.2450, 0.0000],\n",
      "          [0.1681, 0.1277, 0.2919, 0.1933, 0.2190]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.1256, 0.8744, 0.0000, 0.0000, 0.0000],\n",
      "          [0.1301, 0.3112, 0.5587, 0.0000, 0.0000],\n",
      "          [0.0540, 0.2245, 0.5282, 0.1933, 0.0000],\n",
      "          [0.0461, 0.1924, 0.4397, 0.1606, 0.1612]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 5, 5])\n",
      "old attention tensor([[[[0.1711, 0.2375, 0.0761, 0.2519, 0.2633],\n",
      "          [0.0723, 0.1233, 0.1330, 0.2731, 0.3983],\n",
      "          [0.0357, 0.0726, 0.1624, 0.2721, 0.4572],\n",
      "          [0.0706, 0.1034, 0.1635, 0.2531, 0.4094],\n",
      "          [0.0721, 0.1028, 0.1609, 0.2597, 0.4045]],\n",
      "\n",
      "         [[0.3041, 0.1678, 0.0434, 0.2254, 0.2593],\n",
      "          [0.2433, 0.1402, 0.0543, 0.2986, 0.2636],\n",
      "          [0.3280, 0.1919, 0.0373, 0.2533, 0.1895],\n",
      "          [0.2074, 0.2092, 0.0441, 0.2918, 0.2475],\n",
      "          [0.2068, 0.2206, 0.0422, 0.2879, 0.2426]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 6, 6])\n",
      "old attention tensor([[[[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [5.4816e-02, 9.4518e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [5.7779e-03, 3.5214e-03, 9.9070e-01, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [3.3226e-02, 2.2414e-02, 9.2716e-01, 1.7204e-02, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [3.6912e-02, 2.8767e-02, 8.9590e-01, 1.9074e-02, 1.9343e-02,\n",
      "           0.0000e+00],\n",
      "          [1.2720e-03, 1.0555e-03, 3.4793e-01, 8.8854e-04, 8.4552e-04,\n",
      "           6.4801e-01]],\n",
      "\n",
      "         [[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [9.8231e-03, 9.9018e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [2.8250e-03, 1.6355e-02, 9.8082e-01, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [1.5928e-02, 2.7463e-01, 6.4256e-01, 6.6889e-02, 0.0000e+00,\n",
      "           0.0000e+00],\n",
      "          [1.3648e-02, 2.2671e-01, 6.2577e-01, 7.1695e-02, 6.2178e-02,\n",
      "           0.0000e+00],\n",
      "          [8.4786e-04, 6.1163e-03, 4.2721e-01, 5.4456e-02, 5.6871e-02,\n",
      "           4.5449e-01]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 6, 5])\n",
      "old attention tensor([[[[0.3473, 0.5441, 0.0518, 0.0295, 0.0273],\n",
      "          [0.1569, 0.1799, 0.1048, 0.2335, 0.3249],\n",
      "          [0.2340, 0.3305, 0.1192, 0.1576, 0.1587],\n",
      "          [0.4237, 0.1817, 0.1489, 0.1556, 0.0901],\n",
      "          [0.3881, 0.1691, 0.1690, 0.1697, 0.1042],\n",
      "          [0.2524, 0.2961, 0.1220, 0.1625, 0.1670]],\n",
      "\n",
      "         [[0.0659, 0.2653, 0.3948, 0.1714, 0.1025],\n",
      "          [0.2140, 0.0879, 0.3618, 0.2960, 0.0404],\n",
      "          [0.0828, 0.0666, 0.6550, 0.1238, 0.0718],\n",
      "          [0.0898, 0.0082, 0.4004, 0.4644, 0.0372],\n",
      "          [0.0778, 0.0098, 0.4094, 0.4618, 0.0412],\n",
      "          [0.0998, 0.0714, 0.6378, 0.1130, 0.0781]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 6, 6])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0935, 0.9065, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0120, 0.0566, 0.9314, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0092, 0.0405, 0.4919, 0.4584, 0.0000, 0.0000],\n",
      "          [0.0060, 0.0241, 0.3293, 0.3002, 0.3404, 0.0000],\n",
      "          [0.0045, 0.0236, 0.3414, 0.1320, 0.1434, 0.3551]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5710, 0.4290, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0727, 0.1908, 0.7366, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0459, 0.0631, 0.3263, 0.5647, 0.0000, 0.0000],\n",
      "          [0.0338, 0.0379, 0.1950, 0.3440, 0.3894, 0.0000],\n",
      "          [0.0146, 0.0401, 0.1605, 0.2869, 0.3228, 0.1751]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 6, 5])\n",
      "old attention tensor([[[[0.3452, 0.4116, 0.0943, 0.0670, 0.0819],\n",
      "          [0.3562, 0.1717, 0.2403, 0.1222, 0.1096],\n",
      "          [0.3272, 0.1829, 0.2613, 0.1228, 0.1058],\n",
      "          [0.3331, 0.1601, 0.2524, 0.1197, 0.1347],\n",
      "          [0.3144, 0.1802, 0.2601, 0.1092, 0.1361],\n",
      "          [0.3415, 0.1711, 0.2617, 0.1194, 0.1063]],\n",
      "\n",
      "         [[0.1365, 0.6062, 0.0326, 0.2034, 0.0213],\n",
      "          [0.4116, 0.1679, 0.1208, 0.1470, 0.1526],\n",
      "          [0.2640, 0.1358, 0.1020, 0.3879, 0.1103],\n",
      "          [0.3515, 0.2012, 0.1205, 0.2024, 0.1243],\n",
      "          [0.3609, 0.1731, 0.1243, 0.2215, 0.1202],\n",
      "          [0.2416, 0.1444, 0.0983, 0.4006, 0.1152]]]])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 6, 6])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4817, 0.5183, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4191, 0.2409, 0.3400, 0.0000, 0.0000, 0.0000],\n",
      "          [0.2550, 0.1584, 0.3481, 0.2384, 0.0000, 0.0000],\n",
      "          [0.2011, 0.1262, 0.2700, 0.1902, 0.2124, 0.0000],\n",
      "          [0.2133, 0.1181, 0.1784, 0.1518, 0.1656, 0.1728]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.1940, 0.8060, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.1732, 0.3444, 0.4825, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0974, 0.2513, 0.5005, 0.1508, 0.0000, 0.0000],\n",
      "          [0.0844, 0.2227, 0.4257, 0.1305, 0.1367, 0.0000],\n",
      "          [0.1004, 0.2077, 0.2920, 0.0733, 0.0809, 0.2457]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 6, 5])\n",
      "old attention tensor([[[[0.1464, 0.1291, 0.0789, 0.2670, 0.3785],\n",
      "          [0.0672, 0.0731, 0.1122, 0.2577, 0.4899],\n",
      "          [0.0392, 0.0519, 0.1377, 0.2608, 0.5103],\n",
      "          [0.0628, 0.0574, 0.1315, 0.2406, 0.5076],\n",
      "          [0.0644, 0.0581, 0.1305, 0.2463, 0.5007],\n",
      "          [0.0379, 0.0506, 0.1312, 0.2600, 0.5204]],\n",
      "\n",
      "         [[0.4590, 0.2588, 0.0418, 0.1201, 0.1203],\n",
      "          [0.4339, 0.2180, 0.0516, 0.1614, 0.1352],\n",
      "          [0.4573, 0.2617, 0.0360, 0.1416, 0.1034],\n",
      "          [0.3689, 0.3189, 0.0396, 0.1480, 0.1245],\n",
      "          [0.3625, 0.3296, 0.0378, 0.1476, 0.1225],\n",
      "          [0.4621, 0.2590, 0.0353, 0.1396, 0.1040]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 7, 7])\n",
      "old attention tensor([[[[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [5.4816e-02, 9.4518e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [5.7779e-03, 3.5214e-03, 9.9070e-01, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [3.3226e-02, 2.2414e-02, 9.2716e-01, 1.7204e-02, 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [3.6912e-02, 2.8767e-02, 8.9590e-01, 1.9074e-02, 1.9343e-02,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.2720e-03, 1.0555e-03, 3.4793e-01, 8.8854e-04, 8.4552e-04,\n",
      "           6.4801e-01, 0.0000e+00],\n",
      "          [1.7229e-02, 1.8335e-02, 4.1019e-01, 1.0429e-02, 1.0467e-02,\n",
      "           5.2445e-01, 8.9072e-03]],\n",
      "\n",
      "         [[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [9.8231e-03, 9.9018e-01, 0.0000e+00, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [2.8250e-03, 1.6355e-02, 9.8082e-01, 0.0000e+00, 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.5928e-02, 2.7463e-01, 6.4256e-01, 6.6889e-02, 0.0000e+00,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [1.3648e-02, 2.2671e-01, 6.2577e-01, 7.1695e-02, 6.2178e-02,\n",
      "           0.0000e+00, 0.0000e+00],\n",
      "          [8.4786e-04, 6.1163e-03, 4.2721e-01, 5.4456e-02, 5.6871e-02,\n",
      "           4.5449e-01, 0.0000e+00],\n",
      "          [8.3655e-03, 1.9276e-01, 3.0378e-01, 4.1334e-02, 3.5289e-02,\n",
      "           3.7954e-01, 3.8926e-02]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 7, 5])\n",
      "old attention tensor([[[[0.3307, 0.5595, 0.0518, 0.0308, 0.0272],\n",
      "          [0.1490, 0.1832, 0.1044, 0.2417, 0.3217],\n",
      "          [0.2226, 0.3363, 0.1192, 0.1637, 0.1581],\n",
      "          [0.4062, 0.1883, 0.1504, 0.1644, 0.0907],\n",
      "          [0.3715, 0.1748, 0.1703, 0.1787, 0.1047],\n",
      "          [0.2406, 0.3019, 0.1221, 0.1689, 0.1665],\n",
      "          [0.3942, 0.2018, 0.1578, 0.1588, 0.0875]],\n",
      "\n",
      "         [[0.0613, 0.2520, 0.3806, 0.1913, 0.1147],\n",
      "          [0.1995, 0.0836, 0.3471, 0.3251, 0.0448],\n",
      "          [0.0792, 0.0648, 0.6364, 0.1387, 0.0809],\n",
      "          [0.0808, 0.0076, 0.3717, 0.4997, 0.0403],\n",
      "          [0.0700, 0.0090, 0.3803, 0.4962, 0.0445],\n",
      "          [0.0954, 0.0696, 0.6209, 0.1264, 0.0878],\n",
      "          [0.0712, 0.0084, 0.3615, 0.5162, 0.0428]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 7, 7])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0914, 0.9086, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0109, 0.0573, 0.9318, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0085, 0.0441, 0.4991, 0.4484, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0054, 0.0264, 0.3372, 0.2973, 0.3336, 0.0000, 0.0000],\n",
      "          [0.0042, 0.0248, 0.3528, 0.1251, 0.1345, 0.3586, 0.0000],\n",
      "          [0.0038, 0.0179, 0.2129, 0.1890, 0.2104, 0.1844, 0.1816]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.5795, 0.4205, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0816, 0.2079, 0.7106, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0498, 0.0705, 0.3209, 0.5589, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0367, 0.0424, 0.1932, 0.3411, 0.3866, 0.0000, 0.0000],\n",
      "          [0.0166, 0.0438, 0.1575, 0.2872, 0.3231, 0.1718, 0.0000],\n",
      "          [0.0231, 0.0283, 0.1235, 0.2136, 0.2453, 0.1259, 0.2403]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 7, 5])\n",
      "old attention tensor([[[[0.3584, 0.3618, 0.1099, 0.0751, 0.0948],\n",
      "          [0.3484, 0.1456, 0.2656, 0.1259, 0.1145],\n",
      "          [0.3202, 0.1490, 0.2928, 0.1267, 0.1113],\n",
      "          [0.3232, 0.1324, 0.2727, 0.1247, 0.1470],\n",
      "          [0.3083, 0.1500, 0.2794, 0.1136, 0.1487],\n",
      "          [0.3327, 0.1408, 0.2911, 0.1233, 0.1122],\n",
      "          [0.3377, 0.1411, 0.2905, 0.1024, 0.1282]],\n",
      "\n",
      "         [[0.1254, 0.6310, 0.0323, 0.1911, 0.0202],\n",
      "          [0.3986, 0.1714, 0.1272, 0.1459, 0.1570],\n",
      "          [0.2585, 0.1381, 0.1078, 0.3812, 0.1144],\n",
      "          [0.3350, 0.2053, 0.1249, 0.2044, 0.1304],\n",
      "          [0.3464, 0.1777, 0.1286, 0.2223, 0.1251],\n",
      "          [0.2332, 0.1468, 0.1024, 0.3981, 0.1195],\n",
      "          [0.3902, 0.1785, 0.1286, 0.1792, 0.1235]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "old attention torch.Size([1, 2, 7, 7])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4972, 0.5028, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.4298, 0.2293, 0.3410, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.2635, 0.1513, 0.3476, 0.2376, 0.0000, 0.0000, 0.0000],\n",
      "          [0.2081, 0.1204, 0.2709, 0.1890, 0.2117, 0.0000, 0.0000],\n",
      "          [0.2211, 0.1134, 0.1788, 0.1490, 0.1636, 0.1741, 0.0000],\n",
      "          [0.1367, 0.0837, 0.1766, 0.1357, 0.1520, 0.1765, 0.1387]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.1995, 0.8005, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.1858, 0.3440, 0.4702, 0.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0988, 0.2479, 0.4812, 0.1721, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0845, 0.2156, 0.4035, 0.1466, 0.1498, 0.0000, 0.0000],\n",
      "          [0.1059, 0.2068, 0.2813, 0.0809, 0.0872, 0.2380, 0.0000],\n",
      "          [0.0542, 0.1382, 0.2760, 0.0983, 0.0999, 0.2329, 0.1005]]]])\n",
      "new attention tensor([[[[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]],\n",
      "\n",
      "         [[0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311],\n",
      "          [0.1586, 0.1586, 0.1586, 0.1311, 0.1311, 0.1311, 0.1311]]]])\n",
      "old attention torch.Size([1, 2, 7, 5])\n",
      "old attention tensor([[[[0.1402, 0.1221, 0.0872, 0.2808, 0.3697],\n",
      "          [0.0634, 0.0681, 0.1234, 0.2688, 0.4763],\n",
      "          [0.0378, 0.0476, 0.1501, 0.2689, 0.4956],\n",
      "          [0.0617, 0.0547, 0.1468, 0.2498, 0.4870],\n",
      "          [0.0632, 0.0557, 0.1452, 0.2557, 0.4802],\n",
      "          [0.0366, 0.0464, 0.1424, 0.2689, 0.5056],\n",
      "          [0.0636, 0.0527, 0.1429, 0.2542, 0.4867]],\n",
      "\n",
      "         [[0.4414, 0.2596, 0.0421, 0.1334, 0.1235],\n",
      "          [0.4124, 0.2175, 0.0527, 0.1798, 0.1376],\n",
      "          [0.4466, 0.2604, 0.0367, 0.1533, 0.1030],\n",
      "          [0.3452, 0.3153, 0.0414, 0.1695, 0.1286],\n",
      "          [0.3393, 0.3239, 0.0397, 0.1695, 0.1275],\n",
      "          [0.4508, 0.2586, 0.0359, 0.1509, 0.1038],\n",
      "          [0.3478, 0.3198, 0.0416, 0.1676, 0.1231]]]])\n",
      "new attention tensor([[[[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]],\n",
      "\n",
      "         [[0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776],\n",
      "          [0.2149, 0.2149, 0.2149, 0.1776, 0.1776]]]])\n",
      "predicted trg = ['wir', 'lesen', 'zeitung', 'zeitung', 'lesen', 'zeitung', '<eos>']\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_count 1    self.capacity  20\n",
      "0  ------------------------------------------------\n",
      "DecoderLayer@trg4\n",
      "[1, 1, 64]\n"
     ]
    }
   ],
   "source": [
    "invalid_sentences_embeddings = []\n",
    "for i in range(len(tabular_set)):\n",
    "    test_logger = test_sentence(tabular_set[i].src,is_appy_attention=False)\n",
    "    #train_data.examples[example_idx].src\n",
    "    #test_logger.get_default_summary()\n",
    "    trg4 = test_logger.get_summary(labels=[\"DecoderLayer@trg4\"],show_data=False)\n",
    "    invalid_sentences_embeddings.append(trg4[0].numpy().flatten())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1332x756 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_on_vis_multi(invalid_sentences_embeddings,valid_sentences,valid_sentences_embeddings,valid_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAABJgAAAJZCAYAAADlMI+bAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAADd3ElEQVR4nOzde5zN1f7H8dee2YZhiBMOZRi5a4a5CJEoIU4jM4lUakin+pWKUihyOiUR3dPlVHShTjq55RJOU1Ny27mNS1LJiKNcx1zMbX9/f3yaGWP2DJpBM95PDw97f9f3u9b6fpe9Z/Znf9b6uhzHcRAREREREREREfmD/M52B0REREREREREpGxTgElEREREREREREpEASYRERERERERESkRBZhERERERERERKREFGASEREREREREZEScZ/tDhzP6/WSmppKhQoVcLlcZ7s7IiIiIiIiInIWOI5DVlYWVapUwc9P+TF/dn+6AFNqairbtm07290QERERERERkT+Bpk2bUrVq1bPdDTmBP12AqUKFCoD9BwoICDjLvTn7EhMTCQ0NPdvdkFKgsSw/NJbli8az/NBYlh8ay/JDY1l+aCzLj7I0lpmZmWzbti0vTiB/bn+6AFPutLiAgAAqVqx4lnvz56DrUH5oLMsPjWX5ovEsPzSW5YfGsvzQWJYfGsvyo6yNpZbPKRs0iVFEREREREREREpEASYRERERERERESkRBZhERERERERERKREFGASEREREREREZESUYBJRERERERERERKRAEmEREREREREREpEQWYRERERERERESkRBRgEhERERERERGRElGASURERERERERESkQBJhERERERERERKREFmEREREREREREpEQUYBIRERERERERkRJRgElEREREREREREpEASYRERERERERESkRBZhERERERERERKREFGASERERERE5zj3cwzjG+SzrRS82s7nY4+OI4xmeKXafeOIJJfSPdlFE5E/FfbY7ICIiIiIiUpYsYMHZ7oKIyJ+OMphERERERKRMCiecZSwDYCYzqUQl0kkHYAhDmMpUMslkGMOIJJLWtCaOOJJJLlRXMsn0ox/NaEYXurCVrXllIYTQn/60oAWf8AkhhLCGNcQTT0c6MpCBRBBBKKF8zdeF6h7GMLrSlRRSCpWlkEJf+hJOOF3owja2ARTb71/4hRhiiCKKVrRiPOMB2MEOggmmO91pSlP2sKeEV1hE5OQpwCQiIiIiImVSLLEsZCEAi1hEDWqQQAIODgtYQAwxTGACbtx48LCe9VzABYxkZKG6HuMxAglkK1v5iI/4ju8KlIcSyha2EENMge0rWckDPMBa1jKIQYxmdF6Zg8M93MPP/MwCFhBEUKF2k0hiOMNZxzpu5EYGMhCg2H4PZCCDGYwHD6tYxVKW8m/+DcAudjGGMWxjG3WpW4KrKyJyajRFTkREREREypy0zGzapHbnwfNuY5LfJBJIYDjDWcISqlKVRjSiDnWYz3wOcYglLAEsM6g2tQvVt5SlPMdzuHBRi1qFAkmd6OSzHw1oQDjhAEQSyTSm5ZVNYQq/8ivrWEdFKvo8vhWt6EAHwNZtuou7OMzhIvudSipf8AUHOMAYxgCWBbWOdbSlLW7cXMqlJ38hRURKiQJMIiIiIiJSZmTneBkxz8PcxCR2HkqF0Qe4dttkGrdrTLQrmv70x42bvvQFIIccnud5etITsGDMUY76rNvByXvsPu6jkq/sI4BAAvMeu3AVqKMznelIR+KIYwUrqECFQsf741/guQsXFahQZL9zyMHBYTnLqUxlAPaxj0pUYh/7qEjFQn0XETkTNEVORERERETKjBHzPLyQsJUdB1PxOpC9PpJ5DadwdFNLmtOcwxzmfd4nllgAetCDl3iJTDLx4uV2bmcUowrV25OevMmbePFykIPMYU6J+9qGNtzDPVSnepF3pFvPetaxDoDXeI3LuIzKVC6y39WoRnvaM4UpABziEB3pWCr9FREpCQWYRERERESkTEjLzGZOYlKBba6NUfDXPfy4vAFpmdl0oxt1qUswwQCMYQwhhBBBBC1piYPDZCYXqnsc46hABZrTnGiiCSOsVPrswsVbvMUrvMJylhcqb0EL/sE/aE1r5jKX6Uw/Yb9nMIMVrCCMMNrRjgEM4CZuKpX+ioj8UcqdFBERERGRMmFPcjpJh1ILbHP93ATXA+/wq8vK36j5RoHyQAJ5mZdPWHdlKvMO7/gs28GOIp8nkpj3uAtd8p4fuxZTAxpwkIOF6u1CFzawwWebxfU7hBDmM9/ndl93qhMROROUwSQiIiIiImVC3WqB1K9exWdZcPUg6lYL9FkmIiKnnwJMIiIiIiJSJlQOcNM7NNhnWe/QelQO0AQNEZGzRe/AIiIiIiJSZkyKjgJgbuIukg6lEFw9iN6h9fK2i4jI2aEAk4iIiIiIlBlufz+e7XMJT/aKYE9yOnWrBSpzSUTkT0DvxCIiIiIiUuZUDnDTqGbVs90NERH5ndZgEhERERERERGRElGASURERERERERESkQBJhERERERERERKREFmEREREREREREpEQUYBIRERERERERkRJRgElEREREREREREpEASYRERERERERESkRBZhERERERERERKREFGASEREREREREZESUYBJRERERERERERKRAEmEREREREREREpkRIFmNavX8/AgQMB+PnnnxkwYAA33ngjjz32GF6vF4B///vfxMbG0q9fPz7//POS91hEREREzmlBBLGDHYW2r2ENfel7wuNduNjHvtPQM3OYw1zJlaetfhERkT+jPxxgeuONN3j00UfJyMgA4KmnnuL+++9nxowZOI7DsmXL+O2333j33Xf54IMPePPNN5kyZQqZmZml1nkRERERkVxtaMMsZp3tbnCQg6xi1dnuhoiIyBn1hwNM9evX58UXX8x7vmnTJtq2bQvA5ZdfzvLly9mwYQMREREEBARQtWpV6tevz9atW0veaxEREREpsXDCWcYyAGYyk0pUIp10AIYwhKlMJZNMhjGMSCJpTWviiCOZ5EJ1ZZPNcIbTlKa0pCVDGEImmexlL33ow6VcSkMa0oUu/MqvAIQQwjjG0YlONKABYxjjs58JJBBOOBFE8Hf+jhfLlI8nnta0pgMdaEUrFrOYUEIBiCOOe7mXK7iCxjQmllhSSClQ7//4H6GE8jIvF9i+jnUEE5z3vAc9uJVbAcggg/M5n8Mc5i3eoh3tiCCCBjRgKlMBGMQg0kknnHByyGELW+hOd6KIIpxw3uItn/3PIOMURk9EROTPxf1HD+zRowe7du3Ke+44Di6XC4AqVapw5MgRUlJSqFq1at4+VapUISUlpVBdviQmJv7RrpU7Ho/nbHdBSonGsvzQWJYvGs/yQ2N5atrXbc80v2lU/6U674e8T1C1IN766S3aHWnHnLA5XL/leu6tdS9pfmm8/svruHDx8gUvc5v/bYxMGlmgrg9qfcAXNb7g7e/fJsAJ4JGGjzDh8ASS3ckEu4IZs3cMDg73Nb6Pp5Kf4uZfbyYzNJMfDv7Ac788x68VfiUmNIZLNl3ChVyYN5ZZrixiwmL450//pO2RtiyqsYj0i9LZuHEjuwN2k9g0kTmJc6ibWZc1QWtIr5+OZ7OH/Q32s7bSWl7d9ip+jh+3triVSb9Oovf+3hAFn23+jDENxzDof4Nof6A9Hgr+33FCHT7c/iH1Muqx4eINrHetx7PRw1fVvqJ57eZs+HEDzzV5jme3P0v1nOpsrLKRu5vcTdt1bRkeMJyVLVfy5ro3WcMabmx5I4//9DjN05uT4pfCoOaD8PvZjwxXRoH+J1I+f//V67L80FiWHxpLOR3+cIDpeH5++clQqampVKtWjaCgIFJTUwtsPzbgVJzQ0FAqVqxYWt0rszweD1FRUWe7G1IKNJblh8ayfNF4lh8ay1OTlplN79Q4HjzvNiLrRLKZzTzMw+xouoNIImlOc3q07sEYxnCIQ2yoswGATDKpTW2iahe81v/gH9zFXXSM7AjAZ3wGf7GyBBL4ot4XfM/3JJFE9/O6ExUcRQAB/L3O34mqY3X9lb9yYdiF4CFvLD14CCSQu5reBUAUUTzN04SFhVGVqgQTzDVh1wBwhCMEEkhUVBTncz5taculkZcC0I52VAupRlSI1ftgywepRz0eafgIroauQtenP/3ZefFOqlGNnvRkPeupFFWJzWxmMIPpFNGJz/mcT8M/JZ541rGONNLy2vbDj6ioKDazmV/4hUktJ+XV7eCQ3jydFrQo0P/ySK/L8kNjWX6UpbHMyMhQ8kkZUmoBppYtW7Jy5UratWvHl19+Sfv27WnVqhXPPfccGRkZZGZm8sMPP9C0adPSalJERERETlF2jpcR8zzMTUxi56FUGH2Aa7dNpnG7xkS7oulPf9y48xbLziGH53menvQEIIUUjnK0UL1u3LjID9TsZS9evDzHc6xiFYMZzBVcQRZZODh5+wUSmPfYhQsHp0A9QIH9c9vKFURQkefqq+5cr/EaT/IkU5jCAzxQ6NgYYhjDGHazm250oza1WcxiFrKQ8YxnF7u4lEv5O3/nMi6jL32Zz/xC9eSQw3mcxzrWFbg253EeK1hRbP9FRETKkhLdRe5YDz/8MC+++CL9+/cnKyuLHj16UKtWLQYOHMiNN97IrbfeyrBhw5SVJCIiInIWjZjn4YWErew4mIrXgez1kcxrOIWjm1rSnOYc5jDv8z6xxAK2/tBLvEQmmXjxcju3M4pRheq9iquYwQwyyMCLl7u4i5nMZDGLuZ/7GchAalObJSwhh5yT7m8rWuHgsIAFAMxlLgc5WOLrcCmXMp3pPMETPqemdaADP/AD85nPVVxFd7rzHM/RlKacz/msYQ21qMWjPEp3uucFl3LIwY2bHHJwcGhGMwIJ5D3eAyCJJEIJLTQlT0REpKwrUQZTvXr1+Pe//w1Aw4YNee+99wrt069fP/r161eSZkRERESkFKRlZjMnManANtfGKJwrFvDjnAakNc2mW0A3NrAhb5HrMYzhQR4kgghyyCGccCYzuVDdd3AHO9hBFFE4OHShC/dyLyGE8CAPMoYxVKACl3EZ29l+0n2uQAVmM5s7uZPRjCaccGpTu2QX4nfNaMYYxnAzN7OKVQQQkFfmhx896clqVlOLWlzGZRzgANdxHQDd6c5bvEUzmuGHH53pTC1qsZ3tNKYxbWnLxVxMAgnMYQ73cR8TmUgWWfyTf9KRjsQTXyrnISIi8mfgchzHOfFuZ07uHEutwWTK0vxYKZ7GsvzQWJYvGs/yQ2N5Yj/sO0LzCbPx+vjtz98FW0b2oVHNk1sv83TSWJYfGsvyQ2NZfpSlsVR8oGwptSlyIiIiIvLnVrdaIPWrV/FZFlw9iLrVAn2WiYiIiJyIAkwiIiIi54jKAW56hwb7LOsdWo/KAaV2/xcRERE5x+i3CBEREZFzyKRomxYxN3EXSYdSCK4eRO/QennbRURERP4IBZhEREREziFufz+e7XMJT/aKYE9yOnWrBSpzSUREREpMv02IiIiInIMqB7j/FAt6i4iISPmgNZhERERERERERKREFGASEREREREREZESUYBJRERERERERERKRAEmEREREREREREpEQWYRERERERERESkRBRgEhERERERERGRElGASURERERERERESkQBJhERERERERERKREFmEREREREREREpEQUYBIRERERERERkRJRgElEREREREREREpEASYRERERERERESkRBZhERERERERERKREFGASEREREREREZESUYBJRERERERERERKRAEmEREREREREREpEQWYRERERERERESkRBRgEhERERERERGRElGASURERERERERESkQBJhERERERERERKREFmEREREREREREpEQUYBIREZEC7uEexjHOZ1kverGZzcUeH0ccz/DMaehZvsd5nDnMOa1tiIiIiMjJc5/tDoiIiEjZsYAFZ7sLAPyX/9KSlme7GyIiIiLyO2UwiYiIlEHhhLOMZQDMZCaVqEQ66QAMYQhTmUommQxjGJFE0prWxBFHMsmF6kommX70oxnN6EIXtrI1ryyEEPrTnxa04BM+IYQQ1rCGeOLpSEcGMpAIIggllK/5ulDdwxhGV7qSQsop938b2+hGN9rTngY04Fqu5ShHeZmXWcMaRjCCT/gk7zxvanFTofM8vv8iIiIicnoowCQiIlIGxRLLQhYCsIhF1KAGCSTg4LCABcQQwwQm4MaNBw/rWc8FXMBIRhaq6zEeI5BAtrKVj/iI7/iuQHkooWxhCzHEFNi+kpU8wAOsZS2DGMRoRueVOTjcwz38zM8sYAFBBJ1y/9/gDW7lVlawgu1s5yd+4lM+5W7upg1tmMSkAuf53pb3fJ5nUf0XERERkdKjKXIiIiJlTFpmNm1Su/PgebcxyW8SCSQwnOEsYQlVqUojGlGHOsxnPoc4xBKWAJBJJrWpXai+pSzlOZ7DhYta1CoUiOlEJ5/9aEADwgkHIJJIpjEtr2wKU/iVX1nHOipSsdCxMcRwAzcwiaL7/zRPs4QlTGQi29jGbnYXyoQC8s5zbou5BBJY6DyL6r+IiIiIlB4FmERERMqI7BwvI+Z5mJuYxM5DqTD6ANdum0zjdo2JdkXTn/64cdOXvgDkkMPzPE9PegKQQgpHOeqzbgcn77H7uF8Pjs8+yhVIYN5jF64CdXSmMx3pSBxxrGAFFahQ4Ngwwsgkk7nMpQlNiKZw/wcwgGyy6Uc//sbf2MnOAm3kyj3P2ltqExUVVeg8i+q/iIiIiJQeTZETEREpI0bM8/BCwlZ2HEzF60D2+kjmNZzC0U0taU5zDnOY93mfWGIB6EEPXuIlMsnEi5fbuZ1RjCpUb0968iZv4sXLQQ6Wyt3Z2tCGe7iH6lQv8o50McQwkpF0p7vP/i9mMWMZS3/6AzYlL4ccwIJgWWQVOM8sV1ax5ykiIiIip48CTCIiImVAWmY2cxKTCmxzbYyCv+7hx+UNSMvMphvdqEtdggkGYAxjCCGECCJoSUscHCYzuVDd4xhHBSrQnOZEE00YYaXSZxcu3uItXuEVlrO8UHkMMWxlK93oBlCo/+MZTwwxhBHGHdxBZzqzne0A9KY3oxjFdKbnnedNLW4q9jxFRERE5PTRFDkREZEyYE9yOkmHUgtsc/3cBNcD7/Cry8rfqPlGgfJAAnmZl09Yd2Uq8w7v+CzbwY4inyeSmPe4C13ynh+7FlMDGnCQgz7rvpRLC0x5e4OC/f+/3//4cu/vf3K9zMt4NnuIiooqtv8iIiIicnoog0lERKQMqFstkPrVq/gsC64eRN1qgT7LRERERETOBAWYREREyoDKAW56hwb7LOsdWo/KAUpKFhEREZGzRwEmERGRMmJSdBT3dmpOSI0g/F0QUiOIezs1Z1J01IkPFhEpZ4II8jkNdg1r8u5GWRwXLvaxr9h94ojjGZ75o10UETmn6OtOERGRMsLt78ezfS7hyV4R7ElOp261QGUuiYgcpw1tmMWss90NEZFzjjKYREREypjKAW4a1ayq4JKIlIpwwlnGMgBmMpNKVCKddACGMISpTCWTTIYxjEgiaU1r4ogjmeRCdWWTzXCG05SmtKQl/2zwTzLJZC976UMfLuVSGtKQLnThV34FIIQQxjGOTnSiAQ0Ywxif/UwggXDCiSCCv/N3vHgBiCee1rSmAx1oRSsWs5hQQgHLQLqXe7mCK2hMY2KJJYWUAvX+j/8RSmiRN0X4iq9oT3ta0pL7uZ9ssgHYwha6050ooggnnLd4K++YecyjHe2IIIKOdOQbvgHsrp096EEYYdzMzSc3QCIiZYQCTCIiIiIi57BYYlnIQgAWsYga1CCBBBwcFrCAGGKYwATcuPHgYT3ruYALGMnIQnW9wit5+ySSSJpfGh/yIR/wAZdyKd/wDT/yI5WpzLu8m3dcCikkkMBylvMMz/ATPxWoN5NMrud6JjOZtazlCq7IC4KB3dVyJjPZwAYqUrHAsR48LGIRW9jCDnbwER/lle1iF13pyihGcTd3+7w+u9jFMpaxjnWsZz1v8AbZZNOXvkxgAh48fMEXPMMzrGAF3/M9oxnNAhawlrW8zuvEEksqdifQn/mZtazlPd47xZESEflz01efIiIiIiLnqLTMbNqkdufB825jkt8kEkhgOMNZwhKqUpVGNKIOdZjPfA5xiCUsASzgU5vahepbylIGMpBA7M6WT/30FFF/sXXiEkhgClP4nu9JJJF2tMs77lquBeBCLqQ2tTnAARrSMK98IxupQAW60hWAAQzgDu7IKw8mmAY08HmOV3N1XtApjDAOcCCvrBe9qEc9buTGIq/RQAZSBbuL583czKd8Smc68wM/MJjBefulk85a1uLgsIc9eX0F8MOP7WwHoD3tcetjmIiUQ3pnExERERE5x2TneBkxz8PcxCR2HkqF0Qe4dttkGrdrTLQrmv70x407b7HsHHJ4nufpSU/AMo6OcrRQvW7cuHDlPd/v3s8e9vAcz7GKVQxmMFdwBVlk4eDk7ZcbkAJbfPvYslzHbzs2SBNEUJHnWlzdr/EaT/IkU5jCAzzg83h//PMee/FSgQrkkMN5nMc61uWV7WUv53Eeb/AGXenKh3yYV5ZEEhdwAZ/wSbF9FREpyzRFTkRERETkHDNinocXEray42AqXgey10cyr+EUjm5qSXOac5jDvM/7xBILQA968BIvkUkmXrzczu2MYlSheq/iKmYwgwwy8OJlQv0JzGQmi1nM/dzPQAZSm9osYQk55Jx0f1vRKm/KHsBc5nKQgyW+DpdyKdOZzhM8QSKJPvf5gA/IIIOjHGU60+lJT5rRjEAC86a5JZFEKKF48NCVrnzGZ2xlKwALWEArWhWY0iciUh4pg0lERERE5BySlpnNnMSkAttcG6NwrljAj3MakNY0m24B3djABoIJBmAMY3iQB4kgghxyCCecyUwuVPcd3MEOdhBFFA4OF2ddzL3cSwghPMiDjGEMFajAZVyWN2XsZFSgArOZzZ3cyWhGE064zyl6f0QzmjGGMdzMzaxiFQEEFChvSEM60YkjHCGGGG7lVly4mMMc7uM+JjKRLLL4J/+kIx0BeJ3XuYEbcHBw42Yuc5W5JCLlnstxnML5p2dRRkYGiYmJhIaGUrFixRMfUM55PB6ioqLOdjekFGgsyw+NZfmi8Sw/NJblh8by9Pph3xGaT5iN18enAH8XbBnZh0Y1q5ZKWxrL8kNjWX6UpbFUfKBs0RQ5EREREZFzSN1qgdSvXsVnWXD1IOpWC/RZJiIiUhwFmEREREREziGVA9z0Dg32WdY7tB6VA7SKhsixVrOaO7nTZ9m/+Bev8EqJ6r+HexjHOJ9lvejFZjYXe3wccTzDM8XuE088oYT+0S6KnBT99BAREREROcdMirbpMXMTd5F0KIXg6kH0Dq2Xt11E8m1iE7vY5bPsK746rYGb3IXtRcoCZTCJiIiIiJxj3P5+PNvnEjY+FM2WkX3Y+FA0z/a5BLe/Ph7ImRVOOMtYBsBMZlKJSnl33BvCEKYylUwyGcYwIomkNa2JI45kkgvUs5/9BBFEKqmALTjfmc555U1owha2MJ/5dKADbWhDfeozhjGAZfh0pCMDGUgEEYQSytd8TRJJjGUsCSQwiEEF2vyET5jLXJ7lWV7mZbLIYihDaUlLwghjCEM4wpFC55xMMv3oRzOa0YUueXccBAghhP70pwUt+IRPCCGENawpsn/HG8YwutKVFFIKlaWQQl/6cmOLG+lCF7axDaDY6/sLvxBDDFFE0YpWjGc8ADvYQTDBdKc7TWnKHvYUN8xyjtBPEBERERGRc1TlADeNalbVtDg5a2KJZSELAVjEImpQgwQScHBYwAJiiGECE3DjxoOH9aznAi5gJCML1HM+59OWtnzO54AFjL7jO1JIYTObqUAFmtOcyUxmOtNZwxpWsIKneIp97ANgJSt5gAdYy1oGMYjRjCaYYB7ncTrRibd5u0CbMcTQm94MYxh3czdP8AS72c363/948TKCEYXO+TEeI5BAtrKVj/iI7/iuQHkooWxhCzHEFNjuq3+5HBzu4R5+5mcWsMDnXQuTSGI4w5mxZQY3ciMDGQhQ7PUdyEAGMxgPHlaxiqUs5d/8G4Bd7GIMY9jGNupS9wQjLecC/SQRERERERGRMy4tM5s2qd158LzbmOQ3iQQSGM5wlrCEqlSlEY2oQx3mM59DHGIJSwDLuKlN7UL1xRDDQhbSiEZcyIWEEsoXfMEGNnAd1+HCxTzmMZ/5zGAGW9iCg5OX9dSABoQTDkAkkUxj2imdz0IW8iRPUoEKAAxlKH3oU2i/pSzlOZ7DhYta1CoUSOpEJ5/1F9e/KUzhV35lHeuoiO+7rbWiFR3ogAcPccRxF3dxmMNFXt9UUvmCLzjAgbxMrxRSWMc62tIWN24u5dJTuURSzinAJCIiIiIiImdMdo6XEfM8zE1MYuehVBh9gGu3TaZxu8ZEu6LpT3/cuOlLXwByyOF5nqcnPQELchzlaKF6Y4jhci6nKU3pRjdqUIPP+IxVrOJVXiWVVCKIIIYYOtGJwQxmNrNxcAAIJP8Oii5cedtPVg45uHDlPffiJYssn/seW7f7uI/lvrKPTtS/znSmIx2JI44VrMgLch3LH/8Cz124qECFIq9vDjk4OCxnOZWpDMA+9lGJSuxjHxWpWKjvcm7TFDkRERERERE5Y0bM8/BCwlZ2HEzF60D2+kjmNZzC0U0taU5zDnOY93mfWGIB6EEPXuIlMsnEi5fbuZ1RjCpUbz3qUZOavMqrdKc7PejBx3zMfvbTmtZ8z/ckk8wTPEE00cQTTwYZ5JBTbH/duIsMFB1bdjVXM5WpZJGFFy8v8zLd6FbomJ705E3exIuXgxxkDnNO9RIW0oY23MM9VKd6kXekW8961rEOgNd4jcu4jMpULvL6VqMa7WnPFKYAcIhDdKRjqfRXyicFmEREREREROSMSMvMZk5iUoFtro1R8Nc9/Li8AWmZ2XSjG3WpSzDBAIxhDCGEEEEELWmJg8NkJvusP4YYfuM3IoigIQ0JJDBvClorWnEN19Cc5rSgBfOYR0tasp3txfa5Pe35kR/zAl7H6klPXuVVnuIpHuVR6lCHcMJpQQuyyOJ5ni90zDjG5a0JFU00YYSd1LU7ERcu3uItXuEVlrO8UHkLWvAP/sGAFgOYy1ymMx0o/vrOYAYrWEEYYbSjHQMYwE3cVCr9lfLH5TjOqeX9nWYZGRkkJiYSGhpKxYq+546eSzweD1FRul1seaCxLD80luWLxrP80FiWHxrL8kNjWX6U1lj+sO8IzSfMxuvjU6i/C7aM7EOjmlVL3I4UrSy9LhUfKFuUwSQiIiIiIiJnRN1qgdSvXsVnWXD1IOpWC/RZJiJ/fgowiYiIiIiIyBlROcBN79Bgn2W9Q+tROUCLRouUVXr1ioiIiIiIyBkzKdqmZ81N3EXSoRSCqwfRO7Re3nYRKZsUYBIREREREZEzxu3vx7N9LuHJXhHsSU6nbrVAZS6JlAN6FYuIiIiIiMgZVznArQW9RcoRrcEkIiIiIiIiIiIlogCTiIiIiIiIiIiUiAJMIiIiIiIiIiJSIgowiYiIiIiIiIhIiSjAJCIiIiIiIiIiJaIAk4iIiIiIiIiIlIgCTCIiIiIiIiIiUiIKMImIiIiIiIiISIkowCQiIiIiIiIiIiWiAJOIiIiIiIiIiJSIAkwiIiIiIiIiIlIiCjCJiIiIyBm1mtXcyZ0+y/7Fv/io1kclqv8e7mEc43yW9aIXm9lc7PFxxPEMz5SoDyfyOI8zhzmntQ0REZEzSQEmERERETmjNrGJXezyWfYVX3HU7+hpa3sBC2hJy9NW/8n6L/8li6yz3Q0REZFSowCTiIiISDkSTjjLWAbATGZSiUqkkw7AEIYwlalkkskwhhFJJK1pTRxxJJNcoJ797CeIIFJJBeAO7qAznfPKm9CELWxhPvPpQAfa0Ib61GcMYwCIJ56OdGQgA4kgglBC+ZqvSSKJsYwlgQQGMahAm5/wCXOZy4zaM3iZl8kii6EMpSUtCSOMIQzhCEcKnXMyyfSjH81oRhe6sJWteWUhhNCf/rSgBZ/wCSGEsIY1RfbveMMYRle6kkLKKV/nbWyjG91oT3sa0IBruZajHOVlXmYNaxjBCD7hk2LH4/j+i4iI/FkpwCQiIiJSTqRlZtMl9W/MzfkUgEUsogY1SCABB4cFLCCGGCYwATduPHhYz3ou4AJGMrJAXedzPm1py+d8DljA6Du+I4UUNrOZClSgOc2ZzGSmM501rGEFK3iKp9jHPgBWspIHeIC1rGUQgxjNaIIJ5nEepxOdeJu3C7QZQwy96c2Nv97I3dzNEzzBbnaz/vc/XryMYESh836MxwgkkK1s5SM+4ju+K1AeSihb2EIMMQW2++pfLgeHe7iHn/mZBSwgiKACx8YSy0IWFnud3+ANbuVWVrCC7WznJ37iUz7lbu6mDW2YxKSTGo+i+i8iIvJn4j7bHRARERGRksnO8TJinoe5iUn8XKkKfre+g+vrG0i4NoHhruEsYQlVqUojGlGHOsxnPoc4xBKWAJBJJrWpXajeGGJYyEIa0YgLuZBQQvmCL9jABq7jOly4mMc85jOfGcxgC1twcPKynhrQgHDCAYgkkmlMO6XzWshCnuRJKlABgKEMpQ99Cu23lKU8x3O4cFGLWoUCMZ3o5LP+4vo3hSn8yq+sYx0Vqejz2tzADUxiEgkkMJzC1/lpnmYJS5jIRLaxjd3sLpQJBZxwPIrqv4iIyJ+JAkwiIiIiZdyIeR5eSMidFhZMFlm8cGAGwb/WJvqv0fSnP27c9KUvADnk8DzP05OeAKSQwlEKr3sUQwyXczlNaUo3ulGDGnzGZ6xiFa/yKqmkEkEEMcTQiU4MZjCzmY2DA0AggXl1uXDlbT9ZOeTgwpX33Iu3yHWLjq3bfdyvuMdnH+Uqrn+d6UxHOhJHHCtYkRfkyhVGGJlkMpe5NKEJ0RS+zgMYQDbZ9KMff+Nv7GSnz2twovEoqv8iIiJ/JpoiJyIiIlKGpWVmMycxqeDGxCicv/2blA3NqZ/ZmMMc5n3eJ5ZYAHrQg5d4iUwy8eLldm5nFKMK1V2PetSkJq/yKt3pTg968DEfs5/9tKY13/M9ySTzBE8QTTTxxJNBBjnkFNtnN+4iA0Vu3GS7sgG4mquZylSyyMKLl5d5mW50K3RMT3ryJm/ixctBDpbK3dna0IZ7uIfqVC/yjnQxxDCSkXSnO81pXug6L2YxYxlLf/oDNiUv99ocew1OdjxERET+zBRgEhERESnD9iSnk3QotcA218Yo+Osekjc0YU9yOt3oRl3qEkwwAGMYQwghRBBBS1ri4DCZyT7rjyGG3/iNCCJoSEMCCcybgtaKVlzDNTSnOS1owTzm0ZKWbGd7sX1uT3t+5Me8QMyxetKTj2t+zFM8xaM8Sh3qEE44LWhBFlk8z/OFjhnHuLw1oaKJJoywk7p2J+LCxVu8xSu8wnKWFyqPIYatbM0Leh1/nccznhhiCCMsb5H03GvTm96MYhTTmX5K4yEiIvJn5XIc59RylU+zjIwMEhMTCQ0NpWLFwvPdzzUej4eoqKiz3Q0pBRrL8kNjWb5oPMuPc3Us0zKzCZs4lx0HUwuVhdQIYuND0VQOKFurIpyrY1keaSzLD41l+VGWxlLxgbJFGUwiIiIiZVjlADe9Q4N9lvUOrVfmgksiIiJSNuk3DhEREZEyblK0fRM9N3EXSYdSCK4eRO/QennbRURERE43BZhEREREyji3vx/P9rmEJ3tFsCc5nbrVApW5JCIiImeUfvMQERERKScqB7hpVLPq2e6GiIiInIO0BpOIiIiIiIiIiJSIAkwiIiIiIiIiIlIiCjCJiIiIiIiIiEiJKMAkIiIiIiIiIiIlogCTiIiIiIiIiIiUiAJMIiIiIiIiIiJSIgowiYiIiIiIiIhIiSjAJCIiIiIiIiIiJaIAk4iIiIiIiIiIlIgCTCIiIiIiIiIiUiIKMImIiIiIiIiISIkowCQiIiIiIiIiIiWiAJOIiIiIiIiIiJSIAkwiIiIiIiIiIlIiCjCJiIiIiIiIiEiJKMAkIiIiIiIiIiIlogCTiIiIiIiIiIiUiAJMIiIiIiIiIiJSIgowiYiIiIiIiIhIiSjAJCIiIiIiIiIiJaIAk4iIiIiIiIiIlIgCTCIiIiIiIiIiUiIKMImIiIiIiIiISIkowCQiIiIiIiIiIiWiAJOIiIiIiIiIiJSIAkwiIiIiIiIiIlIiCjCJiIiIiMiZtWYNhIQU3r5jBwQFlV478fEQGlp69YmISJEUYBIRERERERERkRIp9QBTnz59GDhwIAMHDmTUqFH8/PPPDBgwgBtvvJHHHnsMr9db2k2KiIiIiMixwsNh2TJ7PHMmVKoE6en2fMgQmDoVMjNh2DCIjITWrSEuDpKTC9c1bhz06AFhYXDzzbbtySftuPBw6NMHdu+27StWwOWXQ7t2UL8+DR5/PL+eqVOhaVO45BJ45ZWi++71Wh8jIqBtW6sTICsLhg6Fli2tL0OGwJEjVrZpE1xxBbRqZefyzjuF6/3qK6hfH5YvP6lLKCIip6ZUA0wZGRkAvPvuu7z77rs89dRTPPXUU9x///3MmDEDx3FYlvuDTkRERORsuOce+8B8vHHjrKy0xMXBM8+UXn0ipyI2FhYutMeLFkGNGpCQAI4DCxZATAxMmABuN3g8sH49XHABjBzpu76ff4a1a+G99yx4s3EjrFoF69ZBr14W7AF4/nl4/HFYuRI2b+a8L7+0+tets9fYl1/C6tUQEFB039PToVs3a++JJ+D66y0Y9sQTFshav97+er0wYgRkZ0Pv3hZ82rDBznv0aPjmm/w6P//cXpPz50OHDiW/viIiUoi7NCvbunUr6enpDB48mOzsbIYPH86mTZto27YtAJdffjlff/013bp1K81mRURERETkd2mZ2ezv0p0L77wNv0mTLLA0fDgsWQJVq0KjRlCnjgVbDh2y7WBBnNq1fVfavr0Fo8COW7UK2rSx5zk5kJZmj6dPtwDW+PGwdSt+GRmQkmJrLnXvbu0C/P3vFvjypXp16N/fHnfvbv9u3WqBoyefhAoVbNvQoZY9tW0bHD1qQTWwQNl111n9V1wBu3bBNdfAXXdZhpOIiJwWpRpgqlSpErfddhvXX389O3bs4Pbbb8dxHFwuFwBVqlThSG4a6wkkJiaWZtfKNI/Hc7a7IKVEY1l+aCzLl3NxPFvceCO77r+fI23bUmPRIkIef5x1//0vTqVKNPjnP0lt0YL9117LhS+8QNVvvwWvl7RmzUh68EG8xy/Am51NvRde4LyvvsLx9ye1VSt2jhyJf3IyDcaPx33gABX27yezTh1+nDCB7L/8hdDoaPZfcw1VV68m4H//48Df/sbuu+4q1M/Q6GhSQ0MJ/P57dt99N6kXX0zwxIkE/O9/uLKzOdi9O/8bPBiAOm+9Reqtt+LKyMA/PZ1d99/PoSuuwC8lhQZPPEHlbdvIqlkTx+0mpXVr9hw37nV37yZo3TpckZG4Dx8mrVkzdo4cibdKFSr98AP1J07E//BhcLnYe9NNHLjmGgBq/uc/1P7gAxx/f7L/8hd2PvQQGQ0a0GD/fo7u2sVej4d6kycTuH07P0yejLdy5dMzqOXMufi6LKlsr8ML3+7li1+S2Zuazba9+/nk/8YyuPZf2XXRRVz0xhsc3reP7Hbt+NXjofmRI+y+5x6SO3YEwC8tDVdmJjk+XhvutDSSft9+0b59JA8YwL6+fQFwZWbin5xMtsdDs7g40ps0IfnSS0mPjaXxF1+wfetWKu/aReX9+9nxex2B339Po8xMEo9rK2D3blo4DuuP2R6WkcH327YRcuQIv3z/PUf+8hcAKm/ZQqO0NL7fuJEm2dlsPOaY4P/9j5wjR0j+7jsaAdtffJFGDzzA9rAw0rTo9x+m12X5obGU08IpRRkZGU56enre8+uuu85p3rx53vMlS5Y4//jHP4qt4+jRo86aNWuco0ePlmbXyqw1a9ac7S5IKdFYlh8ay/LlnB3Pf/zDcR54wB7fcovj1KnjOIsXO47X6zh16zrOnj22z4MP2jbHcZxRoxznrrsK1/X8845z+eWOk5bmODk5jtOvn+O8847jPPec40yYYPt4vY7Ts6fjPPOMPW/QIL/9Xbscp1Ilx/nxx8J1N2jgOI8/nv/8iiscZ+5ce5yebs8//NBxduxwDrdpY31wHMeZOdNxQkPt8f332zl6vY7z66+OU6+e4zz2WOG2HnvMcerXt328Xse56SbHeeghx8nKcpyLLnKcjz+2/X75xXEuvNBxli93nGXLHKdRIzvGcRzn7bcdp0ULO/7WWx1n4kTHuftux4mJcRz9bnPSztnXZQnd/8kqx2/4O3l/J7bp5Wz+S11ndtx9tkODBo4THOw4O3fa81GjHKdXL8fJyLDX7g03OM6QIYUrfuwx+3+c67XXHCcy0nEOH7bnDz3kOFdd5TgHDzqOn5/jHDhg2z//3PH6+TnO0qWOs2GD49Sq5ThJSVY2bJj153g//eQ44Djz5tnzuXPtNZaV5TijRztObKzjZGZafwcNstd2ZqbjhIQUfI3Wres4//2v43z+ueNcfLFtnzbNcZo0cZzU1D9wdUWvy/KjLI2l4gNlS6muwTRr1iwmTJgAwN69e0lJSaFjx46sXLkSgC+//JI2uam0IiIiclakZWaT1KU73gULbT2WY6fPrFhRcPrMnDm20G54OMyeDZs3F65w6VIYOBACA8HPDz780J7fd5+tdTJlCvzf/0Fiok2VyXXttfbvhRfatJwDB3x3uFMn+zc1Fb74AsaMsf60bw87d9raLg0asOMf/4D337c1ZF59Nb+tpUvhllvA5YJatWztmaLExto+LhcMGmTXpLjpN4sW2VSeWrWsLC4OfvnFbrUOdu5Tp8I//gEVK55oaET+sLTMbOYkJhXYNrtxFC0O7OG1Kg1Iy8y2dY3q1oXgYNthzBgICbHXeMuW9n4wefKJGxsyxKactW8PF19s6x5Nm2ZT20aNssW/Q0NhwgRSWreG7dttUe6JE6FrV5tad/Ro0fXXrg0ff2yv86eessduNzz6qL03hYdDixa26Pfzz9uUudmz7XGrVnDVVTB2rE2PO9att0Lz5vDAAyd9XUVE5OSV6hS5vn37MmrUKAYMGIDL5WL8+PHUqFGDMWPGMGXKFC666CJ69OhRmk2KiIjIScrO8TJinoe5iUnsPJTK93sPsGz0ZAY1boxfdLQFStxu+H3aCzk59oGtZ097npLi+0Oh220BmVx799riu889Z+u0DB5sH/SysuwDbK7AwPzHLlfBsmPlTsnLybF9li+H3Glm+/bZ3bG+/ZbmgwfDQw/Zmi2dO9t6K7mOrdtdzK8//v75j71e++Cak1Pw/HLLsrKs7PjFih3HysD60bGjBZ5WrMhfO0aklO1JTifpUGqBbSsuaIL/8Hfwd1l5ozfeKHhQYCC8/PKJKz9+UXw/Pwua/uMfhfd94gn7+7ttHg9RUVH2JC7O/hYnJMTeQ3wprr+tW1sA+nhdulhwO9fcucW3LyIif1ipZjAFBAQwefJkZs6cyYwZM4iMjKRhw4a89957fPjhhzz11FP4H/uLm4iIiJwxI+Z5eCFhKzsOpuJ14KOLIunw+hTmXdjSvtU/fNgygHIzdXr0gJdesoV/vV64/XbLTjjeVVfBjBmQkWH73XWX3RZ98WK4/37LZqpd27KBcnL++AlUq2YZE1Om2PNDhyx4M2cOfPklqS1aWCZW586WzZDbVs+e8Oab1reDB23/osyda/vk5MAbb9ixzZtbYOg//7F9du+2jIpu3eDqq+GDD+C336zs7bfh/POhcWN73qaN3ZmuenXfd64TKSV1qwVSv3oVn2XB1YOoWy3QZ5mIiEhpKdUAk4iIiPw5ndbpM3fcAVFR9jcszOq4916bovLggzZlpXdvuOwymypTEjNmWCZQWBi0awcDBsBNN8GAAbgPHbJpMy1bWtbTgQNw5IgFdipUsEBRdLQdW5SWLW3qT1iYBYVGjix++k23bjBsGFx5pU0Vmj7dphb6HfMrlssFb70Fr7xi2Vcip0HlADe9Q4N9lvUOrUflgFKduCAiIlKIy3GKykc/OzIyMkhMTCQ0NJSKWqsAz7FpxVKmaSzLD41l+XKujOcP+47QfMJsvD5+6vu7YMvIPjSqWfXMd6wUnStjeS7QWP4x+dNgd5F0KIXg6kH0Dq3HpOgo3P5n53tljWX5obEsP8rSWCo+ULboqwwREZFzQO70mR0HUwuVafqMSPng9vfj2T6X8GSvCPYkp1O3WqAyl0RE5IzRFDkREZFzgKbPiJw7Kge4aVSzql7XIiJyRumnjoiIyDliUrSlw/uaPiMiIiIiUhIKMImIiJwjNH1GRERERE4X/VYpIiJyjsmdPiMiIiIiUlq0BpOIiIiIiIiIiJSIAkwiIiIiIiJydq1eDXfe6bvsX/+CV145s/3xZc0aCAkpvH3HDggKKr124uMhNLT06hM5QxRgEhERERERkbNr0ybYtct32VdfQVrame2PiJwyBZhERERERETKs/BwWLbMHs+cCZUqQXq6PR8yBKZOhcxMGDYMIiOhdWuIi4Pk5IL17N9vmTqpqfb8jjugc+f88iZNYMsWmD8fOnSANm2gfn0YM8bK4+OhY0cYOBAiIixL5+uvISkJxo6FhAQYNKhgm598AnPnwrPPwssvQ1YWDB0KLVtCWJj1/8iRwuc8bhz06GH73HyzbXvySTu/8HDo0wd277btK1bA5ZdDu3bW39tuy69n6lRo2hQuuaT4LCqv1/oSEQFt21qdUHx/N22CK66AVq3smr/zTuF6v/rK+rR8edFti/xJKMAkIiIiIiJSnsXGwsKF9njRIqhRw4I5jgMLFkBMDEyYAG43eDywfj1ccAGMHFmwnvPPt+DJ55/b8/h4+O47SEmBzZuhQgVo3hwmT4bp021K2YoV8NRTsG+fHbNyJTzwAKxda8Gk0aMhOBgefxw6dYK33y7YZkwM9O5twa+774YnnrDA0Pr19tfrhREjfJ/3zz9bO++9Z8GbjRth1SpYtw569bJgD8Dzz1v7K1faecyda9dh3ToLVH35pU3hCwgo+hqnp0O3btbeE0/A9ddb0K6o/mZn23kNHQobNtj4jB4N33yTX+fnn1ugLzdgJ/Inp7vIiYiIiIiIlFNpmdns79KdC++8Db9JkyywNHw4LFkCVatCo0ZQp44FMQ4dsu1gwZHatQtXGBNjwZBGjeDCCy0L6YsvLEhy3XXgcsG8eVbfjBmW0eQ4+VlPDRpYBhFYNtG0aad2QgsXWiZShQr2fOhQy0bypX17C5qB9WfVKsuqAsjJyZ92N326BdrGj4etWy1YlJJiAbLu3e36APz97xag86V6dejf3x53727/bt1adH+3bYOjRy34BxbQu+46q/+KK2y64DXXwF13WYaTSBmgAJOIiIiIiEg5k53jZcQ8D3MTk9h5KJXv9x5g2ejJDGrcGL/oaAuGuN3Qt68dkJNjmTw9e9rzlBQLgBwvJsamkzVtahk7NWrAZ59Z8ObVVy2QFBFh+3XqBIMHw+zZFmQCCAzMr8vlyt9+snJy7LhcXq9NQ/Pl2IW3c3Lg4YctYAOQkQEHD9rjyy+3IM7VV0O/fpbJlNuvY/vnLubjs79/wederwWViurv8duPPxe324Je115r2VDt2hXdtsifhKbIiYiIiIiIlDMj5nl4IWErOw6m4nXgo4si6fD6FOZd2NKmsR0+DO+/n59B06MHvPSSZS55vXD77TBqVOGK69WDmjUtmNS9ux338ce2PlPr1vD997Z20xNPQHS0TaPLyLCASnHc7qIDRceWXX21rYuUlWX9fPllC3SdSI8edje63HWlxo61taAOHbLpb08/bddi1y7Yvt362727Bc9yFx8vLttq/37LkgLL4AoMtDWpiupv8+YWgPrPf+yY3bvtOuaeS506Ni3umWesn1rkXMoABZhERERERETKkbTMbOYkJhXYNrtxFC0O7OG1Kg1Iy8y2QEbdurb+EdhC3CEhln3UsqVl7kye7LuBmBj47Tfbt2FDC6bExFhZq1Y2tat5c2jRwoItLVta0KY47dvDjz/mB7yO1bOnBbSeegoefdSCL+HhVn9WlmVenciQIdav9u3h4ottSt+0aTa1bdQom64XGmprUXXsaP0NC4OJE6FrV5ta5yujK1ft2hYgCg+3fn78sQXGiupvhQqW2fX883bNrrrKgl5XXFGw3ltvtWv5wAMnPkeRs8zlOKeak3h6ZWRkkJiYSGhoKBUrVjzb3TnrPB4PUVFRZ7sbUgo0luWHxrJ80XiWHxrL8kNjWX5oLM+OH/YdofmE2Xh9fNLzd8GWkX1oVLPqKdWpsSw/ytJYKj5QtiiDSUREREREpBypWy2Q+tWr+CwLrh5E3WqBPstEREpCASYREREREZFypHKAm96hwT7LeofWo3KA7vUkIqVP7ywiIiIiIiLlzKRomwI1N3EXSYdSCK4eRO/QennbRURKmwJMIiIiIiIi5Yzb349n+1zCk70i2JOcTt1qgcpcEpHTSu8wIiIiIiIi5VTlAPcpL+gtIvJHaA0mEREREREREREpEQWYRERERERERESkRBRgEhERERERERGRElGASURERERERERESkQBJhERERERERERKREFmEREREREREREpEQUYBIRERERERERkRJRgElEREREREREREpEASYRERERERERESkRBZhERERERERERKREFGASEREREQG45x4YN+5s90JERKRMUoBJRERERERERERKRAEmEREREckXHg7LltnjmTOhUiVIT7fnQ4bA1KmQmQnDhkFkJLRuDXFxkJxcuK7sbBg+HJo2hZYt7fjMTNi7F/r0gUsvhYYNoUsX+PVXOyYkhLqvvQadOkGDBjBmjO9+hoRA//7QogV88gn88gvExEBUFLRqBePH5+87fjy0a2fbGzWy/cH63K8fNGtmfdi61Xdb48bZOfboAc2bQ9eusGePlRXVbp8+8Oab9vibb8Dlgh9/tOdPPAEPP2ztdexox0ZGwiuv5Ld3883QubNdu3798q/v/PnQoQO0aQP16+dfn/h4O8d+/awf7drBli1WVtx4HX8dRUTOltWr4c47fRb5vfVW/nvk2bRmjb1vik8KMImIiIhIvthYWLjQHi9aBDVqQEICOA4sWGDBlAkTwO0GjwfWr4cLLoCRIwvX9cor+fskJsKRI/Dhh/DBBxZc+uYbC7pUrgzvvpt3mF96urW5fDk88wz89JPvvoaGWhAlJgYGDoTBg629Vatg6VL497/h55/tcXw8bNgATz4JY8fa8Y89BoGBFuj56CP47ruir0tCgu2zdStUqQKvvmrbi2r3+OtYp46VAcydC9ddB5MmQXS0HbtgAXz5JXi9ts8XX1g9W7fatX78cRuDyZNh+nT7kLNiBTz1FOzbZ8esWQNDh9p5DhpkfYMTj9ex11FE5GzZtAl27fJZ5Ld8OaSlneEOyalSgElEREREAEjLzCapS3e8CxZaMCMhwTKQliyxYEajRhYomT8f5syBiAjLeJo9GzZvLlzh0qUW5AgMBD8/Cy4NHAj33WdZOFOmwP/9nwWfUlLyDjvcubM9uPBCqF0bDhzw3eFOnezf1FQLyIwZY/1p3x527oR16ywL6p134P33Lajy6qv5bS1dCrfcYtlFtWoVH2Dp0gWqVbPHERHWp+LajY62oFZ2NixeDI8+atdx927L1rrkEmtv4kQLRv3nP/DCC3adAK6/Hv76V3t+221Wh8sF8+ZZoOgf/7CxcRzrB1h2Uu41GTwY1q6F/ftPPF65x4hI+XVMdmqNRYv+eHbq/v0QFJT/vnPHHZZtmatJEwtYF5dt2bGj/SyIiLAA99dfQ1KSBf8TEixAfozqn3+O36efwrPPwssvQ1aWBdNbtoSwMOv/kSOFz3ncOMs8DQuzrFCwLxkiI+169Olj78lgP+Muv9yyP+vXt/fdXFOnWjbpJZcUnUW1Y4f9jBw6FNq2tetwbFaor3Znzy74/tusmX3xARZou+ACG5O77rLM1Kgo+9mQkmLtNWhg1z883MYrIcGOPUGWMKNG2bg0bmznlmvePDv/iAgbo2++Kfo6FkEBJhEREZFzXHaOl2GzVxM2cS4Xzf2enXsP8OboyXgbN7ZAyWefWdZN3752QE4OPP+8BVLWrbPMnVmzClfsdltQJNfevTa17OGH7YNErVrw979D9+4WKPmdt2LF/GNcrgJlBQQF5ffHcSzjKbdPK1bA6NHw7bf2S3ZysrXz8MMF6zv2sdtd9EUKDCzcp+LarVHDfumfN8/avuUW++V/9mwLLLlccM018P33Nq1t7Vr75T332/tj++L1gr+/faCLiLBzioy0DKgKFfLP4dhjcrf5+594vHKvo4iUX8dkVZ73zTd/PDv1/PMtgPL55/Y8Pt6yP1NSLHBdoYJNJS4u23LlSnjgAXvfGzTI3jODgy1Ts1MnePvtAk0euuIKvH/7mwW/7r7bphnv3m19XL/e3iNHjPB93j//bO2895592bBxo70HrlsHvXpZcArsPfLxx61vmzfbzzyPx/YbN84yTFevhoCAoq/xjz9aIGbVKruW999v24tqt0cPyzg9dMgCRsnJ9kUEWPt9+lh/4uPtPD0euOgiOwbsC43Ona3OCRNsunNW1gmzhDlwwM4lPt5+Fm/caD+LRo+2/wtr18Lrr9v/mdxA4rHXsRgKMImIiIic40bM8/BCwlZ2HEzF68BHF0XS4fUpzLuwpX1QOHzYMoBiY+2AHj3gpZfsm1WvF26/3b4RPd5VV8GMGZCRYfvddZet67R4sf3iPXCgZSgtWWJBkD+qWjXLHpoyxZ4fOmTfvs6ZYx8K2rSxbJ/OnS3Ak9tWz562TpLXCwcP2v6l1S7Y9Ro92tZsqlrVvgGfMMGmxwHceKNldd1wg30rXq0a/PCDlc2ZY9fd64U33rBA3/ff2weQJ57Iz5DKyMg/n3Xr8j94vP66ZQ9Ur37y4yUi5dLx2alB69aVLDs1JsaCVVu2WKZpx46WzTlnjr2/nSjbskEDqx8sWF5UlmpRFi60tZoqVLAsz6FD86ckH699+/zg+/z5dr5t2lj7L76YPzV6+nR7Dx8/3jJr09MtaLZsmX05UaeO7ff3vxfdrwoVLHh0/HkV1W5goP2cXLLE+n/HHTYl/PDh/GsZFmZfFLRrZ1lg111n7+1gQcIbb7THPXvafhs2nDBLmLvvtjGqVw+uvtq+RFqyxL4A6trV+njTTXZtt28vfB2LoQCTiLCGNfSl7xlr7zCHuZIrfZatZjV34ntxv5M1i1l0oYvPsrGM5R3eKfb4aUzjGq4pUR9O5FM+ZSxjT2sbIiInIy0zmzmJSQW2zW4cRYsDe3itSgPSMrOhWzeoW9e+YQb7JTckxD6EtGyZvzbQ8e64w1L6o6Lsl+S6deHee+0b0wcftJT/3r3hssvyf4n9o2bMsF/gw8LsF/EBA+wX5AED7FvzFi2sr0FB9kv/kSP2rXTut+3R0XZsabUL9u3zd9/Z9QML9GRl5X84GDPGAnetW9uxMTE2RQNselyvXtbv886zQFWrVpb11Ly5bZ83z84p99rVqQOPPGJ9mT07/xvrkx0vESlXispOTa8XXLLs1NwA02ef2ftbt24F6zpRtqWvjNBTkZNTMDvW67X3Vl+OzdDMybEs1tzzW7PGpueBvfcuWGDvr2PHWuAst18nm+kaEJA/zfnY8yqu3ZgYa/ezz+xnRO4XIYmJNrWtenXLXnrmGQsg9e+fP03v+L7kZrueIEvYZ4ZsTo4Fl3L7mJuRGxpa+DoW48QhKBEp99rQhln4+OFxmhzkIKtY5bNsE5vYhe/F/UrD4zx+2uo+FatZzQFO8dsaEZHTYE9yOkmHUgtsW3FBE/yHv4O/y8obvfFGwYMCA20djBPx97c1hiZOLLg9NjY/G+p4O3aQ5vEUeF7UfgWEhNi3xMf761/z16XIdWxw5Z3iv3QALBBV1POi2gWbXpK7aDdY8OeRR/Kft2iR/yHjeK1aWdbR8XLvTHe8+HjLgJo3r3BZceNV1PUVkTIvNzs110cXRXLN61P49Iqe3HRsdmru+1ButmPXrhaEuP12Cywc/zOgXj2oWdPWtHvvPfjLXyyzsnJlC5ivW5efbRkQYMHuY7Mti+J2Fx0oOrbs6qtt7aDOne3nzMsv5wfyi9OjB7z2mn0JUK2aBWG+/dZu4LB6tQXNatSw99Pt262/3bvD00/b9OV69WDatBO3c7LtLlligb7Ro+082ra19saMyc9Imj/fgktLl1oQzHGsr716wW+/2U0krr7a3vsrVLAvGOLiLHPs2mvtTqdLltg07VzvvGPZtDt3WmBr7Fg717Fj7cYSzZtb0Oumm2xtrFOgDCYRIZ54QgkttD2ccJZhiwHOZCaVqEQ6thjgEIYwlalsYxvd6EZ72tOABlzLtRzlKACVqMQ4xtGBDjSkIVOxReQGMYh00gknnBzyf9AkkcRYxpJAAoOwxf1e53VCCaU1relOd7axzec5jGUsjWhEW9ryCfkL6sURR296czEX8zAPE0ccz/BMsf071ixm0YhGfEfBOwvdz/2MwRYr3MMeXLj4HJuL/h7v0Z/+pJLKLdzCpVxKU5oSRRTf8R0rWcmrvMqHfMgj2AeNN3mTKKKIIIKruIqtbPXZfxGR0la3WiD1q1fxWRZcPYi61QJ9lomIyJ9Xcdmp085vWrLsVLDMm99+s30bNrRAdu6NEk6UbVmU9u1tzSAfX0B4e/SwgNZTT9lNE+rUsalcLVpY4On55098UYYMsX61bw8XX2zTyaZNsyyhUaMs2yo01IIvHTtaf8PC7EuSrl1titvRoydu52TbBctQbdHCrqO/vwWjkpLyp1L37GnHhIZa+8uX5y8EXqmSBe9at7ZFxGfPtjpOlCX800+WWXz11XZziWbNbHxef92mbLdubf8X5s495TX6XI5zqvlop1dGRgaJiYmEhoZS8dgFHs9RHo+HqKios90NKQV/5rGMJ557uIdEEgtsf5zHSSaZZ3iGW7mVz/iM6UynG924kAv5lm+ZzGRa05qbuZkssogiisd4jOu4DhcuXuRF7uEePHjoSEcOcYj/8T9CCSWFlEJ9mcY0ZjGL+cznv/yXv/N3vuEbalGLaUxjIhPZxCZc5KfFzmEOoxnNClYQSCB96EMKKcQTTxxx7GIXS7FbQ8cRRyihPMiDRfbvAz5gFrO4iZt4kidZyEKCCc5rz+PxkBqVynCGs4Y1vM3bjGY0gxjEeMbTj370pS9++PElX/ICLwBwJ3dSgQq8yIuMYxz72MdLvMQXfMEYxrCIRVSmMp/xGfdxH1vYUqj/Uvr+zK9NOTUayz9u2OzVBb7lznVvp+Y82+eSM94fjWX5obEsPzSWZcsP+47QfMJsvD4+7fsBW0f1oVHNqme8X6dK8YEi7NhhQaeUwp+nihUSYtMe27Q5Hb1SBpPIuS4tM5tfDqcVyODPFUMMC1mIg0MCCQxnOEtYwgpW0IhG1KEOT/M0tajFRCZyF3exm90FAkfXci0AkUSSQQappBZuqAiLWER/+lOLWoAFh37hF3awo8B+S1lKLLFUpSpu3AxmcIHyy7isyDaK6t9qVjOQgdzJnQWCS8fWuYtd7GUvi1jEozzKEpaQSSZf8AW96EVf+hJHHC/yIvdxH/HE+wyqfcqnbGc7HehAOOE8xEMc5GDeFLri+i8iUhomRUdxb6fmhNQIwt8FITWCuLdTcyZF68OkiEhZVFx26l+ruJWdKqeF1mASOUdl53gZMc/D3MQkdpy/Bv/rkhm2fDWToqNw+1vsOYwwMslkLnNpQhOiiaY//XHjzlsUfAADyCabfvTjb/yNnezEIf+rkkDsh1duxtGxZSeSQw4BFLwVqINDFoXnZh9br/u4t7Ygik7tLKp/1anOTGbSj35cwzWEEFLgOD/8uIZrWMACVrKSd3mXp3iKj/iIDnQgiCCmMpXXeZ17uIcbuZG/8Bd+4ief5zmQgTzN0wB48bKb3dSgxgn7LyJSGtz+fjzb5xKe7BXBnuR06lYLpHKAfk0UESmrKge46R0a7DM7tfOF1fQeX9aFhJx69hKc9nX3lMEkco469pbUjgNZOV5eSNjKiHmeAvvFEMNIRtKd7jSnOYc5zPu8Tyw2N3oxixnLWPrTH4CVrCywrpIvbtzkkOMz2OTGnRdAupqr+YAP+I3fAHibtzmf82lM4wLH9KQnH/ERhziEFy/v8u4fuyjHaEITruRKhjKUW7gFL4VTvGKJZSITCSOMAAK4kisZxSiuw+ZML2YxccRxG7fRjGbMY17etTn2PHvQg5nMZA97AHiVV+lK1xKfg4jIqaoc4KZRzar64CEiUg4UlZ16b+Rfz3bXpJxSgEnkHORr0b9ccxN32aJ/v4shhq1spRt2Z4ZudKMudfOmjY1nPDHEEEYYd3AHnenMdopfwK8udWlLWy7mYvazv0BZe9rzIz8SSyzd6MYwhnElV3IxFzOd6cxnPn7HvXX1oheDGUwb2tCOdpzHead8TYryCI+QSiqTmFSo7CquYje7865ND3qwl71EEw3AgzzIa7xGK1rRiU5EEpl3ba7kShazmKEMpTvdeZiH6UY3WtGKGczgP/ynwDpTIiIiIiKnIjc7deND0WwZ2YeND0XzbJ9LcPvpd0w5PbTI95+cFtMrP/5MY1ncon/+Ltgysmws+ne2/JnGUkpO41l+aCzLD41l+aGxLD80luVHWRpLxQfKFmUwiZyDdEtqERERERERKU0KMImcg3IX/fOld2g9rb0hIiIiIiIip0SfIkXOUbm3np6buIukQykEVw+id2g93ZJaRERERERETpkCTCLnKN2SWkREREREREqLPk2KnONyb0ktIiIiIiIi8kdpDSYRERERERERESkRBZhERERERERERKREFGASEREREREREZESUYBJRERERERERERKRAEmEREREREREREpEQWYRERERERERESkRBRgEhERERERERGRElGASUREREREzh1r1kBIyNnuhYhIuaMAk4iIiIiIiIiIlIgCTCIiIiIiUnrCw2HZMgBqLFoElSpBerqVDRkCU6dCZiYMGwaRkdC6NcTFQXJy4brGjYMePSAsDG6+2bY9+aQdFx4OffrA7t22fcUKuPxyaNcO6teH227Lr2fqVGjaFC65BF55xXe/d+yARo1g6FBo2xaaNIFPPskv99Xu7NnQqVP+Ps2awWOP2eNdu+CCC+xc77oLWrWCqCi4/npISbH2GjSAO+6wOlu3hoQEO3bvXmvj0kuhYUPo0gV+/dXKQkJg1Cho0wYaN7ZzyzVvnp1/RAR07AjffFP0dRQRKWUKMImIiIiISOmJjYWFCwE475tvoEYNC5w4DixYADExMGECuN3g8cD69RaIGTnSd30//wxr18J778E778DGjbBqFaxbB716WdAK4Pnn4fHHYeVK2LwZ5s61+tetswDLl1/C6tUQEFB033/80QIxq1ZZH++/37YX1W6PHrBhAxw6ZAGj5GRYssSOmTvXgkQrV0J8vJ2nxwMXXWTHAOzcCZ07W50TJkD//pCVBR98YMGlb76xPlWuDO++m9/PAwfsXOLjYexY69v338Po0XaN166F11+3sUhNLXwdRUROA/fZ7oCIiIiIiJQPaZnZ7O/SnQvvvA2/SZMIWrcOhg+3oEvVqpYhVKcOzJ9vQZncYExmJtSu7bvS9u0tGAV23KpVlr0DkJMDaWn2ePp0C66MHw9bt1rWVEqKrbnUvbu1C/D3v8OiRb7bqlDBgkdg2UoHDhTfbmAgXHWVnce+fZaN9NprcPgwzJkDDz1kWUP+/pZZ1KMHXHedZUjt2GHBtxtvtDp79rT9NmyA++6zoNyUKRY4Sky043PdfTe4XFCvHlx9NXz2mfVlzx7o2jV/Pz8/2L698HUUETkN9A4jIiIiIiIlkp3jZcQ8D3MTk9h5KJXv9x5g2ejJXFcvmIrR0ZaZ43ZD3752QE6OZRz17GnPU1Lg6FHflQcF5T/OyYGHH7YpZwAZGXDwoD2+/HKbhnb11dCvn2UOOY6V5f4LxQdZAgIsKAMWwMk9rrh2Y2IssHXokAWUtm61qXOJiTa1zd/fspe+/hr++1+7FiNGWCDr+L54vbb/ww9bQGvwYLjiCstqKuocco/JybHg0ocf5pclJVl22CefFLyOIiKngabIiYiIiIhIiYyY5+GFhK3sOJiK14GPLoqkw+tT+LReS2je3DJ63n/fpmyBZfK89JJlLnm9cPvttq7QifToAf/6V/56TWPHwsCBFtxZvRqeftra2LXLMndycix76bPPbBvAtGmnfoJFtQsQHW1rTq1bZ5lJ3bvDmDH5GUnz51vgp0MHm6p3yy3WV4DffsvPppo3zzKowsJg8WKbnjdwoGV2LVli55LrnXfs35077dx69rQ2PvvMAlxgQa9WrfLXvxIROc2UwSQiIiIiIn9YWmY2cxKTCmyb3TiKEWsWcO/5TYnJzKZyt2429Ss42HYYMwYefNAWo87JsUWuJ08+cWNDhsAvv9h0L5fLFvOeNg2qV7cAVWQkVKliU8c6drQgU9euMHGi/Vu1qgWBTlVR7QKcdx60aGHt+vtbMOq222wqHFjwZ+FCCA21LKIaNeCNN6ysUiVbW+nhh22K2+zZVsfYsXZ9xoyxoNNll+VPdQP46SdbMDw9HV54wRYXB1t36YYbLNvJ7bZ1oJS5JCJniMtxjs21PPsyMjJITEwkNDSUihUrnu3unHUej4eoqKiz3Q0pBRrL8kNj6cOaNbY46axZZ6a9w4dtSsJ//1u4bPVqePNNePXVk6rqtI5nUJBNkQgJKbg9JMSuVe5aHiXlctm34DVrlk59ZZRem+WHxrJs+WHfEZpPmI3Xx6cKP2DrqD40qln1jPfrT2/HDgs6paSc2nGl/TPkJOl1WX6UpbFUfKBs0RQ5EREpuTZtzlxwCWzdi1WrfJdt2pQ/DUJERE67utUCqV+9is+yv1ZxU7da4BnukYiInA0KMImISMnFx9u3sMcLD7d1KQBmzrSpALlrQQwZAlOnwrZt0K2bTTto0ACuvTZ/oddKlWy9ig4doGFD2x9g0CCrJzy84JoUSUk2rSAhwfYBmy4QGgqtW9u6GNu2+e5/69bWTqtWtnjrvHl2x56ICJtm8c03tu/evXbb6UsvtT516QK//mplCQnWp4gIu0uR11v0NXv5ZZvKcfHF8NZb+duL6u/hw3DzzVYWFmYLyWZnF6zzf/+z8pdfLrpdEZFSVjnATe/QYJ9lnS+sRuUArcrhU0jIqWcvgWU+neHsJRGRk6EAk4iInD6xsbbuBNgipjVqWBDGcWzx0ZgYW4fi1lthxQpbX+Knn+DTT+2YjAyb9rV8uWVIDRtmwae337a1Ktats7UqcgUHw+OPQ6dOts9//2vrbnz+ud3B58YbLTjka3Z4YqIFwTZssEVTR4+2Pq5da0Gf2FhITYUPPrDg0jffwI8/QuXKtn5GZiZcf72tIbJ2rd31p7iFVQMD4dtvbeHWUaMs86q4/t57L5x/PmzcaFMS16+HZ57Jr2/XLltfZNQou321iMgZNCk6ins7NSekRhD+LgipEcS9nZpzb+Rfz3bXRETkDFGASURESiQtM5tfDqf5XHuDmBgLMDmOBZaGD7eAyooV0KgR1Kljd/ypVcsCK3fdBbt3F/xG99pr7d/ISAs4paaefOcWLbLbQdeqZc/j4myR1h07Cu8bHGwZVGB93LPHAjbh4XDTTXbb6u3b4b77LNNpyhT4v/+zwFRKigV+KlSwYwAGDLDFZItyxx327wUXWKbSsmXF93fhQrjnHltvqWJFuPPO/OAd2O2uq1SxoJSIyBnm9vfj2T6XsPGhaLaM7MPGh6J5ts8luP1cZ7trIiJyhihfVURE/pDsHC8j5nmYm5hEyMY1TN2XzNTZq5kUHYXb//fvL8LCLLNn7lxo0sRu5dy/v93Zpm9f22fAAJvq1a8f/O1vlj10bIZR4O9rd7h+/5ByKvemyMmBgICC2xwHsrIK73vsXXZycixQ9OGH+duSkiwY9PDDtv7T4MGWpZSVld+n4/vmLubH7LGZV16vBaeK66/Xm38Nco859jxeew2efNICXw88UHS7IiKnUeUAtxb0FhE5RymDSURE/pAR8zy8kLCVHQdTcRzIzPHyQsJWRszzFNwxJgZGjrQsnebNbS2h99+3KWcAixfbukn9+9vzlSsLrqvki9tt+/gKNrnd+YGXq6+2KW2//WbP337bppk1blx8/V27wmefwdat9nzBAlubKT3d+nv//TBwINSubdlOOTlWnjv1DyyodvBg0W3k3t56505YutTaLK6/PXrASy9ZGxkZNm2vW7f8+i69FKZPhyeesKwqEREREZEzSBlMIiJyytIys5mTmOSzbG7iLp7sFZG/qGtMDEyalB8M6dbN1jkK/n1B2PHjbZ8qVeC886BzZ5uKVpy6daFtW1sgOyHBgjC52reHf/zDAlj/+Y+t23TllZbxU6sWzJ9v092K07KlBXBuuMECOm63BYyCgiwY9uCDMGaMZR1ddpn1t0IFmD3bpq6NHm1T62rXLrqNo0dt2l9mJrz4IjRtan+L6u8LL8DQoflZYVdfDY88UrDOZs2sXzffbFlWx2dDiYiIiIicJi7HOZW5BqdfRkYGiYmJhIaGUrFixbPdnbPO4/EQFRV1trshpUBjWX5oLOGHfUdoPmG2z3WX/F2wZWSfMjNFQuNZfmgsyw+NZfmhsSw/NJblR1kaS8UHyhZNkRMRkVNWt1og9atX8VkWXD2IutUCz3CPRERERETkbFKASURETlnlADe9Q4N9lvUOrZc/PU5ERERERM4J+gQgIiJ/yKRoS62em7iLpEMpBFcPondovbztIiIiIiJy7lCASURE/hC3vx/P9rmEJ3tFsCc5nbrVApW5JCIiIiJyjtInARERKZHKAe4ys6C3iIiIiIicHlqDSURERERERERESkQBJhERERERERERKREFmEREREREREREpEQUYBIRERERERERkRJRgKmUrWENfel7wv1mMYsudPFZNpaxvMM7xR4/jWlcwzUnbMeFi33sO+F+IiIiIiIiIiJ/lO4iV8ra0IZZzCpRHY/zeCn1RkRERERERETk9FMGUymLJ55QQn2WjWUsjWhEW9ryCZ/kbY8jjt705mIu5mEeJo44nuEZADpEdGAc4+hABxrSkKlMLVTvLGbRiEZ8x3c+232ER4gkknDCmc/8vO1v8iZRRBFBBFdxFVvZCkAmmQxjGJFE0prWxBFHMskAhBBCf/rTghYFzkFEREREREREzl0KMJ0hc5jDx3zMOtaxnOUc5nCB8jTS2MQmnubpAtsz/TKpSU2Ws5xZzGIYwzjK0bzymcxkHOOIJ55mNPPZ9kVcxLd8y3u8x63cym/8xhd8wXSmk0ACa1nLQzxEDDEATGACbtx48LCe9VzABYxkZF59oYSyhS15+4uIiIiIiIjIuU1T5EpRWmY2v6Sn4a1KodDdUpYSSyxVqQrAYAbzAi/klV/GZUXWey3XAhBJJBlkkEoqAKtZzSIW8RzPEUxwkcffyZ2ABYZa0pJv+Iav+IrtbKcDHfL2O8hBDnCA+cznEIdYwhLAMppqUztvv050OomrISIiIiIiIiLnCgWYSkF2jpcR8zzMTUxix/lr8L8umWHLVzMpOgq3f36kycHJe+w+7tIHEVRk/YEEArZg97H1VKc6M5lJP/pxDdcQQojP4/3xz3vsxUsFKpBDDgMZmJcx5cXLbnZTgxrkkMPzPE9PegKQQkqBrKni+ioiIiIiIiIi5x5NkSsFI+Z5eCFhKzsOpuI4kJXj5YWErYyY58nbpyc9+YiPOMQhvHh5l3dL3G4TmnAlVzKUodzCLXjx+txvGtMA+JZv2c522tGOHvRgJjPZwx4AXuVVutIVgB704CVeIpNMvHi5ndsZxagS91dERMqhNWug74nvnlpqDh+GK6/0WVR50ya4884z15fiBAXBjh1nuxciIiIiZ4wCTCWUlpnNnMQkn2VzE3eRlpkNQC96MZjBtKEN7WjHeZxXan14hEdIJZVJTPJZ/iM/EkEEQxjCB3zAX/gL3enOwzxMN7rRilbMYAb/4T+4cDGGMYQQQgQRtKQlDg6TmVxq/RURkXKkTRuYVbK7p56Sgwdh1SqfRYE//gi7dp25voiIiIhIHgWYSmhPcjpJh1Lznrt+aIHfM08BkHQohT3J6XllD/Mw29nOalbzL/5FPPGAZRg9yIN5+x37fI1nDTWpmVfm4FCTmsQRl3dHuNwFuR/m4UL9c3CYwhTWspZv+ZYruCKv7G7uJpFENrCBr/iKi7kYsCl5L/Mym9jEVrbyAR9QjWoA7GAHbWhTomsmIiLlSHw8hPq4e2p4OCxbZo9nzoRKlSD995+JQ4bA1KmwbRt06wbt20ODBnDttXD09ynZlSrBuHHQoQM0bGj7AwwaZPWEh0NOTn57SUlc8OqrkJBg+wC8/rr1rXVr6N7d2vPV/9atrZ1WrSAjA+bNg3btICICOnaEb76xfffuhT594NJLrU9dusCvv1pZQoL1KSIC/v538PrOKiYkxM6rUyc75zFj8st8tbt/v2VDpf7+u8Ydd0DnzvnHNGkCW7bY9WndGi65xOrevDm/vVGjLBDYuHH+dfR64b77rL2WLaFFC/j6ayuLi4O77rLzbNTIHmdlWdmWLXYto6LsfN96q+jrKCIiIucUBZhKqG61QOpXr+KzLLh6EHWrBZ7hHomIiJwZaZnZ/HI4Da/jozA2FhYutMeLFkGNGhaEcRxYsABiYuCNN+DWW2HFCti+HX76CT791I7JyICaNWH5csuQGjbMgk9vvw2BgbBuHfjnrzFIcDC777zTgitvvw3//S9MnAiffw7r18ONN1pwyPHR2cREC4Jt2AA7d8Lo0dbHtWstSBUbawGeDz6woMs338CPP0LlyvDuu5CZCddfD5Mn2zFXXJEfTPMlJcWuxfLl8Mwzdt7ff++73UqVoG1bOw+wQM5331kdmzdDhQrQtCncf79d59WrLcD11Vf57R04YNvj42HsWNi4EVauhN277Vw2b7ZxmDAh/5iVK2HJEivbvBleew2ys2065IQJ4PHAF19Y/1esKHwdK1Ys7r+OiIiIlENa5LuEKge46R0azAsJWwuV9Q6tR+UAXWIRESlfjr25RcjGNUzdl8zU2cfd3CImBm64ASZNsmDK8OEWsKha1bJi6tSBp5+2bRMnWnbR7t0WOMl1rd1FlchICzilphbuTFEWLYL+/aFWLXseF2cZOzt2WPbRsYKDLZsIrD979kDXrvnlfn4WALvvPjuXKVMsIJSYaBlAGzdaoCf3mAEDLNOoKLnndeGFULu2BYBWriy63ZgYC9Y1amTHhIZacGfDBrjuOgu0XX+9ZQ/97W/Qo4cF1HLdfTe4XFCvHlx9NXz2GTzwADzxhAWOfvjBgk9Vq+YfExdnmVMAt9wCs2fb2lc//ACDB+fvl55uAbEWLQpeRxERETnnKPpRCiZFRwG25lLSoRSCqwfRO7Re3nYREZHyJPfmFgANHMj8/eYWAM/2ucR2CguzzJ65c20aV3S0BXzc7vxFwQcMsKyYfv0sMLJzZ8EMo8Dfs4BddhdVn9lHRcnJgYCAgtscJ3+q17GCjrk7ak6OBXk+/DB/W1ISXHABPPywrf80eLBlKWVl5ffp+L65i/kVK/CY7GaXy44trt3zz4fLL7dMpW7dLBvss8+sL6++avu+954FvJYutQyjd9+Ff/+7cF+8XgtIffqpBcweeMACXs2bWx2++p97TE4OnHeeZY/l2rvXtq1YUfA6ioiIyDlHU+RKgdvfj2f7XMLGh6LZMrIPGx+K5tk+l+R/iysiIlJOnOzNLQDLvBk50tbsad7c7gD3/vs29Qtg8WKbstW/vz1fubLgukq+uN22j49gk+Pvnx9Auvpqm9L222/2/O23LVDTuHHx9XftasGbrb9nJi9YYGsKpadbf++/HwYOtMyjJUusL61a5U/9AwuqHTxYfDun0m69ejZd8NVX7Vr26AEff2zrM7VuDfv2WfbQ+edb/554wqbE5XrnHft3505ro2dP63t0tK2v1KaNZSgde+0//NCyxo4ehenTbd9mzSw4lhuISkqybCpP/l1zRURE5NylDKZSVDnATaOaVU+8o4iISBl1/M0tjpV7c4u8n4UxMTZFrls3e96tm03rCg625+PH2z5VqlgWTOfONiWsOHXr2ppEF19s09XOPz+vKDUszIIpsbHwn//Yuk1XXmkZOLVqwfz5Nu2sOC1b2vpHN9xgQSO32wJGQUEWDHvwQVuYu0IFuOwy62+FChagufNOW0cpPNwCUKeiuHZzr+XkybYAuJ+fBXpiYqysZk149FELUgUG2rFvvJFf908/2aLc6enwwgsWKLrzTssgCwuzLLLu3S1olbs4eeXKtp7VwYOWcTZokLU7Z45lPk2caMG8f/7TFiSPjz+18xUREZFyx+U4p5JvfvplZGSQmJhIaGgoFbVAJB6Ph6goTbUrDzSW5YfGsnzReJ6atMxswibOZcfBwkGmkBpBbHwo+qytP6ix9CEkxBZJb3MKd4CNi7PMpAcfPOGup4vGsvzQWJYfGsvyoyyNpeIDZYvmcImIiMhJy725hS+6uYWIiIjIuUu/BYqIiMgp0c0typAdO079mGnTSrsXIiIicg5QgElEREROSe7NLZ7sFcGe5HTqVgtU5pKIiIjIOU6/DYqIiMgfoptbiIiIiEgurcEkIiIiIiIiIiIlogCTiIiIiIiIiIiUiAJMIiIiIiIiIiJSIgowiYiIiIiIiPzup5/guut8l3XpArNmnbm+hIZCfPyZa0+kJBRgEhEREREREfndzz/Dd9+d7V6IlD0KMImIiIiIiMgpCQ+HZcvs8cyZUKkSpKfb8yFDYOpUyMyEYcMgMhJat4a4OEhOLlxXdjYMHw5Nm0LLlnZ8Zibs3Qt9+sCll0LDhpY99OuvdkxICIwbB506QYMGMGaM737+8gvExEBUFLRqBePH55eNHw/t2tn2Ro3gk08gJ8fa/+EH6NHDd52ffAJt2lhfn3zStu3YAcHB0L27nceePbB8ufUvMhIuuQTmz7d9U1PhllvsvJo2tb7lBrQ2b4b27a1P/frZviJlhQJMIiIiIiIictLSMrPpcnUGc+d7AVi0CGrUgIQEcBxYsMCCOhMmgNsNHg+sXw8XXAAjRxau75VX8vdJTIQjR+DDD+GDDywI88038OOPULkyvPtu/nEpKdbm8uXwzDM2te14AwfC4MFW/6pVsHQp/PvflqW0dKlNP9uwwQJFY8eCvz/8618WcFq82Pf5JyfDihX29733YOFC275rlwW6tm2zgNugQdbfb7+FOXPgrrtg507bv3p1O69t2yz49NJLVsdNN8Htt1uf7rvP+ilSVrjPdgdERERERMqS1avhzTfh1VcLl/3rX5Z58X//d/r7cfvtcOedlv1wrGnTbI2Y3GyJ0+2ZZywoMG3amWlPzp7sHC8j5nmYm5jEz3sq4LewM67LvyMhoQ3Dh7tYsgSqVrXgTJ069n/w0CFYssSOz8yE2rUL17t0qQWCAgPt+Ycf5pclJMCUKfD99/b/rF27/LJrr7V/L7zQ6j1wwDKdcqWmwhdf2PbcDKeUFFi3zrKD3nkH3n8ftm+3YFFKysldhyFDLHBWrRr07Wvn16KFbbv0Utvnm28si6lPn/zjXC4LHPXtCxddBC++aG3Hx9tx+/db+S232P4dO9oaTCJlhQJMIiIiIiKnYNMmy1Tw5auvztwHwiVL4I47zkxbIgAj5nl4IWGrPakJWVnwwrQUgs9LJjr6PPr3tyBL3762S04OPP889Oxpz1NS4OjRwvW63RZ8ybV3L3i98NxzlnU0eDBccYW15zj5++UGpMCOP7Yst33HsQynypVt2759ll307bcWoBo2zKa1de5sGUYnw98//7HXCxUq2OOKFe1ccttu0QJWrszfd/duqFXLpg++/jrccw/ceCP85S8Fs6+OPQ+3PrFLGXJGpsh5vV7Gjh1L//79GThwID8rz09EREREfAgPh1WrqgIlW9dl/34ICspfv+SOO+wDZK4mTWDLFsuw6NDB1lOpXz8/yyE+3rIHBg6EiAgLGn39NSQl2TSahASb/nKsTz6BuXPh2Wfh5Zftw/DQobZOS1iY9f/IEd/n/eSTdj7h4ZbxsHu3bV+xAi6/3LI26teH226z7Y88YvvcdFPBD7C59uyBq6+2dVyio+F//7PtXbpAbKz16cUX4fBhu36569MMG2br4QC89Za1GxFha9xMnWrbs7Lsg3jjxnbtvv7a9zlJ+XI028ucxKSCGxsn4XwVSUqdndS/KJvDhy0jKDbWinv0sKlfmZkWiLn9dhg1qnDdV10FM2ZARobtd9dd9vpfvBjuv99eh7VrW1A1J+fk+1ytmq1nNGWKPT90yF7Xc+bAl1/a6374cHtvmD07v2632/6fF+WddywIdPCgTbe7+urC+7Rvb1lXX35pz9ets/edX36x84qLs9dzs2Ywb561ff759lr817/smG+/hY0bT/58Rc62MxJgWrp0KZmZmXz44Yc88MADTJgw4Uw0KyIiIiJlTGwsLF9eDSjZui7nnw9t28Lnn9vz+HhbRDclxRbRrVABmjeHyZNh+nRYs8aCOU89ZRkOYIGbBx6AtWstmDR6tC3i+/jjtnDv228XbDMmBnr3tiDN3XfDE09YEGj9evvr9cKIEYXP+Z137EPkqlX2IbRXLwtGgWV/PP649WXzZgtgeTwWkLrgAvswf+yUoVzbttkH+w0bLLh13335ZTVqWF1Dh1pfo6KszrVr7dynTLHr9MYbds3XrrUpSw89ZMe/8orVv3mzfeDfufOUhljKqH3p2SQdKrjitKvxTjhwHsm1d7AnOZ1u3aBuXXudgAVsQ0IsSNmypb2OJ08uXPcdd9j/w6go+/9aty7ce68Fcx980IKfvXvDZZfZlLJTMWOGvbbDwuy1MmCABWYHDLD/7y1aWN+Cgmwq3ZEj9rxSJXsPOT4rCuC886yvHTrY6+iKKwrvU6sWfPyxveZbt7Yg2bvv2vV48EF47TU7r9xFwHPPa+ZMW3sqLAz++U/rn0hZcUYS7jweD506dQIgPDycxMTEM9GsiIiIiJQhaZnZtOmSwdvTzsNxLLA0fDh/eF2XmBhbTLdRI1ujJTTU1mPZsAGuu86m1MybZ/XNmGEZTY6Tn/XUoIFlFIF9ADzVNYYWLrRAUO70maFDC67Hkmv+fAsutWljz3NyIC3NHk+fbkGe8eNh61bL5jqZdWKuusoyjMCyJC65JL/s91/LC7T95pv2PDdbLCjIyj791LIw1q3Lb3fpUpvWExBgf2+6ya6plG81A93Ur16FHQfzg0yuC/bhGv4u9WsEUbdaIG+8UfCYwEDL5jsRf3+YONH+His2Nj8b6ng7dhT/PFdIiO/1yP76V3uPOdaxwa/1633XFx9fdDvHvzavuMJ3huFll1mA1pdGjfKznkTKmjMSYEpJSSEoKCjvub+/P9nZ2biLmVCqIFQ+j8dztrsgpURjWX5oLMsXjWf5obEsm7K9Di98u5cvfklmb2o2zuE+dPm/NdSu3YSLLkrijTcuYt++w7Rrl43H8ytHjjTnnnt207GjzYtLS/MjM9OFx1Nw7kyjRhV4+ulmBAb+SsuWflStms1771Vi06YqjBq1k6++yuDGG1vQpcshIiJSGDgwjU8+CWXDhk3s3h0A1MfjsU+B27YFkZZmz3fsOJ/Dh6vj8fxQ6Fz272/Arl1H8Xj2cuRIc77//hf+8hebF7dlS2XS0hrh8RSc87Jv30UMGJBM376WOpWZ6SI52R+PJ5u4uGY0aZLOpZcmExubzhdfNGbr1p8JCkohMzOULVt+xOVKK1Dfjh3nk5x8Hh7PjwDs3FkRl6sZHs8Gjhxpyt69v+LxHPq9rdaMG/cdDRvawjhHjvjjcjksWODP4MHNiYn5jYsvTuPGG7OYP78lHo+Hw4cbsWPHITye/QDs2VOL/fsr4/H4XgZDr8vyoZLbj/a1KhYIMOVqXyuALRuLiMjIn5Jel3I6nJEAU1BQEKmp+W9EXq+32OASQGhoKBUrVjzdXfvT83g8RB1/axApkzSW5YfGsnzReJYfGsuya9js1Xyw7UDec+9FO/ny303o1Psw110XygMPwLJllfn6awgODiYmBhYvbsKdd9pUuZtusoyb47MnwKaRffppMO+9Zwvpdupki/0OGNCSdetszZd//asOAQE2fSUzE1q2DKNqVcu+yP0/deRI/vMtW+wOUb7+v/31r/Y3KqoesbGwbFlTbr/dMjReftmmvx1/3A03wGuv1WDUqAZUqwYPP2xrr3z0kWU5fPllEDVq1CI+3hYXb9y4GVFRdh6NG7codBe5jRttfaVataKoX9+ys6KjrV3LBKuad0yvXvDZZxfz2mt27t262bo5F19s1+6VVy4ELIMKIDw8ihtugA8+qM4jj4QAtoBykyYQFVWz0PXQ67L88Hg8TB/Sk9rzPMxN3EXSoRSCqwfRO7Qek6KjcPufkdVXpBSUpddlRkaGkk/KkDPyLhAZGcmXv+f5rVu3jqZNm56JZkVERETkTy4tM7vQwsG567r8WOV70jKz//C6LmDT5H77zfZt2NCCRDExVtaqFVxzja3F1KKFTZdr2fLEa7y0bw8//uh76k7PnvDqq7aW06OP2pS+8HCrPyvL1lQ63pAh1o/27S2ws2GDTcerXt0WRI6MtOl9EybYAsW5/YuNhZtvhs8+K1xnq1Z2563QUFsjKXeR4+O98IJNCQwLs2PCwmytpe7doV49W4C4RQuro1Yta/uOO2w6X2ioLY587G3hpXxz+/vxbJ9L2PhQNFtG9mHjQ9E82+cSBZdEBACX4/hatqx0eb1exo0bx7Zt23Ach/Hjx9OoUSOf++ZGKJXBZMpSdFmKp7EsPzSW5YvGs/zQWJZNP+w7QvMJs/H6+I3U3wVbRvahUc2qZ75jUir0uiw/NJblR1kaS8UHypYzMkXOz8+Pxx9//Ew0JSIiIiJlSN1qgYUWDs4VXN0WDhYREZE/P+UyioiIiMhZUznATe/QYJ9lvUPrUTngjHwfKiIiIiWkn9giIiIiclZNirapGrkLB9eu7Ob6yMZ520VEROTPTwEmERERETmrchcOfrJXBHuS0/nfD1vp2O6Ss90tEREROQWaIiciIiIifwqVA9w0qlmVSm79iioiIlLW6Ke3yO/WsIa+9D3hfrOYRRe6+Cwby1je4Z1ij5/GNK7hmj/SxZP2KZ8ylrGntQ0RERERERGRXJoiJ/K7NrRhFrNKVMfj/Dnulria1RzgwNnuhoiIiIiIiJwjlMEk8rt44gkl1GfZWMbSiEa0pS2f8Ene9jji6E1vLuZiHuZh4ojjGZ4BoBKVGMc4OtCBhjRkVs3CwatZzKIRjfiO7wpsv5/7GcMYAPawBxcuPudzAN7jPfrTn1RSuYVbuJRLaUpToojiO75jJSt5lVf5kA95hEcAeJM3iSKKCCK4iqvYylaf/RcRERERERH5IxRgEjmBOczhYz5mHetYznIOc7hAeRppbGITT/N0ge0ZZFCTmixnObOYxZTgKRzlaF75TGYyjnHEE08zmhU4NpZYFrIQgEUsog51WMISAOYyl+u4joUspDrV+YZv2MY2LuESXuIl2tGOO7mT/vTnSZ7kC75gOtNJIIG1rOUhHiKGmBP2X0RERERERORkaYqcCJCWmc0v6Wl4q1Io7LqUpcQSS1WqAjCYwbzAC3nll3FZkfVey7UARBJJpl8mqaQCNoVtEYt4jucIJrjQcZdxGbvYxV72sohFPMqjTGMa4xjHF3zBW7xFEEFcxEW8yItsZzvxxHMplxaq61M+ZTvb6UCHvG0HOZg3ha64/ouIiIiIiIicDGUwyTktO8fLsNmrCZs4l1tmfMX2fckMm72a7Bxvgf0cnLzH7uPiskEEFVl/IIEAuHAVqKc61fmMzxjHOHawo9BxfvhxDdewgAWsZCW3czt72MNHfEQHOhBEEFOZym3cRmUqcyM3MoABBfqZK4ccBjKQdb//+ZZvWcMaalDjhP0XERERERERORkKMMk5bcQ8Dy8kbGXHwVQcB7JyvLyQsJUR8zx5+/SkJx/xEYc4hBcv7/JuidttQhOu5EqGMpRbuAUv3kL7xBLLRCYSRhgBBHAlVzKKUVzHdQAsZjFxxHEbt9GMZsxjHjnkABYEyyILgB70YCYz2cMeAF7lVbrStcTnICIiIiIiIpJLASY5Z6VlZjMnMcln2dzEXaRlZgPQi14MZjBtaEM72nEe55VaHx7hEVJJZRKTCpVdxVXsZjfd6AZYoGgve4kmGoAHeZDXeI1WtKITnYgkku1sB+BKrmQxixnKULrTnYd5mG50oxWtmMEM/sN/8rKqREREREREREpKazDJOWtPcjpJh1Lznrt+aIHrmacASDqUwp7kdBrVtHWXHv79z/GmMa3I58dPV1vjWUPNqJrE/f4HLNPIgwdfAggosKD4Tb//yXUZl7GZzT6P7UCHAlPv7v79z4n6LyIiIiIiIvJHKINJzll1qwVSv3oVn2XB1YOoWy3wDPdIREREREREpGxSgEnOWZUD3PQOLXwHN4DeofWoHKAEPxEREREREZGToU/Qck6bFB0F2JpLSYdSCK4eRO/QennbRUREREREROTEFGCSc5rb349n+1zCk70i2JOcTt1qgcpcktKzZg1MmACzZp3tnpTMrFnw0ksQH3+2eyIiIiIiIn9S+iQtgk2Xy13QW6TUtGlT9oNLIiIiIiIiJ0FrMImInC7x8RAa6rvsrbfg4ouhVSu48kpISgKvF+67D9q1g5YtoUUL+Ppr2z8uDu69F664Aho3hthYSEkpXG9cHPTubXU//DBkZsKwYRAZCa1bW3lysu07fz506GCBsPr1YcyY/HrGjoVGjaBtW/jkk6LPr2NHGDgQIiLsXHP7W1S7zz1n+wNkZUG1avD22/b8q6/s3FNS4PrrITzcjr/9drs28fFW3q+fXbd27WDLFjt22zbo1g3at4cGDeDaa+HoUStzu+HRRyEqCpo3h//8J/8c3nyT5jffbP2/6irYutX3dRQRERERkWIpwCQichqkZWbzy+E0vI6PwvXrLWixaBFs2GCBjCefhJUrYfdu+OYb2LwZbr3Vptjl8njsmC1bYMcO+OijIhpPg02b4Omn7Xi3245dvx4uuABGjgTHgcmTYfp0m8q3YgU89RTs2wdz5sDHH8O6dbB8ORw+XPSJrlwJDzwAa9fCoEEwerRtL6rd2FhYvNgCRl99BVWqwJIldszcuXDddRbQOnLE2l+92sp+/NH+XbMGhg616zZoUH6w6o037HqtWAHbt8NPP8Gnn1pZTg5Urmx9+fe/YfBg+O03+OILmD6d7/71L+v/Qw9BTIzv6ygiIiIiIsXSFDkRkVKUneNlxDwPcxOTCNm4hqn7kpk6ezWToqNw+/8e01+2DHr0gODf72J4//35FTzxBLz2/+3deVxV1frH8Q9yHEAkvZmlV9SuVg6AKJqWc+ZYqJBDk2WmpdfKLM2hn2alZpl6Nc2hummTlXZTsTK1G2blSDlgmmmZOFzLFAkkkHPO748nOAwHh0AR+L57nRdn77X32mvv3ZHDs5619jzYt88ydipkGbrZuTOULWvvQ0Lg+HHvjWjZ0vN+xQpISPAEcdLSoEoV8PGB6Ggrf+cdC1q53ZCcDGvWWCAo49j9+8PMmd6PVbOmZRqBZRstWHDm49aoYeedESwbPdoCW263BZg++ghKlbJAVdu2lpX06KOWtXXwoGVDtWrladeQIfDbbxYEWr0aXnjBspkOH86e4fXQQ/YzNNSu3RdfWHBs717q9u8Pfn5WfuKE57pmvY4iIiIiInJGCjCJiBSgEdGxzFxnw6xquiHN6cpcnt6jqW3kcFiAJ0NKCvz8swWVhg61jKDu3W0411tvebbLCIKA7e/2lh4FBAR43judMGMGdOliy0lJNnQsOdmGhUVGWsCmf39YutRTZ9a6HWf4VZFXm/I6LtgxP/4YVq2ygNI778B771ldtWvbNnv3WoDtv/+1oWvz51vAK2tbMo7l6wt33AHp6TZ87pZb4MCBvM/B5bJ9nE7o25ddvXsTHh5u6w8fhkqVcl9HERERERE5Iw2RExEpIKfS0lkWF++1bHncQU6lpdtCu3aWJXTkiC3Pm2fDs1avhogIGDzY5kVautSCIPnRqZM9AS4tzQIoAwda1tAPP9icSBMm2DFjYiA11Y7XpYsNv0tIsH3efLPgjguWHfXOO7a+WjXo2NHO/7bbrHzOHBv+1rGjZSZ16gTffGNlW7fa8DiwoNONN0LFijbsbtw46NPHyjZuzH7t3njDfn7zjc2z1KaN1btoEY5jx6xs7lxo3/78z1VERERERJTBJCJSUI4kphCfkOy1LD4hiSOJKfa0wpAQmDLFhrwBVK1qk34nJlomTkiIZeN07GhzIblcf71RY8fC8OGWreR02nC2qVMtO+fWWy1LqmxZO2b9+pY51LUr7NhhQa5KlWxY2q+/FsxxwY7j4+MJ5nTqBM8+6wkw3XOPBbzq17e5k2rUsAnOt22Dq66CJ5+0OaiqVPEEvyZNssyo8uXhssssgLR3r6c9X31lASmXy7KlKlWy6ztyJNf+85+2X2CgTQCeNbtMRERERETOiY/bndcYi8KRmppKXFwcwcHBlM2Ya6QEi42NtaEbUuTpXhYfed3LU2nphLywnP0ncgeZalUKYMcTEfiXUVz/L4uJsbmU4uLObz8fHwuQVa7stVifzeJD97L40L0sPi7Ve7l5M7z2miWv5vTqq5aA+89/Xvh2DBwIgwbZg04vpPHj7Tkes2b99Tou1Xsp568o3UvFB4oWDZETESkg/mUcdAsO8lrWLbi6gksiIiKXiJ077dkR3nz5pT1I9GJYvTrvKRVFRIoaBZhERArQlIhwHmlVl1qVAvD1scylR1rVZUpE0egluqS1bXv+2Utg39zzyF4SEZGCFxZmD0wFWLmyEuXK2fMsAAYMsKn20tJg2DB7AGnDhtCvn40Uz+q332xEd/KficEPPmgjoDNcc409BHXFCpuSr0kTG1U9dqyVx8RAixbQt6+N2A4OthHT8fE2bd+6dTblX1YffmgPNZ0+HWbPhtOn4eGHbdR2SIi1//ffvZ/3xIl2PmFh0KOHPTcCYMMGaN0amjWz9t1/v61/8knb5q67bOrArJKTbcT4DTfAtddahtP331tZ27bw2GNw/fXwj3/AU0/Z+v377eGuDz5obWjY0M4xp0OHbFR5eLg9XHXSJO/nIyJyvhRgEhEpQA7fUkzv0ZQdT0Swa1QPdjwRwfQeTXH46p9bEREpGaKi4JNP7P369ZdRqZIFOtxue4hoZCRMnmwP+IyNtSn2qlWDUaOy13P55RZE+fxzW46JsSBLUhJ89x2ULm1TCU6dCgsXwpYtFsx57jkbDgYWuHn8cfj2WwsmjRkDQUHwzDP2ENXXX89+zMhI6NbNgl9DhtizMA4ftjZu22ZT+Y0Ykfuc33jDpi/ctMmeR9G1qwWjwB6q+swz1pbvvrMAVmysBaSqVYO337bgU1affGLPsFi/HvbsgaZNsw9v+/57C5Z9841NLbhiha0/cMCCcFu32jXu08eCZFn17WsPj42NtfauWQPvv3/2+yoicjYaryEicgH4l3HYhN4iIiIlyKm0dJq0TWX4IH+mTPFh69YAHnvMhoJVqAC1a9vzGlassIeVrl5t+6Wl2bMbcoqMtGBL7drw979bFtLatfZA0dtus2n2oqOtvnfesYwmt9uT9VSzpmXzgGUXLVhwfufzyScWCCpd2pYfftiyk3JascKCNU2a2LLT6Rlmt3ChBdYmTbIHmaakWJDsTHr2tOykl16yZ1bExFg2U4YHH7Q2VawIvXrZw1SDg+0ZFnfeadt06QK+vp6Hr4Jdl7Vr4fhxT6ZXUpIFpHr3Pr9rIyKSkwJMIiIiIiKSL+lOFyOiY1keF8+BhGQ4Gkn3MUeoXr0KERFl6dPHMpZ69rTtnU7L7OnSxZaTkuCPP3LXGxlpw8uuvRY6dLAAyqpVFsyZO9cCJo0a2XatWllmztKlnnmN/Pw8dfn4nP98R05n9oeLuly5M4Iyths5EgYPtuXUVDhxwt63bm1D0Tp3tiDOxo1nb8ecOfbw04cesoDR3/4GP/3kKXdk+SvO5bJAUs71Ocsy2ul2w9df24NawbK9ypU7c3tERM6FxmyIiIiIiEi+jIiOZea63ew/kYzLDen/+Jno+VVIq36IunXh5EkbChYVZdt36mRDvtLSLAgycCCMHp273urVbRq9uXOhY0fb74MPbH6mhg3hhx9s7qYJEyAiwjJ9UlMtkHImDof3QFHOss6dLdhz+rS1c/ZsC3Tl1KmTPX0uYx6pceNsKFpCgj2x7vnn7dwPHrSMpIz25dWOTz+1eanuvx+uu86ytLKe01tvWXtOnLDhbRERtv7XX2HlSnsfHW1ZTiEhnv0CA6F5c5g2zZYTEmyeqmXLzny9RETOhQJMIiIiIiLyl51KS2dZXHy2dT51DsDxyzh0+c+cSkunQweoWtXmPwIbnlWrlmUf1a9vWTVTp3qvPzLSAieNGsHVV1tWUmSklYWGwq232lxM9epZUKV+fQvinEnz5vDjj56AV1ZdulhA67nn4P/+z4b0hYVZ/adPW+ZVTgMGWDuaN4cGDWxY2oIFNoRt9GgbnhccbPMitWjhaV9UFNx9t2VlZTV8OMybZ+fXqpXtn/WcUlJsfqrmzeGf/4T27W19uXLw5psWfJs40bK5smYwgQ0l3LDBAk/NmsEdd9hE4yIi+eXjdl9aD8ZMTU0lLi6O4OBgypYtW9jNKXSxsbGEh+vpU8WB7mXxoXtZvOh+Fh+6l8WH7mXRsu/Y79SdvBSXl78qSgG7R/fQvIQFqG1bGzqXMdwww/79FsQ62/xOf5U+l8VHUbqXig8ULcpgEhERERGRv6xqoB81Kpb3WnZleQdVA/28lomISPGiAJOIiIiIiPxl/mUcdAsO8lrW5u+B+JfRc4UKUkxM7uwlsCGHFyp7SUTkXCjAJCIiIiIi+TIlIpxHWtWlVqUAfH2gVqUAHmlVl0caX1nYTRORIuann+C22y7OsWrVgi1bLs6xSgJ1J4iIiIiISL44fEsxvUdTJnZtxJHEFKoG+uFfxkFsbGxhN01Eipiff4bvvy/sVshfoQwmERGRomzLFu9jJS6UgACbSVZExAv/Mg5qV66gYXEiF1hYGHz2mb1ftMieIJiSYssDBsCcOZCWBsOG2VMIGzaEfv0gMTF3Xenp8NhjcO219hTGAQNs36NHoUcPuOEGe4Jj27bwyy+2T61aMH68PeWwZk17MqQ3hw7ZUx/Dw+2piJMmecomTbInGYaGQu3a8OGH4HTa8fftg06dcte3YQO0bm371agB999v6/fvt3Y8+KBdm4YNYd06Kxs/3p7W2KaNnWPv3t6vQ3S01duokT3tcf36PC+/5EEBJhERkaKsSRNYsqSwWyEiIiIXUVQUfPKJvV+5EipVsoCK2w0ff2xBncmTweGA2FjYtg2qVYNRo3LX9fLLnm3i4uD33+G99+Dddy24tH49/Pgj+PvDm2969ktKsmN+/TW8+KINbcupb1/o39/q37QJ1qyB99+3LKU1a2xOse3bYeJEGDcOfH3h1Vct4PTpp7nrmzEDnnkGNm6E776D5cutboADByyItHWrnXufPnD6tJWtXWvH3b3brskzz2Sv94cfYMwYu3bffgvz59s1Tk4+3ztTsinAJCIiUpTFxNhzqb2tb9gQbrzRugZTU/PumjtTF+W6ddYV2KgRPPAAuFze23Gmrkxvx/3tN8uGyvjm9uCD9q0wwzXXwK5d1gXbsCE0bWp1f/ed53ijR1uArU4d2w6sfUOH2vHq14d69eCrr6ysXz8YPNjOs3Zte5/xzXPXLujY0bpYw8Lg3//O+zqKiIgUolNp6TRpm8zHH7txu+1X9WOPwerVluFTuzZcdRWsWAHLltmv37AwWLrU82s0qzVrLBDk5welSllwqW9f+3V6440wbRr8858WfMo6kXz37vbz73+HKlXg+PHs9SYnW2Bn7Fg7fvPmFgTautW+KrzxBrz9tgW95s49t0nqFy6EhATLfvrnPy1rK2O/SpXgzjvtfZcuFqzavt2We/WCK6+087v//tzBq9Wr4cgRaN/e2nrXXbbt3r1nb5N4KHdVRESkuIqLsy7HmjU9XXMxMXD55bBzJ9x8s31zyuiiHDnSuj5vucW6KB9+2L6Rvf22feNatAheeSXv42V0ZR46ZEGf/v0t7z6v415/PXz+Odx6q5WfPGl1HDgApUtbHntYmOW9V61qbfrySwscgX2T3bzZjteoEeVmzbKc/sOHLYhVqpR1YU6ebEEusC7PL76w+jt2hHnzYNAgG2b45ps2juDkSbseGcfJeh1FREQKSbrTxYjoWJbHxXMgIRmORtJ9zBHq1KlDRIQPffpYdk7GyHmn0zJ+unSx5aQk+OMPyx7KyuEAHx/P8tGj1l/zr39Z1lH//tCunfXJuN2e7fz8PO99fLKXZRzf7bYMJ39/W3fsmA3n++YbC1ANG2a/jtu0sX6fs2nd2vp7One2oW4bN3qO68gR3XC5LMiUsyzr+qxtbd/egmsZ4uMt60vOnTKYREREiqhTaekcOnkKlzuPDYKCPEGRM3XN5dVFuWOHBWLat7c67rgDKlTIu0HeujLPdNzISMvv37XL9mnRwro6ly2zx8f4+lqA68Yb4aGHoGJFz2QLAEOG2Dfa6tWhc2cCN2ywwNCECRY4Gj7chg9m7RLt188yp8qWhXvusS7MPXtssof+/a2NbdpYl+i33+a+jiIiIoVkRHQsM9ftZv+JZFxuSP/Hz0TPr8Iff4+nbl3rH3n7bRvaBTaHUUbfi8sFAwda8m9ON98M77xjSboulwV6Fi2yX5GPPmrZTFWq2K90p/Pc2xsYaFlL06bZckKC/apftsz6epo0scyrNm0suyqjbofDk2CcVUKC9Ss9/7yd48GD9nUiY79ff7XhgmD9SqVLQ0iILS9bZtfH5bK+soiI7HW3bw+rVtkQOrChcqGhnnmt5Nwog0lERKSIydqDWWvHFuYcS2TO0s1MiQjH4Zul7yggwPP+TF1zI0fm3UWZszsyZ/dgVt66Ms903Msvt67Ia6+FDh0st33VKmvL3Lm27VtvWcBrzRrLRHrzTZtEIWdbXC4LXH30kQXMHn/cAl5161od3tqf0YXpdMJll1nOfoajR23dhg3Zr6OIiEghOJWWzrK4+GzrfOocwL2lAT+W38KptGp06OBg+3brFwEbmjZ8uA2RczqtD2XqVEtqzurBBy1ZODzcfnW3bQuPPGKj0YcPt3pKl4aWLc9/yNg771gfUUiIBbruuMP6mo4ehQ8+sJHsLpclMx8/bvM/1a9vWU7XX2+BqAwVK1qArHFjKF/e+pdatLA21a5t+7z5pn2t8fOzoFVGptKVV0LXrpZB1bq1JVdnVb++zbt0++12DRwOm99JXwHOjwJMIiIiRUxGDyZATTekOV2Zy9N7NPW+U/v2Nnvm7t0WdPn4Y/uGFx9vXZRPP20BmUOHrIvynnus6y5jttCuXe2b1okT59fYMx23enWoXNmCSW+9BX/7m2Uf+fvbvEfHjtm34k2brAu1YUMLgmV44w0LOh04AKtWcXLuXIJWr7ZuycGDrdvx+eezd7e+955lQbndNpHDfffBddfZN9G33rLHzMTH27fXpUvP71xFREQukCOJKcQnZJ9x2qfaMXwee5NffKz8lVeyZxn7+cHs2Wev29cXXnjBXllFRXmyoXLK+UDZvB4wW6uWzQWV05VXep7ylmHqVM/7bdvsZ86pDydMsJe39vj6WgaXN6Ghls3lbb8MvXrZS/46BZhERESKEG89mBmWxx1kYtdG3h8PfqauuXHjvHdRli5tQZZBg6yrLyzMcuTPx9m6BCMj7Rtlo0aWgeTnZ+vAgk//938WpPLzs32zzgH100/W3ZqSAjNnklqrFjRoYN2jISE2/1PHjtZFmjE5ub+/TRZ+4oRNUnHffXbcZcss8+mFFyyD69lnrVs0Jub8zldEROQCqBroR42K5dl/IvdjzYIqBlA10M/LXiIXlwJMIiIiRUjOHsy1QfVoeO9zAMQnJHEkMYXalStYfntcXPad8+qaO1MXZdOmnuf/nsmZujLP1CU4enT2CSG85e0/+KD3fUeMsAkcMsTGWpZUxtxJGWbM8Lxv396CaTk1bOg9mOTtOoqIiFxk/mUcdAsOysxYzqpbcHXvnUslSK1aeT+Fbvz4i9mSkq1k/18oIiJSxKgHU0REpGSaEhEOWMZyfEISQRUD6BZcPXO9SGFTgElERKQIUQ/mn/Ka7OFMFiwo6FaIiIhcNA7fUkzv0ZSJXRtxJDGFqoF+Jef3vhQJ+r9RRESkiFEPpoiISMnlX8Zhw+FFLjEKMImIiBQx6sEUERERkUuNvo2KiIgUUerBFBEREZFLRanCboCIiIiIiIiIiBRtCjCJiIiIiIiIiEi+KMAkIiIiIiIiIiL5ogCTiIiIiIiIiIjkiwJMIiIiIiIiIiKSLwowiYiIiIiIiIhIvijAJCIiIiIiIiIi+aIAk4iIiIiIiIiI5IsCTCIiIiIiIiIiki8KMImIiIiIiIiISL4owCQiIiIiIiIiIvmiAJOIiIiIiIiIiOSLAkwiIiIiIiIiIpIvCjCJiIiIiIiIiEi+KMAkIiIiIiIiIiL5ogCTiIiIiIiIiIjkiwJMIiIiIiIiIiKSLwowiYiIiIiIiIhIvijAJCIiIiIiIiIi+aIAk4iIiIiIiIiI5IsCTIVkC1voSc9CbcOt3MoCFngtCyOMBBLOuH9b2rKEJWfcZgELuJVb/2ILRURERERERKQocBR2A0qqJjQ5a3CmMG1la2E3QURERERERESKCGUwFZIYYggm2GvZv/k3DWhAKKEMumYQ8cTjwsVQhtKMZtSnPvWox1d8BUA/+vEIj9COdtShDlFEkURSrnoPc5gOdKABDehKV/7H/zLLylKW3vTmOq5jC1vwwYdjHGMBC+hOdyKJJJhgrud6drErW73ppNOb3tzFXaSTnuu4RzhCZzoTSigRRGQe9yQn6Uc/wgknlFCGMSxz/13soiMdCSecMML4N//OvG4NaciN3EgooaSS+heuvoiIiIiIiIgUJAWYLjHb2MZIRrKSlWxnO61PtmYiE9nIRg5zmPWs5zu+417uZTKTM/eLJZaVrGQXu9jPfhazOFfdQxhCc5qzk53MZCa72Z1ZlkYaEUTwPd/ThCbZ9lvLWl7iJeKIoxnNsh03jTR60YsqVOEt3sLhJSluD3uYxSy2s50QQhjKUACGMYxwwokllm/5lmMcYxrTSCednvRkMpOJJZa1rOVFXmQDGwCII45FLGI72ylL2fxdcBEREblgtmyBnhdxRoCTJ+Gmm7yXbd4MgwZdnHa8+iq8/PKFP05MDAR7768UERG56DRErhCcSkvnUMopXBXIFeL7jM/oRCeCCALgzl/uJDwoHIAJTGAe89jHPmKIoQIVMvfrTOfMYEsIIRzneK7jrmENL/IiAHWow01k/wbWilZe2xtOONWpDkBjGvMf/pNZ9jiP8zu/s499+ODjdf+buZk61AHgfu6nKU0BWMEKNrGJ13gNgBRSAAtI7WMf/emfWUcKKXzLt9SjHkEEUZOaXo8lIiIil44mTWDJRZwR4MQJ2LTJe9nOnXDw4MVpx5dfKvAjIiIljzKYLqJ0p4thSzcT8sJy7nnnS/YeS2TY0s2kO12Z2zhwZAvU/OHzB7vZzUd8xC3cAkB3ujOIQbhxZ27nh1/mex98spXltT5ntlEAAV7bfaa6+9KXwQxmIAPzPG9ffDPfu3BRmtIAOHGymMVs/fO/jWxkFrNw4uQyLstcv5WtbGAD93HfGdspF9jF7oa+UJYsgbZtc68v6G7gBQvgVk1wLyIlW17/tIaFwWef2ftFi6BcOUixfiYGDIAlSyqzZw906ADNm0PNmtC9O/zxh21TrhyMHw833ghXXw1z5tj6++6zesLCwOn0HC8+HsaNg3XrbBuA+fOtbQ0bQseOsGeP93OIjoZmzaBRI2jRAtavt/VHj0KPHnDDDdaGtm3hl1/gww9h+XKYPh1mz85d36RJVl9oKNSubduDnc/dd0ObNnDttdC7NyQmWlmtWjB6tAXs6tTxnG9WaWkwbBg0bmzn1K+fZ38REZGLQQGmi2hEdCwz1+1m/4lk3G447XQxc91uRkTHZm7TjnasYQ1HOALAf674D0/wBKtZTQQRDGYwTWjCUpbixJnXobzqTGfmMx+AAxzgcz7P9zldz/U8y7PsZS+v8IrXbT7ncw5wAIC5zKULXQDoRCemMx03blJJpRvdmMUsruM6/PDjLd4CIJ54ggkmlliv9ctFcrG7oUVEpEg7lZbOoZOncLlzd3pFRcEnn9j7lSuhUiUL/rjd8PHH0LZtAq+8AvfeCxs2wN698NNP8NFHtk9qKlSuDF9/bb+ahg2z4NPrr4OfH2zdCr6e/i2CguCZZ6BVK9vmv/+FF16Azz+HbdvgzjstWJSzqT/8AGPGWJu+/daCUlFRkJwM775rwaX16+HHH8HfH958EyIjoVs3a9OQIdnr+/lnWLPGAm/bt8PEiRb4yrB2Lbz/PuzeDQ6HtTnD8eM2zC8mxvbZsSN73ZMn2z6xsXZO1arBqFHnccNERETySQGmi+RUWjrL4uK9li2PO8ipNJvcOoQQpjCFznSmIQ1ZH7ieucxlEIOIIYYQQmhMY2pTm5/4CRcur3V6M5vZfMd31KMe93M/YYQVxKlRjnIsYAEjGME+9uUqDyWU/vQnmGAOcIBpTANgJjNJJpkQQggllBBCeIInKEMZlrGMV3mVUELpSEee5Vla0KJA2it/0ZkyfP79b2jQwLpjb7rJuopdLhg61Lpp69eHevXgK5uYnn794JFHoF0764qNioKk3BPT06+ffUtv0ABGjjxz9+yKFdaV3aQJ1KgBY8d66hk3zrqJr7/e01XsTVKSZWmFhVlXdEZ39smT1q0cHAwhIfx9xgxI/3NC+3XrrHs9NNSOvXJl7nqXLLHjf/993scWESkmziVjOzLSAkxut/0z+thjsHq1BZNq14bKldN5/nm44goLBA0eDIcPZ/9V0b27/Wzc2AJOycnn3saVK6FPH6sf7NfJoUOwf3/27VavhiNHoH17+9Vw111QqpQFvIYOtV8706bBP/8JcXHef5VlVbMmvPEGvP22BX/mzs2+T69ecOWVdoz774dPP/WUDRkCPj5QvTp07gyrVmWve8UKWLbMMq3CwmDpUvjuu3O/JiIiIvmlOZgukiOJKcQneL75+Oyrh8+LzwEQn5DEkcQUale2OZXu/vM/gNi9sVQLr0Y1qvEt32arcwYzAFjAgmzrcy5nuIIrWMEKr2U5h9RlLPf7878MWZdjiMlcfz3Xk0BCrnpz7p9VZSrzNm97LWtIw2z1Z2hLW+KI87qPFJJt2yz488031kX8r39Zl+y999pfA+vX2zflyZPtFR1t+8XGWhdyqVIWhFq82DNuIatTp2ziDLCu3IzuWR8f61YeNcrGIEydCgsXwjXX2HFr1LBv/199BR98YN3Zfn7WRZ2X+Hh45x37i2H+fOjbFzZutGDY5Zdbd3FaGn5t28KLL8LAgRaQWr7czmHnThvbsHmzp85Fi+x6xMTY9RERKeYyMrYB3O4ATjvdmcvTe9g8jCEh1mewfLn9sx0RYQEfh8MzGvuOOyyW37s33HILHDiQPcPI788R/D5/zizgJVEqT04nlCmTfZ3bDadP596ufXt47z3Puvh4yw4aOdLme+rf3/pLTp8+exu++cYCY8OG2bC8Nm0seJbBkeWbucuVPQvrTGUZbZ0xA7pYojhJSZ4hhSIiIheDMpgukqqBftSoWN5rWVDFAKoG+nktE7kUeIY5eCn87DPo1MkTPHn0UeuSveEGmDAB5s2D4cMtiydrN23nzlC2LJQubX9pHM89MT0ALVt63ufVPevjY4Gr2Fh4+mnrCne7rTt7zRrLkKpQwb6d9+/v/ThgWUg33mjv+/WzeadOnrRu9ocesuOULcux226zdRs3WgZWs2a2T4MGNkFHTIwtb95sQapBgxRcEpES4VwztsGymEaNskBL3br2z+3bb9s/2WDZO+PGWeAJ7J9c51lmB3A4bBtvgR6HwxNA6tzZhrj9+qstv/669SPUqZN9n/btLVNo958P3v34Y/tVkZJi7Xv0UftnvkoVy3bKaF/WY2X1xReW7PrYYxZcWro0+zktW2bXweWCV16xwFuGN96wnwcOWJsyAkkZOnWCWbMscOdyWR/I6NFnvl4iIiIFSQGmi8S/jINuwd7/wOwWXB3/Mkomk0vPuQxzwOHwdB+DfevevdsmyrjFJqane3cLsnjregbbP69u34Ask7pndM9u3WqvTZsscJWcbEGnb76xsRJTpljgKqPOrHU7zvBZy9kd7ONj9bhc2c/R5bK/HJzO7OuzlgFUrGh/BYwfn3vchYhIMZQzYzurjIztDJGR9uuiQwdb7tABqlb1xOMnTbJtQkLgwQctILN375mPX7WqjYZu0AB++y17WfPmNldSVJQda9gwG9XdoIElwK5YYUm1WdWvbwmtt99uI7PHjrWsq4AAC34NH24Bp27drD8ko31dulhfy3PPZa/vjjvg2DEbNV6/vtVz/Dj8/ruVX3kldO1q5ZddZom6GX76CcLDLTg2cyZcd132useOtcnAGzWyut1uS+4VERG5WBTVuIimRIQD1oMXn5BEUMUAugVXz1wvcqnJOsyhphvS/pyYHjzDHGjXzr5BHzli3+znzbOhb//4h3W9Dh5sQafnnz971/PZZHTPtm9vgaKBA+3b+ZAhNhfThAk25uHNN21CDqfTvuUPG2Z/BQQGWlletm2zwFVYmJ1Hy5Y2a2vGcadPh7Q0Kn/4oXW533CD/XW0aZP9RbNzp3VPT51qM89ec4399fLww3DPPZbZlPOvFxGRYiQjY3v/CQsy+QQdxedeGxqdM2P7hhuyx/9fyfGskH/+017e5OyTyLq8dq33ferUsUm7MwwZknsSbm969bJXTlFRnmyrnG67zV45XXmlzTmVVdYgUGio/brxZsQIy37Kqm1bm/sJrN/G21PrRERELhYFmC4ih28ppvdoysSujTiSmELVQD9lLskl62zDHCZ2bWT//4aEWMZQ585WWLWqTfqdmGhdtSEhNolGx442F5Lr3Cemz2XsWAsUNWpkwaOwMPtmHhAAt95qYyzKlrVj1q9vXcldu9rcSU2a2GOKGjb0jInIqV49G2L344823mHhQls/c6YFif6cNCS1cWN48kkLZi1ebGWnTlnw6PXX7fnSX3/tqffJJ63Le8oUm7RDRKSYysjYzuiMyEoZ2yIiIsWbj9t9PlMiXnipqanExcURHBxM2bJlC7s5hS42NpbwcGU4FQdF7V7uO/Y7dScv9Trvkq8P7BrVI3Ni+pKmqN3LQrFli03qvmTJxTleQIB149eqlX19rVrWhpzd/lmc1/308bEAZeXKf7mpcuHos3lpSHe6GBEd6zVj2+F7blmcupfFh+5l8aF7WXwUpXup+EDRom4kEfEq5zCHrDQxvZxVkyYXL7gkIpcUZWyLiIiUTJoMRES80sT0ki8xMRAc7H19w4b2tL7QUJsrKzransTXqJE9hW/9etv26FHo0cMmarn6apts5JdfrGzdOhsi2agRPPDAmYdezp5tk783aGDDNzPMnw/BwdS74w4bwrlnj60/eRLuvtvaHxICTzxhwzyz+t//rFwTnojkyb+Mg9qVK+j3hYiISAmhAJOI5GlKRDiPtKpLrUoB+PpArUoBPNKqriaml/yJi4NFi2D7dnve9pgx9uzvb7+1oE9UlD0Z8N13Lbi0fr3Ni+Xvb5O0p6XZjLtTp9o+7drZRPJ58fOzJwyuXm3P7N650yaif+EF+Pxzdi1aBHfeacEstxseecSeV75jhw3127YNXnzRU9/BgzbR/OjR5zZDsIiIiIhICaAuJRHJk4Y5yF9xKi2dEydPUdWdRy9GUBDUrGnvV6+2JxC2b+8pL1XKJmgfOtQylaZNs0c/xcVZptOOHVC6tGefO+6wZ5jnJaOsWjXLVPrsMwsS9ekDV1xhQa5+/ex4+/fDJ5/AV1/ZfEtly8KgQfCvf8GoUVZP165QvboFpUREREREBFAGk4icAw1zkHOR7nQxbOlmQl5Yzj3vfMneY4kMW7qZdGeO4WsBAZ73TqcFirZu9bw2bLDhZyNHwrhxFgR64AELDmU8lyLn8ykcZ/h/09fX897lsuCU02kBpKzcbjh92rbJWuZy2foM8+ZZEGzatLNcERERERGRkkMBJhERKRAjomOZuW43+08k43ZDmtPFzHW7GREdm/dO7dvDqlWw+89Hmn/8sc3NlJICn34Kjz4KfftClSqW7eR0WrnbbdsCLF8OJ07kfYwFC+zngQOwZo0ds3NnG4L3669W9vrrNiyuTh3o1AlmzbJjpKbasL0OHTz13XADLFwIEyZYVpWIiIiIiGiInIiI5N+ptHSWxcV7LVsed5CJXRt5z4CrX98COLffbgEdh8MCRgEBlr00fDiMHWtZRy1b2tC50qVh6VIbujZmjE32XaVK3o374w+b5DstDV56Ca691l7DhsFNN1H/1CkbtrdihWUmzZwJDz9sE3ynpVkw6skns9d53XXWrrvvhk2boEyZv3ztRERERESKAwWYREQk344kphCfkJy5vDaoHg3vfQ6A+IQkjiSmULtyBXsSXM6sn1697JVTVJS9vGnaFGLPkBmVYf/+vMuGDIEhQ/guNpbw8CwT119+Obzzjvd9sg7Ne+wxe4mIiIiIiIbIiYhI/lUN9KNGxfJey4IqBlA10O8it0hERERERC4mBZhERCTf/Ms46BYc5LWsW3B1TRAvIiIiIlLM6Ru/iIgUiCkRNsxsedxB4hOSCKoYQLfg6pnrRURERESk+FKASURECoTDtxTTezRlYtdGHElMoWqgnzKXREREzsHAgfbsivAL3CczfjwcO2YPSxURKWgaIiciIgXKv4yD2pUrKLgkIiJyjlavzv4cCRGRokgBJhERERERKbHCwuCzz+z9okVQrhykpNjygAEwZw6kpcGwYdC4MTRsCP36QWKi9/omTrTtwsKgRw84fNjWb9gArVtDs2ZQowbcf7+tf/JJ2+auu2Djxux1JSfDPffADTfAtddahtP331tZ27b2MNPrr4d//AOeesrW798PNWvCgw9aGxo2hHXrcrfz0CGIjLQ6Q0Nh0qS/cPFERLJQgElEREREREqsqCj45BN7v3IlVKpkARm3Gz7+2IIwkyeDwwGxsbBtG1SrBqNG5a7rjTdgxw7YtAm2boWuXS1IBTBjBjzzjAWRvvsOli+3+iZOtPreftuCT1l98glUrAjr18OePdC0afbhbd9/D199Bd98A++9BytW2PoDB6BNG2vD5MnQpw+cPp297r59oX9/a8OmTbBmDbz/fgFcUBEpsTR+QURERERESqRTaek0aZvK8EH+TJniw7p1lhW0ejVUqAC1a8NVV1ngJiHB1oNlNFWpkru+FSssWNOkiS07nXDqlL1fuNACVpMmwe7dliWVlHTm9vXsadlJL70Ee/dCTIxlM2V48EEoXdqCUL16waefQnCwBcnuvNO26dIFfH1h+3bPfsnJsHYtHD8OY8fauqQkC0j17n1+11BEJIMCTCIiIiIiUqKkO12MiI5leVw8BxKS4Wgk3cccoU6dOkRE+NCnj2Us9exp2zudloHUpYstJyXBH3/krtfphJEjYfBgW05NhRMn7H3r1jYUrXNnC+Js3Hj2eZfmzIH58+Ghhyxg9Le/wU8/ecodWf6ac7kskJRzfc6yjHa63fD11+Dvb+uOHbPhgSIif5WGyImIiIiISIkyIjqWmet2s/9EMi43pP/jZ6LnV+GPv8dTty6cPGlD1qKibPtOnWxoWlqaBWsGDoTRo3PX26kTvPqqZ36mceNsKFpCAmzeDM8/b3UePGgZSU6nbedw5B7CBpaR1K+fzdd03XUQHe3ZB+Ctt6w9J07Y8LaICFv/66823A9sn9KlISTEs19gIDRvDtOm2XJCArRoAcuW/cULKiKCAkwiIiIiIlKCnEpLZ1lcfLZ1PnUOwPHL+LH8D5xKS6dDB6haFYKCrHzsWKhVCxo1gvr1Lftn6tTcdQ8YALfeasGbBg1sWNqCBTaEbfRom/w7ONjmRWrRwoJMYEGnu++GVauy1zd8OMybZ5lPrVrZ/hn7gA2zu/56O94//wnt29v6cuXgzTdtgu+JE2Hp0uwZTADvvGMTj4eE2NxPd9xhE42LiPxVGiInIiIiIiIlxpHEFOITkrOt86l2DJ/H3uQXHyt/5ZUK2cr9/GD27LPXXaoUPP20vXKaMMFe3rzwgr1yatnSJgTPy113eYbxZeXraxlYOY0f73lfq5ZnUnARkYKgDCYRERERESkxqgb6UaNiea9lQRUDqBrod5FbJCJSPCjAJCIiIiIiJYZ/GQfdgoO8lnULro5/maIxyCMmxnv2Uq1aZ386nYjIhVA0/vUUEREREREpIFMiwgFYHneQ+IQkgioG0C24euZ6ERE5fwowiYiIiIhIieLwLcX0Hk2Z2LURRxJTqBroV2Qyl6TkGjgQBg2C8Bxx0AULYMmSizen1osvQlycHVckKw2RExERERGREsm/jIPalSsouCRFwurV9gRDkUuVAkwiIiIiIiIiZxAWBp99Zu8XLYJy5SAlxZYHDIA5cyAtDYYNg8aNoWFD6NcPEhO91zdxom0XFgY9esDhw7Z+wwZo3RqaNYMaNeD++239k0/aNnfdBRs35q7vyBHo3BlCQyEiAv73P1vfti1ERUH9+vDSS3DyJIwfX5PwcNt22DBIT7dt//1vO26jRlCzpp0TwOnTMHgw1KkDN94IX32Vr0spxZgCTCIiIiIiIiJnEBUFn3xi71euhEqVYN06yyj6+GOIjITJk8HhgNhY2LYNqlWDUaNy1/XGG7BjB2zaBFu3QteuFqQCmDEDnnnGgkjffQfLl1t9EydafW+/bUGgnPbsgVmzYPt2CAmBoUM9ZZUqWV0PP2wBpbp1TxEbC99+C8eOwbRpNjH8K6/YuXz7Lbz3HjzxhO3/8stW/3ffWRbVgQMFemmlGFEuqIiIiIiIiEgeTqWl06RtKsMH+TNlig/r1sFjj1mwpUIFqF0brrrK5kBKSLD1YBlNVarkrm/FCgsuNWliy04nnDpl7xcutCDPpEmwe7dlSZ3LUwFvvtkyjMCynpo29ZS1apX92BUqXJHZxowsrIAAK/voI/jhBwt8ZRx3zRq4804oU8Zed91lgSyRnBRgEhEREREREckh3eliRHQsy+PiOZCQDEcj6T7mCHXq1CEiwoc+fSxjqWdP297ptAykLl1sOSkJ/vgjd71OJ4wcacPOAFJT4cQJe9+6tQ1d69wZeve2TKZzmXfJ19fz3uWC0qU9ywEB2Y/9/PM/0rNnA8ACYj4+cPAg3HADPPAAtGxp55R10vCsbXAoiiB5KLAhcm63m1atWtG3b1/69u3L1KlTAdi6dSu9evXi9ttvZ9asWQV1OBEREREREZELZkR0LDPX7Wb/iWRcbkj/x89Ez6/CH3+Pp25dm8/o7bdt+BxAp042TC0tzYI8AwfC6NG56+3UCV591TM/07hx0LevBXs2b4bnn7c6Dx6EvXstKAQW2Dl92ntbP//cM3Rt7lxPkMvbsd95pwputwW2unWzNm/ZAldcAf/3f9Cxoye45HRaXW+8YcGyP/6w4XMi3hRY7PHAgQM0aNCAuXPnZlv/1FNP8dJLLxEUFMQDDzzAzp07adCgQUEdVkRERERERKRAnUpLZ1lcfLZ1PnUO4N7SgB/Lb+FUWjU6dHCwfTsEBVn52LEwfLhNku102gTef+ZdZDNgABw6BM2bW/ZQjRqwYAFUrGgBqcaNoXx5qF4dWrSwIFP79hZ0uvtum3y7Y8fsdYaGQv/+Nrl3vXowb57385o5E/r2LUVIiAWrbr7Z5lo6fdom+b7uOihVCtq0sYDT3r3w4IP2MzgYLr8crrkmv1dXiqsCCzDt3LmTo0eP0rdvX8qVK8fo0aOpUqUKaWlp1KhRA4CWLVuyfv16BZhERERERETkknUkMYX4hORs63yqHcPnsTf5xcfKX3mlQrZyPz+YPfvsdZcqBU8/ba+cJkywlzcvvGCvnPr1s5c3MTHZlytXhgkT9hMefnm29aVL24TiWWUNUk2bZi+RM/Fxu89lRGd2ixcvZuHChdnWjRs3jt9++40uXbqwZcsWnnvuOWbPns3DDz/M4sWLAViyZAnx8fEMGzYsz7pTU1OJi4s73yaJiIhICfTdd/4sWHAVL7zw40U5XlJSKYYPr83cuT/kKtu5059lyyozZsyFf7zO0qWXc/p0KXr1+jXb+sOHy9CnT33Wrdt6wdsAdv1HjvwH0dH67iYixcsf6S76fLSXI8npucqqlnfw3i11KOfQQ9kvluDgYMqWLVvYzZCz+EsZTL169aJXr17Z1qWkpOD758xiTZo04ejRo5QvX57kZE/UNzk5mcDAwHM6hv4HMrGxsYSHhxd2M6QA6F4WH7qXxYvuZ9EWHm7zVkD4RbmX+/fDrl14Pc6OHTafRXj4FRe0DQAvvWRDFcLDa2Rbf/nl1jN+sf6fdrvtiUIFfTx9LosP3cvioyTey15HYOa63bnXN65Di2ZNvexRNBSle6kElKKlwEKus2bNysxq2r17N9WqVaNChQqULl2aAwcO4Ha7+fLLL2mS8SxGERERkXyKibFAS05hYfDZZ/Z+0SIoV87zKOYBA2z+ij17oEMHmwOjZk3o3t3ztJ9y5WD8eLjxRrj6atse4L77rJ6wMM+kqwDx8TZJ67p1tg3A/PnWtoYNba6MPXu8n0N0NDRrZnN2tGgB69fb+qNHoUcPe6rP1VdD27bwyy/w4Yc2jGH6dO9DMVwuO8dGjeD662HDBls/frxN7hoSYnN4AEycaHN9hIXZsQ4ftvUbNtiTjJo1s7lB7r/fU/+cOXDttfYI7Jdf9n5OIiLFwZSIcB5pVZdalQLw9YFalQJ4pFVdpkQUjeCMyMVWYHMwPfDAA4wYMYK1a9fi6+vLc889B8DTTz/N8OHDcTqdtGzZkoYNGxbUIUVERES8ioqCTz6xSVFXroRKlSz406EDfPyxzW8xdSrce68FW06ftmyojz6C226zTKTKleHrryE21gI/990Hr79uQaOtW7MfLygInnkGliyxbf77X5snY/16myR1wQIL4OzcaRO6ZvjhBxgzxgJll19u5TffbJOpvvuuBZdGjrRMoVtugTffhMcfh2XLrB1DhuQ+95QUO89XX4VVq6BXL9i3z8p+/hni4uxJRG+8YVlXmzbZ8vz5Fpj6+GN7zPYzz1hQKynJAlyxsfYY7PHjYds2uOoqGDToQtw9EZFLg8O3FNN7NGVi10YcSUyhaqAf/mUK7E9okWKnwD4dl112GfPnz8+1PiwsjPfff7+gDiMiIiIC2BN+Dp1Mw+X2A3yylUVGwu23w5QpFlh67DFYvRoqVIDatS048vzztu6FFyy76PBhC6Zk6N7dfjZubAGn5OxzvZ7RypXQp48Fl8AmXx061IbYXX21Z7vVq+HIEQuEZShVygJMQ4da26dNs0BUXJxlFJ1NxYp2bPA8ZWj3nyM8mje3YBLYI6g3bYKM5HKnE06dsvcLF1qgadIk2zclxa7Nli1W51VX2XYPPGDnKiJSnPmXcVC7coWzbyhSwin8KiIiIkVKutPFiOhYlsfFs39HAL7HmjFs6R5u/7snyBQSAmlpNpTsmmsgIsKCLg4H9Oxp29xxB6SnQ+/elh104IBlCmXw87OfGRlH5/NYFKfT5ibKyu22TKmc27VvD++951kXHw/Vqlnm0qZN9tjpdu1s33Npw59TYmZyuezpQAABAdmPPXIkDB5sy6mpcOKEvW/d2h553bmzXZ+NGz3HztoGh75JioiIyJ807b2IiIgUKSOiY5m5bjf7TyRb0MbpZua63cz85mi27SIjYdQoy7ipWxdOnoS337bhcwCffmrzJmVk+2zcmH1eJW8cDtvGW6DH4fAEkDp3tiFuv/75kLfXX7chcHXqZN+nfXsbxpaRYfTxxxbYSUmx9j36qE1iXqWKZTtltC/rsXL67TfLTgKb38nPz4JsOXXqZMPoEhNtedw4O1ZCAmzebBleUVFw8KBlVDmddi1XrbJ1YEP/REREREAZTCIiIlKEnEpLZ1lcvNeytYcSOZWWnjk/RmSkDZHr0MHKO3SA7dttviSw4V+RkVC+PFx2GbRpY4GUM6la1SbObtDAhq9dfrmnrHlzePppC8r85z8wbBjcdJNlEF1xhQV9SuXo2qtf3+Y+uv12C1o5HJZ1FRBgAZ/hw2HsWMtAatnS074uXWzYH8Do0dnrrFIFPvgA/u//wN/f3nvLNBowAA4dsnb7+Nhk3gsW2BC70aNtaGD58lC9us1BtXevBcReeMF+Vqhg10JEREQEwMftPp+E7wsv4zGEwcHBlC1btrCbU+iK0iMk5cx0L4sP3cviRfezaNl37HfqTl6Ky8u3l1LA7tE9NE9GMaDPZfGhe1l86F4WH0XpXio+ULRoiJyIiIgUGVUD/ahRsbzXsivLO6ga6HeRWyQiIiIioACTiIiIFCH+ZRx0Cw7yWtbm74F6fLSIiIhIIdG3MBERESlSpkRYWv/yuIPEJyQRVDGAbsHVsz1FTkREREQuLgWYREREpEhx+JZieo+mTOzaiCOJKVQN9MO/jIPY2NjCbpqIiIhIiaUAk4iIiBRJ/mUcmtBbRERE5BKhOZhERERERERERCRfFGASEREREREREZF8UYBJRERERERERETyRQEmERERERERERHJFwWYREREREREREQkXxRgEhERERERERGRfFGASURERERERERE8kUBJhERERERERERyRcFmEREREREREREJF8UYBIRERERERERkXxRgElERERERERERPJFASYp0bawhZ70LNQ23MqtLGCB17Iwwkgg4Yz7t6UtS1hS8A3LYiADiSX2gh5DREREREREii4FmKREa0KTCx6cyY+tbKUiFQu7GaxmNW7chd0MERERERERuUQpwCQlWgwxBBPstezf/JsGNCCUUG7iJuKJx4WLoQylGc2oT33qUY+v+AqAfvTjER6hHe2oQx2iiCKJpFz1HuYwHehAAxrQla78j/9llpWlLL3pzXVcxxa24IMPxzjGAhbQne5EEkkwwVzP9exiV7Z600mnN725i7tIJz1zvRMnV3AFe9kLwHM8R01qZpbfzM18widsYAOtaU0zmlGDGtzP/QA8yZMc5jB3cRcb2chJTtKPfoQTTiihDGNY5vFytl9ERERERERKBgWYRLzYxjZGMpKVrGQ72+lGNyYykY1s5DCHWc96vuM77uVeJjM5c79YYlnJSnaxi/3sZzGLc9U9hCE0pzk72clMZrKb3ZllaaQRQQTf8z1NaJJtv7Ws5SVeIo44mtEs23HTSKMXvahCFd7iLRw4Mst88SWCCFayEoCVrCSNNPawh5OcZBvbaE97ZjCDZ3iGjWzkO75jOcuJJZaJTKQa1Xibt2lGM4YxjHDCiSWWb/mWYxxjGtPO2n4REREREREpvhxn30SkeDqVls6hlFO4KpAr1PoZn9GJTgQRBMCjPJpZNoEJzGMe+9hHDDFUoEJmWWc6U5ayAIQQwnGO5zruGtbwIi8CUIc63MRN2cpb0cpre8MJpzrVAWhMY/7DfzLLHudxfud39rEPH3xy7RtJJHOZy73cy//4H3dyJ6tZzd/4G53pTBnKsJCFfMzHTGISu9lNCileM7BWsIJNbOI1XgMghZRzar+IiIiIiIgUXwowSYmT7nQxIjqW5XHx7L98C763JTLs681MiQjH4WuRJgeObIGaFFL4mZ/Zxz6GMpTHeZzudKcudXmLtzK388Mv870PPl7nLcq53pHjYxhAgNd2n6nuvvTFjZuBDGQ5y3Pt24EODGAAH/ERbWlLBzowhzn448/t3A5Aa1oTSiid6UxverORjV7b78TJYhZTj3oAJJCQ7Vrl1X4REREREREpvjRETkqcEdGxzFy3m/0nknG74bTTxcx1uxkR7XlKWjvasYY1HOEIAPOYxxM8wWpWE0EEgxlME5qwlKU4cZ7X8TvTmfnMB+AAB/icz/N9TtdzPc/yLHvZyyu8kqu8HOVoQxue5mk60pE2tGE961nHOjrRiQQS2Mxmnud5oojiIAfZy97Mc3Pg4DSnAehEJ6YzHTduUkmlG92Yxax8n4OIiIiIiIgUXQowSYlyKi2dZXHxXsuWxx3kVJpNVh1CCFOYQmc605CGrGQlc5nLIAYRQwwhhNCYxtSmNj/xEy5c59yG2czmO76jHvW4n/sJI6wgTo1ylGMBCxjBCPaxL1d5JJHsYQ83cRN++NGQhrSgBeUoR0UqMprRNKYxwQQzmcm0oEXmxOBRRHE3d7OKVcxkJskkE0IIoYQSQghP8ESBnIOIiIiIiIgUTT5ut/uSevZ4amoqcXFxBAcHU7Zs2cJuTqGLjY0lPDy8sJtRbOw79jt1Jy/F5eX/el8f2DWqB7UrV8hdWAB0L4sP3cviRfez+NC9LD50L4sP3cviQ/ey+ChK91LxgaJFGUxSolQN9KNGxfJey4IqBlA10M9rmYiIiIiIiIjkTQEmKVH8yzjoFhzktaxbcHX8y2jeexEREREREZHzpb+mpcSZEmHpoMvjDhKfkERQxQC6BVfPXC8iIiIiIiIi50cBJilxHL6lmN6jKRO7NuJIYgpVA/2UuSQiIiIiIiKSD/qrWkos/zKOCzaht4iIiIiIiEhJojmYREREREREREQkXxRgEhERERERERGRfFGASURERERERERE8kUBJhEREREpsbZsgZ49C66+V1+Fl18uuPryEhMDwcEX/jgiIiLnSgEmERERESmxmjSBJUsKrr4vv4RTpwquPhERkaJCASYRERERKbHOlAkUHQ3NmkGjRtCiBaxfb+uPHoUePeCGG+Dqq6FtW/jlF/jwQ1i+HKZPh9mzc9c3aZLVFxoKtWvb9gDjx8Pdd0ObNnDttdC7NyQmWlmtWjB6tAXC6tSBOXNy15uWBsOGQePG0LAh9Ovn2V9ERORiUYBJREREREqkU2npHDp5Cpfbnavshx9gzBj4+GP49luYPx+ioiA5Gd5914JL69fDjz+Cvz+8+SZERkK3bhbsGTIke30//wxr1lhAa/t2mDgRxo3zlK9dC++/D7t3g8MBzzzjKTt+HDZvtn3HjYMdO7LXPXmy7RMbC9u2QbVqMGpUgV0mERGRc+Io7AaIiIiIiFxM6U4XI6JjWR4Xz/4dAfgea8awpXuYEhGOw9f6X1evhiNHoH17z36lSsHevTB0KKxbB9OmWSAqLs4yk86kZk144w14+22rY8MGSErylPfqBVdeae/vvx8efRRefNGWhwwBHx+oXh06d4ZVqyA83LPvihWQkGBtBstoqlIlX5dIRETkvCnAJCIiIiIlyojoWGau2w2A2x3Aaac7c3l6j6YAOJ0WXHrvPc9+8fGWHTRyJGzaBP37Q7t2cPo0eEmCyuabb6B7d8tu6tjRhsMNHuwpd2T5Vu5yga/vuZVltHXGDOjSxZaTkuCPP87pUoiIiBQYDZETERERkRLjVFo6y+LivZYtjzvIqbR0wIJLq1bZkDWwoXKhoZCSAp9+ahlGfftaptDq1RbkAQsGnT6du+4vvrB5lB57zIJLS5d69gFYtgxOnrQA0iuvQESEp+yNN+zngQPWpoxAUoZOnWDWLMtccrlg4ECbt0lERORiUoBJREREREqMI4kpxCckey2LT0jiSGIKAPXr27xLt99uE2ePHWsTeAcE2DxIw4dbwKlbN2jZ0oa9gQV/5s6F557LXvcdd8CxY1CvntUdEGBzK/3+u5VfeSV07Wrll11m8z9l+OknGxLXuTPMnAnXXZe97rFjbTLwRo2sbrcbpk4tgIslIiJyHjRETkSkmNrCFiYzmSUU4PO3z+AkJ4kkkv/y31xlm9nMa7zGXOb+5fqXsIRZzCKGmFxl4xhHHepwD/fkuf8CFrCEJaxgxRmP44MPv/Irlan8l9sqIpeuqoF+1KhYnv0nLMjkE3QUn3ujAQiqGEDVQL/MbXv1sldOUVH28ua22+yV05VX2rxNWWUNAoWGWhaSNyNGWPZTVm3b2txPAH5+3p9aJyIicjEpg0lEpJhqQpOLFlwCOMEJNrHJa9lOdnKQgxfs2M/wzBmDSyIiGfzLOOgWHOS1rFtwdfzLqP9VRETkr1CASUSkmIohhmCCc60PI4zP+AyARSyiHOVIwYaEDGAAc5jDHvbQgQ40pzk1qUl3uvMHNmNsOcoxnvHcyI1czdXMYQ4A93EfKaQQRhhOPBOLxBPPOMaxjnXcx30AzGc+wQTTkIZ0pCN72OP1HMYxjtrU5nqu50M+zFzfj350oxsNaMBIRtKPfrzIi2dsX1ZLWEJtavM933s97pM8SWMaE0ZYtoyn13iNcMJpRCNu5mZ2Y5OzpJHGMIbRmMY0pCH96EciiQDUohZ96EM96mU7BxEpPFMiwnmkVV1qVQrA1wdqVQrgkVZ1mRIRfvadL4Dx4/POXtq/P3f2koiIyKVIASYRkRImiig+4RMAVrKSSlRiHetw4+ZjPiaSSF7hFe7lXjawgb3s5Sd+4iM+AiCVVCpTma/5miUsYRjD+IM/eJ3X8cOPrWzFF88jjoII4hmeoRWteJ3X+S//5QVe4HM+ZxvbuJM76UEP3GR/BNMylvEBH7CVrXzN15zkZLbyU5xiJzt5nuezrc+rfRkWsYjxjCeGGK4jx0Qmf/oH/+AbvuEt3uJe7uVXfmUta1nIQtaxjm/5lid4gkgiAZjMZBw4iCWWbWyjGtUYxajM+oIJZhe7MrcXkcLl8C3F9B5N2fFEBLtG9WDHExFM79EUh6++GouIiPxVygEWESmGTqWlcyjlFK4K5OpKiCSS27mdKUxhHet4jMdYzWoqUIHa1OYqruJ5nmc1q3mBF9jDHg5zmCSSMuvoTncAGtOYVFJJxvuEud6sZCV96MMVXAFYNtJQhrKf/VzN1ZnbrWENUURRgQoA9Kc/M5mZWd6SlnkeI6/2bWYzK1nJv/gXQXgfIgMwiEGABYbqU5/1rOdLvmQve7mRGzO3O8EJjnOcFawggQRWsxqwjKYqVMncrhWtzu3iiMhF5V/GQe3KFQq7GSIiIsWCAkwiIsVIutPFiOhYlsfFs//yLfjelsiwrzczJSI8s2c+hBDSSGM5y7mGa4gggj70wYGDnvQE4A7uIJ10etObW7iFAxzIlmHkh02C64MPQK7sozNx4qQMZbKtc+PmNLmf6521XkeOX1kBBOR5jLzaV5GKLGIRvenNrdxKLWp53T9rBpYLF6UpjRMnfembmTHlwsVhDlOJSjhxMoMZdMGeHZ5EUrasqTO1VURERESkOFAesIhIMTIiOpaZ63az/0QybjecdrqYuW43I6Jjs20XSSSjGEVHOlKXupzkJG/zNlHYY5E+5VPGMY4+9AFgIxuzzavkjQMHTpxeg00OHJkBpM505l3e5Vd+BeB1XudyLqcOdbLt04UuLGYxCSTgwsWbvPnXLkoW13ANN3ETD/Mw93APLlxet1vAAgC+4Rv2spdmNKMTnVjEIo5wBIC5zKU97QHoRCdmMYs00nDhYiADGc3ofLdXRERERKSoUIBJRKSYOJWWzrK4eK9ly+MOciotPXM5kkh2s5sOdACgAx2oStXMYWOTmEQkkYQQwoM8SBvasJe9Zzx+VapyPdfTgAb8xm/ZyprTnB/5kSii6EAHhjGMm7iJBjRgIQtZwQpK5fiV1JWu9Kc/TWhCM5pxGZed9zXJy5M8STLJTGGK1/If+ZFGNGIAA3iXd/kbf6MjHRnJSDrQgVBCeYd3+A//wQcfxjKWWtSiEY2oT33cuJnKVK91i4iIiIgURz5ut/vcxzVcBKmpqcTFxREcHEzZsmULuzmFLjY2lvDwwnmiiRQs3cvi41K9l/uO/U7dyUtxeflX3dcHdo3qoblGvLhU76ecP93L4kP3svjQvSw+dC+Lj6J0LxUfKFqUwSQiUkxUDfSjRsXyXsuCKgZQNdDvIrdIRERERERKCgWYRESKCf8yDroFe38yWrfg6viX0XMdRERERETkwtBfGyIixciUCEt3Xh53kPiEJIIqBtAtuHrmehERERERkQtBASYRkWLE4VuK6T2aMrFrI44kplA10E+ZSyIiIiIicsHprw4RkWLIv4xDE3qLiIiIiMhFozmYREREREREREQkXxRgEhERERERERGRfFGASURERERERERE8kUBJhERERERERERyRcFmEREREREREREJF8UYBIRERERERERkXxRgElERERERERERPJFASYREREREREREckXBZhERERERERERCRfFGASEREREREREZF8UYBJREREREQkiy1boGfPwm7FuenYEY4du/DHGT++Ji++eOGPIyJFlwJMIiIiIiIiWTRpAkuWFHYrzs3q1YXdAhERowCTiIiIiIhIFjExEBzsvezf/4YGDSA0FG66CeLjweWCoUOhWTOoXx/q1YOvvrLt+/WDRx6Bdu2gTh2IioKkpNz1pqXBsGHQuDE0bGj7JSZa2YoVcOONFviqUQPGjrX1991nP9u1s3ZkdfQo9OgBN9wAV18NbdvCL79YWa1aMHq01VenDsyZ4znvZs2gd287v2bNYNeu3G3dtcsyp8LDISzMromIiAJMIiIiIiIi52DbNhg5ElauhO3boVs3mDgRNm6Ew4dh/Xr47ju4916YPNmzX2ys7bNrF+zfD4sX56578mRwOGzbbdugWjUYNQrcbpg6FRYutKF7GzbAc8/ZsLjXX7d9P/8cgoKy1/fuuxZcWr8efvwR/P3hzTc95cePw+bNFlQaNw527LD1W7bAww/b+d13H/Ttm73e9HQbPjh5srV17Vp48UVrl4iUbI7CboCIiIiIiMil4lRaOodOpuFy+wE+2co++ww6dfIEcx591FM2YQLMmwf79lnQpkIFT1nnzlC2rL0PCbHgTk4rVkBCgmfIW1oaVKkCPj4QHW3l77xjQSq3G5KToXLlvM9j6FBYtw6mTYMffoC4OMtIyjBkiNVdvbq1b9Uqy0hq2BBatbJt+ve37X77zbPfnj12jv37e9alpMC330Lz5nm3R0SKPwWYRERERESkxEt3uhgRHcvyuHj27wjA91gzhi3dw5SIcBy+NvDD4bCgTIaUFPj5Zwu4DB0Kjz8O3btD3brw1lue7fz8PO99fCxAlJPTCTNmQJcutpyUBH/8YYGkRo0gMtICP/37w9Kl3uvIauRI2LTJtm/XDk6fzr6PI8tfgi4X+PrmXp+xfUZZRjsvuwy2bvWsO3rU1olIyaYhciIiIiIiUuKNiI5l5rrd7D+RjNsNp51uZq7bzYjo2Mxt2rWDNWvgyBFbnjcPnnjCso4iImDwYJvXaOlSC8Scj06dYNYsy1xyuWDgQJsn6YcfbC6mCRPsGDExkJrqqd/X14JHOX36qWVY9e1rmVCrV2dv0xtv2M8DByx7KSOwtXWrDY8DmD/f5n6qWNGz33XXWcAsI4AWH2/zVcV6LpOIlFAKMImIiIiISIl2Ki2dZXHxXsuWxx3kVFo6YMPbpkyxIWUNG9q8SnPnwqBBFvgJCbFJumvXhp9+skDRuRo71ibfbtTIJgrPmHspNBRuvdWyourVs+Fy9evD3r22X69e0KaNDYHLatw4GD7c9u/WDVq29OwD1r7wcDuXmTMtcARw1VXw5JN2LkuXZp+3CaBMGVi2DF591eru2BGefRZatDj3cxWR4klD5EREREREpEQ7kphCfEJy5rJP0FF87o0GID4hiSOJKdSubJMq3X23vbKqVs3mIMpqxgz7uWBB9vU5lzP4+cHs2d7LXnst77YvWuR9fVSUvfIyYoRlW+UUGGhBrJzGj/+Z8HCb9KlhQwuoiYhkpQwmEREREREp0aoG+lGjYnmvZUEVA6ga6Oe1TEREPBRgEhERERGREs2/jINuwUFey7oFV8e/TPEa+LF/v/fspbZtcw+1ExE5V8XrX0oREREREZG/YEpEOGBzLsUnJBFUMYBuwdUz14uIyJkpwCQiIiIiIiWew7cU03s0ZWLXRhxJTKFqoF+xy1wSEbmQ9C+miIiIiIjIn/zLODIn9BYRkXOnOZhERERERERERCRfFGASEREREREREZF8UYBJRERERERERETyRQEmERERERERERHJFwWYREREpEjasgV69izsVpybjh3h2LHc68ePh4ceunjteOghO6aIiIhIQVOASURERIqkJk1gyZLCbsW5Wb26sFsgIiIicmEpwCQiIiJFUkwMBAd7L/v3v6FBAwgNhZtugvh4cLlg6FBo1gzq14d69eCrr2z7fv3gkUegXTuoUweioiApKXe9aWkwbBg0bgwNG9p+iYlWtmIF3HijBb5q1ICxY239fffZz3btrB057doFrVvbufTtC7//butr1YI+faydH34Ihw5BZCSEh9t5TZrkqWPSJDuv0FCoXdu2B2tb795w3XXQti3s3n3Ol1dERETkvCjAJCIiIsXKtm0wciSsXAnbt0O3bjBxImzcCIcPw/r18N13cO+9MHmyZ7/YWNtn1y7Yvx8WL85d9+TJ4HDYttu2QbVqMGoUuN0wdSosXGhD9zZsgOees2Fxr79u+37+OQQF5a5z71744APYscPqmTDBUxYcbO2JjLTgU//+duxNm2DNGnj/ffj5Z3sfE2PnO3EijBtn+z/1FPj5WWBp8WL4/vuCusoiIiIi2TkKuwEiIiIi5+tUWjqHTqbhcvsBPtnKPvsMOnXyBHMefdRTNmECzJsH+/ZZQKZCBU9Z585Qtqy9DwmB48dzH3fFCkhI8Ax5S0uDKlXAxweio638nXcsKOR2Q3IyVK585nOJioIrrrD3990HI0bA88/bcqtW9jM5GdautTZlZEYlJcHWrZah9MYb8PbbFqzasMGTfbVmDfzrX9a+K66wQJWIiIjIhaAMJhERESky0p0uhi3dTMgLy7nnnS/ZeyyRYUs3k+50ZW7jcFhAJUNKimXwfPQR3HKLreveHQYNsiBQBj8/z3sfn+xlGZxOmDHDAjtbt1om0ZIlFgBq1Ai++caGz02ZAqVLe68jJ19fz3uXy/bLEBDgOa7bDV9/7Tn2hg0wZowd84YbbDhcx46WvZX1uFnfO9S1KCIiIheIAkwiIiJSZIyIjmXmut3sP5GM2w2nnW5mrtvNiOjYzG3atbPMnSNHbHnePHjiCcs6ioiAwYNtnqSlSy1wcz46dYJZsyxzyeWCgQNh9Gj44QcL8EyYYMeIiYHUVE/9vr5w+rT3OpcvhxMnbNtXXoEuXXJvExgIzZvDtGm2nJAALVrAsmXwxRd2Po89Bm3aZD+vLl3gtdesrSdO2PYiIiIiF4ICTCIiIlIknEpLZ1mcl1mygeVxB/kj3bKYQkIsg6hzZ5uIe+VKmDvXMpZiYqy8cWObDPunnyz4cq7GjrXJtxs1sonCM+ZeCg2FW2+FunVtUu7oaCvfu9f269XLgj9xcbnrrF/f9g0JgYoVbU4nb955x7KWQkJsQu877oC77rKfx47ZcevXt6yn48dtsvDx4y0jqm5dC3yFhJz7uYqIiIicDyVKi4iISJFwJDGF+ITkzGWfoKP43BsNQHxCEsdS0jPL7r7bXllVqwbffpt93YwZ9nPBguzrcy5n8POD2bO9l732Wt5tX7TI+/rx4/PeZ//+7Mu1atkcTzldeSWsW5d93dSpnvdvvJH3MUREREQKijKYREREpEioGuhHjYrlvZYFVQygsp/6zUREREQKiwJMIiIiUiT4l3HQLTjIa1m34OqUc+hrjYiIiEhh0TcxERERKTKmRITzSKu61KoUgK8P1KoUwCOt6jIlIrywmyYiIiJSoimXXERERIoMh28ppvdoysSujTiSmELVQD/8y+jrjIiIiEhh0zcyERERKXL8yzioXblCYTdDRERERP6kIXIiIiIiIiIiIpIvCjCJiIiIiIiIiEi+KMAkIiIiIiIiIiL5ogCTiIiIiIiIiIjkiwJMIiIiIiIiIiKSLwowiYiIiIiIiIhIvijAJCIiIiIiIiIi+aIAk4iIiIiIiIiI5IsCTCIiIiIiIiIiki8KMImIiIiIiIiISL4owCQiIiIiIiIiIvmiAJOIiIiIiIiIiOSLAkwiIiIiIiIiIpIv+QowrV69mscffzxzeevWrfTq1Yvbb7+dWbNmZa6fNWsWPXv25Pbbb2f79u35OaSIiIiIiIiIiFxiHH91xwkTJvDll19Sr169zHVPPfUUL730EkFBQTzwwAPs3LkTgE2bNrF48WKOHDnCww8/zAcffJD/louIiIiIiIiIyCXhLweYGjduzM0338x7770HQFJSEmlpadSoUQOAli1bsn79esqUKUPLli3x8fGhWrVqOJ1Ojh8/zt/+9reCOQMRERERERERESlUZw0wLV68mIULF2ZbN2nSJLp27crGjRsz1yUlJREQEJC5XL58eeLj4ylbtiwVK1bMtv73338/a4ApLi7uXM+h2IuNjS3sJkgB0b0sPnQvixfdz+JD97L40L0sPnQviw/dy+JD91IuhLMGmHr16kWvXr3OWlFAQADJycmZy8nJyQQGBlK6dOlc6ytUqHDW+oKDgylbtuxZtyvuYmNjCQ8PL+xmSAHQvSw+dC+LF93P4kP3svjQvSw+dC+LD93L4qMo3cvU1FQlnxQhBfYUuYCAAEqXLs2BAwdwu918+eWXNGnShMaNG/Pll1/icrk4fPgwLpdLw+NERERERERERIqRvzwHkzdPP/00w4cPx+l00rJlSxo2bAhAkyZN6NOnDy6Xi3HjxhXkIUVEREREzsuWLTB5MixZUjD1vfoqpKXBP/+Zff3+/RAcDElJBXOcs9myBXr2tOOKiIhcbPkKMDVr1oxmzZplLoeFhfH+++/n2u7hhx/m4Ycfzs+hREREREQKRJMmBRdcAvjySwskiYiIlGQFNkRORERERKQoiInJOyAUHQ3NmkGjRtCiBaxfb+uPHoUePeCGG+Dqq6FtW/jlF/jwQ1i+HKZPh9mzc9fncsGAAVbf9dfDhg22fvx46NQJQkLg7rtt3cSJ0LgxhIXZsQ4ftvUbNkDr1tauGjXg/vs99c+ZA9deC02bwssv5/fKiIiI/HUFOkRORERERKSo+uEHGDPGAlCXXw47d8LNN8PevfDuuxZcGjkS3G645RZ48014/HFYtswCVkOG5K4zJQU6dLBhdKtWQa9esG+flf38M8TFgcMBb7wBO3bApk22PH++BaY+/hhmzIBnnrGgVlKSBbhiY8HX1wJV27bBVVfBoEEX8WKJiIjkoACTiIiIiJQYp9LSOXQyDZfbD/DJVrZ6NRw5Au3be9aVKmUBpqFDYd06mDbNAlFxcZZRdDYVK0KfPva+Y0f7uXu3/Wze3IJJACtWWHCpSRNbdjrh1Cl7v3ChBZomTbJ9U1Is0LRli9V51VW23QMPwMqV531JRERECoQCTCIiIiJS7KU7XYyIjmV5XDz7dwTge6wZw5buYUpEOA5fmzXC6bTg0nvvefaLj4dq1SxzadMm6N8f2rWD06ctk+lsfH2zL7tcULq0vQ8I8Kx3Ou0YgwfbcmoqnDhh71u3htBQ6NwZeveGjRs9x87aBoe+2YuISCHSHEwiIiIiUuyNiI5l5rrd7D+RjNsNp51uZq7bzYjo2Mxt2re3YWwZGUYff2yBnZQU+PRTePRR6NsXqlSxbCen07ZzOCzg5M1vv1l2Etj8Tn5+cM01ubfr1MmG0SUm2vK4cXashATYvBmefx6iouDgQcuocjote2nVKlsHsGBBfq+SiIjIX6d+DhEREREp1k6lpbMsLt5r2fK4g0zs2gj/Mg7q17e5j26/3TKDHA6bwDsgwAI+w4fD2LGWgdSypQV6ALp0gcces/ejR2evv0oV+OAD+L//A39/e+8t02jAADh0yIbN+fjYZN4LFtgQu9GjbfLv8uWhenWbfHzvXguIvfCC/axQwSYRFxERKSwKMImIiIhIsXYkMYX4hOTMZZ+go/jcGw1AfEISRxJTqF25AmCTcPfqlbuOqCh7eXPbbfbKqVYte/qcN+PHZ18uVQqeftpeOU2YYC9v+vWzl4iISGHTEDkRERERKdaqBvpRo2J5r2VBFQOoGuh3kVskIiJS/CjAJCIiIiLFmn8ZB92Cg7yWdQuujn8ZJfWLiIjkl36bioiIiEixNyUiHLA5l+ITkgiqGEC34OqZ60VERCR/FGASERERkWLP4VuK6T2aMrFrI44kplA10E+ZSyIiIgVIv1VFREREpMTwL+PInNBbRERECo7mYBIRERERERERkXxRgElERERERERERPJFASYREREREREREckXBZhERERERERERCRfFGASEREREREREZF8UYBJRERERERERETyRQEmERERERERERHJFwWYREREREREREQkXxRgEhERERERERGRfFGASURERERERERE8kUBJhERERERERERyRcFmEREREREREREJF8UYBIRERERERERkXxRgElERERERERERPJFASYREREREREREckXBZhERERERERERCRfFGASEREREREREZF8UYBJRERERERERETyRQEmERERERERERHJF0dhNyAnt9sNQFpaWiG35NKRmppa2E2QAqJ7WXzoXhYvup/Fh+5l8aF7WXzoXhYfupfFR1G5lxlxgYw4gVzafNyX2J36/fff2bNnT2E3Q0REREREREQuAddeey0VKlQo7GbIWVxyASaXy0VycjKlS5fGx8ensJsjIiIiIiIiIoXA7XZz+vRpypcvT6lSmuHnUnfJBZhERERERERERKRoUQhQRERERERERETyRQEmERERERERERHJFwWYREREREREREQkXxRgEhERERERERGRfHEUdgMku9WrV7Ny5UqmTp0KwNatW5k4cSK+vr60bNmShx56CIBZs2YRExODw+FgzJgxhIaGFmazJQ/z589n3bp1ACQmJnLs2DG++uorVq1axQsvvEDVqlUBePjhh7n++usLs6lyFm63m9atW1OrVi0AwsLCePzxx/P8jMql6/fff2fEiBEkJSVx+vRpRo0aRaNGjfS5LKJcLhfjx4/n+++/p0yZMkyYMIGaNWsWdrPkHJ0+fZoxY8Zw6NAh0tLSGDx4MFdddRWDBg3K/Pf2jjvuoGvXroXbUDlnPXr0yHyUePXq1Rk0aBCjRo3Cx8eHa665hqeeekpPgioC/vOf//Dhhx8CkJqayq5du3j33Xf12Sxitm3bxosvvsibb77Jzz//7PWz+P777/Puu+/icDgYPHgw7dq1K+xmS1HmlkvGs88+6+7UqZP70UcfzVzXrVs3988//+x2uVzuAQMGuOPi4txxcXHuvn37ul0ul/vQoUPuqKioQmy1nKsHHnjA/cUXX7jdbrd72rRp7pUrVxZyi+R87N+/3/3ggw/mWu/tMyqXthkzZrhff/11t9vtdu/bt8/do0cPt9utz2VR9emnn7pHjhzpdrvd7m+//dY9aNCgQm6RnI8lS5a4J0yY4Ha73e7jx4+727Rp437//ffdr732WiG3TP6KP/74w929e/ds6x588EH3hg0b3G632z127Fj3qlWrCqFlkh/jx493v/vuu/psFjHz589333rrre5evXq53W7vn8VffvnFfeutt7pTU1PdiYmJme9F/ip1H1xCGjduzPjx4zOXk5KSSEtLo0aNGvj4+NCyZUvWr19PbGwsLVu2xMfHh2rVquF0Ojl+/HjhNVzOatWqVQQGBtKqVSsAdu7cyQcffMCdd97J5MmTSU9PL+QWytns3LmTo0eP0rdvXwYOHMiPP/6Y52dULm39+vXj9ttvB8DpdFK2bFlAn8uiKjY2NvPf1rCwMOLi4gq5RXI+OnfuzNChQzOXfX19iYuLIyYmhrvuuosxY8aQlJRUiC2U87F7925SUlLo378/99xzD1u3bmXnzp2Z2aCtW7fm66+/LuRWyvnYsWMHe/fupU+fPvpsFjE1atTgpZdeylz29lncvn07jRo1okyZMlSoUIEaNWqwe/fuwmqyFAMaIlcIFi9ezMKFC7OtmzRpEl27dmXjxo2Z65KSkggICMhcLl++PPHx8ZQtW5aKFStmW//777/zt7/97YK3XfKW130NDQ1l3rx5TJs2LXN9ixYtuPnmm6levTpPPfUU7777LnfffffFbrLkwdu9HDduHA888ABdunRhy5YtjBgxgtmzZ3v9jMql40yfy19//ZURI0YwZswYQJ/Loirn70pfX1/S09NxOPQVpygoX748YPfxkUce4dFHHyUtLY1evXoRHBzMnDlzmD17NiNHjizklsq5KFeuHPfffz+9evVi//79DBw4ELfbjY+PD+D5zipFx7x58xgyZAgAoaGh+mwWIZ06deLgwYOZy94+i0lJSZlDWjPWK3Ao+aFvX4WgV69e9OrV66zbBQQEkJycnLmcnJxMYGAgpUuXzrU+6z8MUjjyuq979+4lMDAw25wgt912G4GBgQC0b9+eTz/99KK1U87O271MSUnB19cXgCZNmnD06FHKly/v9TMql468Ppfff/89jz32GE888URmb54+l0VTzt+VLpdLwaUi5siRIwwZMoQ777yTiIgIEhMTMz+LHTp04Nlnny3kFsq5uvrqq6lZsyY+Pj5cffXVVKxYkZ07d2aW6/dk0ZKYmMiPP/5I8+bNAfs86rNZdGWd+yzjs+jt7039XSn5oSFyl7CAgABKly7NgQMHcLvdfPnllzRp0oTGjRvz5Zdf4nK5OHz4MC6XS9lLl7Cvv/6a1q1bZy673W66devG//73PwDWr19PgwYNCqt5co5mzZqVmQmze/duqlWrRoUKFbx+RuXStnfvXoYOHcrUqVNp06YNoM9lUda4cWO++OILwB6Mce211xZyi+R8HDt2jP79+zNixAh69uwJwP3338/27dsBfRaLmiVLljB58mQAjh49SlJSEi1atMjM0P/iiy/0e7II2bx5MzfeeGPmsj6bRVv9+vVzfRZDQ0OJjY0lNTWV33//nX379un3qOSLuvgucU8//TTDhw/H6XTSsmVLGjZsCFgGRZ8+fXC5XIwbN66QWyln8tNPP9GiRYvMZR8fHyZMmMBDDz1EuXLlqF27Nr179y7EFsq5eOCBBxgxYgRr167F19eX5557Dsj7MyqXrqlTp5KWlsbEiRMBC+bPmTNHn8siqkOHDnz11VfcfvvtuN1uJk2aVNhNkvMwd+5cEhMTefnll3n55ZcBGDVqFJMmTaJ06dJUrlxZWRJFSM+ePRk9ejR33HEHPj4+TJo0iUqVKjF27FimTZvGP/7xDzp16lTYzZRz9NNPP1G9evXM5fHjx/Pss8/qs1lEjRw5Mtdn0dfXl759+3LnnXfidrsZNmxY5tyUIn+Fj9vtdhd2I0REREREREREpOjSEDkREREREREREckXBZhERERERERERCRfFGASEREREREREZF8UYBJRERERERERETyRQEmERERERERERHJFwWYREREREREREQkXxRgEhERERERERGRfFGASURERERERERE8uX/AQbHA3mjhl18AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 1332x756 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_on_vis_multi([],[],valid_sentences_embeddings,valid_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(36, 64)\n",
      "(36,)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x396 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:title={'center':'How output of encoder looks'}>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid_sentences = []\n",
    "for i in range(len(tabular_set)):\n",
    "    valid_sentences.append(\" \".join( tabular_set[i].src) )\n",
    "    \n",
    "from matplotlib.axes._axes import _log as matplotlib_axes_logger\n",
    "matplotlib_axes_logger.setLevel('ERROR')\n",
    "    \n",
    "#all_encoder_states[0].shape\n",
    "from yellowbrick.text import TSNEVisualizer\n",
    "print(np.array(valid_sentences_embeddings).shape )\n",
    "print(np.array(valid_sentences).shape )\n",
    "\n",
    "Xs = valid_sentences_embeddings\n",
    "Ys = valid_sentences\n",
    "tsne = TSNEVisualizer(labels=valid_sentences,title=\"How output of encoder looks\",random_state=42)\n",
    "\n",
    "fitted = tsne.fit(np.array(Xs), Ys)\n",
    "tsne.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1332x756 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "result = fitted.transformer_.fit_transform(np.array(valid_sentences_embeddings))\n",
    "\n",
    "import matplotlib\n",
    "fig = matplotlib.pyplot.gcf()\n",
    "fig.set_size_inches(18.5, 10.5)\n",
    "\n",
    "#scatter result words\n",
    "plt.scatter(result[:, 0], result[:, 1])\n",
    "words = list(valid_sentences)\n",
    "#put an annotation on x,y cordinates for words\n",
    "for i, word in enumerate(words):\n",
    "    if \"eat\" in word:\n",
    "        plt.annotate(word, xy=(result[i, 0], result[i, 1]),color='#0000ff')\n",
    "    elif \"drink\" in word:\n",
    "        plt.annotate(word, xy=(result[i, 0], result[i, 1]),color='#00ff00')    \n",
    "    else:\n",
    "        plt.annotate(word, xy=(result[i, 0], result[i, 1]),color='#ff0000')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "48ekHi7yXfBL",
    "outputId": "77ae0249-9a00-49c2-af11-6d28268f19e2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using existing logger\n",
      "src = ['i', 'can', 'drink', 'water']\n",
      "trg = ['ich', 'konnen', 'wasser', 'trinken']\n",
      "predicted trg = ['ich', 'konnen', 'wasser', 'trinken', '<eos>']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcelikkaya\\Anaconda3\\envs\\p37_tensor23\\lib\\site-packages\\ipykernel_launcher.py:17: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "C:\\Users\\mcelikkaya\\Anaconda3\\envs\\p37_tensor23\\lib\\site-packages\\ipykernel_launcher.py:18: UserWarning: FixedFormatter should only be used together with FixedLocator\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1800 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "add_new_logger(\"sample1\")\n",
    "example_idx = 8\n",
    "\n",
    "src = vars(train_data.examples[example_idx])['src']\n",
    "trg = vars(train_data.examples[example_idx])['trg']\n",
    "\n",
    "print(f'src = {src}')\n",
    "print(f'trg = {trg}')\n",
    "\n",
    "currentLogger = StepLogger(100)  \n",
    "translation, attention = translate_sentence(src, SRC, TRG, model, device,is_appy_attention=True)\n",
    "\n",
    "print(f'predicted trg = {translation}')\n",
    " \n",
    "display_attention(src, translation, attention,n_heads=2,n_rows = 1, n_cols = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WgCueVClm0Ju",
    "outputId": "215f978f-c8a3-43e6-c64a-bc3ae419752e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "paC1v43zjJ0y",
    "outputId": "94fab67c-993e-49c4-cec4-5ddc0fb0ca6c"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['training', 'test_loss', 'sample1'])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loggers.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "-OcMDqgWjLu2",
    "outputId": "2a883b80-c016-4ff7-840c-37d4240a37f5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_count 1    self.capacity  20\n",
      "0  ------------------------------------------------\n",
      "Encoder@src\n",
      "[8, 7]\n",
      "Encoder@pos\n",
      "[8, 7]\n",
      "encoder@Q\n",
      "[8, 2, 7, 32]\n",
      "encoder@K\n",
      "[8, 2, 7, 32]\n",
      "encoder@V\n",
      "[8, 2, 7, 32]\n",
      "encoder@energy\n",
      "[8, 2, 7, 7]\n",
      "encoder@mask\n",
      "[8, 1, 1, 7]\n",
      "encoder@attention\n",
      "[8, 2, 7, 7]\n",
      "encoder@x1\n",
      "[8, 2, 7, 32]\n",
      "encoder@x2\n",
      "[8, 7, 2, 32]\n",
      "encoder@x3\n",
      "[8, 7, 64]\n",
      "encoder@x4\n",
      "[8, 7, 64]\n",
      "PositionwiseFeedforwardLayer@x1\n",
      "[8, 7, 128]\n",
      "PositionwiseFeedforwardLayer@x2\n",
      "[8, 7, 64]\n",
      "EncoderLayer@_src\n",
      "[8, 7, 64]\n",
      "EncoderLayer@src2\n",
      "[8, 7, 64]\n",
      "EncoderLayer@_src2\n",
      "[8, 7, 64]\n",
      "EncoderLayer@src3\n",
      "[8, 7, 64]\n",
      "EncoderLayer@src_mask\n",
      "[8, 1, 1, 7]\n",
      "EncoderLayer@sattention\n",
      "[8, 2, 7, 7]\n",
      "Encoder@src_final\n",
      "[8, 7, 64]\n",
      "decoder_self@Q\n",
      "[8, 2, 5, 32]\n",
      "decoder_self@K\n",
      "[8, 2, 5, 32]\n",
      "decoder_self@V\n",
      "[8, 2, 5, 32]\n",
      "decoder_self@energy\n",
      "[8, 2, 5, 5]\n",
      "decoder_self@mask\n",
      "[8, 1, 5, 5]\n",
      "decoder_self@attention\n",
      "[8, 2, 5, 5]\n",
      "decoder_self@x1\n",
      "[8, 2, 5, 32]\n",
      "decoder_self@x2\n",
      "[8, 5, 2, 32]\n",
      "decoder_self@x3\n",
      "[8, 5, 64]\n",
      "decoder_self@x4\n",
      "[8, 5, 64]\n",
      "decoder_encoder_attention@Q\n",
      "[8, 2, 5, 32]\n",
      "decoder_encoder_attention@K\n",
      "[8, 2, 7, 32]\n",
      "decoder_encoder_attention@V\n",
      "[8, 2, 7, 32]\n",
      "decoder_encoder_attention@energy\n",
      "[8, 2, 5, 7]\n",
      "decoder_encoder_attention@mask\n",
      "[8, 1, 1, 7]\n",
      "decoder_encoder_attention@attention\n",
      "[8, 2, 5, 7]\n",
      "decoder_encoder_attention@x1\n",
      "[8, 2, 5, 32]\n",
      "decoder_encoder_attention@x2\n",
      "[8, 5, 2, 32]\n",
      "decoder_encoder_attention@x3\n",
      "[8, 5, 64]\n",
      "decoder_encoder_attention@x4\n",
      "[8, 5, 64]\n",
      "DecoderLayer@_trg1\n",
      "[8, 5, 64]\n",
      "DecoderLayer@trg2\n",
      "[8, 5, 64]\n",
      "DecoderLayer@_trg2\n",
      "[8, 5, 64]\n",
      "DecoderLayer@trg3\n",
      "[8, 5, 64]\n",
      "DecoderLayer@_trg3\n",
      "[8, 5, 64]\n",
      "DecoderLayer@trg4\n",
      "[8, 5, 64]\n",
      "DecoderLayer@attention\n",
      "[8, 2, 5, 7]\n",
      "Decoder@pos\n",
      "[8, 5]\n",
      "Decoder@trg\n",
      "[8, 5, 64]\n",
      "Decoder@output\n",
      "[8, 5, 17]\n",
      "Decoder@attention\n",
      "[8, 2, 5, 7]\n",
      "Seq2Seq@src_mask\n",
      "[8, 1, 1, 7]\n",
      "Seq2Seq@trg_mask\n",
      "[8, 1, 5, 5]\n",
      "Seq2Seq@enc_src\n",
      "[8, 7, 64]\n",
      "Seq2Seq@output\n",
      "[8, 5, 17]\n",
      "Seq2Seq@attention\n",
      "[8, 2, 5, 7]\n"
     ]
    }
   ],
   "source": [
    "loggers[\"training\"].get_default_summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "x5xDzil4jOpB"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_count 1    self.capacity  20\n",
      "0  ------------------------------------------------\n",
      "Encoder@src\n",
      "[8, 5]\n",
      "Encoder@pos\n",
      "[8, 5]\n",
      "encoder@Q\n",
      "[8, 2, 5, 32]\n",
      "encoder@K\n",
      "[8, 2, 5, 32]\n",
      "encoder@V\n",
      "[8, 2, 5, 32]\n",
      "encoder@energy\n",
      "[8, 2, 5, 5]\n",
      "encoder@mask\n",
      "[8, 1, 1, 5]\n",
      "encoder@attention\n",
      "[8, 2, 5, 5]\n",
      "encoder@x1\n",
      "[8, 2, 5, 32]\n",
      "encoder@x2\n",
      "[8, 5, 2, 32]\n",
      "encoder@x3\n",
      "[8, 5, 64]\n",
      "encoder@x4\n",
      "[8, 5, 64]\n",
      "PositionwiseFeedforwardLayer@x1\n",
      "[8, 5, 128]\n",
      "PositionwiseFeedforwardLayer@x2\n",
      "[8, 5, 64]\n",
      "EncoderLayer@_src\n",
      "[8, 5, 64]\n",
      "EncoderLayer@src2\n",
      "[8, 5, 64]\n",
      "EncoderLayer@_src2\n",
      "[8, 5, 64]\n",
      "EncoderLayer@src3\n",
      "[8, 5, 64]\n",
      "EncoderLayer@src_mask\n",
      "[8, 1, 1, 5]\n",
      "EncoderLayer@sattention\n",
      "[8, 2, 5, 5]\n",
      "Encoder@src_final\n",
      "[8, 5, 64]\n",
      "decoder_self@Q\n",
      "[8, 2, 4, 32]\n",
      "decoder_self@K\n",
      "[8, 2, 4, 32]\n",
      "decoder_self@V\n",
      "[8, 2, 4, 32]\n",
      "decoder_self@energy\n",
      "[8, 2, 4, 4]\n",
      "decoder_self@mask\n",
      "[8, 1, 4, 4]\n",
      "decoder_self@attention\n",
      "[8, 2, 4, 4]\n",
      "decoder_self@x1\n",
      "[8, 2, 4, 32]\n",
      "decoder_self@x2\n",
      "[8, 4, 2, 32]\n",
      "decoder_self@x3\n",
      "[8, 4, 64]\n",
      "decoder_self@x4\n",
      "[8, 4, 64]\n",
      "decoder_encoder_attention@Q\n",
      "[8, 2, 4, 32]\n",
      "decoder_encoder_attention@K\n",
      "[8, 2, 5, 32]\n",
      "decoder_encoder_attention@V\n",
      "[8, 2, 5, 32]\n",
      "decoder_encoder_attention@energy\n",
      "[8, 2, 4, 5]\n",
      "decoder_encoder_attention@mask\n",
      "[8, 1, 1, 5]\n",
      "decoder_encoder_attention@attention\n",
      "[8, 2, 4, 5]\n",
      "decoder_encoder_attention@x1\n",
      "[8, 2, 4, 32]\n",
      "decoder_encoder_attention@x2\n",
      "[8, 4, 2, 32]\n",
      "decoder_encoder_attention@x3\n",
      "[8, 4, 64]\n",
      "decoder_encoder_attention@x4\n",
      "[8, 4, 64]\n",
      "DecoderLayer@_trg1\n",
      "[8, 4, 64]\n",
      "DecoderLayer@trg2\n",
      "[8, 4, 64]\n",
      "DecoderLayer@_trg2\n",
      "[8, 4, 64]\n",
      "DecoderLayer@trg3\n",
      "[8, 4, 64]\n",
      "DecoderLayer@_trg3\n",
      "[8, 4, 64]\n",
      "DecoderLayer@trg4\n",
      "[8, 4, 64]\n",
      "DecoderLayer@attention\n",
      "[8, 2, 4, 5]\n",
      "Decoder@pos\n",
      "[8, 4]\n",
      "Decoder@trg\n",
      "[8, 4, 64]\n",
      "Decoder@output\n",
      "[8, 4, 17]\n",
      "Decoder@attention\n",
      "[8, 2, 4, 5]\n",
      "Seq2Seq@src_mask\n",
      "[8, 1, 1, 5]\n",
      "Seq2Seq@trg_mask\n",
      "[8, 1, 4, 4]\n",
      "Seq2Seq@enc_src\n",
      "[8, 5, 64]\n",
      "Seq2Seq@output\n",
      "[8, 4, 17]\n",
      "Seq2Seq@attention\n",
      "[8, 2, 4, 5]\n"
     ]
    }
   ],
   "source": [
    "loggers[\"test_loss\"].get_default_summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_count 1    self.capacity  20\n",
      "0  ------------------------------------------------\n",
      "Encoder@src\n",
      "[1, 6]\n",
      "Encoder@pos\n",
      "[1, 6]\n",
      "encoder@Q\n",
      "[1, 2, 6, 32]\n",
      "encoder@K\n",
      "[1, 2, 6, 32]\n",
      "encoder@V\n",
      "[1, 2, 6, 32]\n",
      "encoder@energy\n",
      "[1, 2, 6, 6]\n",
      "encoder@mask\n",
      "[1, 1, 1, 6]\n",
      "encoder@attention\n",
      "[1, 2, 6, 6]\n",
      "encoder@x1\n",
      "[1, 2, 6, 32]\n",
      "encoder@x2\n",
      "[1, 6, 2, 32]\n",
      "encoder@x3\n",
      "[1, 6, 64]\n",
      "encoder@x4\n",
      "[1, 6, 64]\n",
      "PositionwiseFeedforwardLayer@x1\n",
      "[1, 6, 128]\n",
      "PositionwiseFeedforwardLayer@x2\n",
      "[1, 6, 64]\n",
      "EncoderLayer@_src\n",
      "[1, 6, 64]\n",
      "EncoderLayer@src2\n",
      "[1, 6, 64]\n",
      "EncoderLayer@_src2\n",
      "[1, 6, 64]\n",
      "EncoderLayer@src3\n",
      "[1, 6, 64]\n",
      "EncoderLayer@src_mask\n",
      "[1, 1, 1, 6]\n",
      "EncoderLayer@sattention\n",
      "[1, 2, 6, 6]\n",
      "Encoder@src_final\n",
      "[1, 6, 64]\n",
      "decoder_self@Q\n",
      "[1, 2, 1, 32]\n",
      "decoder_self@K\n",
      "[1, 2, 1, 32]\n",
      "decoder_self@V\n",
      "[1, 2, 1, 32]\n",
      "decoder_self@energy\n",
      "[1, 2, 1, 1]\n",
      "decoder_self@mask\n",
      "[1, 1, 1, 1]\n",
      "decoder_self@attention\n",
      "[1, 2, 1, 1]\n",
      "decoder_self@x1\n",
      "[1, 2, 1, 32]\n",
      "decoder_self@x2\n",
      "[1, 1, 2, 32]\n",
      "decoder_self@x3\n",
      "[1, 1, 64]\n",
      "decoder_self@x4\n",
      "[1, 1, 64]\n",
      "decoder_encoder_attention@Q\n",
      "[1, 2, 1, 32]\n",
      "decoder_encoder_attention@K\n",
      "[1, 2, 6, 32]\n",
      "decoder_encoder_attention@V\n",
      "[1, 2, 6, 32]\n",
      "decoder_encoder_attention@energy\n",
      "[1, 2, 1, 6]\n",
      "decoder_encoder_attention@mask\n",
      "[1, 1, 1, 6]\n",
      "decoder_encoder_attention@attention\n",
      "[1, 2, 1, 6]\n",
      "decoder_encoder_attention@x1\n",
      "[1, 2, 1, 32]\n",
      "decoder_encoder_attention@x2\n",
      "[1, 1, 2, 32]\n",
      "decoder_encoder_attention@x3\n",
      "[1, 1, 64]\n",
      "decoder_encoder_attention@x4\n",
      "[1, 1, 64]\n",
      "DecoderLayer@_trg1\n",
      "[1, 1, 64]\n",
      "DecoderLayer@trg2\n",
      "[1, 1, 64]\n",
      "DecoderLayer@_trg2\n",
      "[1, 1, 64]\n",
      "DecoderLayer@trg3\n",
      "[1, 1, 64]\n",
      "DecoderLayer@_trg3\n",
      "[1, 1, 64]\n",
      "DecoderLayer@trg4\n",
      "[1, 1, 64]\n",
      "DecoderLayer@attention\n",
      "[1, 2, 1, 6]\n",
      "Decoder@pos\n",
      "[1, 1]\n",
      "Decoder@trg\n",
      "[1, 1, 64]\n",
      "Decoder@output\n",
      "[1, 1, 17]\n",
      "Decoder@attention\n",
      "[1, 2, 1, 6]\n"
     ]
    }
   ],
   "source": [
    "loggers[\"sample1\"].get_default_summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_count 1    self.capacity  20\n",
      "0  ------------------------------------------------\n",
      "Encoder@src\n",
      "[1, 6]\n",
      "Encoder@pos\n",
      "[1, 6]\n",
      "encoder@Q\n",
      "[1, 2, 6, 32]\n",
      "encoder@K\n",
      "[1, 2, 6, 32]\n",
      "encoder@V\n",
      "[1, 2, 6, 32]\n",
      "encoder@energy\n",
      "[1, 2, 6, 6]\n",
      "encoder@mask\n",
      "[1, 1, 1, 6]\n",
      "encoder@attention\n",
      "[1, 2, 6, 6]\n",
      "encoder@x1\n",
      "[1, 2, 6, 32]\n",
      "encoder@x2\n",
      "[1, 6, 2, 32]\n",
      "encoder@x3\n",
      "[1, 6, 64]\n",
      "encoder@x4\n",
      "[1, 6, 64]\n",
      "PositionwiseFeedforwardLayer@x1\n",
      "[1, 6, 128]\n",
      "PositionwiseFeedforwardLayer@x2\n",
      "[1, 6, 64]\n",
      "EncoderLayer@_src\n",
      "[1, 6, 64]\n",
      "EncoderLayer@src2\n",
      "[1, 6, 64]\n",
      "EncoderLayer@_src2\n",
      "[1, 6, 64]\n",
      "EncoderLayer@src3\n",
      "[1, 6, 64]\n",
      "EncoderLayer@src_mask\n",
      "[1, 1, 1, 6]\n",
      "EncoderLayer@sattention\n",
      "[1, 2, 6, 6]\n",
      "Encoder@src_final\n",
      "[1, 6, 64]\n",
      "decoder_self@Q\n",
      "[1, 2, 1, 32]\n",
      "decoder_self@K\n",
      "[1, 2, 1, 32]\n",
      "decoder_self@V\n",
      "[1, 2, 1, 32]\n",
      "decoder_self@energy\n",
      "[1, 2, 1, 1]\n",
      "decoder_self@mask\n",
      "[1, 1, 1, 1]\n",
      "decoder_self@attention\n",
      "[1, 2, 1, 1]\n",
      "decoder_self@x1\n",
      "[1, 2, 1, 32]\n",
      "decoder_self@x2\n",
      "[1, 1, 2, 32]\n",
      "decoder_self@x3\n",
      "[1, 1, 64]\n",
      "decoder_self@x4\n",
      "[1, 1, 64]\n",
      "decoder_encoder_attention@Q\n",
      "[1, 2, 1, 32]\n",
      "decoder_encoder_attention@K\n",
      "[1, 2, 6, 32]\n",
      "decoder_encoder_attention@V\n",
      "[1, 2, 6, 32]\n",
      "decoder_encoder_attention@energy\n",
      "[1, 2, 1, 6]\n",
      "decoder_encoder_attention@mask\n",
      "[1, 1, 1, 6]\n",
      "decoder_encoder_attention@attention\n",
      "[1, 2, 1, 6]\n",
      "decoder_encoder_attention@x1\n",
      "[1, 2, 1, 32]\n",
      "decoder_encoder_attention@x2\n",
      "[1, 1, 2, 32]\n",
      "decoder_encoder_attention@x3\n",
      "[1, 1, 64]\n",
      "decoder_encoder_attention@x4\n",
      "[1, 1, 64]\n",
      "DecoderLayer@_trg1\n",
      "[1, 1, 64]\n",
      "DecoderLayer@trg2\n",
      "[1, 1, 64]\n",
      "DecoderLayer@_trg2\n",
      "[1, 1, 64]\n",
      "DecoderLayer@trg3\n",
      "[1, 1, 64]\n",
      "DecoderLayer@_trg3\n",
      "[1, 1, 64]\n",
      "DecoderLayer@trg4\n",
      "[1, 1, 64]\n",
      "DecoderLayer@attention\n",
      "[1, 2, 1, 6]\n",
      "Decoder@pos\n",
      "[1, 1]\n",
      "Decoder@trg\n",
      "[1, 1, 64]\n",
      "Decoder@output\n",
      "[1, 1, 17]\n",
      "Decoder@attention\n",
      "[1, 2, 1, 6]\n"
     ]
    }
   ],
   "source": [
    "current_logger.get_default_summary(show_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#currentLogger.get_default_summary(show_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#currentLogger.get_summary(labels=[\"Q\"],show_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['training', 'test_loss', 'sample1'])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loggers.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_count 1    self.capacity  20\n",
      "0  ------------------------------------------------\n",
      "Encoder@src\n",
      "[1, 6]\n",
      "Encoder@pos\n",
      "[1, 6]\n",
      "encoder@Q\n",
      "[1, 2, 6, 32]\n",
      "encoder@K\n",
      "[1, 2, 6, 32]\n",
      "encoder@V\n",
      "[1, 2, 6, 32]\n",
      "encoder@energy\n",
      "[1, 2, 6, 6]\n",
      "encoder@mask\n",
      "[1, 1, 1, 6]\n",
      "encoder@attention\n",
      "[1, 2, 6, 6]\n",
      "encoder@x1\n",
      "[1, 2, 6, 32]\n",
      "encoder@x2\n",
      "[1, 6, 2, 32]\n",
      "encoder@x3\n",
      "[1, 6, 64]\n",
      "encoder@x4\n",
      "[1, 6, 64]\n",
      "PositionwiseFeedforwardLayer@x1\n",
      "[1, 6, 128]\n",
      "PositionwiseFeedforwardLayer@x2\n",
      "[1, 6, 64]\n",
      "EncoderLayer@_src\n",
      "[1, 6, 64]\n",
      "EncoderLayer@src2\n",
      "[1, 6, 64]\n",
      "EncoderLayer@_src2\n",
      "[1, 6, 64]\n",
      "EncoderLayer@src3\n",
      "[1, 6, 64]\n",
      "EncoderLayer@src_mask\n",
      "[1, 1, 1, 6]\n",
      "EncoderLayer@sattention\n",
      "[1, 2, 6, 6]\n",
      "Encoder@src_final\n",
      "[1, 6, 64]\n",
      "decoder_self@Q\n",
      "[1, 2, 1, 32]\n",
      "decoder_self@K\n",
      "[1, 2, 1, 32]\n",
      "decoder_self@V\n",
      "[1, 2, 1, 32]\n",
      "decoder_self@energy\n",
      "[1, 2, 1, 1]\n",
      "decoder_self@mask\n",
      "[1, 1, 1, 1]\n",
      "decoder_self@attention\n",
      "[1, 2, 1, 1]\n",
      "decoder_self@x1\n",
      "[1, 2, 1, 32]\n",
      "decoder_self@x2\n",
      "[1, 1, 2, 32]\n",
      "decoder_self@x3\n",
      "[1, 1, 64]\n",
      "decoder_self@x4\n",
      "[1, 1, 64]\n",
      "decoder_encoder_attention@Q\n",
      "[1, 2, 1, 32]\n",
      "decoder_encoder_attention@K\n",
      "[1, 2, 6, 32]\n",
      "decoder_encoder_attention@V\n",
      "[1, 2, 6, 32]\n",
      "decoder_encoder_attention@energy\n",
      "[1, 2, 1, 6]\n",
      "decoder_encoder_attention@mask\n",
      "[1, 1, 1, 6]\n",
      "decoder_encoder_attention@attention\n",
      "[1, 2, 1, 6]\n",
      "decoder_encoder_attention@x1\n",
      "[1, 2, 1, 32]\n",
      "decoder_encoder_attention@x2\n",
      "[1, 1, 2, 32]\n",
      "decoder_encoder_attention@x3\n",
      "[1, 1, 64]\n",
      "decoder_encoder_attention@x4\n",
      "[1, 1, 64]\n",
      "DecoderLayer@_trg1\n",
      "[1, 1, 64]\n",
      "DecoderLayer@trg2\n",
      "[1, 1, 64]\n",
      "DecoderLayer@_trg2\n",
      "[1, 1, 64]\n",
      "DecoderLayer@trg3\n",
      "[1, 1, 64]\n",
      "DecoderLayer@_trg3\n",
      "[1, 1, 64]\n",
      "DecoderLayer@trg4\n",
      "[1, 1, 64]\n",
      "DecoderLayer@attention\n",
      "[1, 2, 1, 6]\n",
      "Decoder@pos\n",
      "[1, 1]\n",
      "Decoder@trg\n",
      "[1, 1, 64]\n",
      "Decoder@output\n",
      "[1, 1, 17]\n",
      "Decoder@attention\n",
      "[1, 2, 1, 6]\n"
     ]
    }
   ],
   "source": [
    "loggers[\"sample1\"].get_default_summary(show_data=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "summary_count 1    self.capacity  20\n",
      "0  ------------------------------------------------\n",
      "decoder_encoder_attention@attention\n",
      "[1, 2, 1, 6]\n",
      "tensor([[[[0.5265, 0.1429, 0.0457, 0.0419, 0.1965, 0.0465]],\n",
      "\n",
      "         [[0.1411, 0.4008, 0.0722, 0.0750, 0.2525, 0.0584]]]])\n",
      "summary_count 1    self.capacity  20\n",
      "0  ------------------------------------------------\n",
      "DecoderLayer@trg4\n",
      "[1, 1, 64]\n",
      "tensor([[[-1.4940e+00, -1.5930e-01, -1.0580e+00, -1.0116e+00,  9.1183e-01,\n",
      "           2.2354e+00, -1.5837e-01,  3.4703e-01, -6.4350e-01,  6.9168e-01,\n",
      "           3.9615e-01, -5.1642e-01, -6.9277e-01, -2.2253e+00,  1.0529e+00,\n",
      "          -1.7562e-01,  6.2090e-01,  1.2872e+00,  8.6541e-02, -9.4496e-02,\n",
      "           2.3152e-01, -7.8664e-01, -1.9133e-01, -4.3388e-01,  9.4037e-01,\n",
      "          -6.7833e-01, -6.3566e-01,  2.8480e-01, -5.0138e-01,  5.0984e-01,\n",
      "           4.7199e-01,  9.1885e-02,  2.4657e-01, -3.8347e-01, -5.5224e-01,\n",
      "           4.2976e-01,  5.4698e-01, -4.6524e-01,  8.0617e-01, -4.1947e-01,\n",
      "           3.2164e-02,  1.2576e+00, -8.1290e-02, -1.3973e+00,  1.0309e+00,\n",
      "           2.2332e+00,  2.6824e+00, -1.2395e+00, -4.3061e-04, -8.2146e-01,\n",
      "          -2.3078e-01,  3.4688e-01,  7.8351e-01, -6.1124e-01, -8.7725e-01,\n",
      "           1.7502e+00, -7.8963e-01, -1.2664e+00,  5.3656e-01, -7.3806e-01,\n",
      "          -1.9743e+00,  8.1836e-01, -2.0419e+00,  1.7642e+00]]])\n"
     ]
    }
   ],
   "source": [
    "attention_orig = loggers[\"sample1\"].get_summary(labels=[\"decoder_encoder_attention@attention\"],show_data=True)\n",
    "trg4 = loggers[\"sample1\"].get_summary(labels=[\"DecoderLayer@trg4\"],show_data=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.float32"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_orig[0].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.16666667, 0.16666667],\n",
       "       [0.16666667, 0.16666667]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.full((2, 2), 1/6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = torch.tensor(np.full((1, 2, 1, 6), 1/6) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt.shape[3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667]],\n",
       "\n",
       "         [[0.1667, 0.1667, 0.1667, 0.1667, 0.1667, 0.1667]]]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(np.full((1, 2, 1, 6), 1/tt.shape[3]) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "src = ['we', 'can', 'eat', 'bread']\n",
      "trg = ['wir', 'konnen', 'brot', 'essen']\n",
      "old attention torch.Size([1, 2, 6, 6])\n",
      "old attention tensor([[[[3.0915e-03, 3.4036e-03, 9.5473e-01, 2.4468e-02, 5.7033e-03,\n",
      "           8.6060e-03],\n",
      "          [5.2619e-03, 8.2156e-03, 2.8448e-03, 2.3516e-02, 1.6984e-01,\n",
      "           7.9032e-01],\n",
      "          [1.0137e-02, 1.2041e-01, 1.2520e-02, 1.0268e-02, 8.2733e-01,\n",
      "           1.9334e-02],\n",
      "          [1.6503e-01, 5.6973e-02, 2.9202e-02, 3.2584e-02, 1.1571e-01,\n",
      "           6.0051e-01],\n",
      "          [2.4120e-01, 6.4300e-03, 3.2145e-01, 3.5135e-01, 7.0633e-02,\n",
      "           8.9314e-03],\n",
      "          [1.5624e-02, 3.4402e-03, 7.2293e-01, 8.0642e-02, 1.6753e-01,\n",
      "           9.8307e-03]],\n",
      "\n",
      "         [[3.8369e-02, 6.1600e-01, 2.0416e-01, 1.1993e-02, 9.1193e-02,\n",
      "           3.8287e-02],\n",
      "          [1.7040e-02, 2.5814e-03, 9.0011e-01, 1.1913e-02, 5.1461e-02,\n",
      "           1.6897e-02],\n",
      "          [6.5438e-03, 4.0335e-03, 9.1458e-01, 9.0594e-03, 6.5524e-02,\n",
      "           2.5845e-04],\n",
      "          [3.6952e-02, 6.2526e-02, 6.0582e-02, 4.7157e-02, 3.2426e-02,\n",
      "           7.6036e-01],\n",
      "          [3.7295e-02, 6.7189e-03, 1.5939e-01, 7.3349e-01, 4.4051e-02,\n",
      "           1.9058e-02],\n",
      "          [9.3466e-02, 8.6007e-02, 9.4280e-02, 1.5653e-01, 1.3124e-01,\n",
      "           4.3848e-01]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 6, 6])\n",
      "old attention tensor([[[[0.0994, 0.0474, 0.4739, 0.1228, 0.1379, 0.1187],\n",
      "          [0.0840, 0.1721, 0.0554, 0.0719, 0.1377, 0.4790],\n",
      "          [0.2747, 0.2097, 0.0351, 0.1234, 0.1969, 0.1602],\n",
      "          [0.0254, 0.1034, 0.0660, 0.5197, 0.0804, 0.2050],\n",
      "          [0.1841, 0.1490, 0.1209, 0.1968, 0.1100, 0.2391],\n",
      "          [0.0784, 0.0659, 0.6698, 0.0985, 0.0253, 0.0621]],\n",
      "\n",
      "         [[0.1537, 0.2222, 0.3613, 0.1226, 0.0326, 0.1077],\n",
      "          [0.0386, 0.3986, 0.0783, 0.2291, 0.2282, 0.0272],\n",
      "          [0.4328, 0.1118, 0.2407, 0.0259, 0.0887, 0.1001],\n",
      "          [0.0829, 0.1514, 0.0903, 0.1649, 0.3285, 0.1819],\n",
      "          [0.0237, 0.1080, 0.0768, 0.0411, 0.6233, 0.1271],\n",
      "          [0.0309, 0.0351, 0.0806, 0.4701, 0.1112, 0.2721]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 6, 6])\n",
      "old attention tensor([[[[0.0723, 0.3838, 0.1749, 0.1791, 0.1534, 0.0366],\n",
      "          [0.1017, 0.0953, 0.1426, 0.2072, 0.3204, 0.1327],\n",
      "          [0.1154, 0.0169, 0.0212, 0.0509, 0.3031, 0.4925],\n",
      "          [0.0799, 0.0458, 0.1560, 0.5867, 0.1003, 0.0313],\n",
      "          [0.2873, 0.2300, 0.0492, 0.4148, 0.0125, 0.0062],\n",
      "          [0.1287, 0.2799, 0.0337, 0.4841, 0.0265, 0.0470]],\n",
      "\n",
      "         [[0.0465, 0.0108, 0.7033, 0.1919, 0.0403, 0.0073],\n",
      "          [0.0608, 0.0796, 0.1158, 0.4585, 0.1681, 0.1173],\n",
      "          [0.0247, 0.0065, 0.8336, 0.0380, 0.0891, 0.0079],\n",
      "          [0.0377, 0.1012, 0.1194, 0.2989, 0.2462, 0.1966],\n",
      "          [0.0675, 0.0278, 0.3477, 0.4185, 0.1102, 0.0284],\n",
      "          [0.2093, 0.1183, 0.0285, 0.1540, 0.2966, 0.1934]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 6])\n",
      "old attention tensor([[[[0.1529, 0.4433, 0.0179, 0.1557, 0.1989, 0.0312]],\n",
      "\n",
      "         [[0.1317, 0.6192, 0.0504, 0.1277, 0.0470, 0.0240]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 6])\n",
      "old attention tensor([[[[0.2349, 0.5530, 0.1420, 0.0401, 0.0271, 0.0029]],\n",
      "\n",
      "         [[0.0170, 0.9523, 0.0037, 0.0107, 0.0087, 0.0077]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 1, 1])\n",
      "old attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "new attention tensor([[[[1.]],\n",
      "\n",
      "         [[1.]]]])\n",
      "old attention torch.Size([1, 2, 1, 6])\n",
      "old attention tensor([[[[0.0763, 0.4716, 0.1819, 0.1117, 0.1109, 0.0476]],\n",
      "\n",
      "         [[0.0310, 0.0515, 0.0193, 0.1040, 0.1658, 0.6284]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0548, 0.9452]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0098, 0.9902]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0548, 0.9452]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0098, 0.9902]]]])\n",
      "old attention torch.Size([1, 2, 2, 6])\n",
      "old attention tensor([[[[0.1529, 0.4433, 0.0179, 0.1557, 0.1989, 0.0312],\n",
      "          [0.0969, 0.0450, 0.3164, 0.1646, 0.0071, 0.3699]],\n",
      "\n",
      "         [[0.1317, 0.6192, 0.0504, 0.1277, 0.0470, 0.0240],\n",
      "          [0.1273, 0.0070, 0.8023, 0.0396, 0.0076, 0.0162]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0174, 0.9826]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.5739, 0.4261]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.0174, 0.9826]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.5739, 0.4261]]]])\n",
      "old attention torch.Size([1, 2, 2, 6])\n",
      "old attention tensor([[[[0.2349, 0.5530, 0.1420, 0.0401, 0.0271, 0.0029],\n",
      "          [0.1395, 0.1013, 0.1210, 0.5588, 0.0306, 0.0488]],\n",
      "\n",
      "         [[0.0170, 0.9523, 0.0037, 0.0107, 0.0087, 0.0077],\n",
      "          [0.0797, 0.0499, 0.6845, 0.0434, 0.1250, 0.0175]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 2, 2])\n",
      "old attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.5808, 0.4192]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          [0.0785, 0.9215]]]])\n",
      "new attention tensor([[[[1.0000, 0.0000],\n",
      "          [0.5808, 0.4192]],\n",
      "\n",
      "         [[1.0000, 0.0000],\n",
      "          [0.0785, 0.9215]]]])\n",
      "old attention torch.Size([1, 2, 2, 6])\n",
      "old attention tensor([[[[0.0763, 0.4716, 0.1819, 0.1117, 0.1109, 0.0476],\n",
      "          [0.0287, 0.3707, 0.2062, 0.2213, 0.1149, 0.0582]],\n",
      "\n",
      "         [[0.0310, 0.0515, 0.0193, 0.1040, 0.1658, 0.6284],\n",
      "          [0.0114, 0.0195, 0.0783, 0.1099, 0.1704, 0.6105]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.0548, 0.9452, 0.0000],\n",
      "          [0.0140, 0.1149, 0.8711]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.0098, 0.9902, 0.0000],\n",
      "          [0.0047, 0.0052, 0.9901]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 6])\n",
      "old attention tensor([[[[0.1569, 0.2934, 0.0210, 0.2553, 0.2488, 0.0247],\n",
      "          [0.0913, 0.1112, 0.1349, 0.1823, 0.0259, 0.4544],\n",
      "          [0.0284, 0.0819, 0.0837, 0.1929, 0.3436, 0.2695]],\n",
      "\n",
      "         [[0.0872, 0.5528, 0.0449, 0.1715, 0.0522, 0.0914],\n",
      "          [0.1387, 0.0379, 0.7683, 0.0285, 0.0139, 0.0126],\n",
      "          [0.1894, 0.3421, 0.0563, 0.1794, 0.0463, 0.1866]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.0253, 0.9747, 0.0000],\n",
      "          [0.0416, 0.4488, 0.5095]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.7086, 0.2914, 0.0000],\n",
      "          [0.4260, 0.0559, 0.5182]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 6])\n",
      "old attention tensor([[[[0.2126, 0.4497, 0.1975, 0.0721, 0.0600, 0.0081],\n",
      "          [0.2112, 0.1977, 0.2540, 0.2964, 0.0353, 0.0054],\n",
      "          [0.0505, 0.1544, 0.4655, 0.1961, 0.0922, 0.0414]],\n",
      "\n",
      "         [[0.0339, 0.9243, 0.0048, 0.0183, 0.0151, 0.0035],\n",
      "          [0.1552, 0.5260, 0.0933, 0.0367, 0.1297, 0.0591],\n",
      "          [0.1283, 0.3749, 0.0204, 0.0348, 0.3053, 0.1364]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 3, 3])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000],\n",
      "          [0.2634, 0.7366, 0.0000],\n",
      "          [0.3496, 0.4291, 0.2213]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000],\n",
      "          [0.0629, 0.9371, 0.0000],\n",
      "          [0.0359, 0.2952, 0.6689]]]])\n",
      "new attention tensor([[[[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]],\n",
      "\n",
      "         [[0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333],\n",
      "          [0.3333, 0.3333, 0.3333]]]])\n",
      "old attention torch.Size([1, 2, 3, 6])\n",
      "old attention tensor([[[[0.0635, 0.3260, 0.1489, 0.1866, 0.1842, 0.0908],\n",
      "          [0.0822, 0.2368, 0.1370, 0.1466, 0.2328, 0.1646],\n",
      "          [0.0811, 0.1268, 0.1458, 0.2191, 0.2641, 0.1631]],\n",
      "\n",
      "         [[0.0321, 0.0544, 0.0211, 0.1508, 0.3184, 0.4232],\n",
      "          [0.0222, 0.0286, 0.0373, 0.1456, 0.3626, 0.4037],\n",
      "          [0.0400, 0.0369, 0.0339, 0.1611, 0.4430, 0.2852]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [5.4816e-02, 9.4518e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [1.4026e-02, 1.1485e-01, 8.7112e-01, 0.0000e+00],\n",
      "          [1.0585e-01, 4.4915e-01, 4.1571e-01, 2.9289e-02]],\n",
      "\n",
      "         [[1.0000e+00, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
      "          [9.8231e-03, 9.9018e-01, 0.0000e+00, 0.0000e+00],\n",
      "          [4.7095e-03, 5.2001e-03, 9.9009e-01, 0.0000e+00],\n",
      "          [1.3612e-03, 8.8639e-03, 3.4831e-04, 9.8943e-01]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 6])\n",
      "old attention tensor([[[[0.1829, 0.2833, 0.0263, 0.2155, 0.2748, 0.0173],\n",
      "          [0.1106, 0.1105, 0.1929, 0.1650, 0.0271, 0.3940],\n",
      "          [0.0314, 0.0750, 0.1188, 0.1600, 0.4130, 0.2018],\n",
      "          [0.1151, 0.0172, 0.5490, 0.1922, 0.0248, 0.1017]],\n",
      "\n",
      "         [[0.0503, 0.5549, 0.0212, 0.2179, 0.0497, 0.1060],\n",
      "          [0.1373, 0.0557, 0.7119, 0.0541, 0.0198, 0.0212],\n",
      "          [0.1025, 0.3494, 0.0226, 0.2467, 0.0429, 0.2359],\n",
      "          [0.0699, 0.6863, 0.0436, 0.1133, 0.0444, 0.0425]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0328, 0.9672, 0.0000, 0.0000],\n",
      "          [0.0570, 0.4385, 0.5045, 0.0000],\n",
      "          [0.0632, 0.3210, 0.1582, 0.4577]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.7006, 0.2994, 0.0000, 0.0000],\n",
      "          [0.3726, 0.0410, 0.5864, 0.0000],\n",
      "          [0.0139, 0.3919, 0.5435, 0.0507]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 6])\n",
      "old attention tensor([[[[0.1922, 0.6065, 0.1160, 0.0413, 0.0387, 0.0053],\n",
      "          [0.2194, 0.2398, 0.2056, 0.3017, 0.0280, 0.0055],\n",
      "          [0.0441, 0.1844, 0.4346, 0.2002, 0.0833, 0.0533],\n",
      "          [0.1881, 0.5186, 0.1796, 0.0702, 0.0317, 0.0118]],\n",
      "\n",
      "         [[0.1045, 0.7999, 0.0093, 0.0647, 0.0194, 0.0022],\n",
      "          [0.3178, 0.2355, 0.1702, 0.0797, 0.1583, 0.0384],\n",
      "          [0.2511, 0.1951, 0.0319, 0.0723, 0.3461, 0.1035],\n",
      "          [0.1809, 0.1086, 0.1528, 0.1557, 0.3001, 0.1019]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "old attention torch.Size([1, 2, 4, 4])\n",
      "old attention tensor([[[[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.2128, 0.7872, 0.0000, 0.0000],\n",
      "          [0.2993, 0.4477, 0.2530, 0.0000],\n",
      "          [0.0708, 0.1056, 0.7214, 0.1022]],\n",
      "\n",
      "         [[1.0000, 0.0000, 0.0000, 0.0000],\n",
      "          [0.0506, 0.9494, 0.0000, 0.0000],\n",
      "          [0.0183, 0.1902, 0.7915, 0.0000],\n",
      "          [0.0561, 0.1790, 0.4992, 0.2657]]]])\n",
      "new attention tensor([[[[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]],\n",
      "\n",
      "         [[0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160],\n",
      "          [0.2613, 0.2613, 0.2613, 0.2160]]]])\n",
      "old attention torch.Size([1, 2, 4, 6])\n",
      "old attention tensor([[[[0.0646, 0.2217, 0.1912, 0.2481, 0.1610, 0.1134],\n",
      "          [0.0721, 0.1248, 0.1696, 0.1439, 0.2212, 0.2684],\n",
      "          [0.0696, 0.0435, 0.1552, 0.2470, 0.2349, 0.2499],\n",
      "          [0.0289, 0.1792, 0.1211, 0.1333, 0.1410, 0.3966]],\n",
      "\n",
      "         [[0.0917, 0.0937, 0.0274, 0.2102, 0.2465, 0.3304],\n",
      "          [0.0610, 0.0388, 0.0669, 0.2091, 0.2525, 0.3717],\n",
      "          [0.1346, 0.0663, 0.0397, 0.2230, 0.3366, 0.1999],\n",
      "          [0.0506, 0.0416, 0.1762, 0.1467, 0.3456, 0.2393]]]])\n",
      "new attention tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
      "\n",
      "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508],\n",
      "          [0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]])\n",
      "predicted trg = ['wir', 'konnen', 'essen', '<eos>']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\mcelikkaya\\Anaconda3\\envs\\p37_tensor23\\lib\\site-packages\\ipykernel_launcher.py:17: UserWarning: FixedFormatter should only be used together with FixedLocator\n",
      "C:\\Users\\mcelikkaya\\Anaconda3\\envs\\p37_tensor23\\lib\\site-packages\\ipykernel_launcher.py:18: UserWarning: FixedFormatter should only be used together with FixedLocator\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x1800 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "add_new_logger(\"sample3\")\n",
    "example_idx = 18\n",
    "\n",
    "src = vars(train_data.examples[example_idx])['src']\n",
    "trg = vars(train_data.examples[example_idx])['trg']\n",
    "\n",
    "print(f'src = {src}')\n",
    "print(f'trg = {trg}')\n",
    "\n",
    "currentLogger = StepLogger(100)  \n",
    "translation, attention = translate_sentence(src, SRC, TRG, model, device,is_appy_attention=False)\n",
    "\n",
    "print(f'predicted trg = {translation}')\n",
    " \n",
    "display_attention(src, translation, attention,n_heads=2,n_rows = 1, n_cols = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "i want to eat bread\n",
      "ich mochten brot essen\n",
      "i want to eat apple\n",
      "ich mochten apfel essen\n",
      "i want to drink water\n",
      "ich mochten wasser trinken\n",
      "i want to drink beer\n",
      "ich mochten bier trinken\n",
      "i want to read book\n",
      "ich mochten buch lesen\n",
      "i want to read newspaper\n",
      "ich mochten zeitung lesen\n",
      "i can eat bread\n",
      "ich konnen brot essen\n",
      "i can eat apple\n",
      "ich konnen apfel essen\n",
      "i can drink water\n",
      "ich konnen wasser trinken\n",
      "i can drink beer\n",
      "ich konnen bier trinken\n",
      "i can read book\n",
      "ich konnen buch lesen\n",
      "i can read newspaper\n",
      "ich konnen zeitung lesen\n",
      "we want to eat bread\n",
      "wir mochten brot essen\n",
      "we want to eat apple\n",
      "wir mochten apfel essen\n",
      "we want to drink water\n",
      "wir mochten wasser trinken\n",
      "we want to drink beer\n",
      "wir mochten bier trinken\n",
      "we want to read book\n",
      "wir mochten buch lesen\n",
      "we want to read newspaper\n",
      "wir mochten zeitung lesen\n",
      "we can eat bread\n",
      "wir konnen brot essen\n",
      "we can eat apple\n",
      "wir konnen apfel essen\n",
      "we can drink water\n",
      "wir konnen wasser trinken\n",
      "we can drink beer\n",
      "wir konnen bier trinken\n",
      "we can read book\n",
      "wir konnen buch lesen\n",
      "we can read newspaper\n",
      "wir konnen zeitung lesen\n",
      "i eat bread\n",
      "ich essen apfel\n",
      "i eat apple\n",
      "ich essen apfel\n",
      "i drink water\n",
      "ich trinken bier\n",
      "i drink beer\n",
      "ich trinken bier\n",
      "i read book\n",
      "ich lesen zeitung\n",
      "i read newspaper\n",
      "ich lesen zeitung\n",
      "we eat bread\n",
      "wir essen apfel\n",
      "we eat apple\n",
      "wir essen apfel\n",
      "we drink water\n",
      "wir trinken bier\n",
      "we drink beer\n",
      "wir trinken bier\n",
      "we read book\n",
      "wir lesen zeitung\n",
      "we read newspaper\n",
      "wir lesen zeitung\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for i in range( len(tabular_set)):\n",
    "    print(\" \".join(tabular_set[i].src))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['we', 'read', 'newspaper']"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tabular_set[i].src\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]],\n",
       "\n",
       "         [[0.1825, 0.1825, 0.1825, 0.1508, 0.1508, 0.1508]]]],\n",
       "       dtype=torch.float64)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt = torch.tensor(np.full((1, 2, 1, 6), 1/6) )\n",
    "\n",
    "att1 = torch.tensor(np.full((tt.shape[0], tt.shape[1], tt.shape[2], 3), 1/3) )\n",
    "att2 = torch.tensor(np.full((tt.shape[0], tt.shape[1], tt.shape[2], tt.shape[3] - 3), 1/7) )\n",
    "att3 = torch.cat( (att1,att2),3 )\n",
    "att4 = torch.softmax(att3, dim = -1)\n",
    "att4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "collapsed_sections": [],
   "name": "transformer_____v1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
