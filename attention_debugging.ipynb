{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#In this notebook i copied pytorch documentation attention code\n",
    "#and added logging for every step at training. The log part is appended to the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import unicode_literals, print_function, division\n",
    "from io import open\n",
    "import unicodedata\n",
    "import string\n",
    "import re\n",
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOS_token = 0\n",
    "EOS_token = 1\n",
    "\n",
    "\n",
    "class Lang:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {0: \"SOS\", 1: \"EOS\"}\n",
    "        self.n_words = 2  # Count SOS and EOS\n",
    "\n",
    "    def addSentence(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "\n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.n_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.n_words] = word\n",
    "            self.n_words += 1\n",
    "        else:\n",
    "            self.word2count[word] += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Turn a Unicode string to plain ASCII, thanks to\n",
    "# https://stackoverflow.com/a/518232/2809427\n",
    "def unicodeToAscii(s):\n",
    "    return ''.join(\n",
    "        c for c in unicodedata.normalize('NFD', s)\n",
    "        if unicodedata.category(c) != 'Mn'\n",
    "    )\n",
    "\n",
    "# Lowercase, trim, and remove non-letter characters\n",
    "\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicodeToAscii(s.lower().strip())\n",
    "    s = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def readLangs(lang1, lang2, reverse=False):\n",
    "    print(\"Reading lines...\")\n",
    "\n",
    "    # Read the file and split into lines\n",
    "    lines = open('D:/data6/deu-eng/%s-%s.txt' % (lang1, lang2), encoding='utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "    print(\"len\",len(lines))\n",
    "    # Split every line into pairs and normalize\n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "\n",
    "    # Reverse pairs, make Lang instances\n",
    "    if reverse:\n",
    "        pairs = [list(reversed(p)) for p in pairs]\n",
    "        input_lang = Lang(lang2)\n",
    "        output_lang = Lang(lang1)\n",
    "    else:\n",
    "        input_lang = Lang(lang1)\n",
    "        output_lang = Lang(lang2)\n",
    "\n",
    "    return input_lang, output_lang, pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "lines = open('D:/data6/deu-eng/%s-%s.txt' % (\"eng\", \"deu\"), encoding='utf-8').\\\n",
    "        read().strip().split('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Go.\\tGeh.\\tCC-BY 2.0 (France) Attribution: tatoeba.org #2877272 (CM) & #8597805 (Roujin)'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lines[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "\n",
    "eng_prefixes = (\n",
    "    \"i am \", \"i m \",\n",
    "    \"he is\", \"he s \",\n",
    "    \"she is\", \"she s \",\n",
    "    \"you are\", \"you re \",\n",
    "    \"we are\", \"we re \",\n",
    "    \"they are\", \"they re \"\n",
    ")\n",
    "\n",
    "\n",
    "def filterPair(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and \\\n",
    "        len(p[1].split(' ')) < MAX_LENGTH and \\\n",
    "        p[0].startswith(eng_prefixes)\n",
    "\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filterPair(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading lines...\n",
      "len 217032\n",
      "Read 217032 sentence pairs\n",
      "Trimmed to 11809 sentence pairs\n",
      "Counting words...\n",
      "Counted words:\n",
      "eng 3129\n",
      "deu 4896\n",
      "['i m studying several languages .', 'ich lerne mehrere sprachen .', 'cc by . france attribution tatoeba .org ck yorwba ']\n"
     ]
    }
   ],
   "source": [
    "def prepareData(lang1, lang2, reverse=False):\n",
    "    input_lang, output_lang, pairs = readLangs(lang1, lang2, reverse)\n",
    "    print(\"Read %s sentence pairs\" % len(pairs))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to %s sentence pairs\" % len(pairs))\n",
    "    print(\"Counting words...\")\n",
    "    for pair in pairs:\n",
    "        input_lang.addSentence(pair[0])\n",
    "        output_lang.addSentence(pair[1])\n",
    "    print(\"Counted words:\")\n",
    "    print(input_lang.name, input_lang.n_words)\n",
    "    print(output_lang.name, output_lang.n_words)\n",
    "    return input_lang, output_lang, pairs\n",
    "\n",
    "\n",
    "input_lang, output_lang, pairs = prepareData('eng', 'deu', False)\n",
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i m not tired .', 'ich bin nicht mude .', 'cc by . france attribution tatoeba .org ck pfirsichbaeumchen ']\n"
     ]
    }
   ],
   "source": [
    "print(random.choice(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(input_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        output = embedded\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size):\n",
    "        super(DecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "\n",
    "        self.embedding = nn.Embedding(output_size, hidden_size)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        self.softmax = nn.LogSoftmax(dim=1)\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        output = self.embedding(input).view(1, 1, -1)\n",
    "        output = F.relu(output)\n",
    "        output, hidden = self.gru(output, hidden)\n",
    "        output = self.softmax(self.out(output[0]))\n",
    "        return output, hidden\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I encourage you to train and observe the results of this model, but to\n",
    "save space we'll be going straight for the gold and introducing the\n",
    "Attention Mechanism.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_map = {}\n",
    "class AttnDecoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, output_size, dropout_p=0.1, max_length=MAX_LENGTH):\n",
    "        super(AttnDecoderRNN, self).__init__()\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.dropout_p = dropout_p\n",
    "        self.max_length = max_length\n",
    "\n",
    "        self.embedding = nn.Embedding(self.output_size, self.hidden_size)\n",
    "        self.attn = nn.Linear(self.hidden_size * 2, self.max_length)\n",
    "        self.attn_combine = nn.Linear(self.hidden_size * 2, self.hidden_size)\n",
    "        self.dropout = nn.Dropout(self.dropout_p)\n",
    "        self.gru = nn.GRU(self.hidden_size, self.hidden_size)\n",
    "        self.out = nn.Linear(self.hidden_size, self.output_size)\n",
    "\n",
    "    #input : decoder_input (input obtained at each step)    \n",
    "    #hidden : decoder_hidden, value returned from this function is passed again\n",
    "    #encoder_outputs : all outputs steps of encode,static in this function    \n",
    "    def forward(self, input, hidden, encoder_outputs):\n",
    "        temp_map[\"hidden_\"] = hidden\n",
    "        temp_map[\"input\"] = input\n",
    "        temp_map[\"encoder_outputs\"] = encoder_outputs\n",
    "        \n",
    "        embedded = self.embedding(input).view(1, 1, -1)\n",
    "        temp_map[\"embedded\"] = embedded\n",
    "        \n",
    "        embedded = self.dropout(embedded)\n",
    "        temp_map[\"embedded_dropout\"] = embedded\n",
    "        \n",
    "        \n",
    "        tensor_cat = torch.cat((embedded[0], hidden[0]), 1)\n",
    "        temp_map[\"tensor_cat\"] = tensor_cat\n",
    "        \n",
    "        attn_vector = self.attn(tensor_cat)\n",
    "        temp_map[\"attn_vector\"] = attn_vector\n",
    "        \n",
    "        #!!! attn weights are created without encoder data\n",
    "        #so it means it is learned over time, we are creating these weights(by a linear layer)\n",
    "        #and multiply with encoder outputs \n",
    "        #so over time(with backpropagation) we learn better attention\n",
    "        #examle at 1st we   could be mapping to ich\n",
    "        #but over time I will map to ich\n",
    "        #so attention weights is learned over time\n",
    "        attn_weights = F.softmax(attn_vector, dim=1)\n",
    "        temp_map[\"attn_weights\"] = attn_weights\n",
    "        \n",
    "        attn_applied = torch.bmm(attn_weights.unsqueeze(0),encoder_outputs.unsqueeze(0))\n",
    "        temp_map[\"attn_applied\"] = attn_applied\n",
    "\n",
    "        output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "        temp_map[\"output\"] = output\n",
    "        \n",
    "        output = self.attn_combine(output).unsqueeze(0)\n",
    "        temp_map[\"output attn_combine\"] = output\n",
    "\n",
    "        output = F.relu(output)\n",
    "        temp_map[\"output relu\"] = output\n",
    "        \n",
    "        output_step, hidden_step = self.gru(output, hidden)\n",
    "        temp_map[\"output_step\"] = output_step\n",
    "        temp_map[\"hidden_step\"] = hidden_step\n",
    "\n",
    "        output_softmax = F.log_softmax(self.out(output_step[0]), dim=1)\n",
    "        temp_map[\"output_softmax\"] = output_softmax\n",
    "        \n",
    "        return output_softmax, hidden_step, attn_weights\n",
    "\n",
    "    def initHidden(self):\n",
    "        return torch.zeros(1, 1, self.hidden_size, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesFromSentence(lang, sentence):\n",
    "    return [lang.word2index[word] for word in sentence.split(' ')]\n",
    "\n",
    "\n",
    "def tensorFromSentence(lang, sentence):\n",
    "    indexes = indexesFromSentence(lang, sentence)\n",
    "    indexes.append(EOS_token)\n",
    "    return torch.tensor(indexes, dtype=torch.long, device=device).view(-1, 1)\n",
    "\n",
    "\n",
    "def tensorsFromPair(pair):\n",
    "    input_tensor = tensorFromSentence(input_lang, pair[0])\n",
    "    target_tensor = tensorFromSentence(output_lang, pair[1])\n",
    "    return (input_tensor, target_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "teacher_forcing_ratio = 0.5\n",
    "\n",
    "\n",
    "def train(input_tensor, target_tensor, encoder, decoder, encoder_optimizer, decoder_optimizer, criterion, max_length=MAX_LENGTH):\n",
    "    encoder_hidden = encoder.initHidden()\n",
    "\n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "\n",
    "    input_length = input_tensor.size(0)\n",
    "    target_length = target_tensor.size(0)\n",
    "\n",
    "    encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "\n",
    "    loss = 0\n",
    "\n",
    "    for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(\n",
    "            input_tensor[ei], encoder_hidden)\n",
    "        encoder_outputs[ei] = encoder_output[0, 0]\n",
    "\n",
    "    decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "\n",
    "    decoder_hidden = encoder_hidden\n",
    "\n",
    "    use_teacher_forcing = True if random.random() < teacher_forcing_ratio else False\n",
    "\n",
    "    if use_teacher_forcing:\n",
    "        # Teacher forcing: Feed the target as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            decoder_input = target_tensor[di]  # Teacher forcing\n",
    "\n",
    "    else:\n",
    "        # Without teacher forcing: use its own predictions as the next input\n",
    "        for di in range(target_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(\n",
    "                decoder_input, decoder_hidden, encoder_outputs)\n",
    "            topv, topi = decoder_output.topk(1)\n",
    "            decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "\n",
    "            loss += criterion(decoder_output, target_tensor[di])\n",
    "            if decoder_input.item() == EOS_token:\n",
    "                break\n",
    "\n",
    "    loss.backward()\n",
    "\n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "\n",
    "    return loss.item() / target_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "\n",
    "\n",
    "def asMinutes(s):\n",
    "    m = math.floor(s / 60)\n",
    "    s -= m * 60\n",
    "    return '%dm %ds' % (m, s)\n",
    "\n",
    "\n",
    "def timeSince(since, percent):\n",
    "    now = time.time()\n",
    "    s = now - since\n",
    "    es = s / (percent)\n",
    "    rs = es - s\n",
    "    return '%s (- %s)' % (asMinutes(s), asMinutes(rs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "def trainIters(encoder, decoder, n_iters, print_every=1000, plot_every=100, learning_rate=0.01):\n",
    "    gc.collect()\n",
    "    start = time.time()\n",
    "    plot_losses = []\n",
    "    print_loss_total = 0  # Reset every print_every\n",
    "    plot_loss_total = 0  # Reset every plot_every\n",
    "\n",
    "    encoder_optimizer = optim.SGD(encoder.parameters(), lr=learning_rate)\n",
    "    decoder_optimizer = optim.SGD(decoder.parameters(), lr=learning_rate)\n",
    "    training_pairs = [tensorsFromPair(random.choice(pairs))\n",
    "                      for i in range(n_iters)]\n",
    "    criterion = nn.NLLLoss()\n",
    "\n",
    "    for iter in range(1, n_iters + 1):\n",
    "        training_pair = training_pairs[iter - 1]\n",
    "        input_tensor = training_pair[0]\n",
    "        target_tensor = training_pair[1]\n",
    "\n",
    "        loss = train(input_tensor, target_tensor, encoder,\n",
    "                     decoder, encoder_optimizer, decoder_optimizer, criterion)\n",
    "        print_loss_total += loss\n",
    "        plot_loss_total += loss\n",
    "\n",
    "        if iter % print_every == 0:\n",
    "            print_loss_avg = print_loss_total / print_every\n",
    "            print_loss_total = 0\n",
    "            print('%s (%d %d%%) %.4f' % (timeSince(start, iter / n_iters),\n",
    "                                         iter, iter / n_iters * 100, print_loss_avg))\n",
    "\n",
    "        if iter % plot_every == 0:\n",
    "            plot_loss_avg = plot_loss_total / plot_every\n",
    "            plot_losses.append(plot_loss_avg)\n",
    "            plot_loss_total = 0\n",
    "\n",
    "    showPlot(plot_losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as ticker\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "def showPlot(points):\n",
    "    plt.figure()\n",
    "    fig, ax = plt.subplots()\n",
    "    # this locator puts ticks at regular intervals\n",
    "    loc = ticker.MultipleLocator(base=0.2)\n",
    "    ax.yaxis.set_major_locator(loc)\n",
    "    plt.plot(points)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "evaluate_queue = []\n",
    "\n",
    "def evaluate(encoder, decoder, sentence, max_length=MAX_LENGTH):\n",
    "    with torch.no_grad():\n",
    "        input_tensor = tensorFromSentence(input_lang, sentence)\n",
    "        input_length = input_tensor.size()[0]\n",
    "        encoder_hidden = encoder.initHidden()\n",
    "        \n",
    "        evaluate_queue.append([\"input_tensor\",input_tensor])\n",
    "        evaluate_queue.append([\"encoder_hidden\",encoder_hidden])\n",
    "\n",
    "        encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "        evaluate_queue.append([\"encoder_outputs\",encoder_outputs])\n",
    "\n",
    "        for ei in range(input_length):\n",
    "            evaluate_queue.append([\"input_tensor[ei]\",input_tensor[ei]])\n",
    "            evaluate_queue.append([\"encoder_hidden\",encoder_hidden])\n",
    "            encoder_output, encoder_hidden = encoder(input_tensor[ei],encoder_hidden)\n",
    "            evaluate_queue.append([\"encoder_output\",encoder_output])\n",
    "            evaluate_queue.append([\"encoder_hidden\",encoder_hidden])\n",
    "            \n",
    "            encoder_outputs[ei] += encoder_output[0, 0]\n",
    "            evaluate_queue.append([\"encoder_outputs[ei]\",encoder_outputs[ei]])\n",
    "\n",
    "        decoder_input = torch.tensor([[SOS_token]], device=device)  # SOS\n",
    "        evaluate_queue.append([\"decoder_input\",decoder_input])\n",
    "\n",
    "        decoder_hidden = encoder_hidden\n",
    "        evaluate_queue.append([\"decoder_hidden\",decoder_hidden])\n",
    "\n",
    "        decoded_words = []\n",
    "        decoder_attentions = torch.zeros(max_length, max_length)\n",
    "\n",
    "        for di in range(max_length):\n",
    "            decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            evaluate_queue.append([\"decoder_output\",decoder_output])\n",
    "            evaluate_queue.append([\"decoder_hidden\",decoder_hidden])\n",
    "            evaluate_queue.append([\"decoder_attention\",decoder_attention])\n",
    "            \n",
    "            \n",
    "            decoder_attentions[di] = decoder_attention.data\n",
    "            evaluate_queue.append([\"decoder_attentions[di]\",decoder_attentions[di]])\n",
    "            \n",
    "            topv, topi = decoder_output.data.topk(1)\n",
    "            evaluate_queue.append([\"topv\",topv])\n",
    "            evaluate_queue.append([\"topi\",topi])\n",
    "            \n",
    "            if topi.item() == EOS_token:\n",
    "                decoded_words.append('<EOS>')\n",
    "                break\n",
    "            else:\n",
    "                evaluate_queue.append([\"output_lang.index2word[topi.item()]\",output_lang.index2word[topi.item()]])\n",
    "                decoded_words.append(output_lang.index2word[topi.item()])\n",
    "\n",
    "            decoder_input = topi.squeeze().detach()\n",
    "            evaluate_queue.append([\"decoder_input\",decoder_input])\n",
    "\n",
    "        evaluate_queue.append([\"decoded_words\",decoded_words])    \n",
    "        return decoded_words, decoder_attentions[:di + 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluateRandomly(encoder, decoder, n=10):\n",
    "    for i in range(n):\n",
    "        pair = random.choice(pairs)\n",
    "        print('>', pair[0])\n",
    "        print('=', pair[1])\n",
    "        output_words, attentions = evaluate(encoder, decoder, pair[0])\n",
    "        output_sentence = ' '.join(output_words)\n",
    "        print('<', output_sentence)\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size = 256\n",
    "encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
    "\n",
    "#trainIters(encoder1, attn_decoder1, 1000, print_every=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EncoderRNN(\n",
      "  (embedding): Embedding(3129, 256)\n",
      "  (gru): GRU(256, 256)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print( encoder1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AttnDecoderRNN(\n",
      "  (embedding): Embedding(4896, 256)\n",
      "  (attn): Linear(in_features=512, out_features=10, bias=True)\n",
      "  (attn_combine): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (dropout): Dropout(p=0.1)\n",
      "  (gru): GRU(256, 256)\n",
      "  (out): Linear(in_features=256, out_features=4896, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print( attn_decoder1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2m 49s (- 2m 49s) (500 50%) 1.3836\n",
      "4m 56s (- 0m 0s) (1000 100%) 1.4017\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#1.3408\n",
    "import os.path\n",
    "decoder_path = \"D:/data6/10iter_decoder\"\n",
    "encoder_path = \"D:/data6/10iter_encoder\"\n",
    "\n",
    "for i in range(1):\n",
    "    gc.collect()\n",
    "    encoder1 = EncoderRNN(input_lang.n_words, hidden_size).to(device)\n",
    "    attn_decoder1 = AttnDecoderRNN(hidden_size, output_lang.n_words, dropout_p=0.1).to(device)\n",
    "    \n",
    "    if os.path.isfile(decoder_path) :\n",
    "        encoder1.load_state_dict(torch.load(encoder_path))\n",
    "        attn_decoder1.load_state_dict(torch.load(decoder_path))\n",
    "        \n",
    "    trainIters(encoder1, attn_decoder1, 1000, print_every=500)\n",
    "    torch.save(attn_decoder1.state_dict(), decoder_path)\n",
    "    torch.save(encoder1.state_dict(), encoder_path)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(attn_decoder1.state_dict(), \"D:/data6/10iter_decoder\")\n",
    "#torch.save(encoder1.state_dict(), \"D:/data6/10iter_encoder\")\n",
    "#model = TheModelClass(*args, **kwargs)\n",
    "#model.load_state_dict(torch.load(PATH))\n",
    "#model.eval() 3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> you re stronger than us .\n",
      "= du bist starker als wir .\n",
      "< sie sind starker als wir . <EOS>\n",
      "\n",
      "> he s an excellent brain surgeon .\n",
      "= er ist ein gro artiger hirnchirurg .\n",
      "< er ist ein guter er . . <EOS>\n",
      "\n",
      "> i m so sorry .\n",
      "= das tut mir sehr leid .\n",
      "< es tut mir sehr leid . <EOS>\n",
      "\n",
      "> he is a fast runner .\n",
      "= er ist ein schneller laufer .\n",
      "< er ist ein schneller laufer . <EOS>\n",
      "\n",
      "> i am washing my brother s car .\n",
      "= ich wasche den wagen meines bruders .\n",
      "< ich interessiere mit meinem auto auto . <EOS>\n",
      "\n",
      "> i m going to boston for thanksgiving .\n",
      "= ich fahre zum erntedankfest nach boston .\n",
      "< ich fahre nach boston nach boston . <EOS>\n",
      "\n",
      "> he is always laughing .\n",
      "= er lacht immer .\n",
      "< er lacht immer . <EOS>\n",
      "\n",
      "> he s buying an old hat .\n",
      "= er kauft einen alten hut .\n",
      "< er ist einen alten . . <EOS>\n",
      "\n",
      "> we re a long way from home .\n",
      "= wir sind fernab der heimat .\n",
      "< wir sind von der hause . <EOS>\n",
      "\n",
      "> he is a medical student .\n",
      "= er ist medizinstudent .\n",
      "< er ist student student . <EOS>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "evaluateRandomly(encoder1, attn_decoder1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 10)\n",
      "['ich', 'tue', 'mein', 'an', '.', '<EOS>']\n",
      "[[3.5155601e-06 9.9994254e-01 9.7708853e-06 4.1779476e-05 8.7276923e-09\n",
      "  1.4442042e-09 5.3250083e-08 2.1113597e-06 2.2067022e-07 1.3475658e-07]\n",
      " [1.4700676e-06 2.9412363e-04 1.2592989e-05 9.9690753e-01 3.3379237e-08\n",
      "  2.7584888e-03 6.3479993e-10 2.1748529e-05 6.5016316e-08 3.9088613e-06]\n",
      " [2.8746662e-04 2.5774317e-02 1.2194586e-03 3.4673192e-04 9.1602081e-01\n",
      "  5.5792920e-02 2.1461681e-06 1.6593130e-04 2.6028344e-04 1.2982679e-04]\n",
      " [1.3434930e-05 2.4144172e-04 5.4845359e-06 1.4255546e-05 1.7102620e-02\n",
      "  9.8260337e-01 9.5763575e-09 1.4521927e-05 3.3805375e-07 4.5601369e-06]\n",
      " [5.4318330e-04 2.4096256e-05 2.5761570e-04 7.4889149e-06 2.3950626e-04\n",
      "  9.2479169e-01 1.1867065e-03 1.9699689e-04 4.8817170e-04 7.2264507e-02]\n",
      " [1.3949712e-02 3.9677344e-02 7.6107658e-03 2.5219308e-05 9.2762615e-09\n",
      "  1.7558050e-01 4.9482751e-01 4.8227608e-03 7.8385789e-03 2.5566757e-01]]\n",
      "[1, 3, 4, 5, 5, 6]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "output_words, attentions = evaluate(encoder1, attn_decoder1, \"i am brushing my teeth\")\n",
    "print(attentions.numpy().shape)\n",
    "print(output_words)\n",
    "print(attentions.numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 3, 4, 5, 5, 6]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 480x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"indexes of most important items in row matrix\")\n",
    "print([ np.argmax(nparr) for nparr in  attentions.numpy() ])\n",
    "plt.matshow(attentions.numpy())\n",
    "display(plt.figure())\n",
    "plt.figure().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def showAttention(input_sentence, output_words, attentions):\n",
    "    # Set up figure with colorbar\n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    cax = ax.matshow(attentions.numpy(), cmap='bone')\n",
    "    fig.colorbar(cax)\n",
    "\n",
    "    # Set up axes\n",
    "    ax.set_xticklabels([''] + input_sentence.split(' ') +\n",
    "                       ['<EOS>'], rotation=90)\n",
    "    ax.set_yticklabels([''] + output_words)\n",
    "\n",
    "    # Show label at every tick\n",
    "    ax.xaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "    ax.yaxis.set_major_locator(ticker.MultipleLocator(1))\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def evaluateAndShowAttention(input_sentence):\n",
    "    output_words, attentions = evaluate(\n",
    "        encoder1, attn_decoder1, input_sentence)\n",
    "    print('input =', input_sentence)\n",
    "    print('output =', ' '.join(output_words))\n",
    "    showAttention(input_sentence, output_words, attentions)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input = you re not that old\n",
      "output = das sind alt nicht . <EOS>\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluateAndShowAttention(\"you re not that old\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input = i m buying fruit and chocolate .\n",
      "output = ich bin gerade und und maria . <EOS>\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluateAndShowAttention(\"i m buying fruit and chocolate .\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input = i m a very careful driver .\n",
      "output = ich bin ein sehr vorsichtiger fahrer . <EOS>\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "evaluateAndShowAttention(\"i m a very careful driver .\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_tensor :  i m closing the door . EOS\n",
      "target_tensor :  ich mache die tur zu . EOS\n"
     ]
    }
   ],
   "source": [
    "def indexes_to_word(lang,indexes):\n",
    "    return \" \".join( [lang.index2word[i]  for i in torch.flatten(indexes).numpy() ] )\n",
    "\n",
    "training_pairs = [tensorsFromPair(random.choice(pairs))for i in range(5000)]\n",
    "iter = 1\n",
    "\n",
    "training_pair = training_pairs[iter - 1]\n",
    "input_tensor = training_pair[0]\n",
    "target_tensor = training_pair[1]\n",
    "print(\"input_tensor : \",indexes_to_word(input_lang,input_tensor) )\n",
    "print(\"target_tensor : \",indexes_to_word(output_lang,target_tensor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_length 7\n",
      "target_length 7\n"
     ]
    }
   ],
   "source": [
    "input_length = input_tensor.size(0)\n",
    "target_length = target_tensor.size(0)\n",
    "print(\"input_length\",input_length)\n",
    "print(\"target_length\",target_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_length : 10\n"
     ]
    }
   ],
   "source": [
    "encoder = encoder1\n",
    "decoder = attn_decoder1\n",
    "max_length=MAX_LENGTH\n",
    "print(\"max_length :\",max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AttnDecoderRNN(\n",
      "  (embedding): Embedding(4896, 256)\n",
      "  (attn): Linear(in_features=512, out_features=10, bias=True)\n",
      "  (attn_combine): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (dropout): Dropout(p=0.1)\n",
      "  (gru): GRU(256, 256)\n",
      "  (out): Linear(in_features=256, out_features=4896, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(attn_decoder1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_outputs torch.Size([10, 256])\n"
     ]
    }
   ],
   "source": [
    "encoder_outputs = torch.zeros(max_length, encoder.hidden_size, device=device)\n",
    "print(\"encoder_outputs\",encoder_outputs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_outputs torch.Size([1, 1, 256])\n"
     ]
    }
   ],
   "source": [
    "encoder_hidden = encoder.initHidden()\n",
    "print(\"encoder_outputs\",encoder_hidden.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_hidden torch.Size([1, 1, 256])\n",
      "encoder_hidden tensor([[[-0.1092,  0.6068,  0.6440,  0.1092,  0.1501,  0.6047, -0.8387,\n",
      "          -0.8166, -0.0886, -0.1754,  0.7156, -0.7780,  0.1701,  0.0252,\n",
      "           0.0283, -0.8889,  0.7755, -0.6490,  0.4626, -0.0189, -0.2753,\n",
      "           0.1085,  0.8545,  0.0745, -0.7322,  0.5764,  0.2409, -0.7780,\n",
      "           0.1100,  0.0108, -0.2655, -0.2258,  0.8253, -0.1568,  0.0476,\n",
      "          -0.3258,  0.1139, -0.2597,  0.1731,  0.0390, -0.7949, -0.1106,\n",
      "          -0.9918,  0.4892, -0.0011, -0.9184,  0.0561, -0.1848,  0.2176,\n",
      "           0.8691,  0.5009,  0.1114,  0.9000,  0.0548,  0.1529, -0.2991,\n",
      "          -0.4482, -0.1742,  0.0416,  0.8619,  0.8541,  0.8378, -0.9243,\n",
      "          -0.3110,  0.4997,  0.0314, -0.4088,  0.7165, -0.8355,  0.2656,\n",
      "          -0.7589,  0.4529, -0.9281, -0.6741, -0.0077, -0.8612,  0.3483,\n",
      "          -0.1057, -0.5053,  0.9401,  0.7951, -0.1663, -0.3451,  0.8863,\n",
      "          -0.1060,  0.8377, -0.9407,  0.8254,  0.0784,  0.8332, -0.3038,\n",
      "          -0.0266,  0.0584, -0.8761, -0.5964,  0.2498, -0.2282, -0.3760,\n",
      "           0.4940, -0.2479,  0.1672,  0.4872, -0.3475,  0.9688, -0.1245,\n",
      "           0.2851, -0.0974, -0.2470,  0.9328,  0.8647, -0.4430,  0.1557,\n",
      "          -0.4883, -0.0159,  0.8826,  0.1350, -0.2787, -0.7492,  0.6373,\n",
      "          -0.2143, -0.1203, -0.1220, -0.9317,  0.4598, -0.9888, -0.2049,\n",
      "          -0.9178, -0.9268,  0.0235, -0.7634, -0.0920,  0.2381,  0.3328,\n",
      "           0.7672,  0.8044, -0.2798,  0.0063, -0.8700,  0.1700,  0.8443,\n",
      "          -0.2041,  0.7297,  0.9023, -0.7399, -0.9696,  0.8416,  0.3069,\n",
      "           0.9293,  0.6910,  0.0459,  0.3512, -0.9910,  0.0374,  0.1552,\n",
      "           0.8537,  0.8629, -0.8872,  0.4421,  0.9189, -0.0777,  0.8264,\n",
      "          -0.8764,  0.9869,  0.5751,  0.8739,  0.0553, -0.4139,  0.6360,\n",
      "           0.0461,  0.0839,  0.9244,  0.2797,  0.1449,  0.3668,  0.6134,\n",
      "           0.8323, -0.4133,  0.1577, -0.6245,  0.1442,  0.2696,  0.7792,\n",
      "           0.7934,  0.4425, -0.3556, -0.7061, -0.9007, -0.4681,  0.2276,\n",
      "          -0.6655,  0.2524, -0.0241, -0.2565,  0.8887,  0.5414, -0.0132,\n",
      "          -0.6585, -0.5793, -0.6535, -0.9358,  0.3890, -0.0192,  0.4182,\n",
      "           0.3016,  0.9621, -0.3917, -0.0052,  0.2808, -0.0144,  0.0201,\n",
      "           0.9260,  0.3332,  0.1649, -0.0379, -0.9195, -0.6127,  0.1069,\n",
      "           0.0386, -0.4301, -0.1013,  0.7359,  0.8485, -0.2067,  0.0612,\n",
      "           0.0918,  0.9900, -0.4721,  0.5813,  0.5040, -0.4884, -0.0186,\n",
      "           0.6659,  0.0462,  0.6122,  0.5591,  0.4197,  0.1086,  0.8544,\n",
      "          -0.7995,  0.1715, -0.8784,  0.3103,  0.9831,  0.8356,  0.1967,\n",
      "           0.5462,  0.8352,  0.1294,  0.3536, -0.0632, -0.1395, -0.1212,\n",
      "           0.9878,  0.0129, -0.7997, -0.3886]]], grad_fn=<StackBackward>)\n",
      "encoder_output torch.Size([1, 1, 256])\n",
      "encoder_output tensor([[[-0.1092,  0.6068,  0.6440,  0.1092,  0.1501,  0.6047, -0.8387,\n",
      "          -0.8166, -0.0886, -0.1754,  0.7156, -0.7780,  0.1701,  0.0252,\n",
      "           0.0283, -0.8889,  0.7755, -0.6490,  0.4626, -0.0189, -0.2753,\n",
      "           0.1085,  0.8545,  0.0745, -0.7322,  0.5764,  0.2409, -0.7780,\n",
      "           0.1100,  0.0108, -0.2655, -0.2258,  0.8253, -0.1568,  0.0476,\n",
      "          -0.3258,  0.1139, -0.2597,  0.1731,  0.0390, -0.7949, -0.1106,\n",
      "          -0.9918,  0.4892, -0.0011, -0.9184,  0.0561, -0.1848,  0.2176,\n",
      "           0.8691,  0.5009,  0.1114,  0.9000,  0.0548,  0.1529, -0.2991,\n",
      "          -0.4482, -0.1742,  0.0416,  0.8619,  0.8541,  0.8378, -0.9243,\n",
      "          -0.3110,  0.4997,  0.0314, -0.4088,  0.7165, -0.8355,  0.2656,\n",
      "          -0.7589,  0.4529, -0.9281, -0.6741, -0.0077, -0.8612,  0.3483,\n",
      "          -0.1057, -0.5053,  0.9401,  0.7951, -0.1663, -0.3451,  0.8863,\n",
      "          -0.1060,  0.8377, -0.9407,  0.8254,  0.0784,  0.8332, -0.3038,\n",
      "          -0.0266,  0.0584, -0.8761, -0.5964,  0.2498, -0.2282, -0.3760,\n",
      "           0.4940, -0.2479,  0.1672,  0.4872, -0.3475,  0.9688, -0.1245,\n",
      "           0.2851, -0.0974, -0.2470,  0.9328,  0.8647, -0.4430,  0.1557,\n",
      "          -0.4883, -0.0159,  0.8826,  0.1350, -0.2787, -0.7492,  0.6373,\n",
      "          -0.2143, -0.1203, -0.1220, -0.9317,  0.4598, -0.9888, -0.2049,\n",
      "          -0.9178, -0.9268,  0.0235, -0.7634, -0.0920,  0.2381,  0.3328,\n",
      "           0.7672,  0.8044, -0.2798,  0.0063, -0.8700,  0.1700,  0.8443,\n",
      "          -0.2041,  0.7297,  0.9023, -0.7399, -0.9696,  0.8416,  0.3069,\n",
      "           0.9293,  0.6910,  0.0459,  0.3512, -0.9910,  0.0374,  0.1552,\n",
      "           0.8537,  0.8629, -0.8872,  0.4421,  0.9189, -0.0777,  0.8264,\n",
      "          -0.8764,  0.9869,  0.5751,  0.8739,  0.0553, -0.4139,  0.6360,\n",
      "           0.0461,  0.0839,  0.9244,  0.2797,  0.1449,  0.3668,  0.6134,\n",
      "           0.8323, -0.4133,  0.1577, -0.6245,  0.1442,  0.2696,  0.7792,\n",
      "           0.7934,  0.4425, -0.3556, -0.7061, -0.9007, -0.4681,  0.2276,\n",
      "          -0.6655,  0.2524, -0.0241, -0.2565,  0.8887,  0.5414, -0.0132,\n",
      "          -0.6585, -0.5793, -0.6535, -0.9358,  0.3890, -0.0192,  0.4182,\n",
      "           0.3016,  0.9621, -0.3917, -0.0052,  0.2808, -0.0144,  0.0201,\n",
      "           0.9260,  0.3332,  0.1649, -0.0379, -0.9195, -0.6127,  0.1069,\n",
      "           0.0386, -0.4301, -0.1013,  0.7359,  0.8485, -0.2067,  0.0612,\n",
      "           0.0918,  0.9900, -0.4721,  0.5813,  0.5040, -0.4884, -0.0186,\n",
      "           0.6659,  0.0462,  0.6122,  0.5591,  0.4197,  0.1086,  0.8544,\n",
      "          -0.7995,  0.1715, -0.8784,  0.3103,  0.9831,  0.8356,  0.1967,\n",
      "           0.5462,  0.8352,  0.1294,  0.3536, -0.0632, -0.1395, -0.1212,\n",
      "           0.9878,  0.0129, -0.7997, -0.3886]]], grad_fn=<StackBackward>)\n"
     ]
    }
   ],
   "source": [
    "for ei in range(input_length):\n",
    "        encoder_output, encoder_hidden = encoder(input_tensor[ei], encoder_hidden)\n",
    "        \n",
    "        if ei == 0:\n",
    "            print(\"encoder_hidden\",encoder_hidden.shape)\n",
    "            print(\"encoder_hidden\",encoder_hidden)\n",
    "            print(\"encoder_output\",encoder_output.shape)\n",
    "            print(\"encoder_output\",encoder_output)\n",
    "            \n",
    "        encoder_outputs[ei] = encoder_output[0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "encoder_output torch.Size([10, 256])\n",
      "encoder_output tensor([[-0.1092,  0.6068,  0.6440,  ...,  0.0129, -0.7997, -0.3886],\n",
      "        [-0.8371,  0.6621,  0.5844,  ...,  0.9000, -0.9071, -0.4584],\n",
      "        [-0.3424,  0.7598,  0.1242,  ...,  0.7139, -0.6456,  0.7970],\n",
      "        ...,\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
      "       grad_fn=<CopySlices>)\n"
     ]
    }
   ],
   "source": [
    "#now we have encoder from all steps and we make 10 wors of 256 dim\n",
    "print(\"encoder_output\",encoder_outputs.shape)\n",
    "print(\"encoder_output\",encoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_input = torch.tensor([[SOS_token]], device=device)\n",
    "decoder_hidden = encoder_hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "target_length 7\n",
      "decoder_output.shape torch.Size([1, 4896])\n",
      "decoder_output tensor([[-1.6563e+01, -1.5192e+01, -5.3444e-03,  ..., -1.6197e+01,\n",
      "         -1.6191e+01, -1.5635e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "decoder_hidden.shape torch.Size([1, 1, 256])\n",
      "decoder_hidden tensor([[[-0.8016, -0.7724,  0.9238,  0.7037,  0.5894,  1.0000,  0.9223,\n",
      "           0.9990,  0.7645,  0.9569, -0.1074, -0.3077,  0.9858, -0.5696,\n",
      "           0.6748,  0.9833,  0.0442, -0.9999, -0.9983, -0.8694,  0.0173,\n",
      "           0.9456,  0.9759, -0.6829, -0.2656, -0.9995,  0.9987,  0.9984,\n",
      "           0.7189, -0.9469,  0.9875,  0.5727,  0.9672, -0.3181, -0.9997,\n",
      "          -0.1843, -0.7806,  0.9936, -0.9996, -0.9716,  0.9808,  0.7352,\n",
      "          -0.9904, -0.9927, -0.6990, -0.4892,  0.9596, -0.2970,  0.9999,\n",
      "          -0.9401, -0.2684, -0.9877,  0.7597, -0.9900,  0.8922,  0.9995,\n",
      "          -0.0862, -0.9576, -0.9538, -0.9986,  0.9969,  0.9616,  0.8432,\n",
      "           0.9990, -0.6265, -0.5858, -0.9544, -0.9805,  0.9985, -0.9995,\n",
      "           0.9955, -0.5770, -0.1557, -0.9651,  0.5096, -0.6336, -0.8500,\n",
      "          -0.9835, -0.6220,  0.9906,  0.9913,  0.9954,  0.9708,  0.8624,\n",
      "           1.0000,  0.9981,  0.9639, -0.9678,  0.9745,  0.7659,  0.9761,\n",
      "          -0.7586,  0.7537, -0.9968, -0.5809, -0.0678, -0.9913, -0.2133,\n",
      "           0.3734,  0.7233, -0.6260,  0.1189,  0.9630, -0.9142, -0.1629,\n",
      "          -0.9398,  0.8927,  0.9989,  0.5730, -0.0029, -0.9869, -0.8568,\n",
      "          -0.9970,  0.9475,  0.9879, -0.9572,  0.9908,  0.9617, -0.6184,\n",
      "           0.6167,  0.9222,  0.9233,  0.2805,  0.9025, -0.1979,  0.0959,\n",
      "           0.9984,  0.8612, -0.9969, -0.2268, -0.0645,  0.9452,  0.6616,\n",
      "           0.8540, -0.1089,  0.9742,  0.7900, -0.8106, -0.3366, -0.1564,\n",
      "           0.2420, -0.9999, -0.9953, -0.9637, -0.6672,  0.6520, -0.5433,\n",
      "           0.4821,  0.1737, -0.9708, -0.9172,  0.9988,  0.9679,  0.9999,\n",
      "           0.5521, -0.9998,  0.4125,  0.0720, -0.9742,  0.0542, -0.9182,\n",
      "           0.3320, -0.4805, -0.4277,  0.9881,  0.8479, -0.9981,  0.2460,\n",
      "           0.8852, -0.9909, -0.2045,  0.9519, -0.9969, -0.1988,  0.9980,\n",
      "          -0.7656, -0.9949,  0.2546, -0.5974, -0.9904, -0.9946,  0.9890,\n",
      "          -0.0873,  0.8336,  0.1830,  0.9210,  0.8610,  0.9524, -0.0228,\n",
      "          -0.9988, -0.0145,  0.9954,  0.9868,  0.9999,  0.0903, -0.9160,\n",
      "          -0.7118,  0.1970, -0.9989, -0.6454, -0.8484, -0.7407, -0.3676,\n",
      "           0.9360, -0.9681,  0.9912, -0.9783,  0.5242,  0.9362, -0.9698,\n",
      "           0.9900, -0.1154,  0.9707,  0.9779, -0.9965, -0.9080, -0.0671,\n",
      "           0.6978,  0.9486, -0.9511,  1.0000, -0.9997, -0.3561, -0.9991,\n",
      "           0.9923, -0.5246, -0.7976,  0.5648,  0.2349,  0.0362, -0.5660,\n",
      "           0.9700, -0.2081,  0.0772,  0.9880,  0.8829, -0.9004, -0.8776,\n",
      "           0.9535,  0.9999, -0.8223, -0.9902, -0.4797, -0.5946, -0.7598,\n",
      "           0.9939, -0.8206, -0.9968,  0.9920, -0.8839, -0.8106, -0.9879,\n",
      "          -0.9132,  0.6700, -0.9990,  0.8779]]], grad_fn=<StackBackward>)\n",
      "decoder_attention.shape torch.Size([1, 10])\n",
      "decoder_attention tensor([[3.3713e-06, 9.9991e-01, 8.4205e-06, 7.4170e-05, 4.5717e-09, 1.0559e-09,\n",
      "         3.6912e-09, 8.2498e-07, 2.2968e-07, 2.6430e-07]],\n",
      "       grad_fn=<SoftmaxBackward>)\n",
      "topv tensor([[-0.0053]], grad_fn=<TopkBackward>)\n",
      "topi tensor([[2]])\n",
      "loss decoder_output tensor([[-1.6563e+01, -1.5192e+01, -5.3444e-03,  ..., -1.6197e+01,\n",
      "         -1.6191e+01, -1.5635e+01]], grad_fn=<LogSoftmaxBackward>)\n",
      "loss decoder_output 2\n",
      "loss target_tensor[di] tensor([2])\n"
     ]
    }
   ],
   "source": [
    "print(\"target_length\",target_length)\n",
    "for di in range(target_length):\n",
    "    decoder_output, decoder_hidden, decoder_attention = decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "    topv, topi = decoder_output.topk(1)\n",
    "    decoder_input = topi.squeeze().detach()  # detach from history as input\n",
    "    if di == 0:\n",
    "        print(\"decoder_output.shape\",decoder_output.shape)\n",
    "        print(\"decoder_output\",decoder_output)\n",
    "        print(\"decoder_hidden.shape\",decoder_hidden.shape)\n",
    "        print(\"decoder_hidden\",decoder_hidden)\n",
    "        print(\"decoder_attention.shape\",decoder_attention.shape)\n",
    "        print(\"decoder_attention\",decoder_attention)\n",
    "        \n",
    "        print(\"topv\",topv)\n",
    "        print(\"topi\",topi)\n",
    "        \n",
    "        print(\"loss decoder_output\",decoder_output)\n",
    "        print(\"loss decoder_output\",np.argmax(decoder_output.detach().numpy()))\n",
    "        print(\"loss target_tensor[di]\",target_tensor[di])\n",
    "        \n",
    "\n",
    "    if decoder_input.item() == EOS_token:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#temp_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def dump_step(step,dump_vector=True):\n",
    "    print(\" - \")\n",
    "    print(step)\n",
    "    \n",
    "    print(temp_map[step].shape)\n",
    "    if dump_vector:\n",
    "        nplist = temp_map[step].flatten().detach().numpy()\n",
    "        if np.ndim( nplist ) == 0:\n",
    "            print(nplist)\n",
    "        else:\n",
    "            print( temp_map[step].flatten()[0:10] )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - \n",
      "input\n",
      "torch.Size([])\n",
      "6\n"
     ]
    }
   ],
   "source": [
    "dump_step(\"input\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - \n",
      "encoder_outputs\n",
      "torch.Size([10, 256])\n",
      "tensor([-0.1092,  0.6068,  0.6440,  0.1092,  0.1501,  0.6047, -0.8387, -0.8166,\n",
      "        -0.0886, -0.1754], grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "dump_step(\"encoder_outputs\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - \n",
      "hidden_\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([-0.0854,  0.9885,  0.1168,  0.0655,  0.5957, -0.8884,  0.8772, -0.6210,\n",
      "         0.2647,  0.9457], grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "dump_step(\"hidden_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - \n",
      "embedded\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([ 1.3873, -0.8388, -0.6731,  1.3380,  0.2238, -0.7001, -1.2516,  1.0845,\n",
      "         0.5144, -0.7362], grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "#embedded = self.embedding(input).view(1, 1, -1)\n",
    "dump_step(\"embedded\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - \n",
      "embedded_dropout\n",
      "torch.Size([1, 1, 256])\n",
      "(array([ 41,  59,  66,  68,  76,  84,  89,  90,  92, 100, 154, 156, 158,\n",
      "       161, 164, 184, 186, 187, 191, 196, 203, 204, 218, 229, 231, 239,\n",
      "       255], dtype=int64),)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([-0., -0.,  0., -0., -0.,  0., -0., -0., -0., -0., -0.,  0.,  0.,\n",
       "       -0.,  0.,  0., -0.,  0.,  0.,  0., -0.,  0., -0.,  0.,  0., -0.,\n",
       "       -0.], dtype=float32)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#drop out layes simply makes some layers 0\n",
    "#dropout_p=0.1 so it makes 0 only this much item\n",
    "#embedded = self.dropout(embedded)\n",
    "dump_step(\"embedded_dropout\",False)    \n",
    "dropouted = temp_map[\"embedded_dropout\"].flatten().detach().numpy()\n",
    "print(np.where(dropouted == 0))\n",
    "dropouted[np.where(dropouted == 0)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 256])\n",
      "torch.Size([1, 256])\n"
     ]
    }
   ],
   "source": [
    "print(temp_map[\"embedded\"][0].shape )\n",
    "print(temp_map[\"hidden_\"][0].shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(temp_map[\"embedded\"][0] )\n",
    "#print(temp_map[\"hidden_\"][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - \n",
      "embedded\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([ 1.3873, -0.8388, -0.6731,  1.3380,  0.2238, -0.7001, -1.2516,  1.0845,\n",
      "         0.5144, -0.7362], grad_fn=<SliceBackward>)\n",
      " - \n",
      "hidden_\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([-0.0854,  0.9885,  0.1168,  0.0655,  0.5957, -0.8884,  0.8772, -0.6210,\n",
      "         0.2647,  0.9457], grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "dump_step(\"embedded\") \n",
    "dump_step(\"hidden_\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - \n",
      "tensor_cat\n",
      "torch.Size([1, 512])\n"
     ]
    }
   ],
   "source": [
    "#tensor_cat = torch.cat((embedded[0], hidden[0]), 1)    \n",
    "#cat is combining the embeding of current word with, hidden state so far\n",
    "dump_step(\"tensor_cat\",False) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - \n",
      "attn_vector\n",
      "torch.Size([1, 10])\n",
      "tensor([ 2.0811e+00, -2.5478e+00, -3.0669e-03, -4.0032e+00, -8.2261e+00,\n",
      "        -1.0330e+00,  6.6546e+00,  1.5191e+00,  1.2613e+00,  5.7775e+00],\n",
      "       grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "#attn_vector = self.attn(tensor_cat)\n",
    "#(attn): Linear(in_features=512, out_features=10, bias=True)\n",
    "#then apply a linear layes and change size from 512 to 10\n",
    "dump_step(\"attn_vector\") \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - \n",
      "attn_weights\n",
      "torch.Size([1, 10])\n",
      "tensor([7.1748e-03, 7.0068e-05, 8.9265e-04, 1.6348e-05, 2.3960e-07, 3.1869e-04,\n",
      "        6.9512e-01, 4.0903e-03, 3.1607e-03, 2.8916e-01],\n",
      "       grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "#attn_weights = F.softmax(attn_vector, dim=1\n",
    "#when softmax applied we find similarity inside sentence as a function of positions\n",
    "dump_step(\"attn_weights\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "attn_weights  torch.Size([1, 10])\n",
      "attn_weights unsqueeze  torch.Size([1, 1, 10])\n",
      "encoder_outputs  torch.Size([10, 256])\n",
      "encoder_outputs unsqueeze  torch.Size([1, 10, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"attn_weights \",temp_map[\"attn_weights\"].shape )\n",
    "print(\"attn_weights unsqueeze \",temp_map[\"attn_weights\"].unsqueeze(0).shape )\n",
    "\n",
    "print(\"encoder_outputs \",temp_map[\"encoder_outputs\"].shape )\n",
    "print(\"encoder_outputs unsqueeze \",temp_map[\"encoder_outputs\"].unsqueeze(0).shape )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - \n",
      "attn_applied\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([-0.5581, -0.3945,  0.6545,  0.5017,  0.4100,  0.2473,  0.6360,  0.5516,\n",
      "         0.5317,  0.6636], grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "#attn_applied = torch.bmm(attn_weights.unsqueeze(0),encoder_outputs.unsqueeze(0))\n",
    "#matrix-matrix product of = attn_weights x encoder_outputs\n",
    "# 1x1x10  X 1x10x256 = 1x1x256\n",
    "#this calculation is the representation of current word\n",
    "dump_step(\"attn_applied\")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - \n",
      "output\n",
      "torch.Size([1, 512])\n",
      "tensor([ 1.5415, -0.9320, -0.7479,  1.4867,  0.2486, -0.7779, -1.3906,  1.2050,\n",
      "         0.5715, -0.8180], grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "#output = torch.cat((embedded[0], attn_applied[0]), 1)\n",
    "#concatanete the atten vector of this step with embedding step\n",
    "dump_step(\"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - \n",
      "output attn_combine\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([-3.7517, -3.1053, -0.6451, -2.5792, -2.2424, -5.1601, -1.2088, -3.2299,\n",
      "        -1.5322, -0.9732], grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "#output = self.attn_combine(output).unsqueeze(0)\n",
    "#(attn_combine): Linear(in_features=512, out_features=256, bias=True)\n",
    "#change dimension by applying a linear layer 512 -> 256\n",
    "dump_step(\"output attn_combine\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - \n",
      "output relu\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0.], grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "# output = F.relu(output)\n",
    "#apply a non linear Relu transformation\n",
    "dump_step(\"output relu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "output torch.Size([1, 1, 256])\n",
      "hidden_ torch.Size([1, 1, 256])\n"
     ]
    }
   ],
   "source": [
    "print(\"output\",temp_map[\"output relu\"].shape)\n",
    "print(\"hidden_\",temp_map[\"hidden_\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - \n",
      "output_step\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([-0.1416,  0.9908, -0.3945, -0.8125,  0.6053, -0.9732,  0.8485, -0.5418,\n",
      "         0.2910,  0.9423], grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "#output, hidden = self.gru(output, hidden)\n",
    "#  (gru): GRU(256, 256)\n",
    "#if this was hidden and output , what will be next hidden and next output\n",
    "dump_step(\"output_step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - \n",
      "hidden_step\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([-0.1416,  0.9908, -0.3945, -0.8125,  0.6053, -0.9732,  0.8485, -0.5418,\n",
      "         0.2910,  0.9423], grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "dump_step(\"hidden_step\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - \n",
      "output_softmax\n",
      "torch.Size([1, 4896])\n",
      "tensor([-13.7911,  -0.1420, -11.2998, -14.7008, -14.5092, -14.5094,  -2.2141,\n",
      "        -10.5906, -10.9292, -12.7085], grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "#output = F.log_softmax(self.out(output[0]), dim=1)\n",
    "#apply a nonlinear function\n",
    "dump_step(\"output_softmax\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " - \n",
      "output_softmax\n",
      "torch.Size([1, 4896])\n",
      "tensor([-13.7911,  -0.1420, -11.2998, -14.7008, -14.5092, -14.5094,  -2.2141,\n",
      "        -10.5906, -10.9292, -12.7085], grad_fn=<SliceBackward>)\n",
      " - \n",
      "hidden_step\n",
      "torch.Size([1, 1, 256])\n",
      "tensor([-0.1416,  0.9908, -0.3945, -0.8125,  0.6053, -0.9732,  0.8485, -0.5418,\n",
      "         0.2910,  0.9423], grad_fn=<SliceBackward>)\n",
      " - \n",
      "attn_weights\n",
      "torch.Size([1, 10])\n",
      "tensor([7.1748e-03, 7.0068e-05, 8.9265e-04, 1.6348e-05, 2.3960e-07, 3.1869e-04,\n",
      "        6.9512e-01, 4.0903e-03, 3.1607e-03, 2.8916e-01],\n",
      "       grad_fn=<SliceBackward>)\n"
     ]
    }
   ],
   "source": [
    "#return output, hidden, attn_weights\n",
    "#4896 is the dimension of target language vocublary\n",
    "dump_step(\"output_softmax\")\n",
    "dump_step(\"hidden_step\")\n",
    "dump_step(\"attn_weights\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input = i m buying fruit and chocolate .\n",
      "output = ich bin gerade und und maria . <EOS>\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXgAAAEjCAYAAAA41BqSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAH7VJREFUeJzt3XmcXGWd7/HPlwAJu0pgVBbDXEGNTACN4MIAOugNiDJzAWUbAdHMMOp1RlEYxwHFHa+DooBmEMRlYARRIxcFRZBFtoQl7MoASsALE0DUsKb7e/84p0ml6e6qrq6qU3XyffM6r66z1PM81cZfPf2c5/we2SYiIupnjaobEBER3ZEAHxFRUwnwERE1lQAfEVFTCfARETWVAB8RUVMJ8BERNZUAHxFRUwnwERE1lQAfUZL0Z5K+LunH5f5sSYdX3a6IdiXAR6z0DeAC4IXl/q+Af6ysNRFTlAAfsdJM298FhgFsrwCGqm1SRPsS4CNWWi5pY8AAkl4NPFptkyLat2bVDYjoIx8AFgL/Q9IVwCbAftU2KaJ9SrrgiIKk6RRDMi8BBNwBrGH7yUobFtGmBPiIkqTrbL+i2bGIQZEhmljtSXo+sBmwjqQdKHrvABsC61bWsIgpSoCPgP8JHApsDvxbw/E/Ah+pokERnZAhmoiSpH1sf6/qdkR0SgJ8RANJbwZeDswYOWb7uOpaFNG+zIOPKEn6KvB24H0U4/D7AS+qtFERU5AAH7HSa22/A3jE9seB1wBbVNymjlDhB5JeVnVboncS4CNWerz8+ZikFwJPA1tV2J5OehMwF3hX1Q2J3sksmhqRNNZ87UeB35R5VWJi50l6DvB54DqKlAWnVtukjjmcIrifKOmo/HtYPeQma41Iugp4BbCEYgx52/L1xsDf276wwuYNlPKp1hm2Bz4XjaSZwC9sv1zSycDFts+uul3RfenB18s9wOG2b4EinznwIeATwLlAAvwYJP2vCc5h+9xetqcL3gGcWb4+neLfQwL8aiABvl5eOhLcAWzfKmkH23dJmuh9q7u3THDOFF+Og+wwYB6A7WslvUDSFrbvrbhd0WUJ8PVyh6RTgLPK/bcDvyqHG56urln9zfZhVbehW8p7Cl+xfV/D4SOBmUACfM1lDL5GJK0D/AOwM8UY/OXAycATwLq2/1Rh8/qepI2AY4FdykO/AI6rwzh8rJ4S4CNKkr4H3AycUR76W2A72+OO0fczSe8GLrH9axVjdKcB+1DcqznE9vVVti+6LwG+RiS9DvgYxdOXzwy/2f7zqto0SCTdYHv7ZscGhaSbgR1sPy3pQOCDFPPhdwCOtf2XlTYwui4POtXL1ymyIe4MvKphi9Y8LmnnkZ3yC/PxCa7vdytsj9x72Qv4pu2HbP8MWK/CdkWP5CZrvTxq+8dVN2KAHQGcUY7FAzxCkUZ4UA1LegHF5/gr4FMN59appknRSwnw9XKxpM9TTOt7Zpk529dV16TBYfsGYDtJG5b7f6i4SVN1DLAImAYsbHg+YlfgriobFr2RMfgakXTxGIdt+w09b8wAkvRp4Hjbvy/3nwt80PZHq21Z+yStCWxg+5GGY+tR/H8/s6pqLgE+oiTpets7jDo20GuyStoUeA9FjnsDtwIn236g0oZFT+Qmaw1IOrj8+YGxti7U97lWjg2gaeVDYcAzzxVMn+D6vlbeJL623P0m8O3y9dXluai5jMHXw8iMiA16VN8bgaNGHdtjjGOD5tvARZJOp+jtvpOVc+IH0ReAvx413/2Hkr4PfA3YqZpmRa9kiKZGJD3P9sNdLP8Iiidl/xz4r4ZTGwBX2D64W3X3iqR5wO7l7k9tX1Ble6ZC0q22Z0/2XNRHevD1crWkGygyBv7Ynf/2/g/gx8BngKMbjv+x018skv5I0Ysek+0NO1lfg+uBtcq6B/1JT0l6buMN1vLg88jw7Goh/yPXyzbAAopH7O+U9GlJ23SwfNu+h+Km3R8btpGg0cmKNiiD+Bcpvkw2AzanGAb6ZCfrGiHpbcA1wL7A2yi+MPftRl09cgJwoaRdJW1QbrtRfEmfUG3TohcyRFNTkl5PMaa8HnAjcLTtK6dY5nm295J0N0UPtzEHsbuREkHS1bZ3anasQ3XdCLzR9oPl/ibAz2xv1+m6ekXSXsCHWXUWzedt/6jShkVPZIimRiRtDBxM0YN/AHgfsBDYnmKBhymtL2p7r/JnL9cpHZJ0EEUKZAMHAENdqmuNkeBeeogB/yvX9nnAeVW3I6qRAF8vVwLfopg5sbTh+CJJX+1UJZJ2Geu47Us7VUeDA4EvlZuBK8pj3fATSRewcvWjtwPnd6murpP0XdtvK19/zvZRDecutP2m6loXvZAhmhqRpC7cWB2rnsY/72cAOwKL6/DErKR9gNdRDD9davv7FTepbY0Pbo1+YGush7qiftKDr5efS3pWgO904LW9yhJ3krYAju9kHQ1lbwK8G5jFqimQ39mN+mx/D/heN8quwERf9unZrQYS4OvlyIbXMygWd1jRg3qXAtt2qewfApcBP6N7Y+/AM4tvfw7YlKIHL4qbx92aktlt60rageI+wjrl65HPlWySq4EM0XSZpLnAv7ByEY6RoDGnR/X/wvauHS7zy6zsAa5BcRP3nm486NTLBTck3Qm8xfZtvaiv28ZJPvcM26/vVVuiGunBd993gA8BNwHD3axo1Fz0NYC5wPO7UNWihtcrgDNtX9GFegDOk7Sn7V7c7HygLsEdEsAjPfiuk3S57Z2bX9mRukbmp0MReO+hWDT68g7WMQ04o1dpCconWtejyG//NF0YNimHZgB2pfhC/AGr5tM/t1N19VqZMG0b2zc2HNsSGLJ9X3Uti15ID777jpV0KnAR3Q8asylyxexMEegvY9Xe9pTZHpK0iaS1bT/VybLHqW+D8i+TrSnuK3TDyE1jA49RrFtKw7GBDfAUX/TnSppje3l57FTgI0ACfM0lwHffYcBLKfKbjAzRdCtonAH8ATix3D+AYl78fh2u5x7gCkkLgZGgge1/63A9SHoX8H6KNAU3AK8GfkmxBF1H2D6srOsM4P2jFvz4QqfqqUK54Pb3Keb0n1b23jex3dEv/uhPCfDdt53tv+hRXS8Z9Vj9xeXj9x0h6Vu2/5YiWJxAMc7f7RTF76dYOPwq26+X9FLg412qa85IcAew/Ug582TQnQr8O3Aa8A6KZHSxGkiA776rJM22fWsP6rpe0qttXwUgaSeKJz875ZWSXgT8FvhyB8udyBO2n5CEpOm2b5f0ki7VtUZj9sVyaGjg/z9S/s4oE88dQDGEF6uBgf/HOwB2Bg4pb4A+SRemSUq6iWLYZy3gHZJ+W+6/iCK5VKd8FfgJRU6bxj/xVdbX8WRjwFJJz6G48flTSY8A93ehHiiGY34p6RyKz/M24FNdqutZJD3f9v/rUvFfp+jJLxmdPjjqa7WaRTMyo2WMXONde6Cl7PE+i+3fdLuObtRV1neK7SM6WWaL9e4KbAT8pFs3eCXNBt5A8W/ioh795TVS9/+1/eYulb0u8DtgH9s/60Yd0X9WqwAfEdGvJJ0G7AU8aPtZT4ZLEkXSvT0pZnsdavu6icoc6FSoERE18g1g3gTn96CYLrw1MB84pVmBq32AlzQ/dQ1GXXX8TKlrcOrptjLd9kRLX+4NfNOFq4DnSHrBRGWu9kM0khbZnpu6+r+uOn6m1DU49Yxl3rx5XrZsWdPrFi9efAvwRMOhBbYXjL5O0izgvHGGaM4DPjvyZLqki4CjJnqmIbNoIiLatGzZMhYtav7MmKQnOvAlpDGOTdhDr1WAHysXerfe98pXvnLS9Wy55ZbMnTt30nUtXrx40nVB+7+Pfq6rjp8pdVVWzzLbm0y17h6OgiwFtmjY35wmU4ZrFeB7qZVv7U4pbp5HRIdNefqwgaHhriaJbbQQeK+ks4CdgEdt/26iNyTAR0S0zbhDi2NJOhPYDZgpaSlwLMXDi9j+KsX6wHsCd1JMkzysWZkJ8BER7TIMd2iExvYBTc4beM9kykyAj4iYgn6eiZgAHxHRJgPDCfAREfWUHnxERA3Z7uUsmklLgI+ImIL04CMiaqpT0yS7obJkY5J+2eT8JZIqyS8REdGK4iZr860qlfXgbb+2qrojIjqln4doquzB/6nh9Ycl3STpRkmfbbhsP0nXSPqVpL+soJkREeMrb7I226pS+Ri8pD2AvwZ2sv1YudDxiDVt7yhpT4rHdncf4/3zKZLfR0T0lOnvHnzlAZ4iaJ9u+zEA240J788tfy4GZo315jKn8gLobZa8iAjIg07NiPFzGj9Z/hyiP9oaEbGKfu7B98OSfRcC7yxXfWfUEE1ERB9zS/9VpfJese2fSNoeWCTpKYqUmB+puFkREU254mmQzVQ5TXL9htefBT476vxuDa+XMc4YfERElYaTqiAion6STTIiosb6+SZrAnxERLvs9OAjIuoqPfiIiBoyMJQAHxFRT+nBR0TUVAJ8DUmqugkd18t/qHX8/cXqx7nJGhFRX+nBR0TUVAJ8REQNFbNokqogIqKWkmwsIqKO7AzRRETUUZbsi4iosUyTjIioqfTgIyJqyDZDWfAjIqKeqlxztZlKFt2WNEvSzWMcP1XS7CraFBHRjmE336pSSYAfj+132b616nZERLRiZBZNs60VkuZJukPSnZKOHuP8lpIulnS9pCWS9mxWZpUBfk1JZ5QNPUfSupIukTQXQNKfJH1K0o2SrpL0ZxW2NSJiTJ0I8JKmAScBewCzgQPGGM34KPBd2zsA+wMnNyu3ygD/EmCB7TnAH4B/GHV+PeAq29sBlwLvHqsQSfMlLZK0qKutjYgYrbzJ2mxrwY7Anbbvsv0UcBaw9+jagA3L1xsB9zcrtMoAf6/tK8rX3wZ2HnX+KeC88vViYNZYhdheYHuu7bldaWVExDg6OESzGXBvw/7S8lijjwEHS1oKnA+8r1mhVQb40Z969P7TXvmbGSIzfiKiDw2XOeEn2oCZIyMN5TZ/VDFjLZAwOiYeAHzD9ubAnsC3JE0Yw6sMmltKeo3tKykafjnwlgrbExExaS1Ok1zWZJRhKbBFw/7mPHsI5nBgHoDtKyXNAGYCD45XaJU9+NuAQyQtAZ4HnFJhWyIi2mI331pwLbC1pK0krU1xE3XhqGt+C/wVgKSXATOA/56o0Ep68LbvobhTPNpuDdes3/D6HOCcrjcsImISTGdy0dheIem9wAXANOA027dIOg5YZHsh8EHg3yX9U1n1oW4ywJ9x7YiIdnUwVYHt8ylunjYeO6bh9a3A6yZTZgJ8RESbki44IqLGEuAjImoq+eAjImrJfZ1NMgE+IqJNk5gGWYkE+IiIKciCHzEQpLGelu6OXt6Y6uXnitVLp+bBd0sCfETEFGQWTUREHU1iQY8qJMBHRExFAnxERD0NDyXAR0TUTjFNMgE+IqKWEuAjImopN1kjImrLwwnwERG1kzH4iIgacx+nKqhyTdZnkXSJpIkWpo2I6CsdWpO1K7reg5e0pu0V3a4nIqLn7HqMwUv6V+Ag4F5gGbAY+D5wErAJ8Bjwbtu3S/oG8DCwA3CdpP8EvgisAzwOHGb7DknrAKdTLMB9W3l+pL43AR8HpgP/Vb7nT1P6tBERHTbwY/DlsMk+FAF7TeA6igC/APh727+WtBNwMvCG8m3bALvbHpK0IbBLuXL47sCny/KOAB6zPUfSnLJcJM0EPlq+f7mko4APAMeN0bb5wPz2Pn5ERPvqsibrzsAPbT8OIOlHwAzgtcDZDelYpze852zbQ+XrjYAzJG1N8TtZqzy+C3AigO0lkpaUx19N0au/oix7beDKsRpmewHFFw2S+vc3HRG1VIcAP1ZC7TWA39vefpz3LG94/QngYtt/I2kWcEnDubF+OwJ+avuAFtsXEdF7Nh4a/Fk0lwNvkTRD0vrAmynG3O+WtB+ACtuN8/6NgPvK14c2HL+UYlwfSdsCc8rjVwGvk/Ti8ty6krZpsa0RET3jMmXwRFtVWgrwtq8FFgI3AucCi4BHKYLz4ZJuBG4B9h6niOOBz0i6ApjWcPwUYP1yaObDwDVlff9N8UVwZnnuKuClk/pkERE9UJdpkv/H9sckrUvR8/6C7buBeaMvtH3oqP0rKW66jvjX8vjjwP5jVWb758CrJtG+iIieqstNVoAFkmZT3Fw9w/Z1XWpTRMRgqEuqAtsHdrMhERGDxwz38U3W5KKJiJiCWvTgIyJiVckmGRFRZwnwERH15P4dgk+Aj4iYigzRRIzy8J96lxh0vfU26lldy5c/2rO6og/YDPfxgh8J8BERber3B536akWniIiB4mLR7WZbKyTNk3SHpDslHT3ONW+TdKukWyT9R7My04OPiJiKDvTgJU2jWDzpjcBS4FpJC23f2nDN1sA/A6+z/YikTZuVmx58RETbmmeSbHEIZ0fgTtt32X4KOItnJ298N3CS7UcAbD/YrNAE+IiIKRgedtMNmClpUcM2ehW6zSiWQx2xtDzWaBtgG0lXSLpK0rMSPY6WIZqIiDa5HINvwTLbcyc4P9aiSqMLXhPYGtgN2By4TNK2tn8/XqHpwUdETEGHhmiWAls07G8O3D/GNT+0/XSZqv0OioA/rgT4iIgp6FCAvxbYWtJWktamWCdj4ahrfgC8HkDSTIohm7smKjRDNBERbevMkny2V0h6L3ABxap3p9m+RdJxwCLbC8tzb5J0KzAEfMj2QxOVOzABXtIlwJG2F1XdlogIoKMLftg+Hzh/1LFjGl4b+EC5tWRgAnxERL8x4KH+fZK1ZwFe0izgPNvblvtHAutT3BG+mmJs6TnA4bYvk7QOcDowG7gNWKdXbY2IaFU/pyrolx78mrZ3lLQncCywO3AE8JjtOZLmAFkDNiL6S+s3USvRLwH+3PLnYmBW+XoX4EQA20skLRnrjeUDA6MfGoiI6IlWc81UoZcBfgWrTsuc0fD6yfLnEKu2qelvzvYCYAGApP79TUdELfVzD76X8+AfADaVtLGk6cBeTa6/FDgIQNK2wJwuty8iYlJG0gV3YB58V/SsB2/76XJO59XA3cDtTd5yCnB6OTRzA3BNl5sYETE5Ns6CHwXbJ1KOq49zfhnlGLztxyme5oqI6FtZkzUioqb6eQw+AT4iol0dfJK1GxLgIyLa1O9rsibAR0S0zQwP9e8gfAJ8RES7MkQTEVFjCfAREfXUx/E9AT6qsfEGG/Ssrl7+CS2NtbRm1FVuskZE1FXri25XIgE+IqJtZjipCiIi6ilDNBERdZUAHxFRP84YfEREffVxBz4BPiKifVmTNSKinkxm0URE1JHJGHxERG318xBNLxfdnhJJl0iaW3U7IiJWcjmVpslWkfTgIyLalXTBBUmzgPNsb1vuHwmsD+wGXA28HngOcLjtyyStA5wOzAZuA9bpVVsjIlo1PJQA38yatneUtCdwLLA7cATwmO05kuYA1431Rknzgfm9a2pERCHZJFtzbvlzMTCrfL0LcCKA7SWSloz1RtsLgAUAkvr3Nx0R9ZMhmmesYNWbujMaXj9Z/hxi1Tb1728uIqLPH3Tq5SyaB4BNJW0saTqwV5PrLwUOApC0LTCny+2LiJg02023qvSsB2/7aUnHUdxQvRu4vclbTgFOL4dmbgCu6XITIyImLQ86lWyfSDmuPs75ZZRj8LYfB/bvTcsiIiavk9kkJc0DvgRMA061/dlxrtsXOBt4le1FE5U5MA86RUT0o04M0UiaBpwE7EExNfwASbPHuG4D4H9TjIQ0lQAfEdG25sG9xTH4HYE7bd9l+yngLGDvMa77BHA88EQrhSbAR0S0qxyiaba1YDPg3ob9peWxZ0jaAdjC9nmtNq9f5sFHRAykFnvoMyU1jpcvKJ/hGaGxin7mpLQGcAJw6GTalgAfEdGmSTzJusz2RMkSlwJbNOxvDtzfsL8BsC1wiSSA5wMLJb11ohutCfAREW0z7syCH9cCW0vaCriPYgbhgc/UYj8KzBzZl3QJcGRm0UREdIvBw823psXYK4D3AhdQJFf8ru1bJB0n6a3tNi89+Ki96dN7l4h0+RMtTW7oiPVmzGh+UXRdp55UtX0+cP6oY8eMc+1urZSZAB8RMQX9nIsmAT4iok1JFxwRUVc2w0MducnaFQnwERFTkR58REQ9uY+XrUiAj4hok7OiU0REXRm3MtG9IgnwERFTkB58RERNDXcmVUFXJMBHRLSpyPfevwG+r3LRSHqhpHOqbkdERMuKO60TbxXpmx68pDVt3w/sW3VbIiJa1c/TJKfcg5c0S9Ltkk6VdLOk70jaXdIVkn4tacdy+6Wk68ufLynfe6iksyX9CLiwLOvmhnIvk3Rdub12qm2NiOi0Di3Z1xWd6sG/GNgPmE+R1/hAYGfgrcBHgHcAu9heIWl34NPAPuV7XwPMsf2wpFkNZT4IvNH2E5K2Bs4EnpUwX9L8st6IiB4zw8NDVTdiXJ0K8HfbvglA0i3ARbYt6SZgFrARcEYZqA2s1fDen9p+eIwy1wK+Iml7YAjYZqyKy2WvFpR19+/fShFRO6vLg05PNrwebtgfLuv4BHCx7b8pe+mXNFy/fJwy/wl4ANiOYiipd4m2IyJatDoE+GY2oliGClpfNHYjYKntYUmHANO60bCIiKno5wDfq2mSxwOfkXQFrQfqk4FDJF1FMTwzXk8/IqIiLUyRrPALQP387TNZGYOPsay9du+WtnvkD7/vWV1Zsm/KFtt+1sSNydhww439qlft0fS6n//8O1Ouqx19Mw8+ImLQ2ElVEBFRU9XOc28mAT4iYgr6ORdNAnxExBSkBx8RUVMJ8BERdVTxNMhmEuAjItpkYNj1z0UT0beeeqp3WS6Getibmz593Z7U8+STj/WknsGUWTQREbWVAB8RUVMJ8BERNVTcY808+IiIGjJOqoKIiHrq5zVZE+AjIqYgY/AREbXkjMFHRNRRv6/J2qsVnSIiasl2060VkuZJukPSnZKOHuP8ByTdKmmJpIskvahZmQnwERFTMDw83HRrRtI04CRgD2A2cICk2aMuux6Ya3sOcA7FUqgTSoCPiGibwcPNt+Z2BO60fZftp4CzgL1Xqcm+2PZI3oirgM2bFZoAHxExBW7hP2CmpEUN2/xRxWwG3Nuwv7Q8Np7DgR83a1tuskZEtGkSN1mXNVl0W2MVP+aF0sHAXGDXZpUOfIAvvwlHfxtGRPREh2bRLAW2aNjfHLh/9EWSdgf+BdjV9pPNCh34AG97AbAAQFL/zleKiBrq2Dz4a4GtJW0F3AfsDxzYeIGkHYCvAfNsP9hKoQMf4CMiqtTKLJlmbK+Q9F7gAmAacJrtWyQdByyyvRD4PLA+cLYkgN/afutE5SbAR0S0qZMPOtk+Hzh/1LFjGl7vPtkyB2YWjaTzJb2w6nZERKzkleuyTrRVZGB68Lb3rLoNERGjmeSiiYiopX7ORZMAHxHRNnfkJmu3JMBHRLQpS/ZFRNRYhmgiImoqAT4iopaqnQbZTAJ8RMQUZNHtiNXEE0891bO6nnzyseYXDZj11tuoZ3UtX/7olMuwYXh4qAOt6Y4E+IiItrW+JF8VEuAjIqYgAT4ioqYS4CMiaioPOkVE1FHF2SKbSYCPiGiTgeH04CMi6ilDNBERtZRpkhERtdXPAX7KS/ZJukTSHZJuKLdzGs7Nl3R7uV0jaeeGc3tJul7SjZJulfR3U21LREQvjazJ2myrSls9eElrA2vZXl4eOsj2olHX7AX8HbCz7WWSXgH8QNKOwEPAAmBH20slTQdmle97ru1H2vs4ERG9ZNzHqQom1YOX9DJJXwDuALZpcvlRwIdsLwOwfR1wBvAeYAOKL5eHynNP2r6jfN/bJd0s6UhJm0ymfRERveYW/qtK0wAvaT1Jh0m6HDgVuA2YY/v6hsu+0zBE8/ny2MuBxaOKWwS83PbDwELgN5LOlHSQpDUAbH8V2ANYB7hU0jmS5o2cj4joJ4M+RPM7YAnwLtu3j3PNs4ZoxiGKqaPYfpekvwB2B44E3ggcWp67F/iEpE8C84CvU3xZvPVZBUrzgfkt1B0R0XGDfpN1X+A+4PuSjpH0ohbLvhV45ahjryiPA2D7JtsnUAT3fRovLMfqTwa+DJwN/PNYldheYHuu7bkttisioiOKHvpw060qTQO87Qttvx3YGXgU+KGkn0ma1eStxwOfk7QxgKTtKXroJ0taX9JuDdduD/ymvO5NkpYAnwQuAWbb/kfbt0zic0VE9MSgD9EAYPsh4EvAl8redeOt4+9Ierx8vcz27rYXStoM+KUkA38EDrb9O0kbAB+W9DXgcWA55fAMxY3Xt9j+zZQ+WUREDwwP9++TrOrn8aPJKr9IIirz4KNTXyWoVZtu1LvVj3qlxys6LZ7q0O60aWt6nRnrN6/rsanX1Y48yRoR0TZj+rcHnwAfEdGmkSdZ+1UCfETEFCTAR0TUVAJ8REQtmeE+zkWTAB8R0aZ+H4NPfpeIiKkYWZd1oq0FZc6tOyTdKenoMc5Pl/Sf5fmrW3jYNAE+IqJ9reSSbB7gJU0DTqJItDgbOEDS7FGXHQ48YvvFwAnA55qVW7chmmWUKQ8mYWb5vl5IXYNRT9t1tfnwUd9/rl7VtXx5Ww+KtfuZWs2rNaEO5ZrZEbjT9l0Aks4C9qYhd1e5/7Hy9TnAVyTJE4wR1SrA2550/nhJi3r1hFnqGox6Utdg1dXLzzSWDqUq2Ay4t2F/KbDTeNfYXiHpUWBjJvhyq1WAj4josQso/oJoZoakxpTqC2wvaNjXGO8Z3TNv5ZpVJMBHRLTJ9rwOFbUU2KJhf3Pg/nGuWSppTWAj4OGJCs1N1mJt2NQ1GHXV8TOlrsGpp5uuBbaWtFW55vX+FKveNVoIHFK+3hf4+UTj71CzbJIREYNK0p7AF4FpwGm2PyXpOGBRmX59BvAtYAeKnvv+Izdlxy0zAT4iop4yRBMRUVMJ8BERNZUAHxFRUwnwERE1lQAfEVFTCfARETWVAB8RUVMJ8BERNfX/AU7KTyI1/O73AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "evaluateAndShowAttention(\"i m buying fruit and chocolate .\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_tensor\n",
      "[  86   47  308 1121  785    4    1]\n",
      "encoder_hidden\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "encoder_outputs\n",
      "[-1.7593610e-01 -2.1630865e-01  9.4348907e-01  7.8240514e-02\n",
      " -3.7888288e-02  9.8887897e-01 -2.3685753e-02 -4.6230555e-03\n",
      " -1.6540289e-05 -2.6783466e-02]\n",
      "input_tensor[ei]\n",
      "[86]\n",
      "encoder_hidden\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "encoder_output\n",
      "[-1.7593610e-01 -2.1630865e-01  9.4348907e-01  7.8240514e-02\n",
      " -3.7888288e-02  9.8887897e-01 -2.3685753e-02 -4.6230555e-03\n",
      " -1.6540289e-05 -2.6783466e-02]\n",
      "encoder_hidden\n",
      "[-1.7593610e-01 -2.1630865e-01  9.4348907e-01  7.8240514e-02\n",
      " -3.7888288e-02  9.8887897e-01 -2.3685753e-02 -4.6230555e-03\n",
      " -1.6540289e-05 -2.6783466e-02]\n",
      "encoder_outputs[ei]\n",
      "[-1.7593610e-01 -2.1630865e-01  9.4348907e-01  7.8240514e-02\n",
      " -3.7888288e-02  9.8887897e-01 -2.3685753e-02 -4.6230555e-03\n",
      " -1.6540289e-05 -2.6783466e-02]\n",
      "input_tensor[ei]\n",
      "[47]\n",
      "encoder_hidden\n",
      "[-1.7593610e-01 -2.1630865e-01  9.4348907e-01  7.8240514e-02\n",
      " -3.7888288e-02  9.8887897e-01 -2.3685753e-02 -4.6230555e-03\n",
      " -1.6540289e-05 -2.6783466e-02]\n",
      "encoder_output\n",
      "[-0.7542075   0.88391465  0.8930207   0.2633628   0.90376514 -0.8088015\n",
      "  0.05146366  0.00679323 -0.00627929 -0.07966429]\n",
      "encoder_hidden\n",
      "[-0.7542075   0.88391465  0.8930207   0.2633628   0.90376514 -0.8088015\n",
      "  0.05146366  0.00679323 -0.00627929 -0.07966429]\n",
      "encoder_outputs[ei]\n",
      "[-0.7542075   0.88391465  0.8930207   0.2633628   0.90376514 -0.8088015\n",
      "  0.05146366  0.00679323 -0.00627929 -0.07966429]\n",
      "input_tensor[ei]\n",
      "[308]\n",
      "encoder_hidden\n",
      "[-0.7542075   0.88391465  0.8930207   0.2633628   0.90376514 -0.8088015\n",
      "  0.05146366  0.00679323 -0.00627929 -0.07966429]\n",
      "encoder_output\n",
      "[ 0.39206272  0.3524688   0.5761658  -0.06910108  0.97472256 -0.7349861\n",
      " -0.96825904 -0.8397676  -0.9948695  -0.92325103]\n",
      "encoder_hidden\n",
      "[ 0.39206272  0.3524688   0.5761658  -0.06910108  0.97472256 -0.7349861\n",
      " -0.96825904 -0.8397676  -0.9948695  -0.92325103]\n",
      "encoder_outputs[ei]\n",
      "[ 0.39206272  0.3524688   0.5761658  -0.06910108  0.97472256 -0.7349861\n",
      " -0.96825904 -0.8397676  -0.9948695  -0.92325103]\n",
      "input_tensor[ei]\n",
      "[1121]\n",
      "encoder_hidden\n",
      "[ 0.39206272  0.3524688   0.5761658  -0.06910108  0.97472256 -0.7349861\n",
      " -0.96825904 -0.8397676  -0.9948695  -0.92325103]\n",
      "encoder_output\n",
      "[ 0.54065156 -0.7420459   0.8890293  -0.9529074   0.96917534  0.71407604\n",
      " -0.96831053 -0.2064991  -0.9947927  -0.9235634 ]\n",
      "encoder_hidden\n",
      "[ 0.54065156 -0.7420459   0.8890293  -0.9529074   0.96917534  0.71407604\n",
      " -0.96831053 -0.2064991  -0.9947927  -0.9235634 ]\n",
      "encoder_outputs[ei]\n",
      "[ 0.54065156 -0.7420459   0.8890293  -0.9529074   0.96917534  0.71407604\n",
      " -0.96831053 -0.2064991  -0.9947927  -0.9235634 ]\n",
      "input_tensor[ei]\n",
      "[785]\n",
      "encoder_hidden\n",
      "[ 0.54065156 -0.7420459   0.8890293  -0.9529074   0.96917534  0.71407604\n",
      " -0.96831053 -0.2064991  -0.9947927  -0.9235634 ]\n",
      "encoder_output\n",
      "[ 0.56604874 -0.8650006   0.56354403 -0.8137416   0.97060996  0.8438838\n",
      " -0.9642816  -0.11771834 -0.9941309  -0.7878432 ]\n",
      "encoder_hidden\n",
      "[ 0.56604874 -0.8650006   0.56354403 -0.8137416   0.97060996  0.8438838\n",
      " -0.9642816  -0.11771834 -0.9941309  -0.7878432 ]\n",
      "encoder_outputs[ei]\n",
      "[ 0.56604874 -0.8650006   0.56354403 -0.8137416   0.97060996  0.8438838\n",
      " -0.9642816  -0.11771834 -0.9941309  -0.7878432 ]\n",
      "input_tensor[ei]\n",
      "[4]\n",
      "encoder_hidden\n",
      "[ 0.56604874 -0.8650006   0.56354403 -0.8137416   0.97060996  0.8438838\n",
      " -0.9642816  -0.11771834 -0.9941309  -0.7878432 ]\n",
      "encoder_output\n",
      "[ 0.54352087 -0.88621926  0.51307887 -0.8122682   0.9699768   0.9491329\n",
      " -0.96412814 -0.02189118 -0.9941074  -0.78786874]\n",
      "encoder_hidden\n",
      "[ 0.54352087 -0.88621926  0.51307887 -0.8122682   0.9699768   0.9491329\n",
      " -0.96412814 -0.02189118 -0.9941074  -0.78786874]\n",
      "encoder_outputs[ei]\n",
      "[ 0.54352087 -0.88621926  0.51307887 -0.8122682   0.9699768   0.9491329\n",
      " -0.96412814 -0.02189118 -0.9941074  -0.78786874]\n",
      "input_tensor[ei]\n",
      "[1]\n",
      "encoder_hidden\n",
      "[ 0.54352087 -0.88621926  0.51307887 -0.8122682   0.9699768   0.9491329\n",
      " -0.96412814 -0.02189118 -0.9941074  -0.78786874]\n",
      "encoder_output\n",
      "[ 0.5342927  -0.90317994  0.97692466 -0.81295824  0.9695801   0.7919644\n",
      " -0.96411496  0.6183976  -0.9941051  -0.7878885 ]\n",
      "encoder_hidden\n",
      "[ 0.5342927  -0.90317994  0.97692466 -0.81295824  0.9695801   0.7919644\n",
      " -0.96411496  0.6183976  -0.9941051  -0.7878885 ]\n",
      "encoder_outputs[ei]\n",
      "[ 0.5342927  -0.90317994  0.97692466 -0.81295824  0.9695801   0.7919644\n",
      " -0.96411496  0.6183976  -0.9941051  -0.7878885 ]\n",
      "decoder_input\n",
      "[0]\n",
      "decoder_hidden\n",
      "[ 0.5342927  -0.90317994  0.97692466 -0.81295824  0.9695801   0.7919644\n",
      " -0.96411496  0.6183976  -0.9941051  -0.7878885 ]\n",
      "decoder_output\n",
      "[-14.612953 -18.706139  -9.223409 -15.998459 -15.343628 -14.345232\n",
      " -16.009802 -16.18325  -13.4216   -14.382787]\n",
      "decoder_hidden\n",
      "[-0.47945178 -0.8491018   0.921155   -0.8129932   0.96958077  0.999578\n",
      " -0.9640782   0.99723125 -0.9940752  -0.78761816]\n",
      "decoder_attention\n",
      "[6.8175409e-06 9.9995100e-01 6.0015818e-06 2.7594931e-05 4.9031764e-06\n",
      " 3.2013194e-12 1.4432030e-09 2.9657813e-06 6.7130765e-07 1.6380919e-07]\n",
      "decoder_attentions[di]\n",
      "[6.8175409e-06 9.9995100e-01 6.0015818e-06 2.7594931e-05 4.9031764e-06\n",
      " 3.2013194e-12 1.4432030e-09 2.9657813e-06 6.7130765e-07 1.6380919e-07]\n",
      "topv\n",
      "[-0.49984455]\n",
      "topi\n",
      "[178]\n",
      "output_lang.index2word[topi.item()]\n",
      "sie\n",
      "decoder_input\n",
      "178\n",
      "decoder_output\n",
      "[-14.912771 -21.152826 -18.97574  -13.050278 -13.487589 -12.687142\n",
      " -17.519554 -18.762333 -11.621705 -17.330126]\n",
      "decoder_hidden\n",
      "[ 0.36163074  0.03798312 -0.3487898  -0.43154913  0.96955156  0.9931243\n",
      " -0.9637198   0.99239844 -0.99381447 -0.7791345 ]\n",
      "decoder_attention\n",
      "[2.1189858e-06 1.0819801e-04 3.7001493e-05 9.9984014e-01 8.7757517e-06\n",
      " 3.2306067e-09 1.2289875e-07 2.6449536e-06 4.5542198e-08 9.4000558e-07]\n",
      "decoder_attentions[di]\n",
      "[2.1189858e-06 1.0819801e-04 3.7001493e-05 9.9984014e-01 8.7757517e-06\n",
      " 3.2306067e-09 1.2289875e-07 2.6449536e-06 4.5542198e-08 9.4000558e-07]\n",
      "topv\n",
      "[-0.20918179]\n",
      "topi\n",
      "[61]\n",
      "output_lang.index2word[topi.item()]\n",
      "sind\n",
      "decoder_input\n",
      "61\n",
      "decoder_output\n",
      "[-13.654704  -18.077385  -13.249944  -17.871777  -10.4526005  -9.345276\n",
      " -13.855337  -13.201291  -14.432425  -15.886722 ]\n",
      "decoder_hidden\n",
      "[-0.9955592   0.04830062 -0.97184753 -0.34572828  0.96955806  0.99965495\n",
      " -0.9636041   0.99994284 -0.993823   -0.77752006]\n",
      "decoder_attention\n",
      "[8.9320046e-08 4.7358101e-10 2.0736334e-08 1.0297622e-05 9.9998963e-01\n",
      " 6.9516293e-10 1.4973327e-12 1.3947948e-08 5.4743188e-09 6.3108612e-09]\n",
      "decoder_attentions[di]\n",
      "[8.9320046e-08 4.7358101e-10 2.0736334e-08 1.0297622e-05 9.9998963e-01\n",
      " 6.9516293e-10 1.4973327e-12 1.3947948e-08 5.4743188e-09 6.3108612e-09]\n",
      "topv\n",
      "[-0.0866642]\n",
      "topi\n",
      "[419]\n",
      "output_lang.index2word[topi.item()]\n",
      "starker\n",
      "decoder_input\n",
      "419\n",
      "decoder_output\n",
      "[-18.05985  -16.633566 -17.335865 -27.165249 -14.316173 -14.418795\n",
      " -10.028908 -20.639734 -17.537874 -20.093346]\n",
      "decoder_hidden\n",
      "[-0.9832095  -0.00201285 -0.9949693   0.98426265  0.9695636   0.9998202\n",
      " -0.9635362   0.99848294 -0.9943702  -0.5616342 ]\n",
      "decoder_attention\n",
      "[1.7492690e-05 5.4047379e-04 3.8960252e-06 1.4984146e-06 4.0183857e-01\n",
      " 5.9758943e-01 4.3506612e-09 8.7430919e-07 6.3402135e-06 1.4100337e-06]\n",
      "decoder_attentions[di]\n",
      "[1.7492690e-05 5.4047379e-04 3.8960252e-06 1.4984146e-06 4.0183857e-01\n",
      " 5.9758943e-01 4.3506612e-09 8.7430919e-07 6.3402135e-06 1.4100337e-06]\n",
      "topv\n",
      "[-0.00268173]\n",
      "topi\n",
      "[197]\n",
      "output_lang.index2word[topi.item()]\n",
      "als\n",
      "decoder_input\n",
      "197\n",
      "decoder_output\n",
      "[-15.671103 -12.46684  -12.472179 -23.955578 -15.411159 -16.50602\n",
      "  -7.285095 -20.072042 -15.364641 -17.114822]\n",
      "decoder_hidden\n",
      "[ 0.99720544  0.9171072   0.99783427  0.9656557   0.96960616 -0.9265625\n",
      " -0.96343863  0.33505675 -0.9912677  -0.52683777]\n",
      "decoder_attention\n",
      "[1.5446314e-05 7.9564370e-06 1.0954514e-04 5.7141693e-07 8.2287874e-09\n",
      " 9.8960984e-01 9.6149947e-03 3.0927826e-04 2.3040120e-04 1.0199071e-04]\n",
      "decoder_attentions[di]\n",
      "[1.5446314e-05 7.9564370e-06 1.0954514e-04 5.7141693e-07 8.2287874e-09\n",
      " 9.8960984e-01 9.6149947e-03 3.0927826e-04 2.3040120e-04 1.0199071e-04]\n",
      "topv\n",
      "[-0.00542927]\n",
      "topi\n",
      "[60]\n",
      "output_lang.index2word[topi.item()]\n",
      "wir\n",
      "decoder_input\n",
      "60\n",
      "decoder_output\n",
      "[-12.04853     -5.09879    -14.5455265  -18.802444   -11.215487\n",
      " -13.338102    -0.11153984 -15.2589655   -9.949938   -12.787772  ]\n",
      "decoder_hidden\n",
      "[ 0.990578    0.9978761  -0.667586   -0.7942931   0.9696088  -0.9965898\n",
      " -0.95990163  0.02472603 -0.9334425  -0.5228075 ]\n",
      "decoder_attention\n",
      "[7.1577374e-03 3.7570501e-04 1.2320920e-02 4.9721114e-03 1.7078931e-06\n",
      " 2.4847993e-06 5.4602664e-02 8.2596445e-01 6.8679392e-02 2.5922867e-02]\n",
      "decoder_attentions[di]\n",
      "[7.1577374e-03 3.7570501e-04 1.2320920e-02 4.9721114e-03 1.7078931e-06\n",
      " 2.4847993e-06 5.4602664e-02 8.2596445e-01 6.8679392e-02 2.5922867e-02]\n",
      "topv\n",
      "[-0.11153984]\n",
      "topi\n",
      "[6]\n",
      "output_lang.index2word[topi.item()]\n",
      ".\n",
      "decoder_input\n",
      "6\n",
      "decoder_output\n",
      "[-13.587064    -0.07900429 -16.339703   -16.772223   -13.105274\n",
      " -11.973501    -2.9695377  -14.186764   -12.306777   -14.391694  ]\n",
      "decoder_hidden\n",
      "[-0.18863833  0.99799585 -0.950475   -0.93894553  0.96707946 -0.9995402\n",
      " -0.92334545  0.17458689 -0.727268   -0.4901805 ]\n",
      "decoder_attention\n",
      "[5.3371314e-02 6.3842424e-04 1.7775050e-03 4.9907658e-06 3.4944116e-04\n",
      " 3.3249787e-06 3.8496572e-01 4.1684541e-03 6.0589269e-02 4.9413159e-01]\n",
      "decoder_attentions[di]\n",
      "[5.3371314e-02 6.3842424e-04 1.7775050e-03 4.9907658e-06 3.4944116e-04\n",
      " 3.3249787e-06 3.8496572e-01 4.1684541e-03 6.0589269e-02 4.9413159e-01]\n",
      "topv\n",
      "[-0.07900429]\n",
      "topi\n",
      "[1]\n",
      "decoded_words\n",
      "['sie', 'sind', 'starker', 'als', 'wir', '.', '<EOS>']\n",
      "input_tensor\n",
      "[  48   51  394 2064 2644 2645    4    1]\n",
      "encoder_hidden\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "encoder_outputs\n",
      "[-0.24151272  0.07389677  0.14187232 -0.13187045 -0.21201348  0.7023839\n",
      " -0.01192594 -0.8879513   0.86634135 -0.9917318 ]\n",
      "input_tensor[ei]\n",
      "[48]\n",
      "encoder_hidden\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "encoder_output\n",
      "[-0.24151272  0.07389677  0.14187232 -0.13187045 -0.21201348  0.7023839\n",
      " -0.01192594 -0.8879513   0.86634135 -0.9917318 ]\n",
      "encoder_hidden\n",
      "[-0.24151272  0.07389677  0.14187232 -0.13187045 -0.21201348  0.7023839\n",
      " -0.01192594 -0.8879513   0.86634135 -0.9917318 ]\n",
      "encoder_outputs[ei]\n",
      "[-0.24151272  0.07389677  0.14187232 -0.13187045 -0.21201348  0.7023839\n",
      " -0.01192594 -0.8879513   0.86634135 -0.9917318 ]\n",
      "input_tensor[ei]\n",
      "[51]\n",
      "encoder_hidden\n",
      "[-0.24151272  0.07389677  0.14187232 -0.13187045 -0.21201348  0.7023839\n",
      " -0.01192594 -0.8879513   0.86634135 -0.9917318 ]\n",
      "encoder_output\n",
      "[-0.6482212   0.891448    0.8919973  -0.89152443 -0.97769284  0.22702569\n",
      "  0.9632918  -0.9605221   0.9778843  -0.22546959]\n",
      "encoder_hidden\n",
      "[-0.6482212   0.891448    0.8919973  -0.89152443 -0.97769284  0.22702569\n",
      "  0.9632918  -0.9605221   0.9778843  -0.22546959]\n",
      "encoder_outputs[ei]\n",
      "[-0.6482212   0.891448    0.8919973  -0.89152443 -0.97769284  0.22702569\n",
      "  0.9632918  -0.9605221   0.9778843  -0.22546959]\n",
      "input_tensor[ei]\n",
      "[394]\n",
      "encoder_hidden\n",
      "[-0.6482212   0.891448    0.8919973  -0.89152443 -0.97769284  0.22702569\n",
      "  0.9632918  -0.9605221   0.9778843  -0.22546959]\n",
      "encoder_output\n",
      "[-0.7097806  -0.97800183  0.8518405  -0.95546395  0.97160614  0.4333362\n",
      "  0.9656161  -0.989247    0.998423   -0.90831435]\n",
      "encoder_hidden\n",
      "[-0.7097806  -0.97800183  0.8518405  -0.95546395  0.97160614  0.4333362\n",
      "  0.9656161  -0.989247    0.998423   -0.90831435]\n",
      "encoder_outputs[ei]\n",
      "[-0.7097806  -0.97800183  0.8518405  -0.95546395  0.97160614  0.4333362\n",
      "  0.9656161  -0.989247    0.998423   -0.90831435]\n",
      "input_tensor[ei]\n",
      "[2064]\n",
      "encoder_hidden\n",
      "[-0.7097806  -0.97800183  0.8518405  -0.95546395  0.97160614  0.4333362\n",
      "  0.9656161  -0.989247    0.998423   -0.90831435]\n",
      "encoder_output\n",
      "[-0.9811164  -0.6932014   0.9328215  -0.9708646   0.50961274  0.6248839\n",
      "  0.9861287   0.74900913  0.997554   -0.855233  ]\n",
      "encoder_hidden\n",
      "[-0.9811164  -0.6932014   0.9328215  -0.9708646   0.50961274  0.6248839\n",
      "  0.9861287   0.74900913  0.997554   -0.855233  ]\n",
      "encoder_outputs[ei]\n",
      "[-0.9811164  -0.6932014   0.9328215  -0.9708646   0.50961274  0.6248839\n",
      "  0.9861287   0.74900913  0.997554   -0.855233  ]\n",
      "input_tensor[ei]\n",
      "[2644]\n",
      "encoder_hidden\n",
      "[-0.9811164  -0.6932014   0.9328215  -0.9708646   0.50961274  0.6248839\n",
      "  0.9861287   0.74900913  0.997554   -0.855233  ]\n",
      "encoder_output\n",
      "[ 0.2814749  -0.56617093  0.41634318 -0.9755759   0.49274123  0.49076593\n",
      " -0.5543227   0.30738717  0.39301145 -0.8237745 ]\n",
      "encoder_hidden\n",
      "[ 0.2814749  -0.56617093  0.41634318 -0.9755759   0.49274123  0.49076593\n",
      " -0.5543227   0.30738717  0.39301145 -0.8237745 ]\n",
      "encoder_outputs[ei]\n",
      "[ 0.2814749  -0.56617093  0.41634318 -0.9755759   0.49274123  0.49076593\n",
      " -0.5543227   0.30738717  0.39301145 -0.8237745 ]\n",
      "input_tensor[ei]\n",
      "[2645]\n",
      "encoder_hidden\n",
      "[ 0.2814749  -0.56617093  0.41634318 -0.9755759   0.49274123  0.49076593\n",
      " -0.5543227   0.30738717  0.39301145 -0.8237745 ]\n",
      "encoder_output\n",
      "[ 0.51233464 -0.9239316  -0.3551467  -0.95226556  0.62834954  0.02352881\n",
      "  0.70069575 -0.54278785  0.37186188 -0.22674614]\n",
      "encoder_hidden\n",
      "[ 0.51233464 -0.9239316  -0.3551467  -0.95226556  0.62834954  0.02352881\n",
      "  0.70069575 -0.54278785  0.37186188 -0.22674614]\n",
      "encoder_outputs[ei]\n",
      "[ 0.51233464 -0.9239316  -0.3551467  -0.95226556  0.62834954  0.02352881\n",
      "  0.70069575 -0.54278785  0.37186188 -0.22674614]\n",
      "input_tensor[ei]\n",
      "[4]\n",
      "encoder_hidden\n",
      "[ 0.51233464 -0.9239316  -0.3551467  -0.95226556  0.62834954  0.02352881\n",
      "  0.70069575 -0.54278785  0.37186188 -0.22674614]\n",
      "encoder_output\n",
      "[ 0.37555382 -0.9148173  -0.36451867 -0.94278455  0.6072204   0.876757\n",
      "  0.701567   -0.49528795  0.37250882 -0.22695291]\n",
      "encoder_hidden\n",
      "[ 0.37555382 -0.9148173  -0.36451867 -0.94278455  0.6072204   0.876757\n",
      "  0.701567   -0.49528795  0.37250882 -0.22695291]\n",
      "encoder_outputs[ei]\n",
      "[ 0.37555382 -0.9148173  -0.36451867 -0.94278455  0.6072204   0.876757\n",
      "  0.701567   -0.49528795  0.37250882 -0.22695291]\n",
      "input_tensor[ei]\n",
      "[1]\n",
      "encoder_hidden\n",
      "[ 0.37555382 -0.9148173  -0.36451867 -0.94278455  0.6072204   0.876757\n",
      "  0.701567   -0.49528795  0.37250882 -0.22695291]\n",
      "encoder_output\n",
      "[ 0.34769318 -0.9243834   0.9291804  -0.9401198   0.5980281   0.7479402\n",
      "  0.70163095  0.219544    0.37245244 -0.22705102]\n",
      "encoder_hidden\n",
      "[ 0.34769318 -0.9243834   0.9291804  -0.9401198   0.5980281   0.7479402\n",
      "  0.70163095  0.219544    0.37245244 -0.22705102]\n",
      "encoder_outputs[ei]\n",
      "[ 0.34769318 -0.9243834   0.9291804  -0.9401198   0.5980281   0.7479402\n",
      "  0.70163095  0.219544    0.37245244 -0.22705102]\n",
      "decoder_input\n",
      "[0]\n",
      "decoder_hidden\n",
      "[ 0.34769318 -0.9243834   0.9291804  -0.9401198   0.5980281   0.7479402\n",
      "  0.70163095  0.219544    0.37245244 -0.22705102]\n",
      "decoder_output\n",
      "[-18.42891  -16.179373  -8.261306  -9.853549 -16.792713 -18.963173\n",
      " -14.369553 -15.200756 -12.271185 -15.466122]\n",
      "decoder_hidden\n",
      "[-0.7077142  -0.92912626  0.916765   -0.945661    0.5980258   0.99999744\n",
      "  0.70163107  0.9997997   0.3724491  -0.2270501 ]\n",
      "decoder_attention\n",
      "[2.00579530e-06 9.99984503e-01 6.96410962e-06 5.99954001e-06\n",
      " 3.12173398e-09 4.69172574e-12 9.89575177e-09 4.10461240e-07\n",
      " 1.97859762e-07 1.17601694e-07]\n",
      "decoder_attentions[di]\n",
      "[2.00579530e-06 9.99984503e-01 6.96410962e-06 5.99954001e-06\n",
      " 3.12173398e-09 4.69172574e-12 9.89575177e-09 4.10461240e-07\n",
      " 1.97859762e-07 1.17601694e-07]\n",
      "topv\n",
      "[-0.00095177]\n",
      "topi\n",
      "[64]\n",
      "output_lang.index2word[topi.item()]\n",
      "er\n",
      "decoder_input\n",
      "64\n",
      "decoder_output\n",
      "[-15.954342  -17.251835  -19.014147   -7.0211115 -13.664901  -17.588375\n",
      " -14.908355  -22.272354   -8.957001  -20.229538 ]\n",
      "decoder_hidden\n",
      "[-0.745579    0.97348684 -0.5262456  -0.9420244   0.5980729   0.3948698\n",
      "  0.70163465  0.20689346  0.3462149  -0.22692287]\n",
      "decoder_attention\n",
      "[2.0610150e-06 3.7363626e-04 5.0417138e-06 9.9948502e-01 1.3067867e-04\n",
      " 6.8645962e-13 1.3504856e-06 1.8850227e-07 3.4286558e-07 1.5961764e-06]\n",
      "decoder_attentions[di]\n",
      "[2.0610150e-06 3.7363626e-04 5.0417138e-06 9.9948502e-01 1.3067867e-04\n",
      " 6.8645962e-13 1.3504856e-06 1.8850227e-07 3.4286558e-07 1.5961764e-06]\n",
      "topv\n",
      "[-0.01092434]\n",
      "topi\n",
      "[65]\n",
      "output_lang.index2word[topi.item()]\n",
      "ist\n",
      "decoder_input\n",
      "65\n",
      "decoder_output\n",
      "[-11.502843  -12.963087   -6.8886333  -7.4767456  -9.060211  -12.41973\n",
      "  -8.045053   -9.198845   -9.594577  -12.402844 ]\n",
      "decoder_hidden\n",
      "[-0.88347     0.9073659  -0.8075303  -0.9631132   0.5980721  -0.05086087\n",
      "  0.701658    0.99914396  0.3449629  -0.22601974]\n",
      "decoder_attention\n",
      "[5.0093774e-10 1.8887079e-11 4.7544851e-10 8.1722823e-11 1.0000000e+00\n",
      " 3.5736053e-11 1.5526806e-16 6.7788247e-10 1.0945536e-09 5.6715088e-10]\n",
      "decoder_attentions[di]\n",
      "[5.0093774e-10 1.8887079e-11 4.7544851e-10 8.1722823e-11 1.0000000e+00\n",
      " 3.5736053e-11 1.5526806e-16 6.7788247e-10 1.0945536e-09 5.6715088e-10]\n",
      "topv\n",
      "[-0.63386536]\n",
      "topi\n",
      "[70]\n",
      "output_lang.index2word[topi.item()]\n",
      "ein\n",
      "decoder_input\n",
      "70\n",
      "decoder_output\n",
      "[-10.220689   -9.943879  -10.32873    -8.38318    -7.721979  -12.461495\n",
      "  -4.2690907 -12.30938    -9.017235  -13.502975 ]\n",
      "decoder_hidden\n",
      "[-0.9739234   0.80004114 -0.9884952   0.9968907   0.59795064  0.99248844\n",
      "  0.70162606 -0.99596626  0.33587235 -0.20468056]\n",
      "decoder_attention\n",
      "[3.1392347e-11 1.9214433e-12 1.8712658e-10 6.6259553e-10 9.9999893e-01\n",
      " 1.0960164e-06 1.7887857e-17 8.8284458e-12 4.3163181e-12 2.9094931e-11]\n",
      "decoder_attentions[di]\n",
      "[3.1392347e-11 1.9214433e-12 1.8712658e-10 6.6259553e-10 9.9999893e-01\n",
      " 1.0960164e-06 1.7887857e-17 8.8284458e-12 4.3163181e-12 2.9094931e-11]\n",
      "topv\n",
      "[-3.1644459]\n",
      "topi\n",
      "[231]\n",
      "output_lang.index2word[topi.item()]\n",
      "guter\n",
      "decoder_input\n",
      "231\n",
      "decoder_output\n",
      "[-10.380738   -9.818802   -4.391826   -6.343813   -7.2841296  -9.9403\n",
      "  -5.45562   -10.136951  -10.062593   -9.816312 ]\n",
      "decoder_hidden\n",
      "[-0.9772139   0.19084358 -0.99353373  0.99904466  0.5975884   0.99989516\n",
      "  0.70164657 -0.9862425   0.28418744  0.0365051 ]\n",
      "decoder_attention\n",
      "[5.5780413e-07 4.3310052e-08 2.4238457e-06 4.0044902e-06 1.2482951e-09\n",
      " 9.9983847e-01 1.5165204e-04 1.0667855e-08 4.4309834e-07 2.4112276e-06]\n",
      "decoder_attentions[di]\n",
      "[5.5780413e-07 4.3310052e-08 2.4238457e-06 4.0044902e-06 1.2482951e-09\n",
      " 9.9983847e-01 1.5165204e-04 1.0667855e-08 4.4309834e-07 2.4112276e-06]\n",
      "topv\n",
      "[-2.904664]\n",
      "topi\n",
      "[64]\n",
      "output_lang.index2word[topi.item()]\n",
      "er\n",
      "decoder_input\n",
      "64\n",
      "decoder_output\n",
      "[ -9.906503   -5.340621   -6.4342604  -7.3835096  -6.850927   -8.973874\n",
      "  -2.274722  -11.689122   -8.019247  -11.576337 ]\n",
      "decoder_hidden\n",
      "[-0.9310174   0.8953474   0.73513293  0.995333    0.59949714  0.3427909\n",
      "  0.7017441   0.6780393  -0.928802    0.05442399]\n",
      "decoder_attention\n",
      "[5.7159923e-06 3.2005258e-07 2.3414666e-06 3.3526818e-04 8.7884251e-07\n",
      " 1.3076631e-08 9.9964917e-01 3.0648229e-07 1.4598307e-06 4.4984827e-06]\n",
      "decoder_attentions[di]\n",
      "[5.7159923e-06 3.2005258e-07 2.3414666e-06 3.3526818e-04 8.7884251e-07\n",
      " 1.3076631e-08 9.9964917e-01 3.0648229e-07 1.4598307e-06 4.4984827e-06]\n",
      "topv\n",
      "[-2.274722]\n",
      "topi\n",
      "[6]\n",
      "output_lang.index2word[topi.item()]\n",
      ".\n",
      "decoder_input\n",
      "6\n",
      "decoder_output\n",
      "[-12.1087     -0.837348   -5.1096277  -7.262904   -9.774733   -9.563909\n",
      "  -0.7748604 -10.72351    -8.456727  -10.618118 ]\n",
      "decoder_hidden\n",
      "[-0.94856435  0.6571428   0.03319424 -0.92573094  0.57896715 -0.79952276\n",
      "  0.70007324  0.8073354  -0.4747574   0.15924388]\n",
      "decoder_attention\n",
      "[1.3886768e-06 1.8962496e-07 4.9245142e-07 3.8812193e-09 1.5869911e-12\n",
      " 9.4725493e-08 9.9998331e-01 4.5134559e-08 1.5496116e-07 1.4364473e-05]\n",
      "decoder_attentions[di]\n",
      "[1.3886768e-06 1.8962496e-07 4.9245142e-07 3.8812193e-09 1.5869911e-12\n",
      " 9.4725493e-08 9.9998331e-01 4.5134559e-08 1.5496116e-07 1.4364473e-05]\n",
      "topv\n",
      "[-0.7748604]\n",
      "topi\n",
      "[6]\n",
      "output_lang.index2word[topi.item()]\n",
      ".\n",
      "decoder_input\n",
      "6\n",
      "decoder_output\n",
      "[-15.078605    -0.12340546  -9.58382     -9.90025    -13.483838\n",
      " -12.405626    -2.2026844  -13.124947   -11.535349   -13.206223  ]\n",
      "decoder_hidden\n",
      "[-0.9637291   0.75806034 -0.29991293 -0.98717475  0.5749922  -0.98900354\n",
      "  0.6970877   0.89616084  0.00651889  0.17396188]\n",
      "decoder_attention\n",
      "[1.9904639e-04 6.0911410e-05 9.8134944e-05 1.8773256e-06 4.4381534e-09\n",
      " 1.9624161e-07 9.9244410e-01 5.6739253e-05 9.5484378e-05 7.0434273e-03]\n",
      "decoder_attentions[di]\n",
      "[1.9904639e-04 6.0911410e-05 9.8134944e-05 1.8773256e-06 4.4381534e-09\n",
      " 1.9624161e-07 9.9244410e-01 5.6739253e-05 9.5484378e-05 7.0434273e-03]\n",
      "topv\n",
      "[-0.12340546]\n",
      "topi\n",
      "[1]\n",
      "decoded_words\n",
      "['er', 'ist', 'ein', 'guter', 'er', '.', '.', '<EOS>']\n",
      "input_tensor\n",
      "[  2   3 130  79   4   1]\n",
      "encoder_hidden\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "encoder_outputs\n",
      "[-0.10922617  0.6067832   0.6439681   0.10918707  0.15006319  0.60468507\n",
      " -0.83865154 -0.8165876  -0.08856022 -0.17544824]\n",
      "input_tensor[ei]\n",
      "[2]\n",
      "encoder_hidden\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "encoder_output\n",
      "[-0.10922617  0.6067832   0.6439681   0.10918707  0.15006319  0.60468507\n",
      " -0.83865154 -0.8165876  -0.08856022 -0.17544824]\n",
      "encoder_hidden\n",
      "[-0.10922617  0.6067832   0.6439681   0.10918707  0.15006319  0.60468507\n",
      " -0.83865154 -0.8165876  -0.08856022 -0.17544824]\n",
      "encoder_outputs[ei]\n",
      "[-0.10922617  0.6067832   0.6439681   0.10918707  0.15006319  0.60468507\n",
      " -0.83865154 -0.8165876  -0.08856022 -0.17544824]\n",
      "input_tensor[ei]\n",
      "[3]\n",
      "encoder_hidden\n",
      "[-0.10922617  0.6067832   0.6439681   0.10918707  0.15006319  0.60468507\n",
      " -0.83865154 -0.8165876  -0.08856022 -0.17544824]\n",
      "encoder_output\n",
      "[-0.83710116  0.66214955  0.584383    0.7208886  -0.9831236  -0.8309508\n",
      "  0.68693846  0.53419995 -0.99925417  0.78245384]\n",
      "encoder_hidden\n",
      "[-0.83710116  0.66214955  0.584383    0.7208886  -0.9831236  -0.8309508\n",
      "  0.68693846  0.53419995 -0.99925417  0.78245384]\n",
      "encoder_outputs[ei]\n",
      "[-0.83710116  0.66214955  0.584383    0.7208886  -0.9831236  -0.8309508\n",
      "  0.68693846  0.53419995 -0.99925417  0.78245384]\n",
      "input_tensor[ei]\n",
      "[130]\n",
      "encoder_hidden\n",
      "[-0.83710116  0.66214955  0.584383    0.7208886  -0.9831236  -0.8309508\n",
      "  0.68693846  0.53419995 -0.99925417  0.78245384]\n",
      "encoder_output\n",
      "[ 0.1824039   0.47888607 -0.91579723  0.9388892  -0.996926   -0.966866\n",
      " -0.9417392  -0.9388511  -0.9999983   0.9411565 ]\n",
      "encoder_hidden\n",
      "[ 0.1824039   0.47888607 -0.91579723  0.9388892  -0.996926   -0.966866\n",
      " -0.9417392  -0.9388511  -0.9999983   0.9411565 ]\n",
      "encoder_outputs[ei]\n",
      "[ 0.1824039   0.47888607 -0.91579723  0.9388892  -0.996926   -0.966866\n",
      " -0.9417392  -0.9388511  -0.9999983   0.9411565 ]\n",
      "input_tensor[ei]\n",
      "[79]\n",
      "encoder_hidden\n",
      "[ 0.1824039   0.47888607 -0.91579723  0.9388892  -0.996926   -0.966866\n",
      " -0.9417392  -0.9388511  -0.9999983   0.9411565 ]\n",
      "encoder_output\n",
      "[ 0.4444757   0.6613522  -0.86936474  0.9910363  -0.9942955  -0.38363945\n",
      " -0.8840324  -0.87720585 -0.9780129   0.9623949 ]\n",
      "encoder_hidden\n",
      "[ 0.4444757   0.6613522  -0.86936474  0.9910363  -0.9942955  -0.38363945\n",
      " -0.8840324  -0.87720585 -0.9780129   0.9623949 ]\n",
      "encoder_outputs[ei]\n",
      "[ 0.4444757   0.6613522  -0.86936474  0.9910363  -0.9942955  -0.38363945\n",
      " -0.8840324  -0.87720585 -0.9780129   0.9623949 ]\n",
      "input_tensor[ei]\n",
      "[4]\n",
      "encoder_hidden\n",
      "[ 0.4444757   0.6613522  -0.86936474  0.9910363  -0.9942955  -0.38363945\n",
      " -0.8840324  -0.87720585 -0.9780129   0.9623949 ]\n",
      "encoder_output\n",
      "[ 0.3545708   0.4978618  -0.87708694  0.98768854 -0.99432796  0.90322196\n",
      " -0.88380593 -0.7818755  -0.9590937   0.9619992 ]\n",
      "encoder_hidden\n",
      "[ 0.3545708   0.4978618  -0.87708694  0.98768854 -0.99432796  0.90322196\n",
      " -0.88380593 -0.7818755  -0.9590937   0.9619992 ]\n",
      "encoder_outputs[ei]\n",
      "[ 0.3545708   0.4978618  -0.87708694  0.98768854 -0.99432796  0.90322196\n",
      " -0.88380593 -0.7818755  -0.9590937   0.9619992 ]\n",
      "input_tensor[ei]\n",
      "[1]\n",
      "encoder_hidden\n",
      "[ 0.3545708   0.4978618  -0.87708694  0.98768854 -0.99432796  0.90322196\n",
      " -0.88380593 -0.7818755  -0.9590937   0.9619992 ]\n",
      "encoder_output\n",
      "[ 0.33884415  0.35395014  0.9380882   0.98285204 -0.99332505  0.6669319\n",
      " -0.88376147  0.25599098 -0.95904446  0.96174955]\n",
      "encoder_hidden\n",
      "[ 0.33884415  0.35395014  0.9380882   0.98285204 -0.99332505  0.6669319\n",
      " -0.88376147  0.25599098 -0.95904446  0.96174955]\n",
      "encoder_outputs[ei]\n",
      "[ 0.33884415  0.35395014  0.9380882   0.98285204 -0.99332505  0.6669319\n",
      " -0.88376147  0.25599098 -0.95904446  0.96174955]\n",
      "decoder_input\n",
      "[0]\n",
      "decoder_hidden\n",
      "[ 0.33884415  0.35395014  0.9380882   0.98285204 -0.99332505  0.6669319\n",
      " -0.88376147  0.25599098 -0.95904446  0.96174955]\n",
      "decoder_output\n",
      "[-13.999723  -14.623547   -3.5871563 -10.720814  -15.546545  -15.737626\n",
      " -10.681313   -5.9976444 -12.043419   -9.65263  ]\n",
      "decoder_hidden\n",
      "[ 0.3042841   0.05205297  0.93109864  0.9754637  -0.99331796  0.9999732\n",
      " -0.8837467   0.9982223  -0.9590378   0.9617342 ]\n",
      "decoder_attention\n",
      "[2.6146952e-05 9.9939835e-01 1.1857083e-04 4.3948012e-04 7.6278111e-06\n",
      " 3.0281497e-10 5.3267892e-09 3.0152487e-06 4.4581016e-06 2.3529069e-06]\n",
      "decoder_attentions[di]\n",
      "[2.6146952e-05 9.9939835e-01 1.1857083e-04 4.3948012e-04 7.6278111e-06\n",
      " 3.0281497e-10 5.3267892e-09 3.0152487e-06 4.4581016e-06 2.3529069e-06]\n",
      "topv\n",
      "[-0.53495216]\n",
      "topi\n",
      "[11]\n",
      "output_lang.index2word[topi.item()]\n",
      "es\n",
      "decoder_input\n",
      "11\n",
      "decoder_output\n",
      "[-15.38987   -16.609648  -12.206352   -6.994611  -14.540399  -18.987295\n",
      " -13.14965    -6.4632263  -8.311903  -12.160643 ]\n",
      "decoder_hidden\n",
      "[-0.98979515 -0.97494954  0.9245304  -0.9973067  -0.99330837  0.98908085\n",
      " -0.8837423  -0.97915995 -0.95903873  0.9617349 ]\n",
      "decoder_attention\n",
      "[1.4700693e-04 1.1895826e-03 8.4591564e-04 9.9760485e-01 6.1976693e-06\n",
      " 2.1912754e-05 1.8118816e-07 5.4343077e-06 8.9238092e-06 1.6988385e-04]\n",
      "decoder_attentions[di]\n",
      "[1.4700693e-04 1.1895826e-03 8.4591564e-04 9.9760485e-01 6.1976693e-06\n",
      " 2.1912754e-05 1.8118816e-07 5.4343077e-06 8.9238092e-06 1.6988385e-04]\n",
      "topv\n",
      "[-0.01471806]\n",
      "topi\n",
      "[105]\n",
      "output_lang.index2word[topi.item()]\n",
      "tut\n",
      "decoder_input\n",
      "105\n",
      "decoder_output\n",
      "[-1.7398438e+01 -1.6715004e+01 -9.5633545e+00 -1.2244814e+01\n",
      " -1.6288082e+01 -1.8956827e+01 -1.2743006e+01 -7.8487396e-03\n",
      " -1.3373515e+01 -9.9861755e+00]\n",
      "decoder_hidden\n",
      "[-0.99879044 -0.9758539   0.9151844  -0.97486323 -0.99322414  0.991461\n",
      " -0.8836867   0.9429254  -0.9590632   0.961736  ]\n",
      "decoder_attention\n",
      "[2.4148168e-04 8.2195003e-04 1.2920907e-02 4.4245034e-01 5.3987581e-01\n",
      " 6.9034627e-07 1.0835867e-09 3.0267454e-04 2.0270951e-03 1.3590213e-03]\n",
      "decoder_attentions[di]\n",
      "[2.4148168e-04 8.2195003e-04 1.2920907e-02 4.4245034e-01 5.3987581e-01\n",
      " 6.9034627e-07 1.0835867e-09 3.0267454e-04 2.0270951e-03 1.3590213e-03]\n",
      "topv\n",
      "[-0.00784874]\n",
      "topi\n",
      "[7]\n",
      "output_lang.index2word[topi.item()]\n",
      "mir\n",
      "decoder_input\n",
      "7\n",
      "decoder_output\n",
      "[-14.271004  -11.417038   -8.085415  -10.711678  -11.314285  -14.157711\n",
      "  -5.9686427  -3.7627888 -11.899857   -7.418762 ]\n",
      "decoder_hidden\n",
      "[ 0.9982523  -0.9913148  -0.9262233  -0.9879384  -0.9925307   0.95903134\n",
      " -0.88262004  0.992296   -0.9590713   0.9617801 ]\n",
      "decoder_attention\n",
      "[1.0204203e-10 1.1142467e-12 6.7995097e-12 1.2730895e-07 9.9999988e-01\n",
      " 3.3291003e-10 3.6533713e-15 5.1834119e-12 5.1777597e-12 6.2329586e-11]\n",
      "decoder_attentions[di]\n",
      "[1.0204203e-10 1.1142467e-12 6.7995097e-12 1.2730895e-07 9.9999988e-01\n",
      " 3.3291003e-10 3.6533713e-15 5.1834119e-12 5.1777597e-12 6.2329586e-11]\n",
      "topv\n",
      "[-0.19405079]\n",
      "topi\n",
      "[416]\n",
      "output_lang.index2word[topi.item()]\n",
      "sehr\n",
      "decoder_input\n",
      "416\n",
      "decoder_output\n",
      "[-13.235808   -7.0337763  -9.269595  -14.679388  -10.1872835 -10.875198\n",
      "  -2.0678024 -10.690393  -12.170182   -9.115916 ]\n",
      "decoder_hidden\n",
      "[ 0.9999996   0.93379885 -0.99981874 -0.9977785  -0.9922825   0.8621541\n",
      " -0.8825989   0.9977805  -0.95988303  0.96358484]\n",
      "decoder_attention\n",
      "[1.9233633e-08 2.4887059e-10 3.8009485e-08 3.6861614e-09 1.5080615e-05\n",
      " 9.9998474e-01 7.8338367e-08 2.6353069e-08 1.5096651e-08 2.1170075e-08]\n",
      "decoder_attentions[di]\n",
      "[1.9233633e-08 2.4887059e-10 3.8009485e-08 3.6861614e-09 1.5080615e-05\n",
      " 9.9998474e-01 7.8338367e-08 2.6353069e-08 1.5096651e-08 2.1170075e-08]\n",
      "topv\n",
      "[-0.21155548]\n",
      "topi\n",
      "[106]\n",
      "output_lang.index2word[topi.item()]\n",
      "leid\n",
      "decoder_input\n",
      "106\n",
      "decoder_output\n",
      "[-15.467499    -6.9829183  -10.624548   -14.744355   -11.735604\n",
      " -12.959315    -0.07817841 -12.732145   -12.230544   -11.232483  ]\n",
      "decoder_hidden\n",
      "[ 0.9996635   0.9489492  -0.99807966 -0.99981177 -0.9767795  -0.52597153\n",
      " -0.8748754   0.99795055 -0.99182296  0.9643022 ]\n",
      "decoder_attention\n",
      "[8.7788003e-04 1.2244292e-06 9.4820809e-04 3.2676227e-05 7.8744524e-06\n",
      " 9.4472945e-01 4.2964220e-02 1.1020064e-03 7.4398280e-03 1.8966504e-03]\n",
      "decoder_attentions[di]\n",
      "[8.7788003e-04 1.2244292e-06 9.4820809e-04 3.2676227e-05 7.8744524e-06\n",
      " 9.4472945e-01 4.2964220e-02 1.1020064e-03 7.4398280e-03 1.8966504e-03]\n",
      "topv\n",
      "[-0.07817841]\n",
      "topi\n",
      "[6]\n",
      "output_lang.index2word[topi.item()]\n",
      ".\n",
      "decoder_input\n",
      "6\n",
      "decoder_output\n",
      "[-14.335714    -0.08982944 -10.84725    -11.922806   -12.384678\n",
      " -11.166747    -2.944169   -10.701864   -11.735642   -10.998617  ]\n",
      "decoder_hidden\n",
      "[-0.3051092   0.905164   -0.99594665 -0.99996686 -0.94502646 -0.70628166\n",
      " -0.8499565   0.99820006 -0.5840784   0.96391785]\n",
      "decoder_attention\n",
      "[4.2714542e-03 1.3894174e-04 8.3386677e-04 6.5596885e-07 8.5112811e-07\n",
      " 2.3833663e-05 8.0927849e-01 4.5740041e-03 2.0476492e-02 1.6040142e-01]\n",
      "decoder_attentions[di]\n",
      "[4.2714542e-03 1.3894174e-04 8.3386677e-04 6.5596885e-07 8.5112811e-07\n",
      " 2.3833663e-05 8.0927849e-01 4.5740041e-03 2.0476492e-02 1.6040142e-01]\n",
      "topv\n",
      "[-0.08982944]\n",
      "topi\n",
      "[1]\n",
      "decoded_words\n",
      "['es', 'tut', 'mir', 'sehr', 'leid', '.', '<EOS>']\n",
      "input_tensor\n",
      "[ 48  49  17  52 688   4   1]\n",
      "encoder_hidden\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "encoder_outputs\n",
      "[-0.24151272  0.07389677  0.14187232 -0.13187045 -0.21201348  0.7023839\n",
      " -0.01192594 -0.8879513   0.86634135 -0.9917318 ]\n",
      "input_tensor[ei]\n",
      "[48]\n",
      "encoder_hidden\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "encoder_output\n",
      "[-0.24151272  0.07389677  0.14187232 -0.13187045 -0.21201348  0.7023839\n",
      " -0.01192594 -0.8879513   0.86634135 -0.9917318 ]\n",
      "encoder_hidden\n",
      "[-0.24151272  0.07389677  0.14187232 -0.13187045 -0.21201348  0.7023839\n",
      " -0.01192594 -0.8879513   0.86634135 -0.9917318 ]\n",
      "encoder_outputs[ei]\n",
      "[-0.24151272  0.07389677  0.14187232 -0.13187045 -0.21201348  0.7023839\n",
      " -0.01192594 -0.8879513   0.86634135 -0.9917318 ]\n",
      "input_tensor[ei]\n",
      "[49]\n",
      "encoder_hidden\n",
      "[-0.24151272  0.07389677  0.14187232 -0.13187045 -0.21201348  0.7023839\n",
      " -0.01192594 -0.8879513   0.86634135 -0.9917318 ]\n",
      "encoder_output\n",
      "[-0.94854337  0.78109705 -0.7576846   0.15421624 -0.87620497  0.5647007\n",
      "  0.8045426  -0.8869806   0.9868675   0.82549334]\n",
      "encoder_hidden\n",
      "[-0.94854337  0.78109705 -0.7576846   0.15421624 -0.87620497  0.5647007\n",
      "  0.8045426  -0.8869806   0.9868675   0.82549334]\n",
      "encoder_outputs[ei]\n",
      "[-0.94854337  0.78109705 -0.7576846   0.15421624 -0.87620497  0.5647007\n",
      "  0.8045426  -0.8869806   0.9868675   0.82549334]\n",
      "input_tensor[ei]\n",
      "[17]\n",
      "encoder_hidden\n",
      "[-0.94854337  0.78109705 -0.7576846   0.15421624 -0.87620497  0.5647007\n",
      "  0.8045426  -0.8869806   0.9868675   0.82549334]\n",
      "encoder_output\n",
      "[ 0.9009656   0.9391912   0.9066125  -0.29741564  0.7479242   0.57109225\n",
      " -0.97016263 -0.904247    0.99204326 -0.28691536]\n",
      "encoder_hidden\n",
      "[ 0.9009656   0.9391912   0.9066125  -0.29741564  0.7479242   0.57109225\n",
      " -0.97016263 -0.904247    0.99204326 -0.28691536]\n",
      "encoder_outputs[ei]\n",
      "[ 0.9009656   0.9391912   0.9066125  -0.29741564  0.7479242   0.57109225\n",
      " -0.97016263 -0.904247    0.99204326 -0.28691536]\n",
      "input_tensor[ei]\n",
      "[52]\n",
      "encoder_hidden\n",
      "[ 0.9009656   0.9391912   0.9066125  -0.29741564  0.7479242   0.57109225\n",
      " -0.97016263 -0.904247    0.99204326 -0.28691536]\n",
      "encoder_output\n",
      "[ 0.26153827 -0.2521582   0.10683501 -0.21565238  0.9941557   0.6504115\n",
      " -0.26928443  0.10747739  0.99231803 -0.61620164]\n",
      "encoder_hidden\n",
      "[ 0.26153827 -0.2521582   0.10683501 -0.21565238  0.9941557   0.6504115\n",
      " -0.26928443  0.10747739  0.99231803 -0.61620164]\n",
      "encoder_outputs[ei]\n",
      "[ 0.26153827 -0.2521582   0.10683501 -0.21565238  0.9941557   0.6504115\n",
      " -0.26928443  0.10747739  0.99231803 -0.61620164]\n",
      "input_tensor[ei]\n",
      "[688]\n",
      "encoder_hidden\n",
      "[ 0.26153827 -0.2521582   0.10683501 -0.21565238  0.9941557   0.6504115\n",
      " -0.26928443  0.10747739  0.99231803 -0.61620164]\n",
      "encoder_output\n",
      "[ 0.07514209 -0.46132296  0.5771818  -0.00545618 -0.52867997  0.7859457\n",
      "  0.9769005   0.01487547  0.9925161  -0.8674872 ]\n",
      "encoder_hidden\n",
      "[ 0.07514209 -0.46132296  0.5771818  -0.00545618 -0.52867997  0.7859457\n",
      "  0.9769005   0.01487547  0.9925161  -0.8674872 ]\n",
      "encoder_outputs[ei]\n",
      "[ 0.07514209 -0.46132296  0.5771818  -0.00545618 -0.52867997  0.7859457\n",
      "  0.9769005   0.01487547  0.9925161  -0.8674872 ]\n",
      "input_tensor[ei]\n",
      "[4]\n",
      "encoder_hidden\n",
      "[ 0.07514209 -0.46132296  0.5771818  -0.00545618 -0.52867997  0.7859457\n",
      "  0.9769005   0.01487547  0.9925161  -0.8674872 ]\n",
      "encoder_output\n",
      "[ 0.01338911 -0.68347096  0.5000678  -0.00619189 -0.53486454  0.96973836\n",
      "  0.9769479   0.11827403  0.9925238  -0.86748606]\n",
      "encoder_hidden\n",
      "[ 0.01338911 -0.68347096  0.5000678  -0.00619189 -0.53486454  0.96973836\n",
      "  0.9769479   0.11827403  0.9925238  -0.86748606]\n",
      "encoder_outputs[ei]\n",
      "[ 0.01338911 -0.68347096  0.5000678  -0.00619189 -0.53486454  0.96973836\n",
      "  0.9769479   0.11827403  0.9925238  -0.86748606]\n",
      "input_tensor[ei]\n",
      "[1]\n",
      "encoder_hidden\n",
      "[ 0.01338911 -0.68347096  0.5000678  -0.00619189 -0.53486454  0.96973836\n",
      "  0.9769479   0.11827403  0.9925238  -0.86748606]\n",
      "encoder_output\n",
      "[-5.1707029e-04 -7.9953629e-01  9.8210078e-01 -7.9995096e-03\n",
      " -5.3936052e-01  6.7169881e-01  9.7692555e-01  6.7883229e-01\n",
      "  9.9241483e-01 -8.6751258e-01]\n",
      "encoder_hidden\n",
      "[-5.1707029e-04 -7.9953629e-01  9.8210078e-01 -7.9995096e-03\n",
      " -5.3936052e-01  6.7169881e-01  9.7692555e-01  6.7883229e-01\n",
      "  9.9241483e-01 -8.6751258e-01]\n",
      "encoder_outputs[ei]\n",
      "[-5.1707029e-04 -7.9953629e-01  9.8210078e-01 -7.9995096e-03\n",
      " -5.3936052e-01  6.7169881e-01  9.7692555e-01  6.7883229e-01\n",
      "  9.9241483e-01 -8.6751258e-01]\n",
      "decoder_input\n",
      "[0]\n",
      "decoder_hidden\n",
      "[-5.1707029e-04 -7.9953629e-01  9.8210078e-01 -7.9995096e-03\n",
      " -5.3936052e-01  6.7169881e-01  9.7692555e-01  6.7883229e-01\n",
      "  9.9241483e-01 -8.6751258e-01]\n",
      "decoder_output\n",
      "[-18.74459  -15.819664 -10.580081 -14.932169 -17.7016   -20.2412\n",
      " -14.830758 -16.39663  -16.385456 -17.673721]\n",
      "decoder_hidden\n",
      "[-0.84742785 -0.81279975  0.98035824 -0.04903251 -0.5393611   0.9999916\n",
      "  0.97692555  0.999426    0.99240386 -0.8675121 ]\n",
      "decoder_attention\n",
      "[1.3555737e-06 9.9998569e-01 2.5483707e-06 9.2316513e-06 5.6349316e-09\n",
      " 1.2666806e-11 1.6649212e-08 9.7026611e-07 1.4035942e-07 1.1083455e-07]\n",
      "decoder_attentions[di]\n",
      "[1.3555737e-06 9.9998569e-01 2.5483707e-06 9.2316513e-06 5.6349316e-09\n",
      " 1.2666806e-11 1.6649212e-08 9.7026611e-07 1.4035942e-07 1.1083455e-07]\n",
      "topv\n",
      "[-0.00107002]\n",
      "topi\n",
      "[64]\n",
      "output_lang.index2word[topi.item()]\n",
      "er\n",
      "decoder_input\n",
      "64\n",
      "decoder_output\n",
      "[-15.479827 -16.392986 -20.14276  -11.72573  -14.092239 -17.143536\n",
      " -14.643758 -22.919086 -12.522375 -22.4189  ]\n",
      "decoder_hidden\n",
      "[-0.23793933 -0.993718   -0.40709144  0.00667533 -0.5393131   0.99877346\n",
      "  0.9769256  -0.95091116  0.9767186  -0.86732054]\n",
      "decoder_attention\n",
      "[4.9698730e-08 4.6073924e-06 1.2456721e-07 9.9999332e-01 1.5278758e-06\n",
      " 9.0842881e-14 1.5033429e-07 7.0092860e-08 4.8515774e-09 1.4054145e-07]\n",
      "decoder_attentions[di]\n",
      "[4.9698730e-08 4.6073924e-06 1.2456721e-07 9.9999332e-01 1.5278758e-06\n",
      " 9.0842881e-14 1.5033429e-07 7.0092860e-08 4.8515774e-09 1.4054145e-07]\n",
      "topv\n",
      "[-0.01523399]\n",
      "topi\n",
      "[65]\n",
      "output_lang.index2word[topi.item()]\n",
      "ist\n",
      "decoder_input\n",
      "65\n",
      "decoder_output\n",
      "[-14.109435 -16.980104 -11.285587 -13.297021 -14.326206 -17.911024\n",
      " -12.581308 -14.246393 -16.70105  -18.05314 ]\n",
      "decoder_hidden\n",
      "[-0.84434927 -0.99384356 -0.4397961  -0.18747032 -0.53929806  0.9828247\n",
      "  0.97690624  0.9749254   0.97318685 -0.8648564 ]\n",
      "decoder_attention\n",
      "[9.52496748e-09 3.07452980e-10 1.40856633e-08 2.37660807e-08\n",
      " 9.99999523e-01 4.82931384e-08 6.05188534e-13 3.45726988e-07\n",
      " 3.24606582e-08 1.44314996e-08]\n",
      "decoder_attentions[di]\n",
      "[9.52496748e-09 3.07452980e-10 1.40856633e-08 2.37660807e-08\n",
      " 9.99999523e-01 4.82931384e-08 6.05188534e-13 3.45726988e-07\n",
      " 3.24606582e-08 1.44314996e-08]\n",
      "topv\n",
      "[-0.03236961]\n",
      "topi\n",
      "[70]\n",
      "output_lang.index2word[topi.item()]\n",
      "ein\n",
      "decoder_input\n",
      "70\n",
      "decoder_output\n",
      "[-10.762354 -10.730607 -11.489796 -13.387738 -11.473116 -15.036583\n",
      "  -4.471188 -15.399258 -15.10732  -17.291906]\n",
      "decoder_hidden\n",
      "[-0.47176412 -0.994284   -0.8576211   0.9964899  -0.5393102   0.9999297\n",
      "  0.97664785 -0.98015314  0.9651145  -0.80447716]\n",
      "decoder_attention\n",
      "[9.5080797e-11 1.6579443e-12 4.9649357e-10 6.4550174e-09 9.9999988e-01\n",
      " 1.0861920e-07 5.6027359e-15 3.3352446e-11 1.5618318e-12 1.6712675e-11]\n",
      "decoder_attentions[di]\n",
      "[9.5080797e-11 1.6579443e-12 4.9649357e-10 6.4550174e-09 9.9999988e-01\n",
      " 1.0861920e-07 5.6027359e-15 3.3352446e-11 1.5618318e-12 1.6712675e-11]\n",
      "topv\n",
      "[-1.1581106]\n",
      "topi\n",
      "[1560]\n",
      "output_lang.index2word[topi.item()]\n",
      "schneller\n",
      "decoder_input\n",
      "1560\n",
      "decoder_output\n",
      "[-11.345192   -6.6774745 -11.500883  -15.560982  -11.087338  -14.170717\n",
      "  -2.7982845 -17.255568  -14.661244  -15.21504  ]\n",
      "decoder_hidden\n",
      "[ 0.62317365 -0.9958986  -0.89337873 -0.526305   -0.53915143 -0.9947025\n",
      "  0.97654206 -0.98510486 -0.28908777 -0.6918968 ]\n",
      "decoder_attention\n",
      "[5.0612616e-05 1.7951519e-04 9.1323791e-06 6.2547338e-06 3.0794584e-10\n",
      " 9.9739897e-01 2.1359520e-03 2.1415590e-05 1.1406371e-04 8.4168700e-05]\n",
      "decoder_attentions[di]\n",
      "[5.0612616e-05 1.7951519e-04 9.1323791e-06 6.2547338e-06 3.0794584e-10\n",
      " 9.9739897e-01 2.1359520e-03 2.1415590e-05 1.1406371e-04 8.4168700e-05]\n",
      "topv\n",
      "[-0.53598785]\n",
      "topi\n",
      "[1740]\n",
      "output_lang.index2word[topi.item()]\n",
      "laufer\n",
      "decoder_input\n",
      "1740\n",
      "decoder_output\n",
      "[-1.49451685e+01 -5.68167877e+00 -1.32223024e+01 -1.63773975e+01\n",
      " -1.44137878e+01 -1.54531841e+01 -1.36594772e-02 -1.75090923e+01\n",
      " -1.58092737e+01 -1.53946400e+01]\n",
      "decoder_hidden\n",
      "[ 0.89073145 -0.9882314  -0.961194   -0.9351913  -0.51242006 -0.9997697\n",
      "  0.9492774  -0.9683771  -0.9786204  -0.6453808 ]\n",
      "decoder_attention\n",
      "[1.1680266e-03 1.7366024e-06 4.0718922e-04 1.9463534e-04 1.7191905e-05\n",
      " 2.7120934e-06 9.4889647e-01 1.9542417e-03 1.1692280e-02 3.5665531e-02]\n",
      "decoder_attentions[di]\n",
      "[1.1680266e-03 1.7366024e-06 4.0718922e-04 1.9463534e-04 1.7191905e-05\n",
      " 2.7120934e-06 9.4889647e-01 1.9542417e-03 1.1692280e-02 3.5665531e-02]\n",
      "topv\n",
      "[-0.01365948]\n",
      "topi\n",
      "[6]\n",
      "output_lang.index2word[topi.item()]\n",
      ".\n",
      "decoder_input\n",
      "6\n",
      "decoder_output\n",
      "[-1.7647415e+01 -4.2839050e-03 -1.7205606e+01 -1.7262230e+01\n",
      " -1.7446220e+01 -1.4509620e+01 -5.5686016e+00 -1.8223524e+01\n",
      " -1.8752907e+01 -1.7630442e+01]\n",
      "decoder_hidden\n",
      "[ 0.08498102 -0.65607315 -0.9663848  -0.9833655  -0.46766484 -0.99993104\n",
      "  0.8775197  -0.8874933   0.30023664 -0.57341784]\n",
      "decoder_attention\n",
      "[6.2850444e-03 9.5047115e-04 2.1174555e-03 4.1341878e-05 6.7749519e-05\n",
      " 9.9417520e-08 8.4398389e-02 6.2198949e-04 2.4270078e-02 8.8124722e-01]\n",
      "decoder_attentions[di]\n",
      "[6.2850444e-03 9.5047115e-04 2.1174555e-03 4.1341878e-05 6.7749519e-05\n",
      " 9.9417520e-08 8.4398389e-02 6.2198949e-04 2.4270078e-02 8.8124722e-01]\n",
      "topv\n",
      "[-0.00428391]\n",
      "topi\n",
      "[1]\n",
      "decoded_words\n",
      "['er', 'ist', 'ein', 'schneller', 'laufer', '.', '<EOS>']\n",
      "input_tensor\n",
      "[   2   55 1204  152  601   51  419    4    1]\n",
      "encoder_hidden\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "encoder_outputs\n",
      "[-0.10922617  0.6067832   0.6439681   0.10918707  0.15006319  0.60468507\n",
      " -0.83865154 -0.8165876  -0.08856022 -0.17544824]\n",
      "input_tensor[ei]\n",
      "[2]\n",
      "encoder_hidden\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "encoder_output\n",
      "[-0.10922617  0.6067832   0.6439681   0.10918707  0.15006319  0.60468507\n",
      " -0.83865154 -0.8165876  -0.08856022 -0.17544824]\n",
      "encoder_hidden\n",
      "[-0.10922617  0.6067832   0.6439681   0.10918707  0.15006319  0.60468507\n",
      " -0.83865154 -0.8165876  -0.08856022 -0.17544824]\n",
      "encoder_outputs[ei]\n",
      "[-0.10922617  0.6067832   0.6439681   0.10918707  0.15006319  0.60468507\n",
      " -0.83865154 -0.8165876  -0.08856022 -0.17544824]\n",
      "input_tensor[ei]\n",
      "[55]\n",
      "encoder_hidden\n",
      "[-0.10922617  0.6067832   0.6439681   0.10918707  0.15006319  0.60468507\n",
      " -0.83865154 -0.8165876  -0.08856022 -0.17544824]\n",
      "encoder_output\n",
      "[-0.1475069   0.60773844  0.40916204  0.18194592 -0.98431695 -0.19255847\n",
      " -0.83514357 -0.8144109  -0.1381967   0.30102903]\n",
      "encoder_hidden\n",
      "[-0.1475069   0.60773844  0.40916204  0.18194592 -0.98431695 -0.19255847\n",
      " -0.83514357 -0.8144109  -0.1381967   0.30102903]\n",
      "encoder_outputs[ei]\n",
      "[-0.1475069   0.60773844  0.40916204  0.18194592 -0.98431695 -0.19255847\n",
      " -0.83514357 -0.8144109  -0.1381967   0.30102903]\n",
      "input_tensor[ei]\n",
      "[1204]\n",
      "encoder_hidden\n",
      "[-0.1475069   0.60773844  0.40916204  0.18194592 -0.98431695 -0.19255847\n",
      " -0.83514357 -0.8144109  -0.1381967   0.30102903]\n",
      "encoder_output\n",
      "[-0.6063782  -0.66217154  0.32797444 -0.55478966  0.5524534   0.56298435\n",
      " -0.0360381  -0.85588443  0.9601394   0.69857705]\n",
      "encoder_hidden\n",
      "[-0.6063782  -0.66217154  0.32797444 -0.55478966  0.5524534   0.56298435\n",
      " -0.0360381  -0.85588443  0.9601394   0.69857705]\n",
      "encoder_outputs[ei]\n",
      "[-0.6063782  -0.66217154  0.32797444 -0.55478966  0.5524534   0.56298435\n",
      " -0.0360381  -0.85588443  0.9601394   0.69857705]\n",
      "input_tensor[ei]\n",
      "[152]\n",
      "encoder_hidden\n",
      "[-0.6063782  -0.66217154  0.32797444 -0.55478966  0.5524534   0.56298435\n",
      " -0.0360381  -0.85588443  0.9601394   0.69857705]\n",
      "encoder_output\n",
      "[ 0.64183795  0.14136213  0.02790695 -0.4686585   0.46085376 -0.25538826\n",
      " -0.9789116  -0.5719142   0.96079314  0.977613  ]\n",
      "encoder_hidden\n",
      "[ 0.64183795  0.14136213  0.02790695 -0.4686585   0.46085376 -0.25538826\n",
      " -0.9789116  -0.5719142   0.96079314  0.977613  ]\n",
      "encoder_outputs[ei]\n",
      "[ 0.64183795  0.14136213  0.02790695 -0.4686585   0.46085376 -0.25538826\n",
      " -0.9789116  -0.5719142   0.96079314  0.977613  ]\n",
      "input_tensor[ei]\n",
      "[601]\n",
      "encoder_hidden\n",
      "[ 0.64183795  0.14136213  0.02790695 -0.4686585   0.46085376 -0.25538826\n",
      " -0.9789116  -0.5719142   0.96079314  0.977613  ]\n",
      "encoder_output\n",
      "[ 0.3099969  -0.34189188 -0.36155874  0.86861247  0.68434864  0.7344829\n",
      " -0.97892064 -0.53213286  0.96696234  0.7373433 ]\n",
      "encoder_hidden\n",
      "[ 0.3099969  -0.34189188 -0.36155874  0.86861247  0.68434864  0.7344829\n",
      " -0.97892064 -0.53213286  0.96696234  0.7373433 ]\n",
      "encoder_outputs[ei]\n",
      "[ 0.3099969  -0.34189188 -0.36155874  0.86861247  0.68434864  0.7344829\n",
      " -0.97892064 -0.53213286  0.96696234  0.7373433 ]\n",
      "input_tensor[ei]\n",
      "[51]\n",
      "encoder_hidden\n",
      "[ 0.3099969  -0.34189188 -0.36155874  0.86861247  0.68434864  0.7344829\n",
      " -0.97892064 -0.53213286  0.96696234  0.7373433 ]\n",
      "encoder_output\n",
      "[-0.6567816  -0.09369707  0.82656795 -0.6858261   0.25144583  0.4652397\n",
      " -0.96335226 -0.6671959   0.969749    0.746283  ]\n",
      "encoder_hidden\n",
      "[-0.6567816  -0.09369707  0.82656795 -0.6858261   0.25144583  0.4652397\n",
      " -0.96335226 -0.6671959   0.969749    0.746283  ]\n",
      "encoder_outputs[ei]\n",
      "[-0.6567816  -0.09369707  0.82656795 -0.6858261   0.25144583  0.4652397\n",
      " -0.96335226 -0.6671959   0.969749    0.746283  ]\n",
      "input_tensor[ei]\n",
      "[419]\n",
      "encoder_hidden\n",
      "[-0.6567816  -0.09369707  0.82656795 -0.6858261   0.25144583  0.4652397\n",
      " -0.96335226 -0.6671959   0.969749    0.746283  ]\n",
      "encoder_output\n",
      "[-0.83768946 -0.441953    0.76491904  0.2449699  -0.88221717  0.6434386\n",
      " -0.9620355  -0.29371625 -0.4054913  -0.21054447]\n",
      "encoder_hidden\n",
      "[-0.83768946 -0.441953    0.76491904  0.2449699  -0.88221717  0.6434386\n",
      " -0.9620355  -0.29371625 -0.4054913  -0.21054447]\n",
      "encoder_outputs[ei]\n",
      "[-0.83768946 -0.441953    0.76491904  0.2449699  -0.88221717  0.6434386\n",
      " -0.9620355  -0.29371625 -0.4054913  -0.21054447]\n",
      "input_tensor[ei]\n",
      "[4]\n",
      "encoder_hidden\n",
      "[-0.83768946 -0.441953    0.76491904  0.2449699  -0.88221717  0.6434386\n",
      " -0.9620355  -0.29371625 -0.4054913  -0.21054447]\n",
      "encoder_output\n",
      "[-0.81007963 -0.51644564  0.66140455  0.2417944  -0.8822836   0.97776836\n",
      " -0.9608094  -0.22132158 -0.40536195 -0.21077228]\n",
      "encoder_hidden\n",
      "[-0.81007963 -0.51644564  0.66140455  0.2417944  -0.8822836   0.97776836\n",
      " -0.9608094  -0.22132158 -0.40536195 -0.21077228]\n",
      "encoder_outputs[ei]\n",
      "[-0.81007963 -0.51644564  0.66140455  0.2417944  -0.8822836   0.97776836\n",
      " -0.9608094  -0.22132158 -0.40536195 -0.21077228]\n",
      "input_tensor[ei]\n",
      "[1]\n",
      "encoder_hidden\n",
      "[-0.81007963 -0.51644564  0.66140455  0.2417944  -0.8822836   0.97776836\n",
      " -0.9608094  -0.22132158 -0.40536195 -0.21077228]\n",
      "encoder_output\n",
      "[-0.80554366 -0.56701773  0.9866195   0.23867434 -0.8822311   0.51395506\n",
      " -0.9607366   0.4906956  -0.40536326 -0.21093524]\n",
      "encoder_hidden\n",
      "[-0.80554366 -0.56701773  0.9866195   0.23867434 -0.8822311   0.51395506\n",
      " -0.9607366   0.4906956  -0.40536326 -0.21093524]\n",
      "encoder_outputs[ei]\n",
      "[-0.80554366 -0.56701773  0.9866195   0.23867434 -0.8822311   0.51395506\n",
      " -0.9607366   0.4906956  -0.40536326 -0.21093524]\n",
      "decoder_input\n",
      "[0]\n",
      "decoder_hidden\n",
      "[-0.80554366 -0.56701773  0.9866195   0.23867434 -0.8822311   0.51395506\n",
      " -0.9607366   0.4906956  -0.40536326 -0.21093524]\n",
      "decoder_output\n",
      "[-13.83961    -14.153943    -0.03088951 -14.916436   -15.063077\n",
      " -12.432357   -13.395662    -8.613632   -12.561189   -11.13834   ]\n",
      "decoder_hidden\n",
      "[-0.8082787  -0.6378335   0.96803594  0.23321122 -0.8822175   0.9999654\n",
      " -0.96071947  0.9965741  -0.40540898 -0.21090889]\n",
      "decoder_attention\n",
      "[3.4936972e-06 9.9912530e-01 1.0442078e-05 8.6013658e-04 4.9316643e-08\n",
      " 3.8186818e-11 1.3237165e-08 1.7314569e-07 3.6545484e-07 1.1183914e-07]\n",
      "decoder_attentions[di]\n",
      "[3.4936972e-06 9.9912530e-01 1.0442078e-05 8.6013658e-04 4.9316643e-08\n",
      " 3.8186818e-11 1.3237165e-08 1.7314569e-07 3.6545484e-07 1.1183914e-07]\n",
      "topv\n",
      "[-0.03088951]\n",
      "topi\n",
      "[2]\n",
      "output_lang.index2word[topi.item()]\n",
      "ich\n",
      "decoder_input\n",
      "2\n",
      "decoder_output\n",
      "[-10.539588  -12.94965   -14.322942   -4.0634246  -9.089297   -9.561846\n",
      " -14.330199  -11.935374   -8.088993   -9.796619 ]\n",
      "decoder_hidden\n",
      "[-0.823853    0.6856754  -0.8071464   0.1898589  -0.8821969   0.9993063\n",
      " -0.96032363  0.99772006 -0.40542728 -0.21000636]\n",
      "decoder_attention\n",
      "[1.2576798e-08 7.9285446e-06 1.0495374e-07 9.9998844e-01 3.1875458e-09\n",
      " 3.4846812e-06 8.6039601e-13 1.2916618e-08 1.8472668e-10 4.7650204e-08]\n",
      "decoder_attentions[di]\n",
      "[1.2576798e-08 7.9285446e-06 1.0495374e-07 9.9998844e-01 3.1875458e-09\n",
      " 3.4846812e-06 8.6039601e-13 1.2916618e-08 1.8472668e-10 4.7650204e-08]\n",
      "topv\n",
      "[-2.253543]\n",
      "topi\n",
      "[2721]\n",
      "output_lang.index2word[topi.item()]\n",
      "interessiere\n",
      "decoder_input\n",
      "2721\n",
      "decoder_output\n",
      "[-13.471586  -13.140535  -12.463136  -16.234661  -12.4042425 -11.053648\n",
      " -10.876968   -9.620176  -13.9023285  -8.745324 ]\n",
      "decoder_hidden\n",
      "[-0.888301   -0.1029169  -0.9917513   0.80069846 -0.88217914  0.9999975\n",
      " -0.95986354  0.99999535 -0.4054343  -0.14679545]\n",
      "decoder_attention\n",
      "[1.5912721e-06 3.8716622e-04 9.0870553e-06 5.6338608e-06 9.9958915e-01\n",
      " 5.1363604e-06 2.3678235e-09 2.0948028e-07 1.0840733e-06 8.9775949e-07]\n",
      "decoder_attentions[di]\n",
      "[1.5912721e-06 3.8716622e-04 9.0870553e-06 5.6338608e-06 9.9958915e-01\n",
      " 5.1363604e-06 2.3678235e-09 2.0948028e-07 1.0840733e-06 8.9775949e-07]\n",
      "topv\n",
      "[-0.48054886]\n",
      "topi\n",
      "[42]\n",
      "output_lang.index2word[topi.item()]\n",
      "mit\n",
      "decoder_input\n",
      "42\n",
      "decoder_output\n",
      "[-13.215011 -12.73667  -13.473069 -18.352936 -11.606439 -11.638756\n",
      "  -9.759658 -10.716991 -13.908745 -11.152929]\n",
      "decoder_hidden\n",
      "[-0.9787427  -0.79795134  0.82304806  0.9998949  -0.882162    0.9999978\n",
      " -0.95972747  0.66739136 -0.40543526  0.21515638]\n",
      "decoder_attention\n",
      "[3.1184111e-08 3.6716856e-06 7.0410657e-08 1.1021697e-08 7.7782868e-05\n",
      " 9.9991846e-01 5.5809557e-09 1.7551303e-10 7.6786788e-10 1.7659008e-08]\n",
      "decoder_attentions[di]\n",
      "[3.1184111e-08 3.6716856e-06 7.0410657e-08 1.1021697e-08 7.7782868e-05\n",
      " 9.9991846e-01 5.5809557e-09 1.7551303e-10 7.6786788e-10 1.7659008e-08]\n",
      "topv\n",
      "[-0.13420963]\n",
      "topi\n",
      "[580]\n",
      "output_lang.index2word[topi.item()]\n",
      "meinem\n",
      "decoder_input\n",
      "580\n",
      "decoder_output\n",
      "[-11.129342   -8.992638  -13.199553  -15.960507   -8.900118  -11.821004\n",
      "  -5.216942  -11.6833725  -9.62821   -12.096491 ]\n",
      "decoder_hidden\n",
      "[-0.9812433  -0.95559186  0.99181074  0.99999994 -0.8820617   0.98956406\n",
      " -0.9594954   0.96513236 -0.40546304  0.38871932]\n",
      "decoder_attention\n",
      "[9.1178445e-06 7.7704753e-05 5.4642049e-05 4.3645382e-06 3.5187280e-13\n",
      " 8.5380495e-01 1.4599681e-01 4.4147542e-05 2.2219112e-07 8.0916252e-06]\n",
      "decoder_attentions[di]\n",
      "[9.1178445e-06 7.7704753e-05 5.4642049e-05 4.3645382e-06 3.5187280e-13\n",
      " 8.5380495e-01 1.4599681e-01 4.4147542e-05 2.2219112e-07 8.0916252e-06]\n",
      "topv\n",
      "[-0.69229984]\n",
      "topi\n",
      "[581]\n",
      "output_lang.index2word[topi.item()]\n",
      "auto\n",
      "decoder_input\n",
      "581\n",
      "decoder_output\n",
      "[-11.039499   -5.702614  -15.581286  -15.323387   -8.744682  -10.97284\n",
      "  -1.2117748 -12.345534   -8.779386  -13.030255 ]\n",
      "decoder_hidden\n",
      "[-0.99077994 -0.27284995  0.94031394  0.99987376 -0.8739737  -0.8637073\n",
      " -0.95606583 -0.5847009  -0.4138745   0.9212912 ]\n",
      "decoder_attention\n",
      "[2.6414106e-08 6.2721592e-11 1.6938142e-08 2.0449233e-08 2.7619850e-14\n",
      " 2.1380599e-08 9.9999988e-01 3.5411012e-09 5.5443805e-09 4.6023501e-08]\n",
      "decoder_attentions[di]\n",
      "[2.6414106e-08 6.2721592e-11 1.6938142e-08 2.0449233e-08 2.7619850e-14\n",
      " 2.1380599e-08 9.9999988e-01 3.5411012e-09 5.5443805e-09 4.6023501e-08]\n",
      "topv\n",
      "[-0.9489145]\n",
      "topi\n",
      "[581]\n",
      "output_lang.index2word[topi.item()]\n",
      "auto\n",
      "decoder_input\n",
      "581\n",
      "decoder_output\n",
      "[-12.101024   -4.175484  -17.478449  -15.007107   -9.404994   -9.678028\n",
      "  -0.3534298 -13.173132   -9.3324995 -13.427951 ]\n",
      "decoder_hidden\n",
      "[-0.9991404   0.6270689  -0.25009865  0.9983947  -0.8712366  -0.97832775\n",
      " -0.9532766  -0.90569586 -0.41726345  0.96992064]\n",
      "decoder_attention\n",
      "[2.9809042e-04 1.6111433e-07 2.2481108e-05 2.6760703e-05 8.8288007e-06\n",
      " 2.4781357e-08 9.9758995e-01 5.4409913e-05 1.3457634e-03 6.5346004e-04]\n",
      "decoder_attentions[di]\n",
      "[2.9809042e-04 1.6111433e-07 2.2481108e-05 2.6760703e-05 8.8288007e-06\n",
      " 2.4781357e-08 9.9758995e-01 5.4409913e-05 1.3457634e-03 6.5346004e-04]\n",
      "topv\n",
      "[-0.3534298]\n",
      "topi\n",
      "[6]\n",
      "output_lang.index2word[topi.item()]\n",
      ".\n",
      "decoder_input\n",
      "6\n",
      "decoder_output\n",
      "[-14.531114    -0.08613491 -16.461926   -15.7951565  -13.0186205\n",
      " -10.584882    -2.77882    -13.069895   -12.724806   -14.22835   ]\n",
      "decoder_hidden\n",
      "[-0.9991431   0.7895171  -0.76661146  0.01525164 -0.86781704 -0.99651575\n",
      " -0.94082963  0.42064947 -0.41878188  0.96436757]\n",
      "decoder_attention\n",
      "[1.3090320e-02 1.2196758e-03 2.5084808e-03 1.0573509e-03 2.4785975e-06\n",
      " 1.7405799e-04 6.3750738e-01 9.9626863e-03 3.3845492e-02 3.0063200e-01]\n",
      "decoder_attentions[di]\n",
      "[1.3090320e-02 1.2196758e-03 2.5084808e-03 1.0573509e-03 2.4785975e-06\n",
      " 1.7405799e-04 6.3750738e-01 9.9626863e-03 3.3845492e-02 3.0063200e-01]\n",
      "topv\n",
      "[-0.08613491]\n",
      "topi\n",
      "[1]\n",
      "decoded_words\n",
      "['ich', 'interessiere', 'mit', 'meinem', 'auto', 'auto', '.', '<EOS>']\n",
      "input_tensor\n",
      "[   2    3   70  316  415  109 2626    4    1]\n",
      "encoder_hidden\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "encoder_outputs\n",
      "[-0.10922617  0.6067832   0.6439681   0.10918707  0.15006319  0.60468507\n",
      " -0.83865154 -0.8165876  -0.08856022 -0.17544824]\n",
      "input_tensor[ei]\n",
      "[2]\n",
      "encoder_hidden\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "encoder_output\n",
      "[-0.10922617  0.6067832   0.6439681   0.10918707  0.15006319  0.60468507\n",
      " -0.83865154 -0.8165876  -0.08856022 -0.17544824]\n",
      "encoder_hidden\n",
      "[-0.10922617  0.6067832   0.6439681   0.10918707  0.15006319  0.60468507\n",
      " -0.83865154 -0.8165876  -0.08856022 -0.17544824]\n",
      "encoder_outputs[ei]\n",
      "[-0.10922617  0.6067832   0.6439681   0.10918707  0.15006319  0.60468507\n",
      " -0.83865154 -0.8165876  -0.08856022 -0.17544824]\n",
      "input_tensor[ei]\n",
      "[3]\n",
      "encoder_hidden\n",
      "[-0.10922617  0.6067832   0.6439681   0.10918707  0.15006319  0.60468507\n",
      " -0.83865154 -0.8165876  -0.08856022 -0.17544824]\n",
      "encoder_output\n",
      "[-0.83710116  0.66214955  0.584383    0.7208886  -0.9831236  -0.8309508\n",
      "  0.68693846  0.53419995 -0.99925417  0.78245384]\n",
      "encoder_hidden\n",
      "[-0.83710116  0.66214955  0.584383    0.7208886  -0.9831236  -0.8309508\n",
      "  0.68693846  0.53419995 -0.99925417  0.78245384]\n",
      "encoder_outputs[ei]\n",
      "[-0.83710116  0.66214955  0.584383    0.7208886  -0.9831236  -0.8309508\n",
      "  0.68693846  0.53419995 -0.99925417  0.78245384]\n",
      "input_tensor[ei]\n",
      "[70]\n",
      "encoder_hidden\n",
      "[-0.83710116  0.66214955  0.584383    0.7208886  -0.9831236  -0.8309508\n",
      "  0.68693846  0.53419995 -0.99925417  0.78245384]\n",
      "encoder_output\n",
      "[ 0.8541107   0.96920764 -0.94450724  0.96916664 -0.9821097   0.7049966\n",
      " -0.98100954  0.8647615  -0.8964862   0.96895874]\n",
      "encoder_hidden\n",
      "[ 0.8541107   0.96920764 -0.94450724  0.96916664 -0.9821097   0.7049966\n",
      " -0.98100954  0.8647615  -0.8964862   0.96895874]\n",
      "encoder_outputs[ei]\n",
      "[ 0.8541107   0.96920764 -0.94450724  0.96916664 -0.9821097   0.7049966\n",
      " -0.98100954  0.8647615  -0.8964862   0.96895874]\n",
      "input_tensor[ei]\n",
      "[316]\n",
      "encoder_hidden\n",
      "[ 0.8541107   0.96920764 -0.94450724  0.96916664 -0.9821097   0.7049966\n",
      " -0.98100954  0.8647615  -0.8964862   0.96895874]\n",
      "encoder_output\n",
      "[ 0.8440616   0.7672821  -0.9707212   0.97934455 -0.993663   -0.92133224\n",
      " -0.98063064  0.97234356 -0.99464285  0.97087413]\n",
      "encoder_hidden\n",
      "[ 0.8440616   0.7672821  -0.9707212   0.97934455 -0.993663   -0.92133224\n",
      " -0.98063064  0.97234356 -0.99464285  0.97087413]\n",
      "encoder_outputs[ei]\n",
      "[ 0.8440616   0.7672821  -0.9707212   0.97934455 -0.993663   -0.92133224\n",
      " -0.98063064  0.97234356 -0.99464285  0.97087413]\n",
      "input_tensor[ei]\n",
      "[415]\n",
      "encoder_hidden\n",
      "[ 0.8440616   0.7672821  -0.9707212   0.97934455 -0.993663   -0.92133224\n",
      " -0.98063064  0.97234356 -0.99464285  0.97087413]\n",
      "encoder_output\n",
      "[ 0.1723401  -0.80866075 -0.91403514  0.88434964 -0.9996203   0.8009598\n",
      " -0.9775564   0.9562414  -0.9258637  -0.5315094 ]\n",
      "encoder_hidden\n",
      "[ 0.1723401  -0.80866075 -0.91403514  0.88434964 -0.9996203   0.8009598\n",
      " -0.9775564   0.9562414  -0.9258637  -0.5315094 ]\n",
      "encoder_outputs[ei]\n",
      "[ 0.1723401  -0.80866075 -0.91403514  0.88434964 -0.9996203   0.8009598\n",
      " -0.9775564   0.9562414  -0.9258637  -0.5315094 ]\n",
      "input_tensor[ei]\n",
      "[109]\n",
      "encoder_hidden\n",
      "[ 0.1723401  -0.80866075 -0.91403514  0.88434964 -0.9996203   0.8009598\n",
      " -0.9775564   0.9562414  -0.9258637  -0.5315094 ]\n",
      "encoder_output\n",
      "[-0.7797622  -0.8407864  -0.98123765  0.8200958  -0.99956393  0.86147857\n",
      " -0.9770504   0.86088026 -0.90277517 -0.5864537 ]\n",
      "encoder_hidden\n",
      "[-0.7797622  -0.8407864  -0.98123765  0.8200958  -0.99956393  0.86147857\n",
      " -0.9770504   0.86088026 -0.90277517 -0.5864537 ]\n",
      "encoder_outputs[ei]\n",
      "[-0.7797622  -0.8407864  -0.98123765  0.8200958  -0.99956393  0.86147857\n",
      " -0.9770504   0.86088026 -0.90277517 -0.5864537 ]\n",
      "input_tensor[ei]\n",
      "[2626]\n",
      "encoder_hidden\n",
      "[-0.7797622  -0.8407864  -0.98123765  0.8200958  -0.99956393  0.86147857\n",
      " -0.9770504   0.86088026 -0.90277517 -0.5864537 ]\n",
      "encoder_output\n",
      "[-0.33383232 -0.55156785 -0.9520353   0.6076646  -0.9893947   0.8906942\n",
      " -0.9584436   0.6884959  -0.9030965  -0.5815917 ]\n",
      "encoder_hidden\n",
      "[-0.33383232 -0.55156785 -0.9520353   0.6076646  -0.9893947   0.8906942\n",
      " -0.9584436   0.6884959  -0.9030965  -0.5815917 ]\n",
      "encoder_outputs[ei]\n",
      "[-0.33383232 -0.55156785 -0.9520353   0.6076646  -0.9893947   0.8906942\n",
      " -0.9584436   0.6884959  -0.9030965  -0.5815917 ]\n",
      "input_tensor[ei]\n",
      "[4]\n",
      "encoder_hidden\n",
      "[-0.33383232 -0.55156785 -0.9520353   0.6076646  -0.9893947   0.8906942\n",
      " -0.9584436   0.6884959  -0.9030965  -0.5815917 ]\n",
      "encoder_output\n",
      "[-0.3522435  -0.7401781  -0.9422453   0.60476184 -0.9893951   0.9602115\n",
      " -0.9584215   0.7250402  -0.9030617  -0.5816262 ]\n",
      "encoder_hidden\n",
      "[-0.3522435  -0.7401781  -0.9422453   0.60476184 -0.9893951   0.9602115\n",
      " -0.9584215   0.7250402  -0.9030617  -0.5816262 ]\n",
      "encoder_outputs[ei]\n",
      "[-0.3522435  -0.7401781  -0.9422453   0.60476184 -0.9893951   0.9602115\n",
      " -0.9584215   0.7250402  -0.9030617  -0.5816262 ]\n",
      "input_tensor[ei]\n",
      "[1]\n",
      "encoder_hidden\n",
      "[-0.3522435  -0.7401781  -0.9422453   0.60476184 -0.9893951   0.9602115\n",
      " -0.9584215   0.7250402  -0.9030617  -0.5816262 ]\n",
      "encoder_output\n",
      "[-0.3576297  -0.85226315  0.88953996  0.60051554 -0.9893952   0.60913825\n",
      " -0.95842254  0.85620946 -0.90306205 -0.5816653 ]\n",
      "encoder_hidden\n",
      "[-0.3576297  -0.85226315  0.88953996  0.60051554 -0.9893952   0.60913825\n",
      " -0.95842254  0.85620946 -0.90306205 -0.5816653 ]\n",
      "encoder_outputs[ei]\n",
      "[-0.3576297  -0.85226315  0.88953996  0.60051554 -0.9893952   0.60913825\n",
      " -0.95842254  0.85620946 -0.90306205 -0.5816653 ]\n",
      "decoder_input\n",
      "[0]\n",
      "decoder_hidden\n",
      "[-0.3576297  -0.85226315  0.88953996  0.60051554 -0.9893952   0.60913825\n",
      " -0.95842254  0.85620946 -0.90306205 -0.5816653 ]\n",
      "decoder_output\n",
      "[-14.704549   -13.425407    -0.03944683 -16.65086    -16.873585\n",
      " -15.323432   -12.444698   -10.171982   -13.274241   -10.523732  ]\n",
      "decoder_hidden\n",
      "[-0.36108446 -0.9575214   0.8865506   0.5962839  -0.9893848   0.99997985\n",
      " -0.958411    0.99944836 -0.90306014 -0.5816609 ]\n",
      "decoder_attention\n",
      "[1.5371894e-05 9.9947828e-01 4.6581936e-05 4.5573525e-04 5.9322730e-08\n",
      " 2.0817703e-10 4.9992686e-08 3.2942180e-06 5.3208237e-07 2.4481753e-07]\n",
      "decoder_attentions[di]\n",
      "[1.5371894e-05 9.9947828e-01 4.6581936e-05 4.5573525e-04 5.9322730e-08\n",
      " 2.0817703e-10 4.9992686e-08 3.2942180e-06 5.3208237e-07 2.4481753e-07]\n",
      "topv\n",
      "[-0.03944683]\n",
      "topi\n",
      "[2]\n",
      "output_lang.index2word[topi.item()]\n",
      "ich\n",
      "decoder_input\n",
      "2\n",
      "decoder_output\n",
      "[-13.236439 -16.154896 -13.250394 -10.253301 -13.986941 -16.511917\n",
      " -16.350718 -14.427516 -10.272902 -10.332132]\n",
      "decoder_hidden\n",
      "[-0.44587994  0.47999573  0.48535782  0.55878615 -0.98920345  0.999986\n",
      " -0.9576614   0.6263546  -0.9030683  -0.57871413]\n",
      "decoder_attention\n",
      "[7.38441202e-08 6.27164945e-06 6.05204491e-07 9.99991417e-01\n",
      " 1.01242543e-08 1.30411138e-06 1.48003623e-10 1.17601274e-07\n",
      " 2.92605717e-10 1.86531068e-07]\n",
      "decoder_attentions[di]\n",
      "[7.38441202e-08 6.27164945e-06 6.05204491e-07 9.99991417e-01\n",
      " 1.01242543e-08 1.30411138e-06 1.48003623e-10 1.17601274e-07\n",
      " 2.92605717e-10 1.86531068e-07]\n",
      "topv\n",
      "[-0.53608894]\n",
      "topi\n",
      "[780]\n",
      "output_lang.index2word[topi.item()]\n",
      "fahre\n",
      "decoder_input\n",
      "780\n",
      "decoder_output\n",
      "[-12.142368  -11.77166    -7.611696  -16.588203  -13.429184  -16.058231\n",
      "  -8.2039     -9.267993  -12.70459    -4.7921553]\n",
      "decoder_hidden\n",
      "[-0.7666242   0.9636059  -0.36755556  0.54108083 -0.98914707  0.99995834\n",
      " -0.9575779   0.98824644 -0.9030754  -0.5776697 ]\n",
      "decoder_attention\n",
      "[2.1054730e-04 4.0351567e-04 1.3562165e-04 3.5530860e-03 9.9534553e-01\n",
      " 3.6069654e-05 9.9386096e-05 7.3172094e-05 6.7425557e-05 7.5537100e-05]\n",
      "decoder_attentions[di]\n",
      "[2.1054730e-04 4.0351567e-04 1.3562165e-04 3.5530860e-03 9.9534553e-01\n",
      " 3.6069654e-05 9.9386096e-05 7.3172094e-05 6.7425557e-05 7.5537100e-05]\n",
      "topv\n",
      "[-1.1392393]\n",
      "topi\n",
      "[734]\n",
      "output_lang.index2word[topi.item()]\n",
      "nach\n",
      "decoder_input\n",
      "734\n",
      "decoder_output\n",
      "[-12.735518  -9.543923  -9.120571 -17.784534 -14.832003 -15.487444\n",
      "  -7.123026  -9.435241 -14.099594  -7.416177]\n",
      "decoder_hidden\n",
      "[-0.13606857 -0.39245275  0.78381824 -0.97550875 -0.9887899  -0.26713645\n",
      " -0.95606786 -0.9159582  -0.9030802  -0.5510286 ]\n",
      "decoder_attention\n",
      "[1.9662673e-07 5.9784298e-08 2.7099449e-07 2.5169359e-07 4.2411997e-07\n",
      " 9.9999785e-01 7.4191649e-07 1.5983979e-07 8.6205345e-09 1.2355726e-07]\n",
      "decoder_attentions[di]\n",
      "[1.9662673e-07 5.9784298e-08 2.7099449e-07 2.5169359e-07 4.2411997e-07\n",
      " 9.9999785e-01 7.4191649e-07 1.5983979e-07 8.6205345e-09 1.2355726e-07]\n",
      "topv\n",
      "[-0.42591667]\n",
      "topi\n",
      "[575]\n",
      "output_lang.index2word[topi.item()]\n",
      "boston\n",
      "decoder_input\n",
      "575\n",
      "decoder_output\n",
      "[-12.707465   -6.9544196 -12.931578  -18.618221  -14.000003  -16.105251\n",
      "  -3.8340073 -11.573713  -11.632672   -9.411282 ]\n",
      "decoder_hidden\n",
      "[-0.23750886  0.9915808   0.03332913 -0.9850153  -0.9887513  -0.9047809\n",
      " -0.955955   -0.95817375 -0.90308183 -0.53072184]\n",
      "decoder_attention\n",
      "[5.9577060e-04 3.1675099e-05 7.5892609e-04 4.7279871e-05 4.2440107e-08\n",
      " 3.9329808e-03 9.8165947e-01 1.7534745e-03 3.5656248e-03 7.6548159e-03]\n",
      "decoder_attentions[di]\n",
      "[5.9577060e-04 3.1675099e-05 7.5892609e-04 4.7279871e-05 4.2440107e-08\n",
      " 3.9329808e-03 9.8165947e-01 1.7534745e-03 3.5656248e-03 7.6548159e-03]\n",
      "topv\n",
      "[-0.63692284]\n",
      "topi\n",
      "[734]\n",
      "output_lang.index2word[topi.item()]\n",
      "nach\n",
      "decoder_input\n",
      "734\n",
      "decoder_output\n",
      "[-12.918093   -5.3399887 -12.914714  -17.367704  -17.381886  -16.710577\n",
      "  -5.6348104 -11.2257395 -12.931997  -10.558539 ]\n",
      "decoder_hidden\n",
      "[ 0.16503075  0.9992114  -0.7265859  -0.99744827 -0.98583645 -0.99953574\n",
      " -0.9465947  -0.9760407  -0.9031582  -0.47295898]\n",
      "decoder_attention\n",
      "[1.5037690e-02 1.9738225e-04 5.4694656e-03 1.9966343e-03 1.0703517e-06\n",
      " 6.4039007e-02 5.0195718e-01 9.7960852e-02 2.6549128e-01 4.7849469e-02]\n",
      "decoder_attentions[di]\n",
      "[1.5037690e-02 1.9738225e-04 5.4694656e-03 1.9966343e-03 1.0703517e-06\n",
      " 6.4039007e-02 5.0195718e-01 9.7960852e-02 2.6549128e-01 4.7849469e-02]\n",
      "topv\n",
      "[-0.20847416]\n",
      "topi\n",
      "[575]\n",
      "output_lang.index2word[topi.item()]\n",
      "boston\n",
      "decoder_input\n",
      "575\n",
      "decoder_output\n",
      "[-14.457546   -2.117896  -15.406708  -19.00051   -16.92207   -15.066277\n",
      "  -0.1858139 -13.565638  -12.915009  -11.720101 ]\n",
      "decoder_hidden\n",
      "[ 0.7180232   0.99993896 -0.99241424 -0.9975942  -0.9856071  -0.99999994\n",
      " -0.9462831  -0.9506545  -0.90709287 -0.44783914]\n",
      "decoder_attention\n",
      "[1.1023720e-03 2.8822898e-05 3.7328253e-04 1.5688593e-05 3.1079236e-07\n",
      " 6.7210837e-09 1.6858321e-02 1.2097192e-02 8.7625211e-01 9.3271881e-02]\n",
      "decoder_attentions[di]\n",
      "[1.1023720e-03 2.8822898e-05 3.7328253e-04 1.5688593e-05 3.1079236e-07\n",
      " 6.7210837e-09 1.6858321e-02 1.2097192e-02 8.7625211e-01 9.3271881e-02]\n",
      "topv\n",
      "[-0.1858139]\n",
      "topi\n",
      "[6]\n",
      "output_lang.index2word[topi.item()]\n",
      ".\n",
      "decoder_input\n",
      "6\n",
      "decoder_output\n",
      "[-1.65051842e+01 -1.60026550e-02 -1.72153053e+01 -1.86809292e+01\n",
      " -1.94683685e+01 -1.66656914e+01 -4.33596802e+00 -1.56032648e+01\n",
      " -1.51262665e+01 -1.44427395e+01]\n",
      "decoder_hidden\n",
      "[ 0.49225914  0.9999692  -0.9973302  -0.9980505  -0.9566271  -1.\n",
      " -0.8785405  -0.8853705  -0.8380299  -0.42030787]\n",
      "decoder_attention\n",
      "[1.2281567e-02 8.5855136e-04 1.2369838e-03 2.7627359e-05 1.5774160e-05\n",
      " 5.3819891e-09 2.5047993e-03 9.1513293e-03 6.6875660e-01 3.0516666e-01]\n",
      "decoder_attentions[di]\n",
      "[1.2281567e-02 8.5855136e-04 1.2369838e-03 2.7627359e-05 1.5774160e-05\n",
      " 5.3819891e-09 2.5047993e-03 9.1513293e-03 6.6875660e-01 3.0516666e-01]\n",
      "topv\n",
      "[-0.01600266]\n",
      "topi\n",
      "[1]\n",
      "decoded_words\n",
      "['ich', 'fahre', 'nach', 'boston', 'nach', 'boston', '.', '<EOS>']\n",
      "input_tensor\n",
      "[ 48  49 637 843   4   1]\n",
      "encoder_hidden\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "encoder_outputs\n",
      "[-0.24151272  0.07389677  0.14187232 -0.13187045 -0.21201348  0.7023839\n",
      " -0.01192594 -0.8879513   0.86634135 -0.9917318 ]\n",
      "input_tensor[ei]\n",
      "[48]\n",
      "encoder_hidden\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "encoder_output\n",
      "[-0.24151272  0.07389677  0.14187232 -0.13187045 -0.21201348  0.7023839\n",
      " -0.01192594 -0.8879513   0.86634135 -0.9917318 ]\n",
      "encoder_hidden\n",
      "[-0.24151272  0.07389677  0.14187232 -0.13187045 -0.21201348  0.7023839\n",
      " -0.01192594 -0.8879513   0.86634135 -0.9917318 ]\n",
      "encoder_outputs[ei]\n",
      "[-0.24151272  0.07389677  0.14187232 -0.13187045 -0.21201348  0.7023839\n",
      " -0.01192594 -0.8879513   0.86634135 -0.9917318 ]\n",
      "input_tensor[ei]\n",
      "[49]\n",
      "encoder_hidden\n",
      "[-0.24151272  0.07389677  0.14187232 -0.13187045 -0.21201348  0.7023839\n",
      " -0.01192594 -0.8879513   0.86634135 -0.9917318 ]\n",
      "encoder_output\n",
      "[-0.94854337  0.78109705 -0.7576846   0.15421624 -0.87620497  0.5647007\n",
      "  0.8045426  -0.8869806   0.9868675   0.82549334]\n",
      "encoder_hidden\n",
      "[-0.94854337  0.78109705 -0.7576846   0.15421624 -0.87620497  0.5647007\n",
      "  0.8045426  -0.8869806   0.9868675   0.82549334]\n",
      "encoder_outputs[ei]\n",
      "[-0.94854337  0.78109705 -0.7576846   0.15421624 -0.87620497  0.5647007\n",
      "  0.8045426  -0.8869806   0.9868675   0.82549334]\n",
      "input_tensor[ei]\n",
      "[637]\n",
      "encoder_hidden\n",
      "[-0.94854337  0.78109705 -0.7576846   0.15421624 -0.87620497  0.5647007\n",
      "  0.8045426  -0.8869806   0.9868675   0.82549334]\n",
      "encoder_output\n",
      "[-0.5671539  -0.88122696 -0.88872254  0.95964056  0.9839624   0.5496447\n",
      " -0.93475705 -0.2638158  -0.36452293  0.77500015]\n",
      "encoder_hidden\n",
      "[-0.5671539  -0.88122696 -0.88872254  0.95964056  0.9839624   0.5496447\n",
      " -0.93475705 -0.2638158  -0.36452293  0.77500015]\n",
      "encoder_outputs[ei]\n",
      "[-0.5671539  -0.88122696 -0.88872254  0.95964056  0.9839624   0.5496447\n",
      " -0.93475705 -0.2638158  -0.36452293  0.77500015]\n",
      "input_tensor[ei]\n",
      "[843]\n",
      "encoder_hidden\n",
      "[-0.5671539  -0.88122696 -0.88872254  0.95964056  0.9839624   0.5496447\n",
      " -0.93475705 -0.2638158  -0.36452293  0.77500015]\n",
      "encoder_output\n",
      "[-0.38509688 -0.7853432   0.5314993   0.9463953  -0.8009963   0.75426495\n",
      " -0.9508755  -0.45961893 -0.9505545  -0.08958131]\n",
      "encoder_hidden\n",
      "[-0.38509688 -0.7853432   0.5314993   0.9463953  -0.8009963   0.75426495\n",
      " -0.9508755  -0.45961893 -0.9505545  -0.08958131]\n",
      "encoder_outputs[ei]\n",
      "[-0.38509688 -0.7853432   0.5314993   0.9463953  -0.8009963   0.75426495\n",
      " -0.9508755  -0.45961893 -0.9505545  -0.08958131]\n",
      "input_tensor[ei]\n",
      "[4]\n",
      "encoder_hidden\n",
      "[-0.38509688 -0.7853432   0.5314993   0.9463953  -0.8009963   0.75426495\n",
      " -0.9508755  -0.45961893 -0.9505545  -0.08958131]\n",
      "encoder_output\n",
      "[-0.44625738 -0.8303748   0.4155491   0.94178706 -0.80234843  0.9717098\n",
      " -0.950388   -0.06777889 -0.94152486 -0.09353518]\n",
      "encoder_hidden\n",
      "[-0.44625738 -0.8303748   0.4155491   0.94178706 -0.80234843  0.9717098\n",
      " -0.950388   -0.06777889 -0.94152486 -0.09353518]\n",
      "encoder_outputs[ei]\n",
      "[-0.44625738 -0.8303748   0.4155491   0.94178706 -0.80234843  0.9717098\n",
      " -0.950388   -0.06777889 -0.94152486 -0.09353518]\n",
      "input_tensor[ei]\n",
      "[1]\n",
      "encoder_hidden\n",
      "[-0.44625738 -0.8303748   0.4155491   0.94178706 -0.80234843  0.9717098\n",
      " -0.950388   -0.06777889 -0.94152486 -0.09353518]\n",
      "encoder_output\n",
      "[-0.4557581  -0.8603049   0.97106975  0.9377403  -0.80088747  0.6804615\n",
      " -0.95038426  0.7789275  -0.9415305  -0.09563243]\n",
      "encoder_hidden\n",
      "[-0.4557581  -0.8603049   0.97106975  0.9377403  -0.80088747  0.6804615\n",
      " -0.95038426  0.7789275  -0.9415305  -0.09563243]\n",
      "encoder_outputs[ei]\n",
      "[-0.4557581  -0.8603049   0.97106975  0.9377403  -0.80088747  0.6804615\n",
      " -0.95038426  0.7789275  -0.9415305  -0.09563243]\n",
      "decoder_input\n",
      "[0]\n",
      "decoder_hidden\n",
      "[-0.4557581  -0.8603049   0.97106975  0.9377403  -0.80088747  0.6804615\n",
      " -0.95038426  0.7789275  -0.9415305  -0.09563243]\n",
      "decoder_output\n",
      "[-17.464909  -11.412619  -11.065968  -18.888317  -15.516916  -15.87722\n",
      " -12.396471  -14.5248995 -14.208484  -15.5651   ]\n",
      "decoder_hidden\n",
      "[-0.7693974  -0.8622997   0.9689003   0.890629   -0.8008854   0.9999938\n",
      " -0.95038223  0.9992256  -0.9415303  -0.09563261]\n",
      "decoder_attention\n",
      "[1.46871225e-05 9.99945283e-01 2.08886304e-05 1.18724511e-05\n",
      " 2.72723355e-06 2.70998168e-10 8.18050268e-08 1.93132519e-06\n",
      " 1.81438304e-06 7.05616799e-07]\n",
      "decoder_attentions[di]\n",
      "[1.46871225e-05 9.99945283e-01 2.08886304e-05 1.18724511e-05\n",
      " 2.72723355e-06 2.70998168e-10 8.18050268e-08 1.93132519e-06\n",
      " 1.81438304e-06 7.05616799e-07]\n",
      "topv\n",
      "[-0.00148964]\n",
      "topi\n",
      "[64]\n",
      "output_lang.index2word[topi.item()]\n",
      "er\n",
      "decoder_input\n",
      "64\n",
      "decoder_output\n",
      "[-10.691048   -7.155395  -16.540493  -11.969471   -8.715326   -9.530243\n",
      "  -8.45016   -14.883503   -6.6678796 -14.791459 ]\n",
      "decoder_hidden\n",
      "[-0.9895041   0.9886143  -0.83468276  0.8775133  -0.8007788   0.96365076\n",
      " -0.95025     0.9085391  -0.9416781  -0.09546471]\n",
      "decoder_attention\n",
      "[6.1368866e-07 9.2179680e-06 4.6465149e-07 9.9370146e-01 6.2873885e-03\n",
      " 4.9857801e-13 2.7757568e-07 1.2195366e-07 9.7861680e-08 3.8829788e-07]\n",
      "decoder_attentions[di]\n",
      "[6.1368866e-07 9.2179680e-06 4.6465149e-07 9.9370146e-01 6.2873885e-03\n",
      " 4.9857801e-13 2.7757568e-07 1.2195366e-07 9.7861680e-08 3.8829788e-07]\n",
      "topv\n",
      "[-2.719483]\n",
      "topi\n",
      "[2270]\n",
      "output_lang.index2word[topi.item()]\n",
      "lacht\n",
      "decoder_input\n",
      "2270\n",
      "decoder_output\n",
      "[-11.57281    -6.119882  -13.798042  -15.336195   -7.4202213  -9.890534\n",
      "  -2.234293   -8.319753  -11.925002  -10.601324 ]\n",
      "decoder_hidden\n",
      "[-0.9327601   0.9909571  -0.9894112   0.87379694 -0.7976206  -0.99280167\n",
      " -0.94887334  0.9994287  -0.9523095  -0.0529682 ]\n",
      "decoder_attention\n",
      "[2.58306674e-08 7.37388106e-09 1.23924082e-07 3.53946831e-07\n",
      " 9.99999166e-01 7.72967357e-10 4.67609146e-11 1.34532300e-07\n",
      " 1.56754538e-07 1.00190285e-07]\n",
      "decoder_attentions[di]\n",
      "[2.58306674e-08 7.37388106e-09 1.23924082e-07 3.53946831e-07\n",
      " 9.99999166e-01 7.72967357e-10 4.67609146e-11 1.34532300e-07\n",
      " 1.56754538e-07 1.00190285e-07]\n",
      "topv\n",
      "[-0.90750504]\n",
      "topi\n",
      "[776]\n",
      "output_lang.index2word[topi.item()]\n",
      "immer\n",
      "decoder_input\n",
      "776\n",
      "decoder_output\n",
      "[-1.4270996e+01 -5.8563085e+00 -1.7424740e+01 -2.1959002e+01\n",
      " -1.1540365e+01 -1.1715428e+01 -1.9285202e-02 -1.4731802e+01\n",
      " -1.4037203e+01 -1.4205807e+01]\n",
      "decoder_hidden\n",
      "[-0.9799524   0.9961323   0.84943897  0.85592043 -0.7960207  -0.9946243\n",
      " -0.9481678   0.99229753 -0.950122   -0.00825632]\n",
      "decoder_attention\n",
      "[1.6604709e-11 8.1706685e-13 1.9108985e-11 2.9264753e-12 1.0000000e+00\n",
      " 8.9274678e-11 7.3453440e-18 1.0022285e-11 2.7692124e-10 2.2573274e-09]\n",
      "decoder_attentions[di]\n",
      "[1.6604709e-11 8.1706685e-13 1.9108985e-11 2.9264753e-12 1.0000000e+00\n",
      " 8.9274678e-11 7.3453440e-18 1.0022285e-11 2.7692124e-10 2.2573274e-09]\n",
      "topv\n",
      "[-0.0192852]\n",
      "topi\n",
      "[6]\n",
      "output_lang.index2word[topi.item()]\n",
      ".\n",
      "decoder_input\n",
      "6\n",
      "decoder_output\n",
      "[-16.827833    -0.03777695 -16.443354   -20.174875   -14.313134\n",
      " -11.738449    -3.3270302  -15.215457   -16.529274   -16.665543  ]\n",
      "decoder_hidden\n",
      "[-0.9527456   0.99673796 -0.40718126  0.11094594 -0.73749274 -0.99926233\n",
      " -0.91515213  0.99119276 -0.33149916  0.16882259]\n",
      "decoder_attention\n",
      "[1.0467874e-02 7.7743985e-05 2.5477039e-03 2.4541603e-05 1.9841586e-04\n",
      " 6.3073969e-01 1.8065428e-02 1.1364265e-03 3.3682014e-03 3.3337390e-01]\n",
      "decoder_attentions[di]\n",
      "[1.0467874e-02 7.7743985e-05 2.5477039e-03 2.4541603e-05 1.9841586e-04\n",
      " 6.3073969e-01 1.8065428e-02 1.1364265e-03 3.3682014e-03 3.3337390e-01]\n",
      "topv\n",
      "[-0.03777695]\n",
      "topi\n",
      "[1]\n",
      "decoded_words\n",
      "['er', 'lacht', 'immer', '.', '<EOS>']\n",
      "input_tensor\n",
      "[  48   51  104  394   13 1061    4    1]\n",
      "encoder_hidden\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "encoder_outputs\n",
      "[-0.24151272  0.07389677  0.14187232 -0.13187045 -0.21201348  0.7023839\n",
      " -0.01192594 -0.8879513   0.86634135 -0.9917318 ]\n",
      "input_tensor[ei]\n",
      "[48]\n",
      "encoder_hidden\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "encoder_output\n",
      "[-0.24151272  0.07389677  0.14187232 -0.13187045 -0.21201348  0.7023839\n",
      " -0.01192594 -0.8879513   0.86634135 -0.9917318 ]\n",
      "encoder_hidden\n",
      "[-0.24151272  0.07389677  0.14187232 -0.13187045 -0.21201348  0.7023839\n",
      " -0.01192594 -0.8879513   0.86634135 -0.9917318 ]\n",
      "encoder_outputs[ei]\n",
      "[-0.24151272  0.07389677  0.14187232 -0.13187045 -0.21201348  0.7023839\n",
      " -0.01192594 -0.8879513   0.86634135 -0.9917318 ]\n",
      "input_tensor[ei]\n",
      "[51]\n",
      "encoder_hidden\n",
      "[-0.24151272  0.07389677  0.14187232 -0.13187045 -0.21201348  0.7023839\n",
      " -0.01192594 -0.8879513   0.86634135 -0.9917318 ]\n",
      "encoder_output\n",
      "[-0.6482212   0.891448    0.8919973  -0.89152443 -0.97769284  0.22702569\n",
      "  0.9632918  -0.9605221   0.9778843  -0.22546959]\n",
      "encoder_hidden\n",
      "[-0.6482212   0.891448    0.8919973  -0.89152443 -0.97769284  0.22702569\n",
      "  0.9632918  -0.9605221   0.9778843  -0.22546959]\n",
      "encoder_outputs[ei]\n",
      "[-0.6482212   0.891448    0.8919973  -0.89152443 -0.97769284  0.22702569\n",
      "  0.9632918  -0.9605221   0.9778843  -0.22546959]\n",
      "input_tensor[ei]\n",
      "[104]\n",
      "encoder_hidden\n",
      "[-0.6482212   0.891448    0.8919973  -0.89152443 -0.97769284  0.22702569\n",
      "  0.9632918  -0.9605221   0.9778843  -0.22546959]\n",
      "encoder_output\n",
      "[ 0.28899586  0.03152599  0.6829626   0.24738815  0.97743595 -0.87894887\n",
      " -0.4279979  -0.7750961  -0.93865085 -0.0025689 ]\n",
      "encoder_hidden\n",
      "[ 0.28899586  0.03152599  0.6829626   0.24738815  0.97743595 -0.87894887\n",
      " -0.4279979  -0.7750961  -0.93865085 -0.0025689 ]\n",
      "encoder_outputs[ei]\n",
      "[ 0.28899586  0.03152599  0.6829626   0.24738815  0.97743595 -0.87894887\n",
      " -0.4279979  -0.7750961  -0.93865085 -0.0025689 ]\n",
      "input_tensor[ei]\n",
      "[394]\n",
      "encoder_hidden\n",
      "[ 0.28899586  0.03152599  0.6829626   0.24738815  0.97743595 -0.87894887\n",
      " -0.4279979  -0.7750961  -0.93865085 -0.0025689 ]\n",
      "encoder_output\n",
      "[ 0.16040367 -0.8863878   0.6864484  -0.91423386  0.9995963   0.12159854\n",
      " -0.42260742 -0.9097381  -0.34918457 -0.9287432 ]\n",
      "encoder_hidden\n",
      "[ 0.16040367 -0.8863878   0.6864484  -0.91423386  0.9995963   0.12159854\n",
      " -0.42260742 -0.9097381  -0.34918457 -0.9287432 ]\n",
      "encoder_outputs[ei]\n",
      "[ 0.16040367 -0.8863878   0.6864484  -0.91423386  0.9995963   0.12159854\n",
      " -0.42260742 -0.9097381  -0.34918457 -0.9287432 ]\n",
      "input_tensor[ei]\n",
      "[13]\n",
      "encoder_hidden\n",
      "[ 0.16040367 -0.8863878   0.6864484  -0.91423386  0.9995963   0.12159854\n",
      " -0.42260742 -0.9097381  -0.34918457 -0.9287432 ]\n",
      "encoder_output\n",
      "[ 0.82578003 -0.9097873   0.9164806  -0.92123765  0.9997446   0.95077187\n",
      " -0.98509103  0.18056798  0.8753597  -0.9294386 ]\n",
      "encoder_hidden\n",
      "[ 0.82578003 -0.9097873   0.9164806  -0.92123765  0.9997446   0.95077187\n",
      " -0.98509103  0.18056798  0.8753597  -0.9294386 ]\n",
      "encoder_outputs[ei]\n",
      "[ 0.82578003 -0.9097873   0.9164806  -0.92123765  0.9997446   0.95077187\n",
      " -0.98509103  0.18056798  0.8753597  -0.9294386 ]\n",
      "input_tensor[ei]\n",
      "[1061]\n",
      "encoder_hidden\n",
      "[ 0.82578003 -0.9097873   0.9164806  -0.92123765  0.9997446   0.95077187\n",
      " -0.98509103  0.18056798  0.8753597  -0.9294386 ]\n",
      "encoder_output\n",
      "[ 0.59689033  0.01151872  0.4191224   0.8321996   0.97947705  0.11837\n",
      "  0.96021354  0.5792031   0.875996   -0.8401997 ]\n",
      "encoder_hidden\n",
      "[ 0.59689033  0.01151872  0.4191224   0.8321996   0.97947705  0.11837\n",
      "  0.96021354  0.5792031   0.875996   -0.8401997 ]\n",
      "encoder_outputs[ei]\n",
      "[ 0.59689033  0.01151872  0.4191224   0.8321996   0.97947705  0.11837\n",
      "  0.96021354  0.5792031   0.875996   -0.8401997 ]\n",
      "input_tensor[ei]\n",
      "[4]\n",
      "encoder_hidden\n",
      "[ 0.59689033  0.01151872  0.4191224   0.8321996   0.97947705  0.11837\n",
      "  0.96021354  0.5792031   0.875996   -0.8401997 ]\n",
      "encoder_output\n",
      "[ 0.57724136 -0.52123356  0.34835303  0.82304     0.97622854  0.9252927\n",
      "  0.95989335  0.6569221   0.8759974  -0.8402691 ]\n",
      "encoder_hidden\n",
      "[ 0.57724136 -0.52123356  0.34835303  0.82304     0.97622854  0.9252927\n",
      "  0.95989335  0.6569221   0.8759974  -0.8402691 ]\n",
      "encoder_outputs[ei]\n",
      "[ 0.57724136 -0.52123356  0.34835303  0.82304     0.97622854  0.9252927\n",
      "  0.95989335  0.6569221   0.8759974  -0.8402691 ]\n",
      "input_tensor[ei]\n",
      "[1]\n",
      "encoder_hidden\n",
      "[ 0.57724136 -0.52123356  0.34835303  0.82304     0.97622854  0.9252927\n",
      "  0.95989335  0.6569221   0.8759974  -0.8402691 ]\n",
      "encoder_output\n",
      "[ 0.56963885 -0.7295028   0.976974    0.8139378   0.9744277   0.6165392\n",
      "  0.9597856   0.8523122   0.87599635 -0.8403078 ]\n",
      "encoder_hidden\n",
      "[ 0.56963885 -0.7295028   0.976974    0.8139378   0.9744277   0.6165392\n",
      "  0.9597856   0.8523122   0.87599635 -0.8403078 ]\n",
      "encoder_outputs[ei]\n",
      "[ 0.56963885 -0.7295028   0.976974    0.8139378   0.9744277   0.6165392\n",
      "  0.9597856   0.8523122   0.87599635 -0.8403078 ]\n",
      "decoder_input\n",
      "[0]\n",
      "decoder_hidden\n",
      "[ 0.56963885 -0.7295028   0.976974    0.8139378   0.9744277   0.6165392\n",
      "  0.9597856   0.8523122   0.87599635 -0.8403078 ]\n",
      "decoder_output\n",
      "[-17.043549 -13.424837 -11.215261 -17.722275 -16.392036 -13.875889\n",
      " -13.774058 -12.685908 -12.857317 -15.839002]\n",
      "decoder_hidden\n",
      "[-0.35285282 -0.7533178   0.9662331   0.79716635  0.97442424  0.99999595\n",
      "  0.95978564  0.99980307  0.87599057 -0.8402936 ]\n",
      "decoder_attention\n",
      "[4.8425700e-06 9.9742538e-01 2.2521945e-05 2.5449400e-03 2.0380602e-08\n",
      " 2.4080496e-08 1.2810735e-08 6.3656961e-07 1.6219497e-06 1.4843482e-07]\n",
      "decoder_attentions[di]\n",
      "[4.8425700e-06 9.9742538e-01 2.2521945e-05 2.5449400e-03 2.0380602e-08\n",
      " 2.4080496e-08 1.2810735e-08 6.3656961e-07 1.6219497e-06 1.4843482e-07]\n",
      "topv\n",
      "[-0.00332451]\n",
      "topi\n",
      "[64]\n",
      "output_lang.index2word[topi.item()]\n",
      "er\n",
      "decoder_input\n",
      "64\n",
      "decoder_output\n",
      "[-11.943001  -13.23977   -19.3406    -12.997364  -10.967946   -8.781784\n",
      " -13.462383  -16.35117    -6.9782963 -18.32956  ]\n",
      "decoder_hidden\n",
      "[-0.9201906   0.87885255  0.96693385  0.7576643   0.97442365  0.9742915\n",
      "  0.9597869  -0.9273032   0.8701072  -0.83963305]\n",
      "decoder_attention\n",
      "[5.8467742e-09 8.6063733e-07 2.5178158e-08 9.9999881e-01 2.6455513e-07\n",
      " 3.4444190e-13 1.0616927e-08 5.8080807e-10 1.0370644e-09 5.3043823e-09]\n",
      "decoder_attentions[di]\n",
      "[5.8467742e-09 8.6063733e-07 2.5178158e-08 9.9999881e-01 2.6455513e-07\n",
      " 3.4444190e-13 1.0616927e-08 5.8080807e-10 1.0370644e-09 5.3043823e-09]\n",
      "topv\n",
      "[-1.0418634]\n",
      "topi\n",
      "[65]\n",
      "output_lang.index2word[topi.item()]\n",
      "ist\n",
      "decoder_input\n",
      "65\n",
      "decoder_output\n",
      "[-11.0991745  -9.652613  -12.194846  -15.05278    -8.754135   -5.3317714\n",
      "  -7.713341   -8.736294  -11.929674  -14.026121 ]\n",
      "decoder_hidden\n",
      "[-0.9374145   0.77375054 -0.6955406   0.71442646  0.9742984   0.99505854\n",
      "  0.9597696   0.97546387  0.8699553  -0.8156855 ]\n",
      "decoder_attention\n",
      "[9.9244608e-07 3.0058150e-08 8.8334906e-07 3.7408707e-05 9.9994016e-01\n",
      " 1.1662171e-05 2.8990729e-12 7.0663611e-07 7.5554294e-06 5.4030085e-07]\n",
      "decoder_attentions[di]\n",
      "[9.9244608e-07 3.0058150e-08 8.8334906e-07 3.7408707e-05 9.9994016e-01\n",
      " 1.1662171e-05 2.8990729e-12 7.0663611e-07 7.5554294e-06 5.4030085e-07]\n",
      "topv\n",
      "[-0.6244354]\n",
      "topi\n",
      "[292]\n",
      "output_lang.index2word[topi.item()]\n",
      "einen\n",
      "decoder_input\n",
      "292\n",
      "decoder_output\n",
      "[-11.445456  -10.417593  -14.572057  -16.398159   -7.8604994  -7.14182\n",
      "  -7.22865   -10.166593  -14.645109  -15.852818 ]\n",
      "decoder_hidden\n",
      "[-0.9939476  -0.10567015  0.96927357  0.98741204  0.97428423  0.74995595\n",
      "  0.9594294   0.98804414  0.8698502  -0.70583296]\n",
      "decoder_attention\n",
      "[9.2295191e-04 1.4578708e-03 9.0087386e-05 1.5633492e-03 5.8437121e-01\n",
      " 4.1124982e-01 4.5387689e-05 1.8848166e-05 1.3062837e-04 1.4984859e-04]\n",
      "decoder_attentions[di]\n",
      "[9.2295191e-04 1.4578708e-03 9.0087386e-05 1.5633492e-03 5.8437121e-01\n",
      " 4.1124982e-01 4.5387689e-05 1.8848166e-05 1.3062837e-04 1.4984859e-04]\n",
      "topv\n",
      "[-0.7408562]\n",
      "topi\n",
      "[2493]\n",
      "output_lang.index2word[topi.item()]\n",
      "alten\n",
      "decoder_input\n",
      "2493\n",
      "decoder_output\n",
      "[-11.557752   -6.3629394 -10.717119  -15.403504   -8.453734   -7.8804655\n",
      "  -1.9302378  -9.351182  -13.018925  -14.085838 ]\n",
      "decoder_hidden\n",
      "[-0.9966059  -0.37569016  0.9984452   0.99354017  0.974099    0.86793524\n",
      "  0.9593735  -0.39584333  0.8497856   0.7192066 ]\n",
      "decoder_attention\n",
      "[1.3821320e-07 1.3712818e-07 7.2603818e-08 1.3197964e-06 1.7662188e-12\n",
      " 9.9998033e-01 1.6918253e-05 6.2288029e-07 1.9368905e-07 2.9912130e-07]\n",
      "decoder_attentions[di]\n",
      "[1.3821320e-07 1.3712818e-07 7.2603818e-08 1.3197964e-06 1.7662188e-12\n",
      " 9.9998033e-01 1.6918253e-05 6.2288029e-07 1.9368905e-07 2.9912130e-07]\n",
      "topv\n",
      "[-1.9302378]\n",
      "topi\n",
      "[6]\n",
      "output_lang.index2word[topi.item()]\n",
      ".\n",
      "decoder_input\n",
      "6\n",
      "decoder_output\n",
      "[-12.164767   -1.2416058  -7.241381  -13.267996  -10.718146   -8.487591\n",
      "  -0.6180477  -7.8676972 -12.240226  -12.173821 ]\n",
      "decoder_hidden\n",
      "[-0.9839915  -0.46924275  0.99965006 -0.45666248  0.9451739  -0.738188\n",
      "  0.9372707   0.39402     0.38910526  0.94643736]\n",
      "decoder_attention\n",
      "[9.3020816e-08 4.5094009e-09 1.7771729e-08 2.1144571e-09 1.6255147e-16\n",
      " 2.8885333e-05 9.9996996e-01 1.6849379e-08 5.2695204e-09 9.8053135e-07]\n",
      "decoder_attentions[di]\n",
      "[9.3020816e-08 4.5094009e-09 1.7771729e-08 2.1144571e-09 1.6255147e-16\n",
      " 2.8885333e-05 9.9996996e-01 1.6849379e-08 5.2695204e-09 9.8053135e-07]\n",
      "topv\n",
      "[-0.6180477]\n",
      "topi\n",
      "[6]\n",
      "output_lang.index2word[topi.item()]\n",
      ".\n",
      "decoder_input\n",
      "6\n",
      "decoder_output\n",
      "[-14.301028    -0.19617748  -9.561501   -13.537128   -13.470362\n",
      " -10.393575    -1.8397818   -9.270967   -13.375166   -13.596542  ]\n",
      "decoder_hidden\n",
      "[-0.96943957 -0.07171309  0.9887423  -0.85753345  0.93262804 -0.9905385\n",
      "  0.90727144  0.67251754  0.23766813  0.9581729 ]\n",
      "decoder_attention\n",
      "[2.86886170e-05 3.29044769e-06 7.52678307e-06 6.03900116e-06\n",
      " 1.24540005e-11 7.83107623e-07 9.98630524e-01 3.29357972e-05\n",
      " 6.23949090e-05 1.22780527e-03]\n",
      "decoder_attentions[di]\n",
      "[2.86886170e-05 3.29044769e-06 7.52678307e-06 6.03900116e-06\n",
      " 1.24540005e-11 7.83107623e-07 9.98630524e-01 3.29357972e-05\n",
      " 6.23949090e-05 1.22780527e-03]\n",
      "topv\n",
      "[-0.19617748]\n",
      "topi\n",
      "[1]\n",
      "decoded_words\n",
      "['er', 'ist', 'einen', 'alten', '.', '.', '<EOS>']\n",
      "input_tensor\n",
      "[  46   47   17 1921  430  606   30    4    1]\n",
      "encoder_hidden\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "encoder_outputs\n",
      "[ 0.14944866 -0.14021158  0.90946686 -0.00400773 -0.56244123  0.8094371\n",
      "  0.03909808  0.59136355 -0.24560118 -0.9268498 ]\n",
      "input_tensor[ei]\n",
      "[46]\n",
      "encoder_hidden\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "encoder_output\n",
      "[ 0.14944866 -0.14021158  0.90946686 -0.00400773 -0.56244123  0.8094371\n",
      "  0.03909808  0.59136355 -0.24560118 -0.9268498 ]\n",
      "encoder_hidden\n",
      "[ 0.14944866 -0.14021158  0.90946686 -0.00400773 -0.56244123  0.8094371\n",
      "  0.03909808  0.59136355 -0.24560118 -0.9268498 ]\n",
      "encoder_outputs[ei]\n",
      "[ 0.14944866 -0.14021158  0.90946686 -0.00400773 -0.56244123  0.8094371\n",
      "  0.03909808  0.59136355 -0.24560118 -0.9268498 ]\n",
      "input_tensor[ei]\n",
      "[47]\n",
      "encoder_hidden\n",
      "[ 0.14944866 -0.14021158  0.90946686 -0.00400773 -0.56244123  0.8094371\n",
      "  0.03909808  0.59136355 -0.24560118 -0.9268498 ]\n",
      "encoder_output\n",
      "[-0.79792374  0.905152    0.8520151   0.04179558  0.923291   -0.8262757\n",
      "  0.5117104   0.4886089  -0.24617732 -0.9288666 ]\n",
      "encoder_hidden\n",
      "[-0.79792374  0.905152    0.8520151   0.04179558  0.923291   -0.8262757\n",
      "  0.5117104   0.4886089  -0.24617732 -0.9288666 ]\n",
      "encoder_outputs[ei]\n",
      "[-0.79792374  0.905152    0.8520151   0.04179558  0.923291   -0.8262757\n",
      "  0.5117104   0.4886089  -0.24617732 -0.9288666 ]\n",
      "input_tensor[ei]\n",
      "[17]\n",
      "encoder_hidden\n",
      "[-0.79792374  0.905152    0.8520151   0.04179558  0.923291   -0.8262757\n",
      "  0.5117104   0.4886089  -0.24617732 -0.9288666 ]\n",
      "encoder_output\n",
      "[ 0.9296445   0.949742    0.9713668  -0.3573924   0.96577483 -0.7391368\n",
      " -0.9834323   0.33976084  0.34511256 -0.61588186]\n",
      "encoder_hidden\n",
      "[ 0.9296445   0.949742    0.9713668  -0.3573924   0.96577483 -0.7391368\n",
      " -0.9834323   0.33976084  0.34511256 -0.61588186]\n",
      "encoder_outputs[ei]\n",
      "[ 0.9296445   0.949742    0.9713668  -0.3573924   0.96577483 -0.7391368\n",
      " -0.9834323   0.33976084  0.34511256 -0.61588186]\n",
      "input_tensor[ei]\n",
      "[1921]\n",
      "encoder_hidden\n",
      "[ 0.9296445   0.949742    0.9713668  -0.3573924   0.96577483 -0.7391368\n",
      " -0.9834323   0.33976084  0.34511256 -0.61588186]\n",
      "encoder_output\n",
      "[-7.6829338e-01 -8.3805674e-01  8.3810192e-01 -7.4724507e-01\n",
      "  7.4397045e-01  7.2855401e-01  9.8235536e-01 -2.2065639e-04\n",
      " -3.7984568e-01  6.5225911e-01]\n",
      "encoder_hidden\n",
      "[-7.6829338e-01 -8.3805674e-01  8.3810192e-01 -7.4724507e-01\n",
      "  7.4397045e-01  7.2855401e-01  9.8235536e-01 -2.2065639e-04\n",
      " -3.7984568e-01  6.5225911e-01]\n",
      "encoder_outputs[ei]\n",
      "[-7.6829338e-01 -8.3805674e-01  8.3810192e-01 -7.4724507e-01\n",
      "  7.4397045e-01  7.2855401e-01  9.8235536e-01 -2.2065639e-04\n",
      " -3.7984568e-01  6.5225911e-01]\n",
      "input_tensor[ei]\n",
      "[430]\n",
      "encoder_hidden\n",
      "[-7.6829338e-01 -8.3805674e-01  8.3810192e-01 -7.4724507e-01\n",
      "  7.4397045e-01  7.2855401e-01  9.8235536e-01 -2.2065639e-04\n",
      " -3.7984568e-01  6.5225911e-01]\n",
      "encoder_output\n",
      "[-0.02905715 -0.3044904   0.9226068  -0.78862005 -0.8860478   0.68103\n",
      "  0.9956013  -0.42185944 -0.2201221   0.03281534]\n",
      "encoder_hidden\n",
      "[-0.02905715 -0.3044904   0.9226068  -0.78862005 -0.8860478   0.68103\n",
      "  0.9956013  -0.42185944 -0.2201221   0.03281534]\n",
      "encoder_outputs[ei]\n",
      "[-0.02905715 -0.3044904   0.9226068  -0.78862005 -0.8860478   0.68103\n",
      "  0.9956013  -0.42185944 -0.2201221   0.03281534]\n",
      "input_tensor[ei]\n",
      "[606]\n",
      "encoder_hidden\n",
      "[-0.02905715 -0.3044904   0.9226068  -0.78862005 -0.8860478   0.68103\n",
      "  0.9956013  -0.42185944 -0.2201221   0.03281534]\n",
      "encoder_output\n",
      "[ 0.18704814 -0.63492954  0.98610795 -0.8472779  -0.8747588   0.66438305\n",
      "  0.9225622   0.23677492 -0.16307259 -0.3020564 ]\n",
      "encoder_hidden\n",
      "[ 0.18704814 -0.63492954  0.98610795 -0.8472779  -0.8747588   0.66438305\n",
      "  0.9225622   0.23677492 -0.16307259 -0.3020564 ]\n",
      "encoder_outputs[ei]\n",
      "[ 0.18704814 -0.63492954  0.98610795 -0.8472779  -0.8747588   0.66438305\n",
      "  0.9225622   0.23677492 -0.16307259 -0.3020564 ]\n",
      "input_tensor[ei]\n",
      "[30]\n",
      "encoder_hidden\n",
      "[ 0.18704814 -0.63492954  0.98610795 -0.8472779  -0.8747588   0.66438305\n",
      "  0.9225622   0.23677492 -0.16307259 -0.3020564 ]\n",
      "encoder_output\n",
      "[-0.0362944  -0.8203207   0.8590853  -0.8479521  -0.9483413   0.6626538\n",
      "  0.92351985  0.71577203 -0.16277158  0.40950167]\n",
      "encoder_hidden\n",
      "[-0.0362944  -0.8203207   0.8590853  -0.8479521  -0.9483413   0.6626538\n",
      "  0.92351985  0.71577203 -0.16277158  0.40950167]\n",
      "encoder_outputs[ei]\n",
      "[-0.0362944  -0.8203207   0.8590853  -0.8479521  -0.9483413   0.6626538\n",
      "  0.92351985  0.71577203 -0.16277158  0.40950167]\n",
      "input_tensor[ei]\n",
      "[4]\n",
      "encoder_hidden\n",
      "[-0.0362944  -0.8203207   0.8590853  -0.8479521  -0.9483413   0.6626538\n",
      "  0.92351985  0.71577203 -0.16277158  0.40950167]\n",
      "encoder_output\n",
      "[-0.08398622 -0.88156605  0.76931655 -0.84514034 -0.9483442   0.9449598\n",
      "  0.9235325   0.75766945 -0.16228646  0.40946013]\n",
      "encoder_hidden\n",
      "[-0.08398622 -0.88156605  0.76931655 -0.84514034 -0.9483442   0.9449598\n",
      "  0.9235325   0.75766945 -0.16228646  0.40946013]\n",
      "encoder_outputs[ei]\n",
      "[-0.08398622 -0.88156605  0.76931655 -0.84514034 -0.9483442   0.9449598\n",
      "  0.9235325   0.75766945 -0.16228646  0.40946013]\n",
      "input_tensor[ei]\n",
      "[1]\n",
      "encoder_hidden\n",
      "[-0.08398622 -0.88156605  0.76931655 -0.84514034 -0.9483442   0.9449598\n",
      "  0.9235325   0.75766945 -0.16228646  0.40946013]\n",
      "encoder_output\n",
      "[-0.10238552 -0.92333513  0.9857166  -0.84487426 -0.9483416   0.7403935\n",
      "  0.92349815  0.83705306 -0.16225868  0.40941942]\n",
      "encoder_hidden\n",
      "[-0.10238552 -0.92333513  0.9857166  -0.84487426 -0.9483416   0.7403935\n",
      "  0.92349815  0.83705306 -0.16225868  0.40941942]\n",
      "encoder_outputs[ei]\n",
      "[-0.10238552 -0.92333513  0.9857166  -0.84487426 -0.9483416   0.7403935\n",
      "  0.92349815  0.83705306 -0.16225868  0.40941942]\n",
      "decoder_input\n",
      "[0]\n",
      "decoder_hidden\n",
      "[-0.10238552 -0.92333513  0.9857166  -0.84487426 -0.9483416   0.7403935\n",
      "  0.92349815  0.83705306 -0.16225868  0.40941942]\n",
      "decoder_output\n",
      "[-15.088915 -13.695032  -8.904963 -16.93658  -17.592934 -14.299556\n",
      " -12.60903  -15.692427 -12.314261 -13.465777]\n",
      "decoder_hidden\n",
      "[-0.834164   -0.94576037  0.9854368  -0.84515804 -0.94834113 -0.16919865\n",
      "  0.92349815 -0.9997678  -0.1622584   0.4094207 ]\n",
      "decoder_attention\n",
      "[3.58849070e-06 9.99948502e-01 1.57813665e-05 3.11790900e-05\n",
      " 1.55983997e-07 1.20801369e-09 5.10060616e-09 5.82974963e-07\n",
      " 1.17711345e-07 1.76136652e-07]\n",
      "decoder_attentions[di]\n",
      "[3.58849070e-06 9.99948502e-01 1.57813665e-05 3.11790900e-05\n",
      " 1.55983997e-07 1.20801369e-09 5.10060616e-09 5.82974963e-07\n",
      " 1.17711345e-07 1.76136652e-07]\n",
      "topv\n",
      "[-0.02091599]\n",
      "topi\n",
      "[60]\n",
      "output_lang.index2word[topi.item()]\n",
      "wir\n",
      "decoder_input\n",
      "60\n",
      "decoder_output\n",
      "[-13.841745 -17.257347 -21.993462 -10.289081 -13.764459 -13.312655\n",
      " -16.19237  -20.741844 -10.730402 -15.587248]\n",
      "decoder_hidden\n",
      "[ 0.8106094  -0.03700845  0.9791307  -0.8505844  -0.9480717   0.85966974\n",
      "  0.9233401  -0.99994266 -0.16234583  0.40943903]\n",
      "decoder_attention\n",
      "[1.1934408e-07 6.8710528e-07 2.1904909e-06 9.9995470e-01 4.1491552e-05\n",
      " 1.4468086e-08 1.2063655e-13 7.3212885e-07 3.9546929e-08 9.3688541e-08]\n",
      "decoder_attentions[di]\n",
      "[1.1934408e-07 6.8710528e-07 2.1904909e-06 9.9995470e-01 4.1491552e-05\n",
      " 1.4468086e-08 1.2063655e-13 7.3212885e-07 3.9546929e-08 9.3688541e-08]\n",
      "topv\n",
      "[-0.04487514]\n",
      "topi\n",
      "[61]\n",
      "output_lang.index2word[topi.item()]\n",
      "sind\n",
      "decoder_input\n",
      "61\n",
      "decoder_output\n",
      "[-11.770972  -13.121729  -13.298128  -13.181514  -10.697824  -10.49027\n",
      "  -9.83769   -12.795355  -13.568445  -13.5982485]\n",
      "decoder_hidden\n",
      "[-0.3788132  -0.01879534  0.8818981  -0.8488474  -0.94774646  0.9979367\n",
      "  0.9233385   0.98115396 -0.1623612   0.40949142]\n",
      "decoder_attention\n",
      "[1.2336430e-07 5.2143395e-10 2.7782749e-08 8.2885104e-05 9.9991691e-01\n",
      " 5.8884071e-09 2.0021851e-12 7.4727069e-09 2.0569621e-08 4.1810768e-09]\n",
      "decoder_attentions[di]\n",
      "[1.2336430e-07 5.2143395e-10 2.7782749e-08 8.2885104e-05 9.9991691e-01\n",
      " 5.8884071e-09 2.0021851e-12 7.4727069e-09 2.0569621e-08 4.1810768e-09]\n",
      "topv\n",
      "[-0.62694645]\n",
      "topi\n",
      "[757]\n",
      "output_lang.index2word[topi.item()]\n",
      "von\n",
      "decoder_input\n",
      "757\n",
      "decoder_output\n",
      "[-10.956612  -7.771579 -11.246213 -14.095242  -9.122897 -10.102344\n",
      "  -4.276789 -10.358217 -12.24471  -11.437994]\n",
      "decoder_hidden\n",
      "[-0.961184   -0.04100734 -0.7031456   0.99411184 -0.9477361   0.99999833\n",
      "  0.9233384   0.99662733 -0.1623705   0.41387385]\n",
      "decoder_attention\n",
      "[2.24735995e-05 1.47861729e-05 5.31254955e-06 1.20103705e-05\n",
      " 9.99737322e-01 8.10623969e-05 3.95009803e-10 1.54813890e-07\n",
      " 1.25235834e-04 1.71406589e-06]\n",
      "decoder_attentions[di]\n",
      "[2.24735995e-05 1.47861729e-05 5.31254955e-06 1.20103705e-05\n",
      " 9.99737322e-01 8.10623969e-05 3.95009803e-10 1.54813890e-07\n",
      " 1.25235834e-04 1.71406589e-06]\n",
      "topv\n",
      "[-0.88498974]\n",
      "topi\n",
      "[50]\n",
      "output_lang.index2word[topi.item()]\n",
      "der\n",
      "decoder_input\n",
      "50\n",
      "decoder_output\n",
      "[-10.365225   -5.773586   -8.280958   -8.445091   -8.613877  -10.314883\n",
      "  -3.1529856 -10.994307  -11.634351  -11.362694 ]\n",
      "decoder_hidden\n",
      "[-0.9511063  -0.9835668   0.937365   -0.9866204  -0.94535744  0.5145736\n",
      "  0.92335755  0.9563331  -0.16361082  0.58999157]\n",
      "decoder_attention\n",
      "[1.01125984e-07 2.43035061e-07 3.33740893e-08 8.97766661e-09\n",
      " 1.67743176e-15 9.88340735e-01 1.16588343e-02 3.49690090e-08\n",
      " 4.82938745e-10 3.62532226e-08]\n",
      "decoder_attentions[di]\n",
      "[1.01125984e-07 2.43035061e-07 3.33740893e-08 8.97766661e-09\n",
      " 1.67743176e-15 9.88340735e-01 1.16588343e-02 3.49690090e-08\n",
      " 4.82938745e-10 3.62532226e-08]\n",
      "topv\n",
      "[-2.3024526]\n",
      "topi\n",
      "[44]\n",
      "output_lang.index2word[topi.item()]\n",
      "hause\n",
      "decoder_input\n",
      "44\n",
      "decoder_output\n",
      "[-12.116878   -2.5094786 -12.237497   -8.012741  -11.103927  -11.851276\n",
      "  -0.559145  -12.975771   -9.9095125 -12.826527 ]\n",
      "decoder_hidden\n",
      "[-0.94927204  0.8608397  -0.29184312 -0.9919845  -0.9427862  -0.99457604\n",
      "  0.92324215  0.9812933  -0.17719233  0.6157591 ]\n",
      "decoder_attention\n",
      "[7.7191032e-08 5.5900070e-08 6.1943872e-08 2.4820901e-07 3.2818025e-13\n",
      " 1.6789597e-11 9.9999917e-01 2.0877327e-07 2.6084354e-08 1.7350666e-07]\n",
      "decoder_attentions[di]\n",
      "[7.7191032e-08 5.5900070e-08 6.1943872e-08 2.4820901e-07 3.2818025e-13\n",
      " 1.6789597e-11 9.9999917e-01 2.0877327e-07 2.6084354e-08 1.7350666e-07]\n",
      "topv\n",
      "[-0.559145]\n",
      "topi\n",
      "[6]\n",
      "output_lang.index2word[topi.item()]\n",
      ".\n",
      "decoder_input\n",
      "6\n",
      "decoder_output\n",
      "[-15.386283    -0.06625557 -15.887783   -10.749136   -15.927086\n",
      " -13.884332    -2.915082   -14.374357   -13.094805   -15.755838  ]\n",
      "decoder_hidden\n",
      "[-0.960438    0.9494064  -0.8088561  -0.99634755 -0.90242875 -0.9998318\n",
      "  0.9134046   0.98435664 -0.16470866  0.63459677]\n",
      "decoder_attention\n",
      "[4.12751874e-03 1.09705245e-04 3.16721591e-04 7.93371692e-06\n",
      " 1.11883374e-08 6.03463102e-09 7.12241173e-01 3.40100983e-03\n",
      " 6.17527440e-02 2.18043178e-01]\n",
      "decoder_attentions[di]\n",
      "[4.12751874e-03 1.09705245e-04 3.16721591e-04 7.93371692e-06\n",
      " 1.11883374e-08 6.03463102e-09 7.12241173e-01 3.40100983e-03\n",
      " 6.17527440e-02 2.18043178e-01]\n",
      "topv\n",
      "[-0.06625557]\n",
      "topi\n",
      "[1]\n",
      "decoded_words\n",
      "['wir', 'sind', 'von', 'der', 'hause', '.', '<EOS>']\n",
      "input_tensor\n",
      "[  48   49   17 1795  390    4    1]\n",
      "encoder_hidden\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "encoder_outputs\n",
      "[-0.24151272  0.07389677  0.14187232 -0.13187045 -0.21201348  0.7023839\n",
      " -0.01192594 -0.8879513   0.86634135 -0.9917318 ]\n",
      "input_tensor[ei]\n",
      "[48]\n",
      "encoder_hidden\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "encoder_output\n",
      "[-0.24151272  0.07389677  0.14187232 -0.13187045 -0.21201348  0.7023839\n",
      " -0.01192594 -0.8879513   0.86634135 -0.9917318 ]\n",
      "encoder_hidden\n",
      "[-0.24151272  0.07389677  0.14187232 -0.13187045 -0.21201348  0.7023839\n",
      " -0.01192594 -0.8879513   0.86634135 -0.9917318 ]\n",
      "encoder_outputs[ei]\n",
      "[-0.24151272  0.07389677  0.14187232 -0.13187045 -0.21201348  0.7023839\n",
      " -0.01192594 -0.8879513   0.86634135 -0.9917318 ]\n",
      "input_tensor[ei]\n",
      "[49]\n",
      "encoder_hidden\n",
      "[-0.24151272  0.07389677  0.14187232 -0.13187045 -0.21201348  0.7023839\n",
      " -0.01192594 -0.8879513   0.86634135 -0.9917318 ]\n",
      "encoder_output\n",
      "[-0.94854337  0.78109705 -0.7576846   0.15421624 -0.87620497  0.5647007\n",
      "  0.8045426  -0.8869806   0.9868675   0.82549334]\n",
      "encoder_hidden\n",
      "[-0.94854337  0.78109705 -0.7576846   0.15421624 -0.87620497  0.5647007\n",
      "  0.8045426  -0.8869806   0.9868675   0.82549334]\n",
      "encoder_outputs[ei]\n",
      "[-0.94854337  0.78109705 -0.7576846   0.15421624 -0.87620497  0.5647007\n",
      "  0.8045426  -0.8869806   0.9868675   0.82549334]\n",
      "input_tensor[ei]\n",
      "[17]\n",
      "encoder_hidden\n",
      "[-0.94854337  0.78109705 -0.7576846   0.15421624 -0.87620497  0.5647007\n",
      "  0.8045426  -0.8869806   0.9868675   0.82549334]\n",
      "encoder_output\n",
      "[ 0.9009656   0.9391912   0.9066125  -0.29741564  0.7479242   0.57109225\n",
      " -0.97016263 -0.904247    0.99204326 -0.28691536]\n",
      "encoder_hidden\n",
      "[ 0.9009656   0.9391912   0.9066125  -0.29741564  0.7479242   0.57109225\n",
      " -0.97016263 -0.904247    0.99204326 -0.28691536]\n",
      "encoder_outputs[ei]\n",
      "[ 0.9009656   0.9391912   0.9066125  -0.29741564  0.7479242   0.57109225\n",
      " -0.97016263 -0.904247    0.99204326 -0.28691536]\n",
      "input_tensor[ei]\n",
      "[1795]\n",
      "encoder_hidden\n",
      "[ 0.9009656   0.9391912   0.9066125  -0.29741564  0.7479242   0.57109225\n",
      " -0.97016263 -0.904247    0.99204326 -0.28691536]\n",
      "encoder_output\n",
      "[-0.27153647  0.92097855 -0.17025852  0.36061412 -0.29121855  0.29531622\n",
      "  0.33090988 -0.76399016  0.47039676  0.46157056]\n",
      "encoder_hidden\n",
      "[-0.27153647  0.92097855 -0.17025852  0.36061412 -0.29121855  0.29531622\n",
      "  0.33090988 -0.76399016  0.47039676  0.46157056]\n",
      "encoder_outputs[ei]\n",
      "[-0.27153647  0.92097855 -0.17025852  0.36061412 -0.29121855  0.29531622\n",
      "  0.33090988 -0.76399016  0.47039676  0.46157056]\n",
      "input_tensor[ei]\n",
      "[390]\n",
      "encoder_hidden\n",
      "[-0.27153647  0.92097855 -0.17025852  0.36061412 -0.29121855  0.29531622\n",
      "  0.33090988 -0.76399016  0.47039676  0.46157056]\n",
      "encoder_output\n",
      "[-0.8852597   0.7096524  -0.04670846 -0.90943456  0.7803053   0.50633526\n",
      " -0.74734527 -0.33269146  0.436742    0.976106  ]\n",
      "encoder_hidden\n",
      "[-0.8852597   0.7096524  -0.04670846 -0.90943456  0.7803053   0.50633526\n",
      " -0.74734527 -0.33269146  0.436742    0.976106  ]\n",
      "encoder_outputs[ei]\n",
      "[-0.8852597   0.7096524  -0.04670846 -0.90943456  0.7803053   0.50633526\n",
      " -0.74734527 -0.33269146  0.436742    0.976106  ]\n",
      "input_tensor[ei]\n",
      "[4]\n",
      "encoder_hidden\n",
      "[-0.8852597   0.7096524  -0.04670846 -0.90943456  0.7803053   0.50633526\n",
      " -0.74734527 -0.33269146  0.436742    0.976106  ]\n",
      "encoder_output\n",
      "[-0.88342625 -0.02325445 -0.02511379 -0.9007022   0.77323174  0.9387343\n",
      " -0.7388871  -0.04179245  0.43775427  0.97360134]\n",
      "encoder_hidden\n",
      "[-0.88342625 -0.02325445 -0.02511379 -0.9007022   0.77323174  0.9387343\n",
      " -0.7388871  -0.04179245  0.43775427  0.97360134]\n",
      "encoder_outputs[ei]\n",
      "[-0.88342625 -0.02325445 -0.02511379 -0.9007022   0.77323174  0.9387343\n",
      " -0.7388871  -0.04179245  0.43775427  0.97360134]\n",
      "input_tensor[ei]\n",
      "[1]\n",
      "encoder_hidden\n",
      "[-0.88342625 -0.02325445 -0.02511379 -0.9007022   0.77323174  0.9387343\n",
      " -0.7388871  -0.04179245  0.43775427  0.97360134]\n",
      "encoder_output\n",
      "[-0.87973475 -0.35116196  0.9680375  -0.8979748   0.7691936   0.71632075\n",
      " -0.7383114   0.76621556  0.43759006  0.97250134]\n",
      "encoder_hidden\n",
      "[-0.87973475 -0.35116196  0.9680375  -0.8979748   0.7691936   0.71632075\n",
      " -0.7383114   0.76621556  0.43759006  0.97250134]\n",
      "encoder_outputs[ei]\n",
      "[-0.87973475 -0.35116196  0.9680375  -0.8979748   0.7691936   0.71632075\n",
      " -0.7383114   0.76621556  0.43759006  0.97250134]\n",
      "decoder_input\n",
      "[0]\n",
      "decoder_hidden\n",
      "[-0.87973475 -0.35116196  0.9680375  -0.8979748   0.7691936   0.71632075\n",
      " -0.7383114   0.76621556  0.43759006  0.97250134]\n",
      "decoder_output\n",
      "[-16.199562 -14.529448  -8.982674 -11.490646 -15.15174  -15.239886\n",
      " -15.39623  -16.688158 -14.464813 -15.763046]\n",
      "decoder_hidden\n",
      "[-0.9536602  -0.36582088  0.9667628  -0.89865786  0.769192    0.9999991\n",
      " -0.73831105  0.99982136  0.43758792  0.9725001 ]\n",
      "decoder_attention\n",
      "[3.4352961e-06 9.9995148e-01 9.3832468e-06 3.4338336e-05 3.5925176e-08\n",
      " 8.6872332e-12 1.3300064e-08 1.1196510e-06 9.9987162e-08 1.1360953e-07]\n",
      "decoder_attentions[di]\n",
      "[3.4352961e-06 9.9995148e-01 9.3832468e-06 3.4338336e-05 3.5925176e-08\n",
      " 8.6872332e-12 1.3300064e-08 1.1196510e-06 9.9987162e-08 1.1360953e-07]\n",
      "topv\n",
      "[-0.00927544]\n",
      "topi\n",
      "[64]\n",
      "output_lang.index2word[topi.item()]\n",
      "er\n",
      "decoder_input\n",
      "64\n",
      "decoder_output\n",
      "[-15.298885 -17.960388 -23.916216 -13.287323 -14.542931 -16.970531\n",
      " -18.600477 -25.419605 -13.077519 -23.644924]\n",
      "decoder_hidden\n",
      "[-0.9723776   0.99716425  0.79273355 -0.8990912   0.7692128  -0.02406643\n",
      " -0.7382946  -0.9892949   0.4340405   0.97249836]\n",
      "decoder_attention\n",
      "[7.1212924e-07 2.5896386e-05 1.8250599e-06 9.9994469e-01 2.5742049e-05\n",
      " 3.8992773e-13 3.6637769e-07 2.7811529e-07 4.1690427e-08 4.3572209e-07]\n",
      "decoder_attentions[di]\n",
      "[7.1212924e-07 2.5896386e-05 1.8250599e-06 9.9994469e-01 2.5742049e-05\n",
      " 3.8992773e-13 3.6637769e-07 2.7811529e-07 4.1690427e-08 4.3572209e-07]\n",
      "topv\n",
      "[-0.02569485]\n",
      "topi\n",
      "[65]\n",
      "output_lang.index2word[topi.item()]\n",
      "ist\n",
      "decoder_input\n",
      "65\n",
      "decoder_output\n",
      "[-10.513758 -12.081112 -12.878042 -11.794504 -11.91815  -12.157381\n",
      " -10.24891  -15.128181 -15.462214 -15.949846]\n",
      "decoder_hidden\n",
      "[-0.97331434  0.940083    0.16518348 -0.8992356   0.7692223  -0.92132336\n",
      " -0.7380061   0.99649864  0.43380296  0.972531  ]\n",
      "decoder_attention\n",
      "[4.2644559e-09 4.8348010e-11 1.4523367e-09 1.1060265e-09 9.9999988e-01\n",
      " 2.8389838e-10 9.3186821e-15 9.1431822e-08 2.9516549e-09 1.3734563e-09]\n",
      "decoder_attentions[di]\n",
      "[4.2644559e-09 4.8348010e-11 1.4523367e-09 1.1060265e-09 9.9999988e-01\n",
      " 2.8389838e-10 9.3186821e-15 9.1431822e-08 2.9516549e-09 1.3734563e-09]\n",
      "topv\n",
      "[-1.1376162]\n",
      "topi\n",
      "[542]\n",
      "output_lang.index2word[topi.item()]\n",
      "student\n",
      "decoder_input\n",
      "542\n",
      "decoder_output\n",
      "[-10.759559   -6.356581  -13.176732  -11.925447   -9.40015    -9.899162\n",
      "  -2.7080078 -15.577359  -16.26158   -16.714172 ]\n",
      "decoder_hidden\n",
      "[-0.98805124  0.30840123 -0.5962585  -0.90154195  0.7692392  -0.11358455\n",
      " -0.7378477   0.38790962  0.43368953  0.9725808 ]\n",
      "decoder_attention\n",
      "[9.70094407e-05 2.24898267e-05 3.00201151e-04 8.40625871e-05\n",
      " 9.97763634e-01 1.70981605e-03 1.39100734e-07 7.93151321e-06\n",
      " 8.46901457e-07 1.38378855e-05]\n",
      "decoder_attentions[di]\n",
      "[9.70094407e-05 2.24898267e-05 3.00201151e-04 8.40625871e-05\n",
      " 9.97763634e-01 1.70981605e-03 1.39100734e-07 7.93151321e-06\n",
      " 8.46901457e-07 1.38378855e-05]\n",
      "topv\n",
      "[-2.2625942]\n",
      "topi\n",
      "[542]\n",
      "output_lang.index2word[topi.item()]\n",
      "student\n",
      "decoder_input\n",
      "542\n",
      "decoder_output\n",
      "[-11.247108    -4.9121027  -15.47988    -12.53805    -10.838071\n",
      " -10.989887    -0.71003246 -17.19648    -16.175348   -17.95455   ]\n",
      "decoder_hidden\n",
      "[-0.9918356   0.47875518 -0.6575714  -0.9014619   0.76966095 -0.9989616\n",
      " -0.73768324 -0.6399544   0.43018824  0.97325784]\n",
      "decoder_attention\n",
      "[4.5002881e-02 1.3527881e-03 3.6992993e-02 3.4458278e-04 5.1343006e-05\n",
      " 5.8223712e-01 2.5476921e-01 4.7065750e-02 7.1469657e-03 2.5036328e-02]\n",
      "decoder_attentions[di]\n",
      "[4.5002881e-02 1.3527881e-03 3.6992993e-02 3.4458278e-04 5.1343006e-05\n",
      " 5.8223712e-01 2.5476921e-01 4.7065750e-02 7.1469657e-03 2.5036328e-02]\n",
      "topv\n",
      "[-0.71003246]\n",
      "topi\n",
      "[6]\n",
      "output_lang.index2word[topi.item()]\n",
      ".\n",
      "decoder_input\n",
      "6\n",
      "decoder_output\n",
      "[-13.429673    -0.05492783 -13.786442   -11.954079   -13.455699\n",
      " -10.854346    -3.729024   -15.017083   -16.59471    -17.183151  ]\n",
      "decoder_hidden\n",
      "[-0.9913428   0.5382     -0.7959736  -0.9338274   0.77386475 -0.9999359\n",
      " -0.7113439  -0.23984742  0.29843065  0.96342665]\n",
      "decoder_attention\n",
      "[4.8252802e-02 1.2450899e-03 1.3669814e-02 6.5882712e-05 1.5917949e-06\n",
      " 6.2873736e-03 2.7696270e-01 1.3529754e-02 2.0690931e-02 6.1929411e-01]\n",
      "decoder_attentions[di]\n",
      "[4.8252802e-02 1.2450899e-03 1.3669814e-02 6.5882712e-05 1.5917949e-06\n",
      " 6.2873736e-03 2.7696270e-01 1.3529754e-02 2.0690931e-02 6.1929411e-01]\n",
      "topv\n",
      "[-0.05492783]\n",
      "topi\n",
      "[1]\n",
      "decoded_words\n",
      "['er', 'ist', 'student', 'student', '.', '<EOS>']\n",
      "input_tensor\n",
      "[   2   55 1591  152 1610    1]\n",
      "encoder_hidden\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "encoder_outputs\n",
      "[-0.10922617  0.6067832   0.6439681   0.10918707  0.15006319  0.60468507\n",
      " -0.83865154 -0.8165876  -0.08856022 -0.17544824]\n",
      "input_tensor[ei]\n",
      "[2]\n",
      "encoder_hidden\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "encoder_output\n",
      "[-0.10922617  0.6067832   0.6439681   0.10918707  0.15006319  0.60468507\n",
      " -0.83865154 -0.8165876  -0.08856022 -0.17544824]\n",
      "encoder_hidden\n",
      "[-0.10922617  0.6067832   0.6439681   0.10918707  0.15006319  0.60468507\n",
      " -0.83865154 -0.8165876  -0.08856022 -0.17544824]\n",
      "encoder_outputs[ei]\n",
      "[-0.10922617  0.6067832   0.6439681   0.10918707  0.15006319  0.60468507\n",
      " -0.83865154 -0.8165876  -0.08856022 -0.17544824]\n",
      "input_tensor[ei]\n",
      "[55]\n",
      "encoder_hidden\n",
      "[-0.10922617  0.6067832   0.6439681   0.10918707  0.15006319  0.60468507\n",
      " -0.83865154 -0.8165876  -0.08856022 -0.17544824]\n",
      "encoder_output\n",
      "[-0.1475069   0.60773844  0.40916204  0.18194592 -0.98431695 -0.19255847\n",
      " -0.83514357 -0.8144109  -0.1381967   0.30102903]\n",
      "encoder_hidden\n",
      "[-0.1475069   0.60773844  0.40916204  0.18194592 -0.98431695 -0.19255847\n",
      " -0.83514357 -0.8144109  -0.1381967   0.30102903]\n",
      "encoder_outputs[ei]\n",
      "[-0.1475069   0.60773844  0.40916204  0.18194592 -0.98431695 -0.19255847\n",
      " -0.83514357 -0.8144109  -0.1381967   0.30102903]\n",
      "input_tensor[ei]\n",
      "[1591]\n",
      "encoder_hidden\n",
      "[-0.1475069   0.60773844  0.40916204  0.18194592 -0.98431695 -0.19255847\n",
      " -0.83514357 -0.8144109  -0.1381967   0.30102903]\n",
      "encoder_output\n",
      "[-0.6327473   0.92737085  0.45732537  0.34349775  0.99784    -0.5396167\n",
      " -0.62375724 -0.91728514  0.8807485  -0.49037644]\n",
      "encoder_hidden\n",
      "[-0.6327473   0.92737085  0.45732537  0.34349775  0.99784    -0.5396167\n",
      " -0.62375724 -0.91728514  0.8807485  -0.49037644]\n",
      "encoder_outputs[ei]\n",
      "[-0.6327473   0.92737085  0.45732537  0.34349775  0.99784    -0.5396167\n",
      " -0.62375724 -0.91728514  0.8807485  -0.49037644]\n",
      "input_tensor[ei]\n",
      "[152]\n",
      "encoder_hidden\n",
      "[-0.6327473   0.92737085  0.45732537  0.34349775  0.99784    -0.5396167\n",
      " -0.62375724 -0.91728514  0.8807485  -0.49037644]\n",
      "encoder_output\n",
      "[ 0.66104776  0.951222    0.34116942  0.2991881   0.94849586 -0.848196\n",
      " -0.9978037  -0.0208419   0.89620346  0.97644717]\n",
      "encoder_hidden\n",
      "[ 0.66104776  0.951222    0.34116942  0.2991881   0.94849586 -0.848196\n",
      " -0.9978037  -0.0208419   0.89620346  0.97644717]\n",
      "encoder_outputs[ei]\n",
      "[ 0.66104776  0.951222    0.34116942  0.2991881   0.94849586 -0.848196\n",
      " -0.9978037  -0.0208419   0.89620346  0.97644717]\n",
      "input_tensor[ei]\n",
      "[1610]\n",
      "encoder_hidden\n",
      "[ 0.66104776  0.951222    0.34116942  0.2991881   0.94849586 -0.848196\n",
      " -0.9978037  -0.0208419   0.89620346  0.97644717]\n",
      "encoder_output\n",
      "[ 0.7886971   0.6726251  -0.04997355  0.40447426  0.93160343  0.3541585\n",
      " -0.99777126  0.335207    0.89776725 -0.5271658 ]\n",
      "encoder_hidden\n",
      "[ 0.7886971   0.6726251  -0.04997355  0.40447426  0.93160343  0.3541585\n",
      " -0.99777126  0.335207    0.89776725 -0.5271658 ]\n",
      "encoder_outputs[ei]\n",
      "[ 0.7886971   0.6726251  -0.04997355  0.40447426  0.93160343  0.3541585\n",
      " -0.99777126  0.335207    0.89776725 -0.5271658 ]\n",
      "input_tensor[ei]\n",
      "[1]\n",
      "encoder_hidden\n",
      "[ 0.7886971   0.6726251  -0.04997355  0.40447426  0.93160343  0.3541585\n",
      " -0.99777126  0.335207    0.89776725 -0.5271658 ]\n",
      "encoder_output\n",
      "[ 0.77328575  0.23417109  0.9243926   0.3933707   0.92970246 -0.40380538\n",
      " -0.9977601   0.83227825  0.89770657 -0.52796865]\n",
      "encoder_hidden\n",
      "[ 0.77328575  0.23417109  0.9243926   0.3933707   0.92970246 -0.40380538\n",
      " -0.9977601   0.83227825  0.89770657 -0.52796865]\n",
      "encoder_outputs[ei]\n",
      "[ 0.77328575  0.23417109  0.9243926   0.3933707   0.92970246 -0.40380538\n",
      " -0.9977601   0.83227825  0.89770657 -0.52796865]\n",
      "decoder_input\n",
      "[0]\n",
      "decoder_hidden\n",
      "[ 0.77328575  0.23417109  0.9243926   0.3933707   0.92970246 -0.40380538\n",
      " -0.9977601   0.83227825  0.89770657 -0.52796865]\n",
      "decoder_output\n",
      "[-14.232163   -13.312216    -0.02991772 -15.034936   -14.893482\n",
      " -12.036127   -14.78888     -5.9902763  -12.774064   -12.661588  ]\n",
      "decoder_hidden\n",
      "[ 0.75919765  0.05968118  0.8922026   0.3830387   0.9296628   0.9996317\n",
      " -0.99772066  0.9947932   0.8964758  -0.5279496 ]\n",
      "decoder_attention\n",
      "[4.8541738e-06 9.9993360e-01 2.1311263e-05 3.0872092e-05 8.5129113e-09\n",
      " 1.3301570e-09 3.9242313e-08 8.5233878e-06 5.9546056e-07 1.3411970e-07]\n",
      "decoder_attentions[di]\n",
      "[4.8541738e-06 9.9993360e-01 2.1311263e-05 3.0872092e-05 8.5129113e-09\n",
      " 1.3301570e-09 3.9242313e-08 8.5233878e-06 5.9546056e-07 1.3411970e-07]\n",
      "topv\n",
      "[-0.02991772]\n",
      "topi\n",
      "[2]\n",
      "output_lang.index2word[topi.item()]\n",
      "ich\n",
      "decoder_input\n",
      "2\n",
      "decoder_output\n",
      "[-10.042462 -12.002014 -11.13488   -5.512292 -10.040148  -7.820183\n",
      " -13.825052  -7.402439  -8.502974 -10.679655]\n",
      "decoder_hidden\n",
      "[ 0.5026973   0.9557671  -0.7093077   0.301747    0.9296566   0.8119263\n",
      " -0.9962692   0.99593145  0.8955942  -0.526474  ]\n",
      "decoder_attention\n",
      "[7.1193301e-07 1.7992411e-04 6.7814185e-06 9.9932408e-01 4.5731835e-07\n",
      " 4.8057959e-04 8.4696812e-11 4.9577829e-06 2.2881121e-08 2.4686021e-06]\n",
      "decoder_attentions[di]\n",
      "[7.1193301e-07 1.7992411e-04 6.7814185e-06 9.9932408e-01 4.5731835e-07\n",
      " 4.8057959e-04 8.4696812e-11 4.9577829e-06 2.2881121e-08 2.4686021e-06]\n",
      "topv\n",
      "[-2.9787412]\n",
      "topi\n",
      "[1352]\n",
      "output_lang.index2word[topi.item()]\n",
      "tue\n",
      "decoder_input\n",
      "1352\n",
      "decoder_output\n",
      "[-13.198298  -11.69492    -6.269575  -13.832989  -14.102698   -9.511745\n",
      " -11.674685   -4.6139326 -13.758654   -9.458519 ]\n",
      "decoder_hidden\n",
      "[ 0.34082663  0.8893185  -0.9670988   0.43627936  0.9297213   0.8310445\n",
      " -0.9899491   0.9992821   0.8774978  -0.5015434 ]\n",
      "decoder_attention\n",
      "[1.2787340e-04 1.0223298e-02 2.6392785e-04 2.6738324e-04 9.8145640e-01\n",
      " 7.5392271e-03 2.4009234e-06 4.2784090e-05 3.8455644e-05 3.8062542e-05]\n",
      "decoder_attentions[di]\n",
      "[1.2787340e-04 1.0223298e-02 2.6392785e-04 2.6738324e-04 9.8145640e-01\n",
      " 7.5392271e-03 2.4009234e-06 4.2784090e-05 3.8455644e-05 3.8062542e-05]\n",
      "topv\n",
      "[-0.62931824]\n",
      "topi\n",
      "[47]\n",
      "output_lang.index2word[topi.item()]\n",
      "mich\n",
      "decoder_input\n",
      "47\n",
      "decoder_output\n",
      "[-10.854974   -5.3213735  -8.458312  -13.025513  -10.159166   -8.086256\n",
      "  -4.2722845  -5.9738216 -11.352211   -8.18732  ]\n",
      "decoder_hidden\n",
      "[ 0.95874697  0.9985635  -0.9012601  -0.96622145  0.929752   -0.31330502\n",
      " -0.9895933   0.9994866   0.83835244 -0.45258272]\n",
      "decoder_attention\n",
      "[9.6976777e-08 5.5669112e-08 1.1955133e-07 3.5877953e-08 8.9257068e-05\n",
      " 9.9991024e-01 8.7300576e-09 7.1085722e-08 9.0803219e-08 3.6320472e-08]\n",
      "decoder_attentions[di]\n",
      "[9.6976777e-08 5.5669112e-08 1.1955133e-07 3.5877953e-08 8.9257068e-05\n",
      " 9.9991024e-01 8.7300576e-09 7.1085722e-08 9.0803219e-08 3.6320472e-08]\n",
      "topv\n",
      "[-1.1837206]\n",
      "topi\n",
      "[922]\n",
      "output_lang.index2word[topi.item()]\n",
      "an\n",
      "decoder_input\n",
      "922\n",
      "decoder_output\n",
      "[-11.907079   -2.5793953  -6.248797  -12.837965  -11.010009   -8.826761\n",
      "  -1.0860758  -5.0615487 -11.494164   -6.100775 ]\n",
      "decoder_hidden\n",
      "[ 0.96718794 -0.39732432 -0.8889414  -0.9951527   0.9319459  -0.6695049\n",
      " -0.9807351   0.9997633   0.7949078  -0.29661697]\n",
      "decoder_attention\n",
      "[4.8611139e-07 5.1260955e-09 1.2070349e-07 9.8053174e-09 1.9092367e-06\n",
      " 9.9998188e-01 1.9696451e-08 1.8392502e-07 6.5111919e-08 1.5295724e-05]\n",
      "decoder_attentions[di]\n",
      "[4.8611139e-07 5.1260955e-09 1.2070349e-07 9.8053174e-09 1.9092367e-06\n",
      " 9.9998188e-01 1.9696451e-08 1.8392502e-07 6.5111919e-08 1.5295724e-05]\n",
      "topv\n",
      "[-1.0860758]\n",
      "topi\n",
      "[6]\n",
      "output_lang.index2word[topi.item()]\n",
      ".\n",
      "decoder_input\n",
      "6\n",
      "decoder_output\n",
      "[-12.369797    -0.32594967  -7.3930993  -11.668742   -11.73155\n",
      " -10.047049    -2.4610825   -6.100282   -12.004868    -8.392854  ]\n",
      "decoder_hidden\n",
      "[ 0.87884146  0.49914163 -0.83693695 -0.99850994  0.9259256  -0.7583477\n",
      " -0.9630827   0.9997685   0.7548399  -0.0716483 ]\n",
      "decoder_attention\n",
      "[1.87099897e-04 2.12886502e-04 2.73116912e-05 1.62736441e-07\n",
      " 1.09811424e-10 5.78702688e-01 4.18737143e-01 4.80883136e-05\n",
      " 1.55009584e-05 2.06909911e-03]\n",
      "decoder_attentions[di]\n",
      "[1.87099897e-04 2.12886502e-04 2.73116912e-05 1.62736441e-07\n",
      " 1.09811424e-10 5.78702688e-01 4.18737143e-01 4.80883136e-05\n",
      " 1.55009584e-05 2.06909911e-03]\n",
      "topv\n",
      "[-0.32594967]\n",
      "topi\n",
      "[1]\n",
      "decoded_words\n",
      "['ich', 'tue', 'mich', 'an', '.', '<EOS>']\n",
      "input_tensor\n",
      "[ 86  47 123 274  13   1]\n",
      "encoder_hidden\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "encoder_outputs\n",
      "[-1.7593610e-01 -2.1630865e-01  9.4348907e-01  7.8240514e-02\n",
      " -3.7888288e-02  9.8887897e-01 -2.3685753e-02 -4.6230555e-03\n",
      " -1.6540289e-05 -2.6783466e-02]\n",
      "input_tensor[ei]\n",
      "[86]\n",
      "encoder_hidden\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "encoder_output\n",
      "[-1.7593610e-01 -2.1630865e-01  9.4348907e-01  7.8240514e-02\n",
      " -3.7888288e-02  9.8887897e-01 -2.3685753e-02 -4.6230555e-03\n",
      " -1.6540289e-05 -2.6783466e-02]\n",
      "encoder_hidden\n",
      "[-1.7593610e-01 -2.1630865e-01  9.4348907e-01  7.8240514e-02\n",
      " -3.7888288e-02  9.8887897e-01 -2.3685753e-02 -4.6230555e-03\n",
      " -1.6540289e-05 -2.6783466e-02]\n",
      "encoder_outputs[ei]\n",
      "[-1.7593610e-01 -2.1630865e-01  9.4348907e-01  7.8240514e-02\n",
      " -3.7888288e-02  9.8887897e-01 -2.3685753e-02 -4.6230555e-03\n",
      " -1.6540289e-05 -2.6783466e-02]\n",
      "input_tensor[ei]\n",
      "[47]\n",
      "encoder_hidden\n",
      "[-1.7593610e-01 -2.1630865e-01  9.4348907e-01  7.8240514e-02\n",
      " -3.7888288e-02  9.8887897e-01 -2.3685753e-02 -4.6230555e-03\n",
      " -1.6540289e-05 -2.6783466e-02]\n",
      "encoder_output\n",
      "[-0.7542075   0.88391465  0.8930207   0.2633628   0.90376514 -0.8088015\n",
      "  0.05146366  0.00679323 -0.00627929 -0.07966429]\n",
      "encoder_hidden\n",
      "[-0.7542075   0.88391465  0.8930207   0.2633628   0.90376514 -0.8088015\n",
      "  0.05146366  0.00679323 -0.00627929 -0.07966429]\n",
      "encoder_outputs[ei]\n",
      "[-0.7542075   0.88391465  0.8930207   0.2633628   0.90376514 -0.8088015\n",
      "  0.05146366  0.00679323 -0.00627929 -0.07966429]\n",
      "input_tensor[ei]\n",
      "[123]\n",
      "encoder_hidden\n",
      "[-0.7542075   0.88391465  0.8930207   0.2633628   0.90376514 -0.8088015\n",
      "  0.05146366  0.00679323 -0.00627929 -0.07966429]\n",
      "encoder_output\n",
      "[0.38225704 0.9746376  0.17046891 0.9525153  0.9955943  0.07598352\n",
      " 0.9992435  0.7442045  0.9998205  0.8893903 ]\n",
      "encoder_hidden\n",
      "[0.38225704 0.9746376  0.17046891 0.9525153  0.9955943  0.07598352\n",
      " 0.9992435  0.7442045  0.9998205  0.8893903 ]\n",
      "encoder_outputs[ei]\n",
      "[0.38225704 0.9746376  0.17046891 0.9525153  0.9955943  0.07598352\n",
      " 0.9992435  0.7442045  0.9998205  0.8893903 ]\n",
      "input_tensor[ei]\n",
      "[274]\n",
      "encoder_hidden\n",
      "[0.38225704 0.9746376  0.17046891 0.9525153  0.9955943  0.07598352\n",
      " 0.9992435  0.7442045  0.9998205  0.8893903 ]\n",
      "encoder_output\n",
      "[-0.81088996  0.5001256   0.37628636  0.94058424 -0.88479483  0.48607546\n",
      "  0.99922454 -0.9435456  -0.69821155  0.8918899 ]\n",
      "encoder_hidden\n",
      "[-0.81088996  0.5001256   0.37628636  0.94058424 -0.88479483  0.48607546\n",
      "  0.99922454 -0.9435456  -0.69821155  0.8918899 ]\n",
      "encoder_outputs[ei]\n",
      "[-0.81088996  0.5001256   0.37628636  0.94058424 -0.88479483  0.48607546\n",
      "  0.99922454 -0.9435456  -0.69821155  0.8918899 ]\n",
      "input_tensor[ei]\n",
      "[13]\n",
      "encoder_hidden\n",
      "[-0.81088996  0.5001256   0.37628636  0.94058424 -0.88479483  0.48607546\n",
      "  0.99922454 -0.9435456  -0.69821155  0.8918899 ]\n",
      "encoder_output\n",
      "[ 0.7124542   0.32229644  0.74224377  0.8038542   0.94710195  0.9604828\n",
      "  0.99502105 -0.6696136   0.9988305   0.88661623]\n",
      "encoder_hidden\n",
      "[ 0.7124542   0.32229644  0.74224377  0.8038542   0.94710195  0.9604828\n",
      "  0.99502105 -0.6696136   0.9988305   0.88661623]\n",
      "encoder_outputs[ei]\n",
      "[ 0.7124542   0.32229644  0.74224377  0.8038542   0.94710195  0.9604828\n",
      "  0.99502105 -0.6696136   0.9988305   0.88661623]\n",
      "input_tensor[ei]\n",
      "[1]\n",
      "encoder_hidden\n",
      "[ 0.7124542   0.32229644  0.74224377  0.8038542   0.94710195  0.9604828\n",
      "  0.99502105 -0.6696136   0.9988305   0.88661623]\n",
      "encoder_output\n",
      "[0.6961001  0.10450292 0.956207   0.7956247  0.94692594 0.5637771\n",
      " 0.99502075 0.14771885 0.9988229  0.8861974 ]\n",
      "encoder_hidden\n",
      "[0.6961001  0.10450292 0.956207   0.7956247  0.94692594 0.5637771\n",
      " 0.99502075 0.14771885 0.9988229  0.8861974 ]\n",
      "encoder_outputs[ei]\n",
      "[0.6961001  0.10450292 0.956207   0.7956247  0.94692594 0.5637771\n",
      " 0.99502075 0.14771885 0.9988229  0.8861974 ]\n",
      "decoder_input\n",
      "[0]\n",
      "decoder_hidden\n",
      "[0.6961001  0.10450292 0.956207   0.7956247  0.94692594 0.5637771\n",
      " 0.99502075 0.14771885 0.9988229  0.8861974 ]\n",
      "decoder_output\n",
      "[-12.271917   -9.362948  -10.415305  -11.38618   -11.090663   -1.7832661\n",
      " -10.785706  -12.593747  -14.49502   -12.260618 ]\n",
      "decoder_hidden\n",
      "[0.19513464 0.09969902 0.9370656  0.7934173  0.9469271  0.99833083\n",
      " 0.9950208  0.9462038  0.9957356  0.8865696 ]\n",
      "decoder_attention\n",
      "[1.3840660e-04 9.9951863e-01 1.2533292e-04 4.2686215e-06 8.1648332e-06\n",
      " 3.4353467e-09 3.1203438e-06 1.7910384e-05 1.7286131e-04 1.1290305e-05]\n",
      "decoder_attentions[di]\n",
      "[1.3840660e-04 9.9951863e-01 1.2533292e-04 4.2686215e-06 8.1648332e-06\n",
      " 3.4353467e-09 3.1203438e-06 1.7910384e-05 1.7286131e-04 1.1290305e-05]\n",
      "topv\n",
      "[-1.0552988]\n",
      "topi\n",
      "[272]\n",
      "output_lang.index2word[topi.item()]\n",
      "das\n",
      "decoder_input\n",
      "272\n",
      "decoder_output\n",
      "[-12.266834   -9.046951  -12.463359   -5.812012   -9.522644   -1.4076567\n",
      "  -9.6687155 -11.738688  -11.7535515 -12.307799 ]\n",
      "decoder_hidden\n",
      "[-0.957894    0.15863949  0.79854524 -0.9498385   0.9469519   0.99956954\n",
      "  0.99492455  0.987762    0.9955812   0.88669425]\n",
      "decoder_attention\n",
      "[1.2636874e-04 7.2850511e-05 5.1194496e-05 9.9932170e-01 3.9813131e-05\n",
      " 6.6071974e-05 2.3548042e-05 6.2836647e-05 9.5003648e-05 1.4057176e-04]\n",
      "decoder_attentions[di]\n",
      "[1.2636874e-04 7.2850511e-05 5.1194496e-05 9.9932170e-01 3.9813131e-05\n",
      " 6.6071974e-05 2.3548042e-05 6.2836647e-05 9.5003648e-05 1.4057176e-04]\n",
      "topv\n",
      "[-0.63879776]\n",
      "topi\n",
      "[61]\n",
      "output_lang.index2word[topi.item()]\n",
      "sind\n",
      "decoder_input\n",
      "61\n",
      "decoder_output\n",
      "[-13.546244   -9.4893     -9.211637   -7.633853   -9.449769   -0.4821577\n",
      "  -8.991272  -10.371539  -13.903199  -12.037276 ]\n",
      "decoder_hidden\n",
      "[-0.9958757   0.15358013  0.75183827  0.31178632  0.9469562   0.99993443\n",
      "  0.9949042   0.99655616  0.9954366   0.8869787 ]\n",
      "decoder_attention\n",
      "[4.9310661e-06 3.5391963e-08 1.9342401e-06 1.3103485e-04 9.9981982e-01\n",
      " 3.9822797e-05 3.7084971e-10 1.3030744e-06 3.6862744e-07 8.2895389e-07]\n",
      "decoder_attentions[di]\n",
      "[4.9310661e-06 3.5391963e-08 1.9342401e-06 1.3103485e-04 9.9981982e-01\n",
      " 3.9822797e-05 3.7084971e-10 1.3030744e-06 3.6862744e-07 8.2895389e-07]\n",
      "topv\n",
      "[-0.4821577]\n",
      "topi\n",
      "[5]\n",
      "output_lang.index2word[topi.item()]\n",
      "alt\n",
      "decoder_input\n",
      "5\n",
      "decoder_output\n",
      "[-13.613436   -6.454407   -7.6200485  -8.741894   -9.288815   -2.632784\n",
      "  -2.9807253 -10.507803  -13.299446  -10.817227 ]\n",
      "decoder_hidden\n",
      "[ 0.9557573   0.04649496 -0.9914549   0.98757374  0.9470111   0.9992465\n",
      "  0.99486476  0.99845123  0.49019152  0.89189076]\n",
      "decoder_attention\n",
      "[2.8547679e-06 4.2972738e-07 3.7943821e-07 6.8086123e-08 2.4208240e-02\n",
      " 9.7576845e-01 2.1373189e-08 5.7225856e-07 1.8604404e-05 4.5151026e-07]\n",
      "decoder_attentions[di]\n",
      "[2.8547679e-06 4.2972738e-07 3.7943821e-07 6.8086123e-08 2.4208240e-02\n",
      " 9.7576845e-01 2.1373189e-08 5.7225856e-07 1.8604404e-05 4.5151026e-07]\n",
      "topv\n",
      "[-0.5546551]\n",
      "topi\n",
      "[169]\n",
      "output_lang.index2word[topi.item()]\n",
      "nicht\n",
      "decoder_input\n",
      "169\n",
      "decoder_output\n",
      "[-13.022045   -3.6384668  -8.060631  -10.895206   -9.218959   -1.4963369\n",
      "  -0.9743166 -13.472703  -11.514124  -11.307767 ]\n",
      "decoder_hidden\n",
      "[ 0.80377716 -0.02635187 -0.5677053   0.88781166  0.9497731   0.99679494\n",
      "  0.9931225   0.9986806   0.2310102   0.8970686 ]\n",
      "decoder_attention\n",
      "[1.12907257e-08 1.24635342e-08 2.19063212e-09 2.27221453e-11\n",
      " 2.44965070e-09 9.99999762e-01 9.12166911e-08 8.10816136e-10\n",
      " 8.61098748e-09 1.09364656e-07]\n",
      "decoder_attentions[di]\n",
      "[1.12907257e-08 1.24635342e-08 2.19063212e-09 2.27221453e-11\n",
      " 2.44965070e-09 9.99999762e-01 9.12166911e-08 8.10816136e-10\n",
      " 8.61098748e-09 1.09364656e-07]\n",
      "topv\n",
      "[-0.9743166]\n",
      "topi\n",
      "[6]\n",
      "output_lang.index2word[topi.item()]\n",
      ".\n",
      "decoder_input\n",
      "6\n",
      "decoder_output\n",
      "[-14.94699     -0.13771439  -9.100914    -9.588987   -12.170481\n",
      "  -3.8994398   -2.612895   -14.854426   -12.874166   -12.933331  ]\n",
      "decoder_hidden\n",
      "[ 0.02595037 -0.21920568 -0.28919747 -0.93833554  0.94784075  0.66076964\n",
      "  0.99209327  0.99873084  0.13499331  0.9091434 ]\n",
      "decoder_attention\n",
      "[2.1231265e-06 6.1984861e-07 3.3708045e-07 1.4940118e-09 8.6934210e-15\n",
      " 1.3950254e-03 9.9858510e-01 2.1450813e-07 4.4538217e-07 1.6116483e-05]\n",
      "decoder_attentions[di]\n",
      "[2.1231265e-06 6.1984861e-07 3.3708045e-07 1.4940118e-09 8.6934210e-15\n",
      " 1.3950254e-03 9.9858510e-01 2.1450813e-07 4.4538217e-07 1.6116483e-05]\n",
      "topv\n",
      "[-0.13771439]\n",
      "topi\n",
      "[1]\n",
      "decoded_words\n",
      "['das', 'sind', 'alt', 'nicht', '.', '<EOS>']\n",
      "input_tensor\n",
      "[   2    3  104  814 1055 2112    4    1]\n",
      "encoder_hidden\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "encoder_outputs\n",
      "[-0.10922617  0.6067832   0.6439681   0.10918707  0.15006319  0.60468507\n",
      " -0.83865154 -0.8165876  -0.08856022 -0.17544824]\n",
      "input_tensor[ei]\n",
      "[2]\n",
      "encoder_hidden\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "encoder_output\n",
      "[-0.10922617  0.6067832   0.6439681   0.10918707  0.15006319  0.60468507\n",
      " -0.83865154 -0.8165876  -0.08856022 -0.17544824]\n",
      "encoder_hidden\n",
      "[-0.10922617  0.6067832   0.6439681   0.10918707  0.15006319  0.60468507\n",
      " -0.83865154 -0.8165876  -0.08856022 -0.17544824]\n",
      "encoder_outputs[ei]\n",
      "[-0.10922617  0.6067832   0.6439681   0.10918707  0.15006319  0.60468507\n",
      " -0.83865154 -0.8165876  -0.08856022 -0.17544824]\n",
      "input_tensor[ei]\n",
      "[3]\n",
      "encoder_hidden\n",
      "[-0.10922617  0.6067832   0.6439681   0.10918707  0.15006319  0.60468507\n",
      " -0.83865154 -0.8165876  -0.08856022 -0.17544824]\n",
      "encoder_output\n",
      "[-0.83710116  0.66214955  0.584383    0.7208886  -0.9831236  -0.8309508\n",
      "  0.68693846  0.53419995 -0.99925417  0.78245384]\n",
      "encoder_hidden\n",
      "[-0.83710116  0.66214955  0.584383    0.7208886  -0.9831236  -0.8309508\n",
      "  0.68693846  0.53419995 -0.99925417  0.78245384]\n",
      "encoder_outputs[ei]\n",
      "[-0.83710116  0.66214955  0.584383    0.7208886  -0.9831236  -0.8309508\n",
      "  0.68693846  0.53419995 -0.99925417  0.78245384]\n",
      "input_tensor[ei]\n",
      "[104]\n",
      "encoder_hidden\n",
      "[-0.83710116  0.66214955  0.584383    0.7208886  -0.9831236  -0.8309508\n",
      "  0.68693846  0.53419995 -0.99925417  0.78245384]\n",
      "encoder_output\n",
      "[ 0.52780247 -0.26336068  0.5967597   0.77204883  0.98304886 -0.9308181\n",
      " -0.5888175  -0.39611197 -0.91029817  0.53893536]\n",
      "encoder_hidden\n",
      "[ 0.52780247 -0.26336068  0.5967597   0.77204883  0.98304886 -0.9308181\n",
      " -0.5888175  -0.39611197 -0.91029817  0.53893536]\n",
      "encoder_outputs[ei]\n",
      "[ 0.52780247 -0.26336068  0.5967597   0.77204883  0.98304886 -0.9308181\n",
      " -0.5888175  -0.39611197 -0.91029817  0.53893536]\n",
      "input_tensor[ei]\n",
      "[814]\n",
      "encoder_hidden\n",
      "[ 0.52780247 -0.26336068  0.5967597   0.77204883  0.98304886 -0.9308181\n",
      " -0.5888175  -0.39611197 -0.91029817  0.53893536]\n",
      "encoder_output\n",
      "[-0.21167088 -0.32540387 -0.10798484 -0.18020281 -0.99599594 -0.18422616\n",
      "  0.99047387  0.84186697 -0.99797875  0.5521182 ]\n",
      "encoder_hidden\n",
      "[-0.21167088 -0.32540387 -0.10798484 -0.18020281 -0.99599594 -0.18422616\n",
      "  0.99047387  0.84186697 -0.99797875  0.5521182 ]\n",
      "encoder_outputs[ei]\n",
      "[-0.21167088 -0.32540387 -0.10798484 -0.18020281 -0.99599594 -0.18422616\n",
      "  0.99047387  0.84186697 -0.99797875  0.5521182 ]\n",
      "input_tensor[ei]\n",
      "[1055]\n",
      "encoder_hidden\n",
      "[-0.21167088 -0.32540387 -0.10798484 -0.18020281 -0.99599594 -0.18422616\n",
      "  0.99047387  0.84186697 -0.99797875  0.5521182 ]\n",
      "encoder_output\n",
      "[ 0.26661003 -0.8637945  -0.15634519  0.24812824  0.9228532   0.88579684\n",
      "  0.99161464 -0.0889011  -0.7824618  -0.9390972 ]\n",
      "encoder_hidden\n",
      "[ 0.26661003 -0.8637945  -0.15634519  0.24812824  0.9228532   0.88579684\n",
      "  0.99161464 -0.0889011  -0.7824618  -0.9390972 ]\n",
      "encoder_outputs[ei]\n",
      "[ 0.26661003 -0.8637945  -0.15634519  0.24812824  0.9228532   0.88579684\n",
      "  0.99161464 -0.0889011  -0.7824618  -0.9390972 ]\n",
      "input_tensor[ei]\n",
      "[2112]\n",
      "encoder_hidden\n",
      "[ 0.26661003 -0.8637945  -0.15634519  0.24812824  0.9228532   0.88579684\n",
      "  0.99161464 -0.0889011  -0.7824618  -0.9390972 ]\n",
      "encoder_output\n",
      "[ 0.7347546  -0.18032753 -0.5127904   0.47473842  0.9994609   0.45442826\n",
      " -0.69578403  0.00690638  0.75051296 -0.9603093 ]\n",
      "encoder_hidden\n",
      "[ 0.7347546  -0.18032753 -0.5127904   0.47473842  0.9994609   0.45442826\n",
      " -0.69578403  0.00690638  0.75051296 -0.9603093 ]\n",
      "encoder_outputs[ei]\n",
      "[ 0.7347546  -0.18032753 -0.5127904   0.47473842  0.9994609   0.45442826\n",
      " -0.69578403  0.00690638  0.75051296 -0.9603093 ]\n",
      "input_tensor[ei]\n",
      "[4]\n",
      "encoder_hidden\n",
      "[ 0.7347546  -0.18032753 -0.5127904   0.47473842  0.9994609   0.45442826\n",
      " -0.69578403  0.00690638  0.75051296 -0.9603093 ]\n",
      "encoder_output\n",
      "[ 0.7048228  -0.35540295 -0.5181151   0.4730705   0.9973961   0.9697012\n",
      " -0.6953768   0.09791481  0.75057423 -0.9603448 ]\n",
      "encoder_hidden\n",
      "[ 0.7048228  -0.35540295 -0.5181151   0.4730705   0.9973961   0.9697012\n",
      " -0.6953768   0.09791481  0.75057423 -0.9603448 ]\n",
      "encoder_outputs[ei]\n",
      "[ 0.7048228  -0.35540295 -0.5181151   0.4730705   0.9973961   0.9697012\n",
      " -0.6953768   0.09791481  0.75057423 -0.9603448 ]\n",
      "input_tensor[ei]\n",
      "[1]\n",
      "encoder_hidden\n",
      "[ 0.7048228  -0.35540295 -0.5181151   0.4730705   0.9973961   0.9697012\n",
      " -0.6953768   0.09791481  0.75057423 -0.9603448 ]\n",
      "encoder_output\n",
      "[ 0.68565696 -0.46851754  0.9538388   0.47107196  0.99638045  0.53442925\n",
      " -0.69535494  0.6525604   0.7505494  -0.9603598 ]\n",
      "encoder_hidden\n",
      "[ 0.68565696 -0.46851754  0.9538388   0.47107196  0.99638045  0.53442925\n",
      " -0.69535494  0.6525604   0.7505494  -0.9603598 ]\n",
      "encoder_outputs[ei]\n",
      "[ 0.68565696 -0.46851754  0.9538388   0.47107196  0.99638045  0.53442925\n",
      " -0.69535494  0.6525604   0.7505494  -0.9603598 ]\n",
      "decoder_input\n",
      "[0]\n",
      "decoder_hidden\n",
      "[ 0.68565696 -0.46851754  0.9538388   0.47107196  0.99638045  0.53442925\n",
      " -0.69535494  0.6525604   0.7505494  -0.9603598 ]\n",
      "decoder_output\n",
      "[-1.4958190e+01 -1.4434786e+01 -7.8706741e-03 -1.2068974e+01\n",
      " -1.7306103e+01 -1.5080862e+01 -1.5886658e+01 -1.1397622e+01\n",
      " -1.5455456e+01 -1.2844902e+01]\n",
      "decoder_hidden\n",
      "[ 0.66719955 -0.6878231   0.94193554  0.45395952  0.99636775  0.99993414\n",
      " -0.69534445  0.9986683   0.7505207  -0.9603566 ]\n",
      "decoder_attention\n",
      "[1.5862166e-06 9.9997950e-01 4.6033233e-06 1.3334685e-05 4.3015220e-07\n",
      " 1.4788532e-10 3.8248746e-09 3.8654761e-07 3.4495024e-08 3.6299230e-08]\n",
      "decoder_attentions[di]\n",
      "[1.5862166e-06 9.9997950e-01 4.6033233e-06 1.3334685e-05 4.3015220e-07\n",
      " 1.4788532e-10 3.8248746e-09 3.8654761e-07 3.4495024e-08 3.6299230e-08]\n",
      "topv\n",
      "[-0.00787067]\n",
      "topi\n",
      "[2]\n",
      "output_lang.index2word[topi.item()]\n",
      "ich\n",
      "decoder_input\n",
      "2\n",
      "decoder_output\n",
      "[-10.69099    -14.500459   -10.804659    -0.61434174 -10.109966\n",
      " -13.324387   -15.98127    -14.024138    -9.61228    -12.174251  ]\n",
      "decoder_hidden\n",
      "[ 0.38267195 -0.96802974 -0.5028183  -0.5269852   0.9957478   0.79653734\n",
      " -0.69126797  0.99786437  0.74670005 -0.9567062 ]\n",
      "decoder_attention\n",
      "[7.9765135e-07 1.0440693e-03 4.9942769e-06 9.9698263e-01 1.1985384e-06\n",
      " 1.9620820e-03 6.9729805e-11 2.2463596e-06 2.8926206e-09 1.9527399e-06]\n",
      "decoder_attentions[di]\n",
      "[7.9765135e-07 1.0440693e-03 4.9942769e-06 9.9698263e-01 1.1985384e-06\n",
      " 1.9620820e-03 6.9729805e-11 2.2463596e-06 2.8926206e-09 1.9527399e-06]\n",
      "topv\n",
      "[-0.61434174]\n",
      "topi\n",
      "[3]\n",
      "output_lang.index2word[topi.item()]\n",
      "bin\n",
      "decoder_input\n",
      "3\n",
      "decoder_output\n",
      "[-10.152562  -11.136599   -6.402135   -8.554128   -8.3689575 -10.028683\n",
      " -11.225451   -5.830781  -12.50977    -9.091963 ]\n",
      "decoder_hidden\n",
      "[-0.07916212 -0.9331608  -0.623555    0.6202301   0.9948834   0.9969403\n",
      " -0.68992275  0.9999866   0.742701   -0.9549435 ]\n",
      "decoder_attention\n",
      "[4.8215248e-10 6.5864638e-09 1.3856234e-09 8.8981478e-10 1.0000000e+00\n",
      " 1.1301942e-10 7.2930875e-15 1.3134203e-11 1.2773990e-10 1.0252377e-09]\n",
      "decoder_attentions[di]\n",
      "[4.8215248e-10 6.5864638e-09 1.3856234e-09 8.8981478e-10 1.0000000e+00\n",
      " 1.1301942e-10 7.2930875e-15 1.3134203e-11 1.2773990e-10 1.0252377e-09]\n",
      "topv\n",
      "[-1.0356798]\n",
      "topi\n",
      "[143]\n",
      "output_lang.index2word[topi.item()]\n",
      "gerade\n",
      "decoder_input\n",
      "143\n",
      "decoder_output\n",
      "[-11.555027  -10.62591   -10.37199   -11.965808   -5.9794197 -10.431119\n",
      "  -9.830104   -9.508772  -13.736942  -11.487545 ]\n",
      "decoder_hidden\n",
      "[-0.48507953 -0.98673236 -0.98073834  0.9977961   0.99479425  0.998711\n",
      " -0.6898326  -0.9268922   0.73596656 -0.9227379 ]\n",
      "decoder_attention\n",
      "[2.7633274e-07 4.1562548e-06 6.1484508e-07 2.1042815e-08 9.4149530e-01\n",
      " 5.8499563e-02 3.5079053e-09 4.6829980e-09 4.8872845e-08 6.4749095e-08]\n",
      "decoder_attentions[di]\n",
      "[2.7633274e-07 4.1562548e-06 6.1484508e-07 2.1042815e-08 9.4149530e-01\n",
      " 5.8499563e-02 3.5079053e-09 4.6829980e-09 4.8872845e-08 6.4749095e-08]\n",
      "topv\n",
      "[-0.15467644]\n",
      "topi\n",
      "[1071]\n",
      "output_lang.index2word[topi.item()]\n",
      "und\n",
      "decoder_input\n",
      "1071\n",
      "decoder_output\n",
      "[ -9.781379   -7.5690365  -5.1050553  -9.8908205  -7.951061  -11.435212\n",
      "  -6.8649044  -6.162785  -11.583005   -7.252163 ]\n",
      "decoder_hidden\n",
      "[ 0.74511576 -0.9992078   0.98328483  0.98995996  0.9943657   0.99892807\n",
      " -0.6874232  -0.42932504  0.6803015  -0.31098145]\n",
      "decoder_attention\n",
      "[3.3460051e-12 2.5622534e-12 2.9969378e-12 6.7171346e-14 2.2197568e-15\n",
      " 1.0000000e+00 4.6111879e-09 6.0469728e-13 6.0855622e-16 8.1590664e-13]\n",
      "decoder_attentions[di]\n",
      "[3.3460051e-12 2.5622534e-12 2.9969378e-12 6.7171346e-14 2.2197568e-15\n",
      " 1.0000000e+00 4.6111879e-09 6.0469728e-13 6.0855622e-16 8.1590664e-13]\n",
      "topv\n",
      "[-1.7596264]\n",
      "topi\n",
      "[1071]\n",
      "output_lang.index2word[topi.item()]\n",
      "und\n",
      "decoder_input\n",
      "1071\n",
      "decoder_output\n",
      "[ -9.747324   -3.9865332  -4.6716924  -8.848644   -8.810793  -14.123427\n",
      "  -4.1295853  -6.3879414  -9.110932   -6.4059525]\n",
      "decoder_hidden\n",
      "[ 0.84210485  0.14622794  0.9996276  -0.7850257   0.99415886 -0.6454735\n",
      " -0.68418336  0.36709356  0.29518205 -0.02490562]\n",
      "decoder_attention\n",
      "[3.5736630e-08 1.1026779e-07 6.5440133e-08 1.2132846e-09 1.8320408e-14\n",
      " 9.9812567e-02 9.0018702e-01 8.2040714e-08 3.0191353e-11 2.2042036e-08]\n",
      "decoder_attentions[di]\n",
      "[3.5736630e-08 1.1026779e-07 6.5440133e-08 1.2132846e-09 1.8320408e-14\n",
      " 9.9812567e-02 9.0018702e-01 8.2040714e-08 3.0191353e-11 2.2042036e-08]\n",
      "topv\n",
      "[-2.1702971]\n",
      "topi\n",
      "[2184]\n",
      "output_lang.index2word[topi.item()]\n",
      "maria\n",
      "decoder_input\n",
      "2184\n",
      "decoder_output\n",
      "[-11.215955   -1.8837824  -9.216207  -13.43902    -9.823517  -12.8309\n",
      "  -0.4560318 -10.951237  -11.291017  -10.339548 ]\n",
      "decoder_hidden\n",
      "[-0.04083025  0.9725159   0.98539263  0.418994    0.9941632  -0.9893248\n",
      " -0.66829723  0.47362202 -0.07066983  0.15971702]\n",
      "decoder_attention\n",
      "[3.4028340e-05 4.5242313e-08 3.2136081e-06 4.2616083e-08 2.9852951e-09\n",
      " 9.6537378e-06 9.9656785e-01 3.3211356e-03 1.6878964e-06 6.2256062e-05]\n",
      "decoder_attentions[di]\n",
      "[3.4028340e-05 4.5242313e-08 3.2136081e-06 4.2616083e-08 2.9852951e-09\n",
      " 9.6537378e-06 9.9656785e-01 3.3211356e-03 1.6878964e-06 6.2256062e-05]\n",
      "topv\n",
      "[-0.4560318]\n",
      "topi\n",
      "[6]\n",
      "output_lang.index2word[topi.item()]\n",
      ".\n",
      "decoder_input\n",
      "6\n",
      "decoder_output\n",
      "[-14.596032    -0.04238129 -12.425599   -15.2241335  -13.869432\n",
      " -12.162754    -3.346466   -13.198466   -14.116194   -13.788697  ]\n",
      "decoder_hidden\n",
      "[-0.24465144  0.9759674   0.3631485  -0.89880997  0.98495865 -0.99820876\n",
      " -0.54697955  0.5030216   0.49279022  0.33164233]\n",
      "decoder_attention\n",
      "[7.9448067e-04 1.6596499e-05 1.3141619e-04 3.9276713e-08 4.2313012e-08\n",
      " 1.6625796e-06 9.7726667e-01 5.2085827e-04 5.2822568e-04 2.0739930e-02]\n",
      "decoder_attentions[di]\n",
      "[7.9448067e-04 1.6596499e-05 1.3141619e-04 3.9276713e-08 4.2313012e-08\n",
      " 1.6625796e-06 9.7726667e-01 5.2085827e-04 5.2822568e-04 2.0739930e-02]\n",
      "topv\n",
      "[-0.04238129]\n",
      "topi\n",
      "[1]\n",
      "decoded_words\n",
      "['ich', 'bin', 'gerade', 'und', 'und', 'maria', '.', '<EOS>']\n",
      "input_tensor\n",
      "[  2   3  17 319 170 782   4   1]\n",
      "encoder_hidden\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "encoder_outputs\n",
      "[-0.10922617  0.6067832   0.6439681   0.10918707  0.15006319  0.60468507\n",
      " -0.83865154 -0.8165876  -0.08856022 -0.17544824]\n",
      "input_tensor[ei]\n",
      "[2]\n",
      "encoder_hidden\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "encoder_output\n",
      "[-0.10922617  0.6067832   0.6439681   0.10918707  0.15006319  0.60468507\n",
      " -0.83865154 -0.8165876  -0.08856022 -0.17544824]\n",
      "encoder_hidden\n",
      "[-0.10922617  0.6067832   0.6439681   0.10918707  0.15006319  0.60468507\n",
      " -0.83865154 -0.8165876  -0.08856022 -0.17544824]\n",
      "encoder_outputs[ei]\n",
      "[-0.10922617  0.6067832   0.6439681   0.10918707  0.15006319  0.60468507\n",
      " -0.83865154 -0.8165876  -0.08856022 -0.17544824]\n",
      "input_tensor[ei]\n",
      "[3]\n",
      "encoder_hidden\n",
      "[-0.10922617  0.6067832   0.6439681   0.10918707  0.15006319  0.60468507\n",
      " -0.83865154 -0.8165876  -0.08856022 -0.17544824]\n",
      "encoder_output\n",
      "[-0.83710116  0.66214955  0.584383    0.7208886  -0.9831236  -0.8309508\n",
      "  0.68693846  0.53419995 -0.99925417  0.78245384]\n",
      "encoder_hidden\n",
      "[-0.83710116  0.66214955  0.584383    0.7208886  -0.9831236  -0.8309508\n",
      "  0.68693846  0.53419995 -0.99925417  0.78245384]\n",
      "encoder_outputs[ei]\n",
      "[-0.83710116  0.66214955  0.584383    0.7208886  -0.9831236  -0.8309508\n",
      "  0.68693846  0.53419995 -0.99925417  0.78245384]\n",
      "input_tensor[ei]\n",
      "[17]\n",
      "encoder_hidden\n",
      "[-0.83710116  0.66214955  0.584383    0.7208886  -0.9831236  -0.8309508\n",
      "  0.68693846  0.53419995 -0.99925417  0.78245384]\n",
      "encoder_output\n",
      "[ 0.9185466   0.8931822   0.9842643   0.35537905  0.85176635 -0.68210363\n",
      " -0.9566606  -0.2203387   0.9522077   0.57743573]\n",
      "encoder_hidden\n",
      "[ 0.9185466   0.8931822   0.9842643   0.35537905  0.85176635 -0.68210363\n",
      " -0.9566606  -0.2203387   0.9522077   0.57743573]\n",
      "encoder_outputs[ei]\n",
      "[ 0.9185466   0.8931822   0.9842643   0.35537905  0.85176635 -0.68210363\n",
      " -0.9566606  -0.2203387   0.9522077   0.57743573]\n",
      "input_tensor[ei]\n",
      "[319]\n",
      "encoder_hidden\n",
      "[ 0.9185466   0.8931822   0.9842643   0.35537905  0.85176635 -0.68210363\n",
      " -0.9566606  -0.2203387   0.9522077   0.57743573]\n",
      "encoder_output\n",
      "[ 0.9035351  -0.9206548  -0.93824613 -0.4269206   0.9703231  -0.65633476\n",
      " -0.91189754  0.9681498   0.9979394   0.9965694 ]\n",
      "encoder_hidden\n",
      "[ 0.9035351  -0.9206548  -0.93824613 -0.4269206   0.9703231  -0.65633476\n",
      " -0.91189754  0.9681498   0.9979394   0.9965694 ]\n",
      "encoder_outputs[ei]\n",
      "[ 0.9035351  -0.9206548  -0.93824613 -0.4269206   0.9703231  -0.65633476\n",
      " -0.91189754  0.9681498   0.9979394   0.9965694 ]\n",
      "input_tensor[ei]\n",
      "[170]\n",
      "encoder_hidden\n",
      "[ 0.9035351  -0.9206548  -0.93824613 -0.4269206   0.9703231  -0.65633476\n",
      " -0.91189754  0.9681498   0.9979394   0.9965694 ]\n",
      "encoder_output\n",
      "[ 0.96162903 -0.7828545  -0.9555132  -0.7140905   0.9923921  -0.70022047\n",
      "  0.59549457  0.8496238  -0.97383994  0.9760102 ]\n",
      "encoder_hidden\n",
      "[ 0.96162903 -0.7828545  -0.9555132  -0.7140905   0.9923921  -0.70022047\n",
      "  0.59549457  0.8496238  -0.97383994  0.9760102 ]\n",
      "encoder_outputs[ei]\n",
      "[ 0.96162903 -0.7828545  -0.9555132  -0.7140905   0.9923921  -0.70022047\n",
      "  0.59549457  0.8496238  -0.97383994  0.9760102 ]\n",
      "input_tensor[ei]\n",
      "[782]\n",
      "encoder_hidden\n",
      "[ 0.96162903 -0.7828545  -0.9555132  -0.7140905   0.9923921  -0.70022047\n",
      "  0.59549457  0.8496238  -0.97383994  0.9760102 ]\n",
      "encoder_output\n",
      "[ 0.78997624 -0.79539794  0.13517398 -0.556696    0.22818744  0.13522226\n",
      "  0.978749    0.95017064 -0.9945963   0.9757116 ]\n",
      "encoder_hidden\n",
      "[ 0.78997624 -0.79539794  0.13517398 -0.556696    0.22818744  0.13522226\n",
      "  0.978749    0.95017064 -0.9945963   0.9757116 ]\n",
      "encoder_outputs[ei]\n",
      "[ 0.78997624 -0.79539794  0.13517398 -0.556696    0.22818744  0.13522226\n",
      "  0.978749    0.95017064 -0.9945963   0.9757116 ]\n",
      "input_tensor[ei]\n",
      "[4]\n",
      "encoder_hidden\n",
      "[ 0.78997624 -0.79539794  0.13517398 -0.556696    0.22818744  0.13522226\n",
      "  0.978749    0.95017064 -0.9945963   0.9757116 ]\n",
      "encoder_output\n",
      "[ 0.7163522  -0.8447215   0.09710711 -0.5550552   0.22696364  0.85867155\n",
      "  0.97793657  0.9546464  -0.99368757  0.9737528 ]\n",
      "encoder_hidden\n",
      "[ 0.7163522  -0.8447215   0.09710711 -0.5550552   0.22696364  0.85867155\n",
      "  0.97793657  0.9546464  -0.99368757  0.9737528 ]\n",
      "encoder_outputs[ei]\n",
      "[ 0.7163522  -0.8447215   0.09710711 -0.5550552   0.22696364  0.85867155\n",
      "  0.97793657  0.9546464  -0.99368757  0.9737528 ]\n",
      "input_tensor[ei]\n",
      "[1]\n",
      "encoder_hidden\n",
      "[ 0.7163522  -0.8447215   0.09710711 -0.5550552   0.22696364  0.85867155\n",
      "  0.97793657  0.9546464  -0.99368757  0.9737528 ]\n",
      "encoder_output\n",
      "[ 0.68788344 -0.88463837  0.9797069  -0.55651206  0.2255649   0.7417621\n",
      "  0.97746044  0.8920448  -0.9936784   0.9724561 ]\n",
      "encoder_hidden\n",
      "[ 0.68788344 -0.88463837  0.9797069  -0.55651206  0.2255649   0.7417621\n",
      "  0.97746044  0.8920448  -0.9936784   0.9724561 ]\n",
      "encoder_outputs[ei]\n",
      "[ 0.68788344 -0.88463837  0.9797069  -0.55651206  0.2255649   0.7417621\n",
      "  0.97746044  0.8920448  -0.9936784   0.9724561 ]\n",
      "decoder_input\n",
      "[0]\n",
      "decoder_hidden\n",
      "[ 0.68788344 -0.88463837  0.9797069  -0.55651206  0.2255649   0.7417621\n",
      "  0.97746044  0.8920448  -0.9936784   0.9724561 ]\n",
      "decoder_output\n",
      "[-1.6380266e+01 -1.4273677e+01 -4.3029785e-03 -7.6650505e+00\n",
      " -1.8190315e+01 -1.6597532e+01 -1.3543566e+01 -8.7287693e+00\n",
      " -1.2657492e+01 -1.1720844e+01]\n",
      "decoder_hidden\n",
      "[ 0.6708527  -0.96765774  0.9560605  -0.56415606  0.22556618  0.99998814\n",
      "  0.9774605   0.99992204 -0.99367654  0.9724549 ]\n",
      "decoder_attention\n",
      "[2.0129335e-06 9.9998546e-01 6.8129466e-06 4.2333627e-06 2.4187749e-08\n",
      " 1.5329930e-11 9.3184331e-09 1.1759749e-06 1.6857155e-07 1.0867794e-07]\n",
      "decoder_attentions[di]\n",
      "[2.0129335e-06 9.9998546e-01 6.8129466e-06 4.2333627e-06 2.4187749e-08\n",
      " 1.5329930e-11 9.3184331e-09 1.1759749e-06 1.6857155e-07 1.0867794e-07]\n",
      "topv\n",
      "[-0.00430298]\n",
      "topi\n",
      "[2]\n",
      "output_lang.index2word[topi.item()]\n",
      "ich\n",
      "decoder_input\n",
      "2\n",
      "decoder_output\n",
      "[-1.8254833e+01 -1.8831400e+01 -1.9991947e+01 -9.1934204e-04\n",
      " -1.6774403e+01 -2.0773739e+01 -1.8602226e+01 -1.8723488e+01\n",
      " -1.3622737e+01 -1.8158960e+01]\n",
      "decoder_hidden\n",
      "[ 0.6051501  -0.99996424 -0.8449916  -0.9875377   0.22556885  0.49874648\n",
      "  0.9774607   0.9999857  -0.9936769   0.9724552 ]\n",
      "decoder_attention\n",
      "[8.5608906e-07 7.0638373e-04 8.6216314e-06 9.9896252e-01 7.5242887e-08\n",
      " 3.1374881e-04 1.7243523e-10 1.3836283e-06 1.5946087e-08 6.2207696e-06]\n",
      "decoder_attentions[di]\n",
      "[8.5608906e-07 7.0638373e-04 8.6216314e-06 9.9896252e-01 7.5242887e-08\n",
      " 3.1374881e-04 1.7243523e-10 1.3836283e-06 1.5946087e-08 6.2207696e-06]\n",
      "topv\n",
      "[-0.00091934]\n",
      "topi\n",
      "[3]\n",
      "output_lang.index2word[topi.item()]\n",
      "bin\n",
      "decoder_input\n",
      "3\n",
      "decoder_output\n",
      "[-13.553711 -13.038663  -9.701617  -7.372038 -13.273033 -16.567732\n",
      " -12.252631  -9.019289 -13.619722 -12.036814]\n",
      "decoder_hidden\n",
      "[ 0.3808124  -0.9999755  -0.84610194 -0.99558824  0.22556329  0.9889668\n",
      "  0.9774609   0.99983287 -0.9936769   0.9724562 ]\n",
      "decoder_attention\n",
      "[2.0876347e-09 9.8440420e-09 4.3356785e-09 3.6606421e-10 1.0000000e+00\n",
      " 5.6514963e-11 5.0915733e-14 2.0980202e-10 1.2948193e-08 8.9588124e-09]\n",
      "decoder_attentions[di]\n",
      "[2.0876347e-09 9.8440420e-09 4.3356785e-09 3.6606421e-10 1.0000000e+00\n",
      " 5.6514963e-11 5.0915733e-14 2.0980202e-10 1.2948193e-08 8.9588124e-09]\n",
      "topv\n",
      "[-0.13888931]\n",
      "topi\n",
      "[70]\n",
      "output_lang.index2word[topi.item()]\n",
      "ein\n",
      "decoder_input\n",
      "70\n",
      "decoder_output\n",
      "[-13.998359  -12.201855  -13.3565855 -10.344261  -12.259649  -15.59634\n",
      "  -9.588631  -12.807681  -17.20951   -14.697985 ]\n",
      "decoder_hidden\n",
      "[-0.7820545  -0.99999565 -0.9544443   0.9991038   0.22554517  0.99846697\n",
      "  0.9774172  -0.98842466 -0.9936767   0.97255725]\n",
      "decoder_attention\n",
      "[2.2485734e-10 4.9521578e-11 1.0092044e-09 5.9701000e-09 9.9994493e-01\n",
      " 5.5031986e-05 2.0116021e-14 2.0732647e-11 2.5280062e-12 3.5122953e-11]\n",
      "decoder_attentions[di]\n",
      "[2.2485734e-10 4.9521578e-11 1.0092044e-09 5.9701000e-09 9.9994493e-01\n",
      " 5.5031986e-05 2.0116021e-14 2.0732647e-11 2.5280062e-12 3.5122953e-11]\n",
      "topv\n",
      "[-0.03139591]\n",
      "topi\n",
      "[416]\n",
      "output_lang.index2word[topi.item()]\n",
      "sehr\n",
      "decoder_input\n",
      "416\n",
      "decoder_output\n",
      "[-10.302682   -7.176304  -10.435495   -9.563489   -9.528356  -11.611767\n",
      "  -4.5876904 -14.402931  -14.101475  -12.111143 ]\n",
      "decoder_hidden\n",
      "[ 0.9405039  -0.99996877 -0.4219906   0.9624779   0.22582066  0.7260368\n",
      "  0.97634804 -0.991371   -0.99367595  0.98223734]\n",
      "decoder_attention\n",
      "[1.52097943e-08 5.27337507e-09 1.46536987e-08 7.80746934e-09\n",
      " 5.12274994e-07 9.99999285e-01 1.12097645e-07 2.42125342e-09\n",
      " 1.81964399e-09 3.21702642e-09]\n",
      "decoder_attentions[di]\n",
      "[1.52097943e-08 5.27337507e-09 1.46536987e-08 7.80746934e-09\n",
      " 5.12274994e-07 9.99999285e-01 1.12097645e-07 2.42125342e-09\n",
      " 1.81964399e-09 3.21702642e-09]\n",
      "topv\n",
      "[-0.60725594]\n",
      "topi\n",
      "[3143]\n",
      "output_lang.index2word[topi.item()]\n",
      "vorsichtiger\n",
      "decoder_input\n",
      "3143\n",
      "decoder_output\n",
      "[-11.355477   -6.086423  -11.970604   -9.181911  -10.249422  -16.29137\n",
      "  -2.1476383 -14.789521  -13.112524  -13.206244 ]\n",
      "decoder_hidden\n",
      "[ 0.26010507 -0.99999714  0.12471753 -0.5822674   0.22608781 -0.9969515\n",
      "  0.97614056 -0.99662286 -0.9943467   0.98382634]\n",
      "decoder_attention\n",
      "[3.9424489e-07 1.5565360e-05 6.3625924e-07 2.4806046e-09 7.6788288e-13\n",
      " 7.9680307e-05 9.9990320e-01 9.0021182e-09 1.3431517e-07 4.0715776e-07]\n",
      "decoder_attentions[di]\n",
      "[3.9424489e-07 1.5565360e-05 6.3625924e-07 2.4806046e-09 7.6788288e-13\n",
      " 7.9680307e-05 9.9990320e-01 9.0021182e-09 1.3431517e-07 4.0715776e-07]\n",
      "topv\n",
      "[-0.34108734]\n",
      "topi\n",
      "[1100]\n",
      "output_lang.index2word[topi.item()]\n",
      "fahrer\n",
      "decoder_input\n",
      "1100\n",
      "decoder_output\n",
      "[-13.0942745   -5.4657235  -14.246742   -10.492389   -13.944094\n",
      " -17.389282    -0.06016922 -14.661139   -12.924925   -13.666477  ]\n",
      "decoder_hidden\n",
      "[-0.6690201   0.5549519   0.31839582 -0.9948405   0.22869644 -0.999916\n",
      "  0.9728734  -0.930317   -0.96542877  0.9832204 ]\n",
      "decoder_attention\n",
      "[1.8097135e-03 1.6501147e-04 1.2195978e-03 3.2371611e-06 6.3977311e-08\n",
      " 7.4599229e-06 9.0884990e-01 3.0649470e-02 1.8205456e-02 3.9090116e-02]\n",
      "decoder_attentions[di]\n",
      "[1.8097135e-03 1.6501147e-04 1.2195978e-03 3.2371611e-06 6.3977311e-08\n",
      " 7.4599229e-06 9.0884990e-01 3.0649470e-02 1.8205456e-02 3.9090116e-02]\n",
      "topv\n",
      "[-0.06016922]\n",
      "topi\n",
      "[6]\n",
      "output_lang.index2word[topi.item()]\n",
      ".\n",
      "decoder_input\n",
      "6\n",
      "decoder_output\n",
      "[-16.214745    -0.02602386 -16.67698    -15.367795   -17.484116\n",
      " -16.054596    -3.722659   -15.142237   -16.243908   -15.637856  ]\n",
      "decoder_hidden\n",
      "[-0.78733605  0.63874495 -0.12429738 -0.9993871   0.2532395  -0.9999839\n",
      "  0.90112406 -0.8534403  -0.4485176   0.9822978 ]\n",
      "decoder_attention\n",
      "[2.0709621e-02 2.8482222e-03 4.6009622e-03 2.5521826e-05 1.9996094e-06\n",
      " 2.4483782e-07 5.4761227e-02 2.5563240e-03 2.0674299e-01 7.0775282e-01]\n",
      "decoder_attentions[di]\n",
      "[2.0709621e-02 2.8482222e-03 4.6009622e-03 2.5521826e-05 1.9996094e-06\n",
      " 2.4483782e-07 5.4761227e-02 2.5563240e-03 2.0674299e-01 7.0775282e-01]\n",
      "topv\n",
      "[-0.02602386]\n",
      "topi\n",
      "[1]\n",
      "decoded_words\n",
      "['ich', 'bin', 'ein', 'sehr', 'vorsichtiger', 'fahrer', '.', '<EOS>']\n",
      "input_tensor\n",
      "[   2    3  104  814 1055 2112    4    1]\n",
      "encoder_hidden\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "encoder_outputs\n",
      "[-0.10922617  0.6067832   0.6439681   0.10918707  0.15006319  0.60468507\n",
      " -0.83865154 -0.8165876  -0.08856022 -0.17544824]\n",
      "input_tensor[ei]\n",
      "[2]\n",
      "encoder_hidden\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      "encoder_output\n",
      "[-0.10922617  0.6067832   0.6439681   0.10918707  0.15006319  0.60468507\n",
      " -0.83865154 -0.8165876  -0.08856022 -0.17544824]\n",
      "encoder_hidden\n",
      "[-0.10922617  0.6067832   0.6439681   0.10918707  0.15006319  0.60468507\n",
      " -0.83865154 -0.8165876  -0.08856022 -0.17544824]\n",
      "encoder_outputs[ei]\n",
      "[-0.10922617  0.6067832   0.6439681   0.10918707  0.15006319  0.60468507\n",
      " -0.83865154 -0.8165876  -0.08856022 -0.17544824]\n",
      "input_tensor[ei]\n",
      "[3]\n",
      "encoder_hidden\n",
      "[-0.10922617  0.6067832   0.6439681   0.10918707  0.15006319  0.60468507\n",
      " -0.83865154 -0.8165876  -0.08856022 -0.17544824]\n",
      "encoder_output\n",
      "[-0.83710116  0.66214955  0.584383    0.7208886  -0.9831236  -0.8309508\n",
      "  0.68693846  0.53419995 -0.99925417  0.78245384]\n",
      "encoder_hidden\n",
      "[-0.83710116  0.66214955  0.584383    0.7208886  -0.9831236  -0.8309508\n",
      "  0.68693846  0.53419995 -0.99925417  0.78245384]\n",
      "encoder_outputs[ei]\n",
      "[-0.83710116  0.66214955  0.584383    0.7208886  -0.9831236  -0.8309508\n",
      "  0.68693846  0.53419995 -0.99925417  0.78245384]\n",
      "input_tensor[ei]\n",
      "[104]\n",
      "encoder_hidden\n",
      "[-0.83710116  0.66214955  0.584383    0.7208886  -0.9831236  -0.8309508\n",
      "  0.68693846  0.53419995 -0.99925417  0.78245384]\n",
      "encoder_output\n",
      "[ 0.52780247 -0.26336068  0.5967597   0.77204883  0.98304886 -0.9308181\n",
      " -0.5888175  -0.39611197 -0.91029817  0.53893536]\n",
      "encoder_hidden\n",
      "[ 0.52780247 -0.26336068  0.5967597   0.77204883  0.98304886 -0.9308181\n",
      " -0.5888175  -0.39611197 -0.91029817  0.53893536]\n",
      "encoder_outputs[ei]\n",
      "[ 0.52780247 -0.26336068  0.5967597   0.77204883  0.98304886 -0.9308181\n",
      " -0.5888175  -0.39611197 -0.91029817  0.53893536]\n",
      "input_tensor[ei]\n",
      "[814]\n",
      "encoder_hidden\n",
      "[ 0.52780247 -0.26336068  0.5967597   0.77204883  0.98304886 -0.9308181\n",
      " -0.5888175  -0.39611197 -0.91029817  0.53893536]\n",
      "encoder_output\n",
      "[-0.21167088 -0.32540387 -0.10798484 -0.18020281 -0.99599594 -0.18422616\n",
      "  0.99047387  0.84186697 -0.99797875  0.5521182 ]\n",
      "encoder_hidden\n",
      "[-0.21167088 -0.32540387 -0.10798484 -0.18020281 -0.99599594 -0.18422616\n",
      "  0.99047387  0.84186697 -0.99797875  0.5521182 ]\n",
      "encoder_outputs[ei]\n",
      "[-0.21167088 -0.32540387 -0.10798484 -0.18020281 -0.99599594 -0.18422616\n",
      "  0.99047387  0.84186697 -0.99797875  0.5521182 ]\n",
      "input_tensor[ei]\n",
      "[1055]\n",
      "encoder_hidden\n",
      "[-0.21167088 -0.32540387 -0.10798484 -0.18020281 -0.99599594 -0.18422616\n",
      "  0.99047387  0.84186697 -0.99797875  0.5521182 ]\n",
      "encoder_output\n",
      "[ 0.26661003 -0.8637945  -0.15634519  0.24812824  0.9228532   0.88579684\n",
      "  0.99161464 -0.0889011  -0.7824618  -0.9390972 ]\n",
      "encoder_hidden\n",
      "[ 0.26661003 -0.8637945  -0.15634519  0.24812824  0.9228532   0.88579684\n",
      "  0.99161464 -0.0889011  -0.7824618  -0.9390972 ]\n",
      "encoder_outputs[ei]\n",
      "[ 0.26661003 -0.8637945  -0.15634519  0.24812824  0.9228532   0.88579684\n",
      "  0.99161464 -0.0889011  -0.7824618  -0.9390972 ]\n",
      "input_tensor[ei]\n",
      "[2112]\n",
      "encoder_hidden\n",
      "[ 0.26661003 -0.8637945  -0.15634519  0.24812824  0.9228532   0.88579684\n",
      "  0.99161464 -0.0889011  -0.7824618  -0.9390972 ]\n",
      "encoder_output\n",
      "[ 0.7347546  -0.18032753 -0.5127904   0.47473842  0.9994609   0.45442826\n",
      " -0.69578403  0.00690638  0.75051296 -0.9603093 ]\n",
      "encoder_hidden\n",
      "[ 0.7347546  -0.18032753 -0.5127904   0.47473842  0.9994609   0.45442826\n",
      " -0.69578403  0.00690638  0.75051296 -0.9603093 ]\n",
      "encoder_outputs[ei]\n",
      "[ 0.7347546  -0.18032753 -0.5127904   0.47473842  0.9994609   0.45442826\n",
      " -0.69578403  0.00690638  0.75051296 -0.9603093 ]\n",
      "input_tensor[ei]\n",
      "[4]\n",
      "encoder_hidden\n",
      "[ 0.7347546  -0.18032753 -0.5127904   0.47473842  0.9994609   0.45442826\n",
      " -0.69578403  0.00690638  0.75051296 -0.9603093 ]\n",
      "encoder_output\n",
      "[ 0.7048228  -0.35540295 -0.5181151   0.4730705   0.9973961   0.9697012\n",
      " -0.6953768   0.09791481  0.75057423 -0.9603448 ]\n",
      "encoder_hidden\n",
      "[ 0.7048228  -0.35540295 -0.5181151   0.4730705   0.9973961   0.9697012\n",
      " -0.6953768   0.09791481  0.75057423 -0.9603448 ]\n",
      "encoder_outputs[ei]\n",
      "[ 0.7048228  -0.35540295 -0.5181151   0.4730705   0.9973961   0.9697012\n",
      " -0.6953768   0.09791481  0.75057423 -0.9603448 ]\n",
      "input_tensor[ei]\n",
      "[1]\n",
      "encoder_hidden\n",
      "[ 0.7048228  -0.35540295 -0.5181151   0.4730705   0.9973961   0.9697012\n",
      " -0.6953768   0.09791481  0.75057423 -0.9603448 ]\n",
      "encoder_output\n",
      "[ 0.68565696 -0.46851754  0.9538388   0.47107196  0.99638045  0.53442925\n",
      " -0.69535494  0.6525604   0.7505494  -0.9603598 ]\n",
      "encoder_hidden\n",
      "[ 0.68565696 -0.46851754  0.9538388   0.47107196  0.99638045  0.53442925\n",
      " -0.69535494  0.6525604   0.7505494  -0.9603598 ]\n",
      "encoder_outputs[ei]\n",
      "[ 0.68565696 -0.46851754  0.9538388   0.47107196  0.99638045  0.53442925\n",
      " -0.69535494  0.6525604   0.7505494  -0.9603598 ]\n",
      "decoder_input\n",
      "[0]\n",
      "decoder_hidden\n",
      "[ 0.68565696 -0.46851754  0.9538388   0.47107196  0.99638045  0.53442925\n",
      " -0.69535494  0.6525604   0.7505494  -0.9603598 ]\n",
      "decoder_output\n",
      "[-1.49142103e+01 -1.44888525e+01 -8.04233551e-03 -1.20159092e+01\n",
      " -1.72511139e+01 -1.50447340e+01 -1.59043121e+01 -1.13704453e+01\n",
      " -1.54563494e+01 -1.28634958e+01]\n",
      "decoder_hidden\n",
      "[ 0.6760015  -0.64903915  0.9438313   0.4526053   0.996366    0.99992675\n",
      " -0.6953494   0.99881166  0.7505087  -0.9603567 ]\n",
      "decoder_attention\n",
      "[1.7673806e-06 9.9999022e-01 3.6657632e-06 3.2109886e-06 5.4433781e-07\n",
      " 5.3509858e-10 7.4038298e-10 5.1840175e-07 4.8593165e-08 3.4953711e-08]\n",
      "decoder_attentions[di]\n",
      "[1.7673806e-06 9.9999022e-01 3.6657632e-06 3.2109886e-06 5.4433781e-07\n",
      " 5.3509858e-10 7.4038298e-10 5.1840175e-07 4.8593165e-08 3.4953711e-08]\n",
      "topv\n",
      "[-0.00804234]\n",
      "topi\n",
      "[2]\n",
      "output_lang.index2word[topi.item()]\n",
      "ich\n",
      "decoder_input\n",
      "2\n",
      "decoder_output\n",
      "[-10.969773  -14.679537  -11.065954   -0.4854946 -10.262679  -13.315891\n",
      " -16.415443  -14.648816  -10.055664  -12.73436  ]\n",
      "decoder_hidden\n",
      "[ 0.47602588 -0.9320136  -0.52412915 -0.34523308  0.9954381   0.91713905\n",
      " -0.6910631   0.9990163   0.7463942  -0.9567057 ]\n",
      "decoder_attention\n",
      "[6.0071397e-07 6.0360169e-04 4.9024898e-06 9.9885404e-01 3.4206471e-07\n",
      " 5.3322274e-04 1.2398861e-10 1.6046851e-06 2.0062378e-09 1.7879428e-06]\n",
      "decoder_attentions[di]\n",
      "[6.0071397e-07 6.0360169e-04 4.9024898e-06 9.9885404e-01 3.4206471e-07\n",
      " 5.3322274e-04 1.2398861e-10 1.6046851e-06 2.0062378e-09 1.7879428e-06]\n",
      "topv\n",
      "[-0.4854946]\n",
      "topi\n",
      "[3]\n",
      "output_lang.index2word[topi.item()]\n",
      "bin\n",
      "decoder_input\n",
      "3\n",
      "decoder_output\n",
      "[ -9.863782  -10.763502   -6.7490206  -8.546474   -8.601123  -10.075111\n",
      " -11.328457   -6.1428947 -12.702145   -8.955938 ]\n",
      "decoder_hidden\n",
      "[-0.04828435 -0.89708394 -0.568555    0.717577    0.99502844  0.9980476\n",
      " -0.69053143  0.9999959   0.7446426  -0.95623946]\n",
      "decoder_attention\n",
      "[2.8378540e-09 1.8957632e-08 7.6709652e-09 1.3011769e-08 1.0000000e+00\n",
      " 1.5563063e-09 1.6077610e-14 1.1824898e-10 9.9369823e-10 9.6186463e-09]\n",
      "decoder_attentions[di]\n",
      "[2.8378540e-09 1.8957632e-08 7.6709652e-09 1.3011769e-08 1.0000000e+00\n",
      " 1.5563063e-09 1.6077610e-14 1.1824898e-10 9.9369823e-10 9.6186463e-09]\n",
      "topv\n",
      "[-1.2581348]\n",
      "topi\n",
      "[143]\n",
      "output_lang.index2word[topi.item()]\n",
      "gerade\n",
      "decoder_input\n",
      "143\n",
      "decoder_output\n",
      "[-11.840399 -11.506075 -10.555836 -12.630643  -6.12982  -10.640461\n",
      " -10.49016   -9.921433 -14.38563  -12.443251]\n",
      "decoder_hidden\n",
      "[-0.71127987 -0.93286794 -0.98274714  0.9984805   0.99489975  0.999324\n",
      " -0.69043124 -0.5199074   0.73465043 -0.90885365]\n",
      "decoder_attention\n",
      "[1.7217224e-07 7.7112952e-07 2.1052698e-07 2.9834737e-08 9.4794863e-01\n",
      " 5.2050132e-02 5.1880683e-10 5.5539511e-09 2.8224934e-08 3.8175152e-08]\n",
      "decoder_attentions[di]\n",
      "[1.7217224e-07 7.7112952e-07 2.1052698e-07 2.9834737e-08 9.4794863e-01\n",
      " 5.2050132e-02 5.1880683e-10 5.5539511e-09 2.8224934e-08 3.8175152e-08]\n",
      "topv\n",
      "[-0.11724663]\n",
      "topi\n",
      "[1071]\n",
      "output_lang.index2word[topi.item()]\n",
      "und\n",
      "decoder_input\n",
      "1071\n",
      "decoder_output\n",
      "[ -9.886413   -7.5052357  -5.1351614  -9.972297   -8.172732  -11.473795\n",
      "  -7.130171   -6.2805514 -11.5758705  -7.4200497]\n",
      "decoder_hidden\n",
      "[ 0.83364743 -0.99900305  0.98173714  0.9974545   0.99405926  0.9992953\n",
      " -0.6890348  -0.82060593  0.63562465 -0.16418546]\n",
      "decoder_attention\n",
      "[3.0521965e-12 8.1366606e-12 4.2316025e-12 6.3635749e-14 9.8195022e-15\n",
      " 1.0000000e+00 2.0441504e-09 1.3111344e-12 4.5659851e-16 1.0454192e-12]\n",
      "decoder_attentions[di]\n",
      "[3.0521965e-12 8.1366606e-12 4.2316025e-12 6.3635749e-14 9.8195022e-15\n",
      " 1.0000000e+00 2.0441504e-09 1.3111344e-12 4.5659851e-16 1.0454192e-12]\n",
      "topv\n",
      "[-1.7584896]\n",
      "topi\n",
      "[1071]\n",
      "output_lang.index2word[topi.item()]\n",
      "und\n",
      "decoder_input\n",
      "1071\n",
      "decoder_output\n",
      "[ -9.840973   -3.804688   -4.5338497  -9.627275   -8.897713  -13.148808\n",
      "  -3.4629593  -6.107775   -9.607219   -6.6406927]\n",
      "decoder_hidden\n",
      "[ 0.908425    0.76410115  0.999794   -0.8108654   0.99385947 -0.15879923\n",
      " -0.68175346  0.83715606  0.05518895  0.25629652]\n",
      "decoder_attention\n",
      "[4.9275123e-08 4.3589299e-07 7.0637768e-08 2.4288657e-10 1.1872708e-14\n",
      " 2.7347988e-02 9.7265112e-01 3.6748671e-07 7.6522601e-11 2.4541309e-08]\n",
      "decoder_attentions[di]\n",
      "[4.9275123e-08 4.3589299e-07 7.0637768e-08 2.4288657e-10 1.1872708e-14\n",
      " 2.7347988e-02 9.7265112e-01 3.6748671e-07 7.6522601e-11 2.4541309e-08]\n",
      "topv\n",
      "[-2.3381696]\n",
      "topi\n",
      "[2184]\n",
      "output_lang.index2word[topi.item()]\n",
      "maria\n",
      "decoder_input\n",
      "2184\n",
      "decoder_output\n",
      "[-11.4202795   -1.9875412   -9.628626   -13.767653   -10.542679\n",
      " -13.027429    -0.37905693 -10.540081   -11.404757   -10.394635  ]\n",
      "decoder_hidden\n",
      "[-0.05933803  0.99253374  0.9883177   0.07634369  0.9938981  -0.97734773\n",
      " -0.666656    0.8720423  -0.45285317  0.35994452]\n",
      "decoder_attention\n",
      "[2.0181386e-04 3.0000243e-07 2.4350236e-05 4.9957602e-08 2.5303327e-08\n",
      " 6.4618413e-05 9.6179760e-01 3.7195601e-02 4.9132057e-05 6.6644669e-04]\n",
      "decoder_attentions[di]\n",
      "[2.0181386e-04 3.0000243e-07 2.4350236e-05 4.9957602e-08 2.5303327e-08\n",
      " 6.4618413e-05 9.6179760e-01 3.7195601e-02 4.9132057e-05 6.6644669e-04]\n",
      "topv\n",
      "[-0.37905693]\n",
      "topi\n",
      "[6]\n",
      "output_lang.index2word[topi.item()]\n",
      ".\n",
      "decoder_input\n",
      "6\n",
      "decoder_output\n",
      "[-14.601977    -0.03172016 -12.876225   -14.803789   -14.259503\n",
      " -12.288771    -3.678627   -13.482559   -14.430447   -14.038196  ]\n",
      "decoder_hidden\n",
      "[-0.2928869   0.99367505  0.08210087 -0.8745117   0.98379976 -0.9974961\n",
      " -0.5473843   0.8800137   0.4130447   0.46650222]\n",
      "decoder_attention\n",
      "[2.21450278e-03 2.94321417e-05 2.46206822e-04 1.22396330e-07\n",
      " 1.18538644e-07 2.71266140e-06 9.39564347e-01 5.04552794e-04\n",
      " 3.70619027e-03 5.37318364e-02]\n",
      "decoder_attentions[di]\n",
      "[2.21450278e-03 2.94321417e-05 2.46206822e-04 1.22396330e-07\n",
      " 1.18538644e-07 2.71266140e-06 9.39564347e-01 5.04552794e-04\n",
      " 3.70619027e-03 5.37318364e-02]\n",
      "topv\n",
      "[-0.03172016]\n",
      "topi\n",
      "[1]\n",
      "decoded_words\n",
      "['ich', 'bin', 'gerade', 'und', 'und', 'maria', '.', '<EOS>']\n"
     ]
    }
   ],
   "source": [
    "for qitem in evaluate_queue:\n",
    "    print( qitem[0] )    \n",
    "    if isinstance(qitem[1],str):\n",
    "        print( qitem[1] )\n",
    "    elif isinstance(qitem[1],list):\n",
    "        print( qitem[1] )    \n",
    "    else:    \n",
    "        nplist = qitem[1].flatten().detach().numpy()    \n",
    "        if np.ndim( nplist ) == 0:\n",
    "            print(nplist)\n",
    "        else:\n",
    "            print( nplist.flatten()[0:10] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
